{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Fast, accurate and scalable probabilistic data linkage using your choice of SQL backend. \u00b6 splink is a Python package for probabilistic record linkage (entity resolution). Its key features are: It is extremely fast. It is capable of linking a million records on a laptop in around a minute. It is highly accurate, with support for term frequency adjustments, and sophisticated fuzzy matching logic. Linking jobs can be executed in Python (using the DuckDB package), or using big-data backends like AWS Athena and Spark to link 100+ million records. Training data is not required because models can be trained using an unsupervised approach. It produces a wide variety of interactive outputs, helping users to understand their model and diagnose linkage problems. The core linkage algorithm is an implementation of Fellegi-Sunter's model of record linkage, with various customisations to improve accuracy. What does Splink do? \u00b6 Splink deduplicates and links records from datasets that lack a unique identifier. For example, a few of your records may look like this: row_id first_name surname dob city 1 lucas smith 1984-01-02 London 2 lucas smyth 1984-07-02 Manchester 3 lucas smyth 1984-07-02 4 david jones Leeds 5 david jones 1990-03-21 Leeds Splink produces pairwise predictions of the links: row_id_l row_id_r match_probability 1 2 0.9 1 3 0.85 2 3 0.92 4 5 0.7 And clusters the predictions to produce an estimated unique id: cluster_id row_id a 1 a 2 a 3 b 4 b 5 Documentation \u00b6 The homepage for the Splink documentation can be found here . Interactive demos can be found here , or by clicking the following Binder link: The specification of the Fellegi Sunter statistical model behind splink is similar as that used in the R fastLink package . Accompanying the fastLink package is an academic paper that describes this model. A series of interactive articles also explores the theory behind Splink. Installation \u00b6 Splink supports python 3.7+. To obtain the latest released version of splink: pip install splink Quickstart \u00b6 The following code demonstrates how to estimate the parameters of a deduplication model, use it to identify duplicate records, and then use clustering to generate an estimated unique person ID. For more detailed tutorials, please see here . from splink.duckdb.duckdb_linker import DuckDBLinker from splink.duckdb.duckdb_comparison_library import ( exact_match, levenshtein_at_thresholds, ) import pandas as pd df = pd.read_csv(\"./tests/datasets/fake_1000_from_splink_demos.csv\") settings = { \"link_type\": \"dedupe_only\", \"blocking_rules_to_generate_predictions\": [ \"l.first_name = r.first_name\", \"l.surname = r.surname\", ], \"comparisons\": [ levenshtein_at_thresholds(\"first_name\", 2), exact_match(\"surname\"), exact_match(\"dob\"), exact_match(\"city\", term_frequency_adjustments=True), exact_match(\"email\"), ], } linker = DuckDBLinker(df, settings) linker.estimate_u_using_random_sampling(target_rows=1e6) blocking_rule_for_training = \"l.first_name = r.first_name and l.surname = r.surname\" linker.estimate_parameters_using_expectation_maximisation(blocking_rule_for_training) blocking_rule_for_training = \"l.dob = r.dob\" linker.estimate_parameters_using_expectation_maximisation(blocking_rule_for_training) pairwise_predictions = linker.predict() clusters = linker.cluster_pairwise_predictions_at_threshold(pairwise_predictions, 0.95) clusters.as_pandas_dataframe(limit=5) Acknowledgements \u00b6 We are very grateful to ADR UK (Administrative Data Research UK) for providing the initial funding for this work as part of the Data First project. We are extremely grateful to professors Katie Harron, James Doidge and Peter Christen for their expert advice and guidance in the development of Splink. We are also very grateful to colleagues at the UK's Office for National Statistics for their expert advice and peer review of this work. Any errors remain our own.","title":"Home"},{"location":"index.html#fast-accurate-and-scalable-probabilistic-data-linkage-using-your-choice-of-sql-backend","text":"splink is a Python package for probabilistic record linkage (entity resolution). Its key features are: It is extremely fast. It is capable of linking a million records on a laptop in around a minute. It is highly accurate, with support for term frequency adjustments, and sophisticated fuzzy matching logic. Linking jobs can be executed in Python (using the DuckDB package), or using big-data backends like AWS Athena and Spark to link 100+ million records. Training data is not required because models can be trained using an unsupervised approach. It produces a wide variety of interactive outputs, helping users to understand their model and diagnose linkage problems. The core linkage algorithm is an implementation of Fellegi-Sunter's model of record linkage, with various customisations to improve accuracy.","title":"Fast, accurate and scalable probabilistic data linkage using your choice of SQL backend."},{"location":"index.html#what-does-splink-do","text":"Splink deduplicates and links records from datasets that lack a unique identifier. For example, a few of your records may look like this: row_id first_name surname dob city 1 lucas smith 1984-01-02 London 2 lucas smyth 1984-07-02 Manchester 3 lucas smyth 1984-07-02 4 david jones Leeds 5 david jones 1990-03-21 Leeds Splink produces pairwise predictions of the links: row_id_l row_id_r match_probability 1 2 0.9 1 3 0.85 2 3 0.92 4 5 0.7 And clusters the predictions to produce an estimated unique id: cluster_id row_id a 1 a 2 a 3 b 4 b 5","title":"What does Splink do?"},{"location":"index.html#documentation","text":"The homepage for the Splink documentation can be found here . Interactive demos can be found here , or by clicking the following Binder link: The specification of the Fellegi Sunter statistical model behind splink is similar as that used in the R fastLink package . Accompanying the fastLink package is an academic paper that describes this model. A series of interactive articles also explores the theory behind Splink.","title":"Documentation"},{"location":"index.html#installation","text":"Splink supports python 3.7+. To obtain the latest released version of splink: pip install splink","title":"Installation"},{"location":"index.html#quickstart","text":"The following code demonstrates how to estimate the parameters of a deduplication model, use it to identify duplicate records, and then use clustering to generate an estimated unique person ID. For more detailed tutorials, please see here . from splink.duckdb.duckdb_linker import DuckDBLinker from splink.duckdb.duckdb_comparison_library import ( exact_match, levenshtein_at_thresholds, ) import pandas as pd df = pd.read_csv(\"./tests/datasets/fake_1000_from_splink_demos.csv\") settings = { \"link_type\": \"dedupe_only\", \"blocking_rules_to_generate_predictions\": [ \"l.first_name = r.first_name\", \"l.surname = r.surname\", ], \"comparisons\": [ levenshtein_at_thresholds(\"first_name\", 2), exact_match(\"surname\"), exact_match(\"dob\"), exact_match(\"city\", term_frequency_adjustments=True), exact_match(\"email\"), ], } linker = DuckDBLinker(df, settings) linker.estimate_u_using_random_sampling(target_rows=1e6) blocking_rule_for_training = \"l.first_name = r.first_name and l.surname = r.surname\" linker.estimate_parameters_using_expectation_maximisation(blocking_rule_for_training) blocking_rule_for_training = \"l.dob = r.dob\" linker.estimate_parameters_using_expectation_maximisation(blocking_rule_for_training) pairwise_predictions = linker.predict() clusters = linker.cluster_pairwise_predictions_at_threshold(pairwise_predictions, 0.95) clusters.as_pandas_dataframe(limit=5)","title":"Quickstart"},{"location":"index.html#acknowledgements","text":"We are very grateful to ADR UK (Administrative Data Research UK) for providing the initial funding for this work as part of the Data First project. We are extremely grateful to professors Katie Harron, James Doidge and Peter Christen for their expert advice and guidance in the development of Splink. We are also very grateful to colleagues at the UK's Office for National Statistics for their expert advice and peer review of this work. Any errors remain our own.","title":"Acknowledgements"},{"location":"SplinkDataFrame.html","tags":["API"],"text":"Documentation for SplinkDataFrame object \u00b6 Abstraction over dataframe to handle basic operations like retrieving data and retrieving column names, which need different implementations depending on whether it's a spark dataframe, sqlite table etc. Uses methods like as_pandas_dataframe() and as_record_dict() to retrieve data Source code in splink/splink_dataframe.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 class SplinkDataFrame : \"\"\"Abstraction over dataframe to handle basic operations like retrieving data and retrieving column names, which need different implementations depending on whether it's a spark dataframe, sqlite table etc. Uses methods like `as_pandas_dataframe()` and `as_record_dict()` to retrieve data \"\"\" def __init__ ( self , templated_name , physical_name ): self . templated_name = templated_name self . physical_name = physical_name @property def columns ( self ): pass @property def columns_escaped ( self ): cols = self . columns return escape_columns ( cols ) def validate (): pass def _random_sample_sql ( percent ): raise NotImplementedError ( \"Random sample sql not implemented for this linker\" ) @property def physical_and_template_names_equal ( self ): return self . templated_name == self . physical_name def _check_drop_table_created_by_splink ( self , force_non_splink_table = False ): if not self . physical_name . startswith ( \"__splink__\" ): if not force_non_splink_table : raise ValueError ( f \"You've asked to drop table { self . physical_name } from your \" \"database which is not a table created by Splink. If you really \" \"want to drop this table, you can do so by setting \" \"force_non_splink_table=True\" ) logger . debug ( f \"Dropping table with templated name { self . templated_name } and \" f \"physical name { self . physical_name } \" ) def drop_table_from_database ( self , force_non_splink_table = False ): raise NotImplementedError ( \"Drop table from database not implemented for this linker\" ) def as_record_dict ( self , limit = None ): pass def as_pandas_dataframe ( self , limit = None ): \"\"\"Return the dataframe as a pandas dataframe. This can be computationally expensive if the dataframe is large. Args: limit (int, optional): If provided, return this number of rows (equivalent to a limit statement in SQL). Defaults to None, meaning return all rows Returns: pandas.DataFrame: pandas Dataframe \"\"\" import pandas as pd return pd . DataFrame ( self . as_record_dict ( limit = limit )) def __repr__ ( self ): return ( f \"Table name in database: ` { self . physical_name } ` \\n \" \" \\n To retrieve records, you can call the following methods on this object:\" \" \\n `.as_record_dict(limit=5)` or \" \"`.as_pandas_dataframe(limit=5)`. \\n \" \" \\n You may omit the `limit` argument to return all records.\" \" \\n\\n This table represents the following splink entity: \" f \" { self . templated_name } \" ) drop_table_from_database ( force_non_splink_table = False ) \u00b6 Source code in splink/splink_dataframe.py 55 56 57 58 def drop_table_from_database ( self , force_non_splink_table = False ): raise NotImplementedError ( \"Drop table from database not implemented for this linker\" ) as_pandas_dataframe ( limit = None ) \u00b6 Return the dataframe as a pandas dataframe. This can be computationally expensive if the dataframe is large. Parameters: Name Type Description Default limit int If provided, return this number of rows (equivalent None Returns: Type Description pandas.DataFrame: pandas Dataframe Source code in splink/splink_dataframe.py 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def as_pandas_dataframe ( self , limit = None ): \"\"\"Return the dataframe as a pandas dataframe. This can be computationally expensive if the dataframe is large. Args: limit (int, optional): If provided, return this number of rows (equivalent to a limit statement in SQL). Defaults to None, meaning return all rows Returns: pandas.DataFrame: pandas Dataframe \"\"\" import pandas as pd return pd . DataFrame ( self . as_record_dict ( limit = limit ))","title":"SplinkDataFrame API"},{"location":"SplinkDataFrame.html#documentation-for-splinkdataframe-object","text":"Abstraction over dataframe to handle basic operations like retrieving data and retrieving column names, which need different implementations depending on whether it's a spark dataframe, sqlite table etc. Uses methods like as_pandas_dataframe() and as_record_dict() to retrieve data Source code in splink/splink_dataframe.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 class SplinkDataFrame : \"\"\"Abstraction over dataframe to handle basic operations like retrieving data and retrieving column names, which need different implementations depending on whether it's a spark dataframe, sqlite table etc. Uses methods like `as_pandas_dataframe()` and `as_record_dict()` to retrieve data \"\"\" def __init__ ( self , templated_name , physical_name ): self . templated_name = templated_name self . physical_name = physical_name @property def columns ( self ): pass @property def columns_escaped ( self ): cols = self . columns return escape_columns ( cols ) def validate (): pass def _random_sample_sql ( percent ): raise NotImplementedError ( \"Random sample sql not implemented for this linker\" ) @property def physical_and_template_names_equal ( self ): return self . templated_name == self . physical_name def _check_drop_table_created_by_splink ( self , force_non_splink_table = False ): if not self . physical_name . startswith ( \"__splink__\" ): if not force_non_splink_table : raise ValueError ( f \"You've asked to drop table { self . physical_name } from your \" \"database which is not a table created by Splink. If you really \" \"want to drop this table, you can do so by setting \" \"force_non_splink_table=True\" ) logger . debug ( f \"Dropping table with templated name { self . templated_name } and \" f \"physical name { self . physical_name } \" ) def drop_table_from_database ( self , force_non_splink_table = False ): raise NotImplementedError ( \"Drop table from database not implemented for this linker\" ) def as_record_dict ( self , limit = None ): pass def as_pandas_dataframe ( self , limit = None ): \"\"\"Return the dataframe as a pandas dataframe. This can be computationally expensive if the dataframe is large. Args: limit (int, optional): If provided, return this number of rows (equivalent to a limit statement in SQL). Defaults to None, meaning return all rows Returns: pandas.DataFrame: pandas Dataframe \"\"\" import pandas as pd return pd . DataFrame ( self . as_record_dict ( limit = limit )) def __repr__ ( self ): return ( f \"Table name in database: ` { self . physical_name } ` \\n \" \" \\n To retrieve records, you can call the following methods on this object:\" \" \\n `.as_record_dict(limit=5)` or \" \"`.as_pandas_dataframe(limit=5)`. \\n \" \" \\n You may omit the `limit` argument to return all records.\" \" \\n\\n This table represents the following splink entity: \" f \" { self . templated_name } \" )","title":"Documentation for SplinkDataFrame object"},{"location":"SplinkDataFrame.html#splink.splink_dataframe.SplinkDataFrame.drop_table_from_database","text":"Source code in splink/splink_dataframe.py 55 56 57 58 def drop_table_from_database ( self , force_non_splink_table = False ): raise NotImplementedError ( \"Drop table from database not implemented for this linker\" )","title":"drop_table_from_database()"},{"location":"SplinkDataFrame.html#splink.splink_dataframe.SplinkDataFrame.as_pandas_dataframe","text":"Return the dataframe as a pandas dataframe. This can be computationally expensive if the dataframe is large. Parameters: Name Type Description Default limit int If provided, return this number of rows (equivalent None Returns: Type Description pandas.DataFrame: pandas Dataframe Source code in splink/splink_dataframe.py 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def as_pandas_dataframe ( self , limit = None ): \"\"\"Return the dataframe as a pandas dataframe. This can be computationally expensive if the dataframe is large. Args: limit (int, optional): If provided, return this number of rows (equivalent to a limit statement in SQL). Defaults to None, meaning return all rows Returns: pandas.DataFrame: pandas Dataframe \"\"\" import pandas as pd return pd . DataFrame ( self . as_record_dict ( limit = limit ))","title":"as_pandas_dataframe()"},{"location":"comparison.html","tags":["API"],"text":"Documentation for Comparison object \u00b6 Each Comparison defines how data from one or more input columns is compared to assess its similarity. For example, one Comparison may represent how similarity is assessed for a person's date of birth. Others may represent the comparison of a person's name or location. The method used to assess similarity will depend on the type of data - for instance, the method used to assess similarity of a company's turnover would be different to the method used to assess the similarity of a person's first name. A linking model thus usually contains several Comparisons. As far as possible, Comparisons should be configured to satisfy the assumption of independece conditional on the true match status, a key assumption of the Fellegi Sunter probabilistic linkage model. This would be broken, for example, if a model contained one Comparison for city, and another for postcode. Instead, in this example, a single comparison should be modelled, which may to capture similarity taking account of both the city and postcode field. Each Comparison contains two or more ComparisonLevel s which define the gradations of similarity between the input columns within the Comparison. For example, for the date of birth Comparison there may be a ComparisonLevel for an exact match, another for a one-character difference, and another for all other comparisons. To summarise: Data Linking Model \u251c\u2500-- Comparison: Date of birth \u2502 \u251c\u2500-- ComparisonLevel: Exact match \u2502 \u251c\u2500-- ComparisonLevel: One character difference \u2502 \u251c\u2500-- ComparisonLevel: All other \u251c\u2500-- Comparison: Name \u2502 \u251c\u2500-- ComparisonLevel: Exact match on first name and surname \u2502 \u251c\u2500-- ComparisonLevel: Exact match on first name \u2502 \u251c\u2500-- etc. Source code in splink/comparison.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 class Comparison : \"\"\"Each Comparison defines how data from one or more input columns is compared to assess its similarity. For example, one Comparison may represent how similarity is assessed for a person's date of birth. Others may represent the comparison of a person's name or location. The method used to assess similarity will depend on the type of data - for instance, the method used to assess similarity of a company's turnover would be different to the method used to assess the similarity of a person's first name. A linking model thus usually contains several Comparisons. As far as possible, Comparisons should be configured to satisfy the assumption of independece conditional on the true match status, a key assumption of the Fellegi Sunter probabilistic linkage model. This would be broken, for example, if a model contained one Comparison for city, and another for postcode. Instead, in this example, a single comparison should be modelled, which may to capture similarity taking account of both the city and postcode field. Each Comparison contains two or more `ComparisonLevel`s which define the gradations of similarity between the input columns within the Comparison. For example, for the date of birth Comparison there may be a ComparisonLevel for an exact match, another for a one-character difference, and another for all other comparisons. To summarise: ``` Data Linking Model \u251c\u2500-- Comparison: Date of birth \u2502 \u251c\u2500-- ComparisonLevel: Exact match \u2502 \u251c\u2500-- ComparisonLevel: One character difference \u2502 \u251c\u2500-- ComparisonLevel: All other \u251c\u2500-- Comparison: Name \u2502 \u251c\u2500-- ComparisonLevel: Exact match on first name and surname \u2502 \u251c\u2500-- ComparisonLevel: Exact match on first name \u2502 \u251c\u2500-- etc. ``` \"\"\" def __init__ ( self , comparison_dict , settings_obj : \"Settings\" = None ): # Protected because we don't want to modify self . _comparison_dict = comparison_dict comparison_level_list = comparison_dict [ \"comparison_levels\" ] self . comparison_levels : List [ ComparisonLevel ] = [] # If comparison_levels are already of type ComparisonLevel, register # the settings object on them # otherwise turn the dictionaries into ComparisonLevel for cl in comparison_level_list : if isinstance ( cl , ComparisonLevel ): cl . comparison = self elif settings_obj is None : cl = ComparisonLevel ( cl , self ) else : cl = ComparisonLevel ( cl , self , sql_dialect = settings_obj . _sql_dialect ) self . comparison_levels . append ( cl ) self . _settings_obj : \"Settings\" = settings_obj # Assign comparison vector values starting at highest level, count down to 0 num_levels = self . _num_levels counter = num_levels - 1 for level in self . comparison_levels : if level . _is_null_level : level . _comparison_vector_value = - 1 level . _max_level = False else : level . _comparison_vector_value = counter if counter == num_levels - 1 : level . _max_level = True else : level . _max_level = False counter -= 1 def __deepcopy__ ( self , memo ): \"\"\"When we do EM training, we need a copy of the Comparison which is independent of the original e.g. modifying the copy will not affect the original. This method implements ensures the Comparison can be deepcopied. \"\"\" cc = Comparison ( self . as_dict (), self . _settings_obj ) return cc @property def _num_levels ( self ): return len ([ cl for cl in self . comparison_levels if not cl . _is_null_level ]) @property def _comparison_levels_excluding_null ( self ): return [ cl for cl in self . comparison_levels if not cl . _is_null_level ] @property def _gamma_prefix ( self ): return self . _settings_obj . _gamma_prefix @property def _retain_intermediate_calculation_columns ( self ): return self . _settings_obj . _retain_intermediate_calculation_columns @property def _bf_column_name ( self ): return f \" { self . _settings_obj . _bf_prefix }{ self . _output_column_name } \" . replace ( \" \" , \"_\" ) @property def _has_null_level ( self ): return any ([ cl . _is_null_level for cl in self . comparison_levels ]) @property def _bf_tf_adj_column_name ( self ): bf = self . _settings_obj . _bf_prefix tf = self . _settings_obj . _tf_prefix cc_name = self . _output_column_name return f \" { bf }{ tf } adj_ { cc_name } \" . replace ( \" \" , \"_\" ) @property def _has_tf_adjustments ( self ): return any ([ cl . _has_tf_adjustments for cl in self . comparison_levels ]) @property def _case_statement ( self ): sqls = [ cl . _when_then_comparison_vector_value_sql for cl in self . comparison_levels ] sql = \" \" . join ( sqls ) sql = f \"CASE { sql } END as { self . _gamma_column_name } \" return sql @property def _input_columns_used_by_case_statement ( self ): cols = [] for cl in self . comparison_levels : cols . extend ( cl . _input_columns_used_by_sql_condition ) # dedupe_preserving_order on input column already_observed = [] deduped_cols = [] for col in cols : if col . input_name not in already_observed : deduped_cols . append ( col ) already_observed . append ( col . input_name ) return deduped_cols @property def _output_column_name ( self ): if \"output_column_name\" in self . _comparison_dict : return self . _comparison_dict [ \"output_column_name\" ] else : cols = self . _input_columns_used_by_case_statement cols = [ c . input_name for c in cols ] if len ( cols ) == 1 : return cols [ 0 ] else : return f \"custom_ { '_' . join ( cols ) } \" @property def _comparison_description ( self ): if \"comparison_description\" in self . _comparison_dict : return self . _comparison_dict [ \"comparison_description\" ] else : return self . _output_column_name @property def _gamma_column_name ( self ): return f \" { self . _gamma_prefix }{ self . _output_column_name } \" . replace ( \" \" , \"_\" ) @property def _tf_adjustment_input_col_names ( self ): cols = [ cl . _tf_adjustment_input_column_name for cl in self . comparison_levels ] cols = [ c for c in cols if c ] return cols @property def _columns_to_select_for_blocking ( self ): cols = [] for cl in self . comparison_levels : cols . extend ( cl . _columns_to_select_for_blocking ) return dedupe_preserving_order ( cols ) @property def _columns_to_select_for_comparison_vector_values ( self ): input_cols = [] for cl in self . comparison_levels : input_cols . extend ( cl . _input_columns_used_by_sql_condition ) output_cols = [] for col in input_cols : if self . _settings_obj . _retain_matching_columns : output_cols . extend ( col . names_l_r ()) output_cols . append ( self . _case_statement ) for col in input_cols : if self . _has_tf_adjustments : output_cols . extend ( col . tf_name_l_r ()) return dedupe_preserving_order ( output_cols ) @property def _columns_to_select_for_bayes_factor_parts ( self ): input_cols = [] for cl in self . comparison_levels : input_cols . extend ( cl . _input_columns_used_by_sql_condition ) output_cols = [] for col in input_cols : if self . _settings_obj . _retain_matching_columns : output_cols . extend ( col . names_l_r ()) output_cols . append ( self . _gamma_column_name ) for col in input_cols : if self . _has_tf_adjustments : if self . _settings_obj . _retain_intermediate_calculation_columns : output_cols . extend ( col . tf_name_l_r ()) # Bayes factor case when statement sqls = [ cl . _bayes_factor_sql for cl in self . comparison_levels ] sql = \" \" . join ( sqls ) sql = f \"CASE { sql } END as { self . _bf_column_name } \" output_cols . append ( sql ) # tf adjustment case when statement if self . _has_tf_adjustments : sqls = [ cl . _tf_adjustment_sql for cl in self . comparison_levels ] sql = \" \" . join ( sqls ) sql = f \"CASE { sql } END as { self . _bf_tf_adj_column_name } \" output_cols . append ( sql ) output_cols . append ( self . _gamma_column_name ) return dedupe_preserving_order ( output_cols ) @property def _columns_to_select_for_predict ( self ): input_cols = [] for cl in self . comparison_levels : input_cols . extend ( cl . _input_columns_used_by_sql_condition ) output_cols = [] for col in input_cols : if self . _settings_obj . _retain_matching_columns : output_cols . extend ( col . names_l_r ()) if ( self . _settings_obj . _training_mode or self . _settings_obj . _retain_matching_columns ): output_cols . append ( self . _gamma_column_name ) for col in input_cols : if self . _settings_obj . _retain_intermediate_calculation_columns : if self . _has_tf_adjustments : output_cols . extend ( col . tf_name_l_r ()) output_cols . extend ( self . _match_weight_columns_to_multiply ) return dedupe_preserving_order ( output_cols ) @property def _match_weight_columns_to_multiply ( self ): cols = [] cols . append ( self . _bf_column_name ) if self . _has_tf_adjustments : cols . append ( self . _bf_tf_adj_column_name ) return cols @property def _term_frequency_columns ( self ): cols = set () for cl in self . comparison_levels : cols . add ( cl . tf_adjustment_input_col_name ) return list ( cols ) def as_dict ( self ): d = { \"output_column_name\" : self . _output_column_name , \"comparison_levels\" : [ cl . as_dict () for cl in self . comparison_levels ], } if \"comparison_description\" in self . _comparison_dict : d [ \"comparison_description\" ] = self . _comparison_dict [ \"comparison_description\" ] return d def _as_completed_dict ( self ): return { \"column_name\" : self . _output_column_name , \"comparison_levels\" : [ cl . _as_completed_dict () for cl in self . comparison_levels ], \"input_columns_used_by_case_statement\" : [ c . input_name for c in self . _input_columns_used_by_case_statement ], } @property def _has_estimated_m_values ( self ): return all ( cl . _has_estimated_m_values for cl in self . comparison_levels ) @property def _has_estimated_u_values ( self ): return all ( cl . _has_estimated_u_values for cl in self . comparison_levels ) @property def _all_m_are_trained ( self ): return all ( cl . _m_is_trained for cl in self . comparison_levels ) @property def _all_u_are_trained ( self ): return all ( cl . _u_is_trained for cl in self . comparison_levels ) @property def _some_m_are_trained ( self ): return any ( cl . _m_is_trained for cl in self . _comparison_levels_excluding_null ) @property def _some_u_are_trained ( self ): return any ( cl . _u_is_trained for cl in self . _comparison_levels_excluding_null ) @property def _is_trained_message ( self ): messages = [] if self . _all_m_are_trained and self . _all_u_are_trained : return None if not self . _some_u_are_trained : messages . append ( \"no u values are trained\" ) elif self . _some_u_are_trained and not self . _all_u_are_trained : messages . append ( \"some u values are not trained\" ) if not self . _some_m_are_trained : messages . append ( \"no m values are trained\" ) elif self . _some_m_are_trained and not self . _all_m_are_trained : messages . append ( \"some m values are not trained\" ) message = \", \" . join ( messages ) message = f \" - { self . _output_column_name } ( { message } ).\" return message @property def _is_trained ( self ): return self . _all_m_are_trained and self . _all_u_are_trained @property def _as_detailed_records ( self ): records = [] for cl in self . comparison_levels : record = {} record [ \"comparison_name\" ] = self . _output_column_name record = { ** record , ** cl . _as_detailed_record } records . append ( record ) return records @property def _parameter_estimates_as_records ( self ): records = [] for cl in self . comparison_levels : new_records = cl . _parameter_estimates_as_records for r in new_records : r [ \"comparison_name\" ] = self . _output_column_name records . extend ( new_records ) return records def _get_comparison_level_by_comparison_vector_value ( self , value ) -> ComparisonLevel : for cl in self . comparison_levels : if cl . _comparison_vector_value == value : return cl raise ValueError ( f \"No comparison level with comparison vector value { value } \" ) def __repr__ ( self ): return ( f \"<Comparison { self . _comparison_description } with \" f \" { self . _num_levels } levels at { hex ( id ( self )) } >\" ) @property def _not_trained_messages ( self ): msgs = [] cname = self . _output_column_name header = f \"Comparison: ' { cname } ': \\n \" msg_template = \" {header} {m_or_u} values not fully trained\" if not self . _all_m_are_trained : msgs . append ( msg_template . format ( header = header , m_or_u = \"m\" )) if not self . _all_u_are_trained : msgs . append ( msg_template . format ( header = header , m_or_u = \"u\" )) return msgs @property def _comparison_level_description_list ( self ): cl_template = \" - ' {label} ' with SQL rule: {sql} \\n \" comp_levels = [ cl_template . format ( cvv = cl . _comparison_vector_value , label = cl . _label_for_charts , sql = cl . _sql_condition , ) for cl in self . comparison_levels ] comp_levels = \"\" . join ( comp_levels ) return comp_levels @property def _human_readable_description_succinct ( self ): input_cols = join_list_with_commas_final_and ( [ c . name ( escape = False ) for c in self . _input_columns_used_by_case_statement ] ) comp_levels = self . _comparison_level_description_list if \"comparison_description\" in self . _comparison_dict : main_desc = ( f \"of { input_cols } \\n Description: ' { self . _comparison_description } '\" ) else : main_desc = f \"of { input_cols } \" desc = f \"Comparison { main_desc } \\n Comparison levels: \\n { comp_levels } \" return desc @property def human_readable_description ( self ): input_cols = join_list_with_commas_final_and ( [ c . name ( escape = False ) for c in self . _input_columns_used_by_case_statement ] ) comp_levels = self . _comparison_level_description_list if \"comparison_description\" in self . _comparison_dict : main_desc = f \"' { self . _comparison_description } ' of { input_cols } \" else : main_desc = f \"of { input_cols } \" desc = ( f \"Comparison { main_desc } . \\n \" \"Similarity is assessed using the following \" f \"ComparisonLevels: \\n { comp_levels } \" ) return desc def match_weights_chart ( self , as_dict = False ): \"\"\"Display a chart of comparison levels of the comparison\"\"\" from .charts import comparison_match_weights_chart records = self . _as_detailed_records return comparison_match_weights_chart ( records , as_dict = as_dict ) __init__ ( comparison_dict , settings_obj = None ) \u00b6 Source code in splink/comparison.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 def __init__ ( self , comparison_dict , settings_obj : \"Settings\" = None ): # Protected because we don't want to modify self . _comparison_dict = comparison_dict comparison_level_list = comparison_dict [ \"comparison_levels\" ] self . comparison_levels : List [ ComparisonLevel ] = [] # If comparison_levels are already of type ComparisonLevel, register # the settings object on them # otherwise turn the dictionaries into ComparisonLevel for cl in comparison_level_list : if isinstance ( cl , ComparisonLevel ): cl . comparison = self elif settings_obj is None : cl = ComparisonLevel ( cl , self ) else : cl = ComparisonLevel ( cl , self , sql_dialect = settings_obj . _sql_dialect ) self . comparison_levels . append ( cl ) self . _settings_obj : \"Settings\" = settings_obj # Assign comparison vector values starting at highest level, count down to 0 num_levels = self . _num_levels counter = num_levels - 1 for level in self . comparison_levels : if level . _is_null_level : level . _comparison_vector_value = - 1 level . _max_level = False else : level . _comparison_vector_value = counter if counter == num_levels - 1 : level . _max_level = True else : level . _max_level = False counter -= 1 human_readable_description () property \u00b6 Source code in splink/comparison.py 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 @property def human_readable_description ( self ): input_cols = join_list_with_commas_final_and ( [ c . name ( escape = False ) for c in self . _input_columns_used_by_case_statement ] ) comp_levels = self . _comparison_level_description_list if \"comparison_description\" in self . _comparison_dict : main_desc = f \"' { self . _comparison_description } ' of { input_cols } \" else : main_desc = f \"of { input_cols } \" desc = ( f \"Comparison { main_desc } . \\n \" \"Similarity is assessed using the following \" f \"ComparisonLevels: \\n { comp_levels } \" ) return desc match_weights_chart ( as_dict = False ) \u00b6 Display a chart of comparison levels of the comparison Source code in splink/comparison.py 488 489 490 491 492 493 def match_weights_chart ( self , as_dict = False ): \"\"\"Display a chart of comparison levels of the comparison\"\"\" from .charts import comparison_match_weights_chart records = self . _as_detailed_records return comparison_match_weights_chart ( records , as_dict = as_dict )","title":"Comparison"},{"location":"comparison.html#documentation-for-comparison-object","text":"Each Comparison defines how data from one or more input columns is compared to assess its similarity. For example, one Comparison may represent how similarity is assessed for a person's date of birth. Others may represent the comparison of a person's name or location. The method used to assess similarity will depend on the type of data - for instance, the method used to assess similarity of a company's turnover would be different to the method used to assess the similarity of a person's first name. A linking model thus usually contains several Comparisons. As far as possible, Comparisons should be configured to satisfy the assumption of independece conditional on the true match status, a key assumption of the Fellegi Sunter probabilistic linkage model. This would be broken, for example, if a model contained one Comparison for city, and another for postcode. Instead, in this example, a single comparison should be modelled, which may to capture similarity taking account of both the city and postcode field. Each Comparison contains two or more ComparisonLevel s which define the gradations of similarity between the input columns within the Comparison. For example, for the date of birth Comparison there may be a ComparisonLevel for an exact match, another for a one-character difference, and another for all other comparisons. To summarise: Data Linking Model \u251c\u2500-- Comparison: Date of birth \u2502 \u251c\u2500-- ComparisonLevel: Exact match \u2502 \u251c\u2500-- ComparisonLevel: One character difference \u2502 \u251c\u2500-- ComparisonLevel: All other \u251c\u2500-- Comparison: Name \u2502 \u251c\u2500-- ComparisonLevel: Exact match on first name and surname \u2502 \u251c\u2500-- ComparisonLevel: Exact match on first name \u2502 \u251c\u2500-- etc. Source code in splink/comparison.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 class Comparison : \"\"\"Each Comparison defines how data from one or more input columns is compared to assess its similarity. For example, one Comparison may represent how similarity is assessed for a person's date of birth. Others may represent the comparison of a person's name or location. The method used to assess similarity will depend on the type of data - for instance, the method used to assess similarity of a company's turnover would be different to the method used to assess the similarity of a person's first name. A linking model thus usually contains several Comparisons. As far as possible, Comparisons should be configured to satisfy the assumption of independece conditional on the true match status, a key assumption of the Fellegi Sunter probabilistic linkage model. This would be broken, for example, if a model contained one Comparison for city, and another for postcode. Instead, in this example, a single comparison should be modelled, which may to capture similarity taking account of both the city and postcode field. Each Comparison contains two or more `ComparisonLevel`s which define the gradations of similarity between the input columns within the Comparison. For example, for the date of birth Comparison there may be a ComparisonLevel for an exact match, another for a one-character difference, and another for all other comparisons. To summarise: ``` Data Linking Model \u251c\u2500-- Comparison: Date of birth \u2502 \u251c\u2500-- ComparisonLevel: Exact match \u2502 \u251c\u2500-- ComparisonLevel: One character difference \u2502 \u251c\u2500-- ComparisonLevel: All other \u251c\u2500-- Comparison: Name \u2502 \u251c\u2500-- ComparisonLevel: Exact match on first name and surname \u2502 \u251c\u2500-- ComparisonLevel: Exact match on first name \u2502 \u251c\u2500-- etc. ``` \"\"\" def __init__ ( self , comparison_dict , settings_obj : \"Settings\" = None ): # Protected because we don't want to modify self . _comparison_dict = comparison_dict comparison_level_list = comparison_dict [ \"comparison_levels\" ] self . comparison_levels : List [ ComparisonLevel ] = [] # If comparison_levels are already of type ComparisonLevel, register # the settings object on them # otherwise turn the dictionaries into ComparisonLevel for cl in comparison_level_list : if isinstance ( cl , ComparisonLevel ): cl . comparison = self elif settings_obj is None : cl = ComparisonLevel ( cl , self ) else : cl = ComparisonLevel ( cl , self , sql_dialect = settings_obj . _sql_dialect ) self . comparison_levels . append ( cl ) self . _settings_obj : \"Settings\" = settings_obj # Assign comparison vector values starting at highest level, count down to 0 num_levels = self . _num_levels counter = num_levels - 1 for level in self . comparison_levels : if level . _is_null_level : level . _comparison_vector_value = - 1 level . _max_level = False else : level . _comparison_vector_value = counter if counter == num_levels - 1 : level . _max_level = True else : level . _max_level = False counter -= 1 def __deepcopy__ ( self , memo ): \"\"\"When we do EM training, we need a copy of the Comparison which is independent of the original e.g. modifying the copy will not affect the original. This method implements ensures the Comparison can be deepcopied. \"\"\" cc = Comparison ( self . as_dict (), self . _settings_obj ) return cc @property def _num_levels ( self ): return len ([ cl for cl in self . comparison_levels if not cl . _is_null_level ]) @property def _comparison_levels_excluding_null ( self ): return [ cl for cl in self . comparison_levels if not cl . _is_null_level ] @property def _gamma_prefix ( self ): return self . _settings_obj . _gamma_prefix @property def _retain_intermediate_calculation_columns ( self ): return self . _settings_obj . _retain_intermediate_calculation_columns @property def _bf_column_name ( self ): return f \" { self . _settings_obj . _bf_prefix }{ self . _output_column_name } \" . replace ( \" \" , \"_\" ) @property def _has_null_level ( self ): return any ([ cl . _is_null_level for cl in self . comparison_levels ]) @property def _bf_tf_adj_column_name ( self ): bf = self . _settings_obj . _bf_prefix tf = self . _settings_obj . _tf_prefix cc_name = self . _output_column_name return f \" { bf }{ tf } adj_ { cc_name } \" . replace ( \" \" , \"_\" ) @property def _has_tf_adjustments ( self ): return any ([ cl . _has_tf_adjustments for cl in self . comparison_levels ]) @property def _case_statement ( self ): sqls = [ cl . _when_then_comparison_vector_value_sql for cl in self . comparison_levels ] sql = \" \" . join ( sqls ) sql = f \"CASE { sql } END as { self . _gamma_column_name } \" return sql @property def _input_columns_used_by_case_statement ( self ): cols = [] for cl in self . comparison_levels : cols . extend ( cl . _input_columns_used_by_sql_condition ) # dedupe_preserving_order on input column already_observed = [] deduped_cols = [] for col in cols : if col . input_name not in already_observed : deduped_cols . append ( col ) already_observed . append ( col . input_name ) return deduped_cols @property def _output_column_name ( self ): if \"output_column_name\" in self . _comparison_dict : return self . _comparison_dict [ \"output_column_name\" ] else : cols = self . _input_columns_used_by_case_statement cols = [ c . input_name for c in cols ] if len ( cols ) == 1 : return cols [ 0 ] else : return f \"custom_ { '_' . join ( cols ) } \" @property def _comparison_description ( self ): if \"comparison_description\" in self . _comparison_dict : return self . _comparison_dict [ \"comparison_description\" ] else : return self . _output_column_name @property def _gamma_column_name ( self ): return f \" { self . _gamma_prefix }{ self . _output_column_name } \" . replace ( \" \" , \"_\" ) @property def _tf_adjustment_input_col_names ( self ): cols = [ cl . _tf_adjustment_input_column_name for cl in self . comparison_levels ] cols = [ c for c in cols if c ] return cols @property def _columns_to_select_for_blocking ( self ): cols = [] for cl in self . comparison_levels : cols . extend ( cl . _columns_to_select_for_blocking ) return dedupe_preserving_order ( cols ) @property def _columns_to_select_for_comparison_vector_values ( self ): input_cols = [] for cl in self . comparison_levels : input_cols . extend ( cl . _input_columns_used_by_sql_condition ) output_cols = [] for col in input_cols : if self . _settings_obj . _retain_matching_columns : output_cols . extend ( col . names_l_r ()) output_cols . append ( self . _case_statement ) for col in input_cols : if self . _has_tf_adjustments : output_cols . extend ( col . tf_name_l_r ()) return dedupe_preserving_order ( output_cols ) @property def _columns_to_select_for_bayes_factor_parts ( self ): input_cols = [] for cl in self . comparison_levels : input_cols . extend ( cl . _input_columns_used_by_sql_condition ) output_cols = [] for col in input_cols : if self . _settings_obj . _retain_matching_columns : output_cols . extend ( col . names_l_r ()) output_cols . append ( self . _gamma_column_name ) for col in input_cols : if self . _has_tf_adjustments : if self . _settings_obj . _retain_intermediate_calculation_columns : output_cols . extend ( col . tf_name_l_r ()) # Bayes factor case when statement sqls = [ cl . _bayes_factor_sql for cl in self . comparison_levels ] sql = \" \" . join ( sqls ) sql = f \"CASE { sql } END as { self . _bf_column_name } \" output_cols . append ( sql ) # tf adjustment case when statement if self . _has_tf_adjustments : sqls = [ cl . _tf_adjustment_sql for cl in self . comparison_levels ] sql = \" \" . join ( sqls ) sql = f \"CASE { sql } END as { self . _bf_tf_adj_column_name } \" output_cols . append ( sql ) output_cols . append ( self . _gamma_column_name ) return dedupe_preserving_order ( output_cols ) @property def _columns_to_select_for_predict ( self ): input_cols = [] for cl in self . comparison_levels : input_cols . extend ( cl . _input_columns_used_by_sql_condition ) output_cols = [] for col in input_cols : if self . _settings_obj . _retain_matching_columns : output_cols . extend ( col . names_l_r ()) if ( self . _settings_obj . _training_mode or self . _settings_obj . _retain_matching_columns ): output_cols . append ( self . _gamma_column_name ) for col in input_cols : if self . _settings_obj . _retain_intermediate_calculation_columns : if self . _has_tf_adjustments : output_cols . extend ( col . tf_name_l_r ()) output_cols . extend ( self . _match_weight_columns_to_multiply ) return dedupe_preserving_order ( output_cols ) @property def _match_weight_columns_to_multiply ( self ): cols = [] cols . append ( self . _bf_column_name ) if self . _has_tf_adjustments : cols . append ( self . _bf_tf_adj_column_name ) return cols @property def _term_frequency_columns ( self ): cols = set () for cl in self . comparison_levels : cols . add ( cl . tf_adjustment_input_col_name ) return list ( cols ) def as_dict ( self ): d = { \"output_column_name\" : self . _output_column_name , \"comparison_levels\" : [ cl . as_dict () for cl in self . comparison_levels ], } if \"comparison_description\" in self . _comparison_dict : d [ \"comparison_description\" ] = self . _comparison_dict [ \"comparison_description\" ] return d def _as_completed_dict ( self ): return { \"column_name\" : self . _output_column_name , \"comparison_levels\" : [ cl . _as_completed_dict () for cl in self . comparison_levels ], \"input_columns_used_by_case_statement\" : [ c . input_name for c in self . _input_columns_used_by_case_statement ], } @property def _has_estimated_m_values ( self ): return all ( cl . _has_estimated_m_values for cl in self . comparison_levels ) @property def _has_estimated_u_values ( self ): return all ( cl . _has_estimated_u_values for cl in self . comparison_levels ) @property def _all_m_are_trained ( self ): return all ( cl . _m_is_trained for cl in self . comparison_levels ) @property def _all_u_are_trained ( self ): return all ( cl . _u_is_trained for cl in self . comparison_levels ) @property def _some_m_are_trained ( self ): return any ( cl . _m_is_trained for cl in self . _comparison_levels_excluding_null ) @property def _some_u_are_trained ( self ): return any ( cl . _u_is_trained for cl in self . _comparison_levels_excluding_null ) @property def _is_trained_message ( self ): messages = [] if self . _all_m_are_trained and self . _all_u_are_trained : return None if not self . _some_u_are_trained : messages . append ( \"no u values are trained\" ) elif self . _some_u_are_trained and not self . _all_u_are_trained : messages . append ( \"some u values are not trained\" ) if not self . _some_m_are_trained : messages . append ( \"no m values are trained\" ) elif self . _some_m_are_trained and not self . _all_m_are_trained : messages . append ( \"some m values are not trained\" ) message = \", \" . join ( messages ) message = f \" - { self . _output_column_name } ( { message } ).\" return message @property def _is_trained ( self ): return self . _all_m_are_trained and self . _all_u_are_trained @property def _as_detailed_records ( self ): records = [] for cl in self . comparison_levels : record = {} record [ \"comparison_name\" ] = self . _output_column_name record = { ** record , ** cl . _as_detailed_record } records . append ( record ) return records @property def _parameter_estimates_as_records ( self ): records = [] for cl in self . comparison_levels : new_records = cl . _parameter_estimates_as_records for r in new_records : r [ \"comparison_name\" ] = self . _output_column_name records . extend ( new_records ) return records def _get_comparison_level_by_comparison_vector_value ( self , value ) -> ComparisonLevel : for cl in self . comparison_levels : if cl . _comparison_vector_value == value : return cl raise ValueError ( f \"No comparison level with comparison vector value { value } \" ) def __repr__ ( self ): return ( f \"<Comparison { self . _comparison_description } with \" f \" { self . _num_levels } levels at { hex ( id ( self )) } >\" ) @property def _not_trained_messages ( self ): msgs = [] cname = self . _output_column_name header = f \"Comparison: ' { cname } ': \\n \" msg_template = \" {header} {m_or_u} values not fully trained\" if not self . _all_m_are_trained : msgs . append ( msg_template . format ( header = header , m_or_u = \"m\" )) if not self . _all_u_are_trained : msgs . append ( msg_template . format ( header = header , m_or_u = \"u\" )) return msgs @property def _comparison_level_description_list ( self ): cl_template = \" - ' {label} ' with SQL rule: {sql} \\n \" comp_levels = [ cl_template . format ( cvv = cl . _comparison_vector_value , label = cl . _label_for_charts , sql = cl . _sql_condition , ) for cl in self . comparison_levels ] comp_levels = \"\" . join ( comp_levels ) return comp_levels @property def _human_readable_description_succinct ( self ): input_cols = join_list_with_commas_final_and ( [ c . name ( escape = False ) for c in self . _input_columns_used_by_case_statement ] ) comp_levels = self . _comparison_level_description_list if \"comparison_description\" in self . _comparison_dict : main_desc = ( f \"of { input_cols } \\n Description: ' { self . _comparison_description } '\" ) else : main_desc = f \"of { input_cols } \" desc = f \"Comparison { main_desc } \\n Comparison levels: \\n { comp_levels } \" return desc @property def human_readable_description ( self ): input_cols = join_list_with_commas_final_and ( [ c . name ( escape = False ) for c in self . _input_columns_used_by_case_statement ] ) comp_levels = self . _comparison_level_description_list if \"comparison_description\" in self . _comparison_dict : main_desc = f \"' { self . _comparison_description } ' of { input_cols } \" else : main_desc = f \"of { input_cols } \" desc = ( f \"Comparison { main_desc } . \\n \" \"Similarity is assessed using the following \" f \"ComparisonLevels: \\n { comp_levels } \" ) return desc def match_weights_chart ( self , as_dict = False ): \"\"\"Display a chart of comparison levels of the comparison\"\"\" from .charts import comparison_match_weights_chart records = self . _as_detailed_records return comparison_match_weights_chart ( records , as_dict = as_dict )","title":"Documentation for Comparison object"},{"location":"comparison.html#splink.comparison.Comparison.__init__","text":"Source code in splink/comparison.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 def __init__ ( self , comparison_dict , settings_obj : \"Settings\" = None ): # Protected because we don't want to modify self . _comparison_dict = comparison_dict comparison_level_list = comparison_dict [ \"comparison_levels\" ] self . comparison_levels : List [ ComparisonLevel ] = [] # If comparison_levels are already of type ComparisonLevel, register # the settings object on them # otherwise turn the dictionaries into ComparisonLevel for cl in comparison_level_list : if isinstance ( cl , ComparisonLevel ): cl . comparison = self elif settings_obj is None : cl = ComparisonLevel ( cl , self ) else : cl = ComparisonLevel ( cl , self , sql_dialect = settings_obj . _sql_dialect ) self . comparison_levels . append ( cl ) self . _settings_obj : \"Settings\" = settings_obj # Assign comparison vector values starting at highest level, count down to 0 num_levels = self . _num_levels counter = num_levels - 1 for level in self . comparison_levels : if level . _is_null_level : level . _comparison_vector_value = - 1 level . _max_level = False else : level . _comparison_vector_value = counter if counter == num_levels - 1 : level . _max_level = True else : level . _max_level = False counter -= 1","title":"__init__()"},{"location":"comparison.html#splink.comparison.Comparison.human_readable_description","text":"Source code in splink/comparison.py 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 @property def human_readable_description ( self ): input_cols = join_list_with_commas_final_and ( [ c . name ( escape = False ) for c in self . _input_columns_used_by_case_statement ] ) comp_levels = self . _comparison_level_description_list if \"comparison_description\" in self . _comparison_dict : main_desc = f \"' { self . _comparison_description } ' of { input_cols } \" else : main_desc = f \"of { input_cols } \" desc = ( f \"Comparison { main_desc } . \\n \" \"Similarity is assessed using the following \" f \"ComparisonLevels: \\n { comp_levels } \" ) return desc","title":"human_readable_description()"},{"location":"comparison.html#splink.comparison.Comparison.match_weights_chart","text":"Display a chart of comparison levels of the comparison Source code in splink/comparison.py 488 489 490 491 492 493 def match_weights_chart ( self , as_dict = False ): \"\"\"Display a chart of comparison levels of the comparison\"\"\" from .charts import comparison_match_weights_chart records = self . _as_detailed_records return comparison_match_weights_chart ( records , as_dict = as_dict )","title":"match_weights_chart()"},{"location":"comparison_level.html","tags":["API","comparisons"],"text":"Documentation for ComparisonLevel object \u00b6 Each ComparisonLevel defines a gradation (category) of similarity within a Comparison . For example, a Comparison that uses the first_name and surname columns may define three ComparisonLevel s: An exact match on first name and surname First name and surname have a JaroWinkler score of above 0.95 All other comparisons The method used to assess similarity will depend on the type of data - for instance, the method used to assess similarity of a company's turnover would be different to the method used to assess the similarity of a person's first name. To summarise: Data Linking Model \u251c\u2500-- Comparison: Name \u2502 \u251c\u2500-- ComparisonLevel: Exact match on first_name and surname \u2502 \u251c\u2500-- ComparisonLevel: first_name and surname have JaroWinkler > 0.95 \u2502 \u251c\u2500-- ComparisonLevel: All other \u251c\u2500-- Comparison: Date of birth \u2502 \u251c\u2500-- ComparisonLevel: Exact match \u2502 \u251c\u2500-- ComparisonLevel: One character difference \u2502 \u251c\u2500-- ComparisonLevel: All other \u251c\u2500-- etc. Source code in splink/comparison_level.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 class ComparisonLevel : \"\"\"Each ComparisonLevel defines a gradation (category) of similarity within a `Comparison`. For example, a `Comparison` that uses the first_name and surname columns may define three `ComparisonLevel`s: An exact match on first name and surname First name and surname have a JaroWinkler score of above 0.95 All other comparisons The method used to assess similarity will depend on the type of data - for instance, the method used to assess similarity of a company's turnover would be different to the method used to assess the similarity of a person's first name. To summarise: ``` Data Linking Model \u251c\u2500-- Comparison: Name \u2502 \u251c\u2500-- ComparisonLevel: Exact match on first_name and surname \u2502 \u251c\u2500-- ComparisonLevel: first_name and surname have JaroWinkler > 0.95 \u2502 \u251c\u2500-- ComparisonLevel: All other \u251c\u2500-- Comparison: Date of birth \u2502 \u251c\u2500-- ComparisonLevel: Exact match \u2502 \u251c\u2500-- ComparisonLevel: One character difference \u2502 \u251c\u2500-- ComparisonLevel: All other \u251c\u2500-- etc. ``` \"\"\" def __init__ ( self , level_dict , comparison : \"Comparison\" = None , sql_dialect : str = None , ): # Protected, because we don't want to modify the original dict self . _level_dict = level_dict self . comparison : \"Comparison\" = comparison self . _sql_dialect = sql_dialect self . _sql_condition = self . _level_dict [ \"sql_condition\" ] self . _is_null_level = self . _level_dict_val_else_default ( \"is_null_level\" ) self . _tf_adjustment_weight = self . _level_dict_val_else_default ( \"tf_adjustment_weight\" ) self . _tf_minimum_u_value = self . _level_dict_val_else_default ( \"tf_minimum_u_value\" ) # Private values controlled with getter/setter self . _m_probability = self . _level_dict . get ( \"m_probability\" ) self . _u_probability = self . _level_dict . get ( \"u_probability\" ) # These will be set when the ComparisonLevel is passed into a Comparison self . _comparison_vector_value : int = None self . _max_level : bool = None # Enable the level to 'know' when it's been trained self . _trained_m_probabilities : list = [] self . _trained_u_probabilities : list = [] self . _validate () def _level_dict_val_else_default ( self , key ): val = self . _level_dict . get ( key ) if not val : val = default_value_from_schema ( key , \"comparison_level\" ) return val @property def _tf_adjustment_input_column ( self ): val = self . _level_dict_val_else_default ( \"tf_adjustment_column\" ) if val : return InputColumn ( val , tf_adjustments = True , sql_dialect = self . _sql_dialect ) else : return None @property def _tf_adjustment_input_column_name ( self ): input_column = self . _tf_adjustment_input_column if input_column : return input_column . input_name else : return None @property def _has_comparison ( self ): from .comparison import Comparison return isinstance ( self . comparison , Comparison ) @property def m_probability ( self ): if self . _is_null_level : return None if self . _m_probability == \"level not observed in training dataset\" : return 1e-6 if self . _m_probability is None and self . _has_comparison : vals = _default_m_values ( self . comparison . _num_levels ) return vals [ self . _comparison_vector_value ] return self . _m_probability @m_probability . setter def m_probability ( self , value ): if self . _is_null_level : raise AttributeError ( \"Cannot set m_probability when is_null_level is true\" ) if value == \"level not observed in training dataset\" : cc_n = self . comparison . _output_column_name cl_n = self . _label_for_charts logger . warning ( \" \\n WARNING: \\n \" f \"Level { cl_n } on comparison { cc_n } not observed in dataset, \" \"unable to train m value\" ) self . _m_probability = value @property def u_probability ( self ): if self . _is_null_level : return None if self . _u_probability == \"level not observed in training dataset\" : return 1e-6 if self . _u_probability is None : vals = _default_u_values ( self . comparison . _num_levels ) return vals [ self . _comparison_vector_value ] return self . _u_probability @u_probability . setter def u_probability ( self , value ): if self . _is_null_level : raise AttributeError ( \"Cannot set u_probability when is_null_level is true\" ) if value == \"level not observed in training dataset\" : cc_n = self . comparison . _output_column_name cl_n = self . _label_for_charts logger . warning ( \" \\n WARNING: \\n \" f \"Level { cl_n } on comparison { cc_n } not observed in dataset, \" \"unable to train u value\" ) self . _u_probability = value @property def _m_probability_description ( self ): if self . m_probability is not None : return ( \"Amongst matching record comparisons, \" f \" { self . m_probability : .2% } of records are in the \" f \" { self . _label_for_charts . lower () } comparison level\" ) @property def _u_probability_description ( self ): if self . u_probability is not None : return ( \"Amongst non-matching record comparisons, \" f \" { self . u_probability : .2% } of records are in the \" f \" { self . _label_for_charts . lower () } comparison level\" ) def _add_trained_u_probability ( self , val , desc = \"no description given\" ): self . _trained_u_probabilities . append ( { \"probability\" : val , \"description\" : desc , \"m_or_u\" : \"u\" } ) def _add_trained_m_probability ( self , val , desc = \"no description given\" ): self . _trained_m_probabilities . append ( { \"probability\" : val , \"description\" : desc , \"m_or_u\" : \"m\" } ) @property def _has_estimated_u_values ( self ): if self . _is_null_level : return True vals = [ r [ \"probability\" ] for r in self . _trained_u_probabilities ] vals = [ v for v in vals if isinstance ( v , ( int , float ))] return len ( vals ) > 0 @property def _has_estimated_m_values ( self ): if self . _is_null_level : return True vals = [ r [ \"probability\" ] for r in self . _trained_m_probabilities ] vals = [ v for v in vals if isinstance ( v , ( int , float ))] return len ( vals ) > 0 @property def _has_estimated_values ( self ): return self . _has_estimated_m_values and self . _has_estimated_u_values @property def _trained_m_median ( self ): vals = [ r [ \"probability\" ] for r in self . _trained_m_probabilities ] vals = [ v for v in vals if isinstance ( v , ( int , float ))] if len ( vals ) == 0 : return None return median ( vals ) @property def _trained_u_median ( self ): vals = [ r [ \"probability\" ] for r in self . _trained_u_probabilities ] vals = [ v for v in vals if isinstance ( v , ( int , float ))] if len ( vals ) == 0 : return None return median ( vals ) @property def _m_is_trained ( self ): if self . _is_null_level : return True if self . _m_probability == \"level not observed in data\" : return False if self . _m_probability is None : return False return True @property def _u_is_trained ( self ): if self . _is_null_level : return True if self . _u_probability == \"level not observed in data\" : return False if self . _u_probability is None : return False return True @property def _is_trained ( self ): return self . _m_is_trained and self . _u_is_trained @property def _bayes_factor ( self ): if self . _is_null_level : return 1.0 if self . m_probability is None or self . u_probability is None : return None else : return self . m_probability / self . u_probability @property def _log2_bayes_factor ( self ): if self . _is_null_level : return 0.0 else : return math . log2 ( self . _bayes_factor ) @property def _bayes_factor_description ( self ): text = ( f \"If comparison level is ` { self . _label_for_charts . lower () } ` \" \"then comparison is\" ) if self . _bayes_factor >= 1.0 : return f \" { text } { self . _bayes_factor : ,.2f } times more likely to be a match\" else : mult = 1 / self . _bayes_factor return f \" { text } { mult : ,.2f } times less likely to be a match\" @property def _label_for_charts ( self ): return self . _level_dict . get ( \"label_for_charts\" , str ( self . _comparison_vector_value ) ) @property def _is_else_level ( self ): if self . _sql_condition . strip () . upper () == \"ELSE\" : return True @property def _has_tf_adjustments ( self ): col = self . _level_dict . get ( \"tf_adjustment_column\" ) return col is not None @property def _sql_read_dialect ( self ): read_dialect = None if self . _sql_dialect is not None : read_dialect = self . _sql_dialect return read_dialect def _validate_sql ( self ): sql = self . _sql_condition if self . _is_else_level : return True try : sqlglot . parse_one ( sql , read = self . _sql_read_dialect ) except sqlglot . ParseError as e : raise ValueError ( f \"Error parsing sql_statement: \\n { sql } \" ) from e return True @property def _input_columns_used_by_sql_condition ( self ) -> List [ InputColumn ]: # returns e.g. InputColumn(first_name), InputColumn(surname) if self . _is_else_level : return [] cols = get_columns_used_from_sql ( self . _sql_condition , dialect = self . _sql_read_dialect ) # Parsed order seems to be roughly in reverse order of apearance cols = cols [:: - 1 ] cols = [ re . sub ( r \"_L$|_R$\" , \"\" , c , flags = re . IGNORECASE ) for c in cols ] cols = dedupe_preserving_order ( cols ) input_cols = [] for c in cols : # We could have tf adjustments for surname on a dmeta_surname column # If so, we want to set the tf adjustments against the surname col, # not the dmeta_surname one if c == self . _tf_adjustment_input_column_name : input_cols . append ( InputColumn ( c , tf_adjustments = True , sql_dialect = self . _sql_dialect ) ) else : input_cols . append ( InputColumn ( c , tf_adjustments = False , sql_dialect = self . _sql_dialect ) ) return input_cols @property def _columns_to_select_for_blocking ( self ): # e.g. l.first_name as first_name_l, r.first_name as first_name_r output_cols = [] cols = self . _input_columns_used_by_sql_condition for c in cols : output_cols . extend ( c . l_r_names_as_l_r ()) output_cols . extend ( c . l_r_tf_names_as_l_r ()) return dedupe_preserving_order ( output_cols ) @property def _when_then_comparison_vector_value_sql ( self ): # e.g. when first_name_l = first_name_r then 1 if not hasattr ( self , \"_comparison_vector_value\" ): raise ValueError ( \"Cannot get the 'when .. then ...' sql expression because \" \"this comparison level does not belong to a parent Comparison. \" \"The comparison_vector_value is only defined in the \" \"context of a list of ComparisonLevels within a Comparison.\" ) if self . _is_else_level : return f \" { self . _sql_condition } { self . _comparison_vector_value } \" else : return f \"WHEN { self . _sql_condition } THEN { self . _comparison_vector_value } \" @property def _is_exact_match ( self ): if self . _is_else_level : return False sqls = re . split ( r \" and \" , self . _sql_condition , flags = re . IGNORECASE ) for sql in sqls : if not _is_exact_match ( sql ): return False return True @property def _exact_match_colnames ( self ): sqls = re . split ( r \" and \" , self . _sql_condition , flags = re . IGNORECASE ) for sql in sqls : if not _is_exact_match ( sql ): raise ValueError ( \"sql_cond not an exact match so can't get exact match column name\" ) cols = [] for sql in sqls : col = _exact_match_colname ( sql ) cols . append ( col ) return cols @property def _u_probability_corresponding_to_exact_match ( self ): levels = self . comparison . comparison_levels # Find a level with a single exact match colname # which is equal to the tf adjustment input colname for level in levels : if not level . _is_exact_match : continue colnames = level . _exact_match_colnames if len ( colnames ) != 1 : continue if colnames [ 0 ] == self . _tf_adjustment_input_column_name . lower (): return level . u_probability raise ValueError ( \"Could not find an exact match level for \" f \" { self . _tf_adjustment_input_column_name } .\" \" \\n An exact match level is required to make a term frequency adjustment \" \"on a comparison level that is not an exact match.\" ) @property def _bayes_factor_sql ( self ): sql = f \"\"\" WHEN { self . comparison . _gamma_column_name } = { self . _comparison_vector_value } THEN cast( { self . _bayes_factor } as double) \"\"\" return dedent ( sql ) @property def _tf_adjustment_sql ( self ): gamma_column_name = self . comparison . _gamma_column_name gamma_colname_value_is_this_level = ( f \" { gamma_column_name } = { self . _comparison_vector_value } \" ) # A tf adjustment of 1D is a multiplier of 1.0, i.e. no adjustment if self . _comparison_vector_value == - 1 : sql = f \"WHEN { gamma_colname_value_is_this_level } then cast(1 as double)\" elif not self . _has_tf_adjustments : sql = f \"WHEN { gamma_colname_value_is_this_level } then cast(1 as double)\" elif self . _tf_adjustment_weight == 0 : sql = f \"WHEN { gamma_colname_value_is_this_level } then cast(1 as double)\" elif self . _is_else_level : sql = f \"WHEN { gamma_colname_value_is_this_level } then cast(1 as double)\" else : tf_adj_col = self . _tf_adjustment_input_column coalesce_l_r = ( f \"coalesce( { tf_adj_col . tf_name_l () } , { tf_adj_col . tf_name_r () } )\" ) coalesce_r_l = ( f \"coalesce( { tf_adj_col . tf_name_r () } , { tf_adj_col . tf_name_l () } )\" ) tf_adjustment_exists = f \" { coalesce_l_r } is not null\" u_prob_exact_match = self . _u_probability_corresponding_to_exact_match # Using coalesce protects against one of the tf adjustments being null # Which would happen if the user provided their own tf adjustment table # That didn't contain some of the values in this data # In this case rather than taking the greater of the two, we take # whichever value exists if self . _tf_minimum_u_value == 0.0 : divisor_sql = f \"\"\" (CASE WHEN { coalesce_l_r } >= { coalesce_r_l } THEN { coalesce_l_r } ELSE { coalesce_r_l } END) \"\"\" else : # This sql works correctly even when the tf_minimum_u_value is 0.0 # but is less efficient to execute, hence the above if statement divisor_sql = f \"\"\" (CASE WHEN { coalesce_l_r } >= { coalesce_r_l } AND { coalesce_l_r } > cast( { self . _tf_minimum_u_value } as double) THEN { coalesce_l_r } WHEN { coalesce_r_l } > cast( { self . _tf_minimum_u_value } as double) THEN { coalesce_r_l } ELSE cast( { self . _tf_minimum_u_value } as double) END) \"\"\" sql = f \"\"\" WHEN { gamma_colname_value_is_this_level } then (CASE WHEN { tf_adjustment_exists } THEN POW( cast( { u_prob_exact_match } as double) / { divisor_sql } , cast( { self . _tf_adjustment_weight } as double) ) ELSE cast(1 as double) END) \"\"\" return dedent ( sql ) . strip () def as_dict ( self ): \"The minimal representation of this level to use as an input to Splink\" output = {} output [ \"sql_condition\" ] = self . _sql_condition if self . _level_dict . get ( \"label_for_charts\" ): output [ \"label_for_charts\" ] = self . _label_for_charts if self . _m_probability and self . _m_is_trained : output [ \"m_probability\" ] = self . m_probability if self . _u_probability and self . _u_is_trained : output [ \"u_probability\" ] = self . u_probability if self . _has_tf_adjustments : output [ \"tf_adjustment_column\" ] = self . _tf_adjustment_input_column . input_name if self . _tf_adjustment_weight != 0 : output [ \"tf_adjustment_weight\" ] = self . _tf_adjustment_weight if self . _is_null_level : output [ \"is_null_level\" ] = True return output def _as_completed_dict ( self ): comp_dict = self . as_dict () comp_dict [ \"comparison_vector_value\" ] = self . _comparison_vector_value return comp_dict @property def _as_detailed_record ( self ): \"A detailed representation of this level to describe it in charting outputs\" output = {} output [ \"sql_condition\" ] = self . _sql_condition output [ \"label_for_charts\" ] = self . _label_for_charts output [ \"m_probability\" ] = self . m_probability output [ \"u_probability\" ] = self . u_probability output [ \"m_probability_description\" ] = self . _m_probability_description output [ \"u_probability_description\" ] = self . _u_probability_description output [ \"has_tf_adjustments\" ] = self . _has_tf_adjustments if self . _has_tf_adjustments : output [ \"tf_adjustment_column\" ] = self . _tf_adjustment_input_column . input_name else : output [ \"tf_adjustment_column\" ] = None output [ \"tf_adjustment_weight\" ] = self . _tf_adjustment_weight output [ \"is_null_level\" ] = self . _is_null_level output [ \"bayes_factor\" ] = self . _bayes_factor output [ \"log2_bayes_factor\" ] = self . _log2_bayes_factor output [ \"comparison_vector_value\" ] = self . _comparison_vector_value output [ \"max_comparison_vector_value\" ] = self . comparison . _num_levels - 1 output [ \"bayes_factor_description\" ] = self . _bayes_factor_description return output @property def _parameter_estimates_as_records ( self ): output_records = [] cl_record = self . _as_detailed_record trained_values = self . _trained_u_probabilities + self . _trained_m_probabilities for trained_value in trained_values : record = {} record [ \"m_or_u\" ] = trained_value [ \"m_or_u\" ] p = trained_value [ \"probability\" ] record [ \"estimated_probability\" ] = p record [ \"estimate_description\" ] = trained_value [ \"description\" ] if p is not None and p > 0.0 : record [ \"estimated_probability_as_log_odds\" ] = math . log2 ( p / ( 1 - p )) else : record [ \"estimated_probability_as_log_odds\" ] = None record [ \"sql_condition\" ] = cl_record [ \"sql_condition\" ] record [ \"comparison_level_label\" ] = cl_record [ \"label_for_charts\" ] record [ \"comparison_vector_value\" ] = cl_record [ \"comparison_vector_value\" ] output_records . append ( record ) return output_records def _validate ( self ): self . _validate_sql () def _abbreviated_sql ( self , cutoff = 75 ): sql = self . _sql_condition sql = ( sql [: 75 ] + \"...\" ) if len ( sql ) > 75 else sql return sql def __repr__ ( self ): return f \"< { self . _human_readable_succinct } >\" @property def _human_readable_succinct ( self ): sql = self . _abbreviated_sql ( 75 ) return f \"Comparison level ' { self . _label_for_charts } ' using SQL rule: { sql } \" @property def human_readable_description ( self ): input_cols = join_list_with_commas_final_and ( [ c . name ( escape = False ) for c in self . _input_columns_used_by_sql_condition ] ) desc = ( f \"Comparison level: { self . _label_for_charts } of { input_cols } \\n \" \"Assesses similarity between pairwise comparisons of the input columns \" f \"using the following rule \\n { self . _sql_condition } \" ) return desc __init__ ( level_dict , comparison = None , sql_dialect = None ) \u00b6 Source code in splink/comparison_level.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 def __init__ ( self , level_dict , comparison : \"Comparison\" = None , sql_dialect : str = None , ): # Protected, because we don't want to modify the original dict self . _level_dict = level_dict self . comparison : \"Comparison\" = comparison self . _sql_dialect = sql_dialect self . _sql_condition = self . _level_dict [ \"sql_condition\" ] self . _is_null_level = self . _level_dict_val_else_default ( \"is_null_level\" ) self . _tf_adjustment_weight = self . _level_dict_val_else_default ( \"tf_adjustment_weight\" ) self . _tf_minimum_u_value = self . _level_dict_val_else_default ( \"tf_minimum_u_value\" ) # Private values controlled with getter/setter self . _m_probability = self . _level_dict . get ( \"m_probability\" ) self . _u_probability = self . _level_dict . get ( \"u_probability\" ) # These will be set when the ComparisonLevel is passed into a Comparison self . _comparison_vector_value : int = None self . _max_level : bool = None # Enable the level to 'know' when it's been trained self . _trained_m_probabilities : list = [] self . _trained_u_probabilities : list = [] self . _validate () m_probability () property writable \u00b6 Source code in splink/comparison_level.py 182 183 184 185 186 187 188 189 190 191 @property def m_probability ( self ): if self . _is_null_level : return None if self . _m_probability == \"level not observed in training dataset\" : return 1e-6 if self . _m_probability is None and self . _has_comparison : vals = _default_m_values ( self . comparison . _num_levels ) return vals [ self . _comparison_vector_value ] return self . _m_probability u_probability () property writable \u00b6 Source code in splink/comparison_level.py 208 209 210 211 212 213 214 215 216 217 @property def u_probability ( self ): if self . _is_null_level : return None if self . _u_probability == \"level not observed in training dataset\" : return 1e-6 if self . _u_probability is None : vals = _default_u_values ( self . comparison . _num_levels ) return vals [ self . _comparison_vector_value ] return self . _u_probability","title":"Comparison Level"},{"location":"comparison_level.html#documentation-for-comparisonlevel-object","text":"Each ComparisonLevel defines a gradation (category) of similarity within a Comparison . For example, a Comparison that uses the first_name and surname columns may define three ComparisonLevel s: An exact match on first name and surname First name and surname have a JaroWinkler score of above 0.95 All other comparisons The method used to assess similarity will depend on the type of data - for instance, the method used to assess similarity of a company's turnover would be different to the method used to assess the similarity of a person's first name. To summarise: Data Linking Model \u251c\u2500-- Comparison: Name \u2502 \u251c\u2500-- ComparisonLevel: Exact match on first_name and surname \u2502 \u251c\u2500-- ComparisonLevel: first_name and surname have JaroWinkler > 0.95 \u2502 \u251c\u2500-- ComparisonLevel: All other \u251c\u2500-- Comparison: Date of birth \u2502 \u251c\u2500-- ComparisonLevel: Exact match \u2502 \u251c\u2500-- ComparisonLevel: One character difference \u2502 \u251c\u2500-- ComparisonLevel: All other \u251c\u2500-- etc. Source code in splink/comparison_level.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 class ComparisonLevel : \"\"\"Each ComparisonLevel defines a gradation (category) of similarity within a `Comparison`. For example, a `Comparison` that uses the first_name and surname columns may define three `ComparisonLevel`s: An exact match on first name and surname First name and surname have a JaroWinkler score of above 0.95 All other comparisons The method used to assess similarity will depend on the type of data - for instance, the method used to assess similarity of a company's turnover would be different to the method used to assess the similarity of a person's first name. To summarise: ``` Data Linking Model \u251c\u2500-- Comparison: Name \u2502 \u251c\u2500-- ComparisonLevel: Exact match on first_name and surname \u2502 \u251c\u2500-- ComparisonLevel: first_name and surname have JaroWinkler > 0.95 \u2502 \u251c\u2500-- ComparisonLevel: All other \u251c\u2500-- Comparison: Date of birth \u2502 \u251c\u2500-- ComparisonLevel: Exact match \u2502 \u251c\u2500-- ComparisonLevel: One character difference \u2502 \u251c\u2500-- ComparisonLevel: All other \u251c\u2500-- etc. ``` \"\"\" def __init__ ( self , level_dict , comparison : \"Comparison\" = None , sql_dialect : str = None , ): # Protected, because we don't want to modify the original dict self . _level_dict = level_dict self . comparison : \"Comparison\" = comparison self . _sql_dialect = sql_dialect self . _sql_condition = self . _level_dict [ \"sql_condition\" ] self . _is_null_level = self . _level_dict_val_else_default ( \"is_null_level\" ) self . _tf_adjustment_weight = self . _level_dict_val_else_default ( \"tf_adjustment_weight\" ) self . _tf_minimum_u_value = self . _level_dict_val_else_default ( \"tf_minimum_u_value\" ) # Private values controlled with getter/setter self . _m_probability = self . _level_dict . get ( \"m_probability\" ) self . _u_probability = self . _level_dict . get ( \"u_probability\" ) # These will be set when the ComparisonLevel is passed into a Comparison self . _comparison_vector_value : int = None self . _max_level : bool = None # Enable the level to 'know' when it's been trained self . _trained_m_probabilities : list = [] self . _trained_u_probabilities : list = [] self . _validate () def _level_dict_val_else_default ( self , key ): val = self . _level_dict . get ( key ) if not val : val = default_value_from_schema ( key , \"comparison_level\" ) return val @property def _tf_adjustment_input_column ( self ): val = self . _level_dict_val_else_default ( \"tf_adjustment_column\" ) if val : return InputColumn ( val , tf_adjustments = True , sql_dialect = self . _sql_dialect ) else : return None @property def _tf_adjustment_input_column_name ( self ): input_column = self . _tf_adjustment_input_column if input_column : return input_column . input_name else : return None @property def _has_comparison ( self ): from .comparison import Comparison return isinstance ( self . comparison , Comparison ) @property def m_probability ( self ): if self . _is_null_level : return None if self . _m_probability == \"level not observed in training dataset\" : return 1e-6 if self . _m_probability is None and self . _has_comparison : vals = _default_m_values ( self . comparison . _num_levels ) return vals [ self . _comparison_vector_value ] return self . _m_probability @m_probability . setter def m_probability ( self , value ): if self . _is_null_level : raise AttributeError ( \"Cannot set m_probability when is_null_level is true\" ) if value == \"level not observed in training dataset\" : cc_n = self . comparison . _output_column_name cl_n = self . _label_for_charts logger . warning ( \" \\n WARNING: \\n \" f \"Level { cl_n } on comparison { cc_n } not observed in dataset, \" \"unable to train m value\" ) self . _m_probability = value @property def u_probability ( self ): if self . _is_null_level : return None if self . _u_probability == \"level not observed in training dataset\" : return 1e-6 if self . _u_probability is None : vals = _default_u_values ( self . comparison . _num_levels ) return vals [ self . _comparison_vector_value ] return self . _u_probability @u_probability . setter def u_probability ( self , value ): if self . _is_null_level : raise AttributeError ( \"Cannot set u_probability when is_null_level is true\" ) if value == \"level not observed in training dataset\" : cc_n = self . comparison . _output_column_name cl_n = self . _label_for_charts logger . warning ( \" \\n WARNING: \\n \" f \"Level { cl_n } on comparison { cc_n } not observed in dataset, \" \"unable to train u value\" ) self . _u_probability = value @property def _m_probability_description ( self ): if self . m_probability is not None : return ( \"Amongst matching record comparisons, \" f \" { self . m_probability : .2% } of records are in the \" f \" { self . _label_for_charts . lower () } comparison level\" ) @property def _u_probability_description ( self ): if self . u_probability is not None : return ( \"Amongst non-matching record comparisons, \" f \" { self . u_probability : .2% } of records are in the \" f \" { self . _label_for_charts . lower () } comparison level\" ) def _add_trained_u_probability ( self , val , desc = \"no description given\" ): self . _trained_u_probabilities . append ( { \"probability\" : val , \"description\" : desc , \"m_or_u\" : \"u\" } ) def _add_trained_m_probability ( self , val , desc = \"no description given\" ): self . _trained_m_probabilities . append ( { \"probability\" : val , \"description\" : desc , \"m_or_u\" : \"m\" } ) @property def _has_estimated_u_values ( self ): if self . _is_null_level : return True vals = [ r [ \"probability\" ] for r in self . _trained_u_probabilities ] vals = [ v for v in vals if isinstance ( v , ( int , float ))] return len ( vals ) > 0 @property def _has_estimated_m_values ( self ): if self . _is_null_level : return True vals = [ r [ \"probability\" ] for r in self . _trained_m_probabilities ] vals = [ v for v in vals if isinstance ( v , ( int , float ))] return len ( vals ) > 0 @property def _has_estimated_values ( self ): return self . _has_estimated_m_values and self . _has_estimated_u_values @property def _trained_m_median ( self ): vals = [ r [ \"probability\" ] for r in self . _trained_m_probabilities ] vals = [ v for v in vals if isinstance ( v , ( int , float ))] if len ( vals ) == 0 : return None return median ( vals ) @property def _trained_u_median ( self ): vals = [ r [ \"probability\" ] for r in self . _trained_u_probabilities ] vals = [ v for v in vals if isinstance ( v , ( int , float ))] if len ( vals ) == 0 : return None return median ( vals ) @property def _m_is_trained ( self ): if self . _is_null_level : return True if self . _m_probability == \"level not observed in data\" : return False if self . _m_probability is None : return False return True @property def _u_is_trained ( self ): if self . _is_null_level : return True if self . _u_probability == \"level not observed in data\" : return False if self . _u_probability is None : return False return True @property def _is_trained ( self ): return self . _m_is_trained and self . _u_is_trained @property def _bayes_factor ( self ): if self . _is_null_level : return 1.0 if self . m_probability is None or self . u_probability is None : return None else : return self . m_probability / self . u_probability @property def _log2_bayes_factor ( self ): if self . _is_null_level : return 0.0 else : return math . log2 ( self . _bayes_factor ) @property def _bayes_factor_description ( self ): text = ( f \"If comparison level is ` { self . _label_for_charts . lower () } ` \" \"then comparison is\" ) if self . _bayes_factor >= 1.0 : return f \" { text } { self . _bayes_factor : ,.2f } times more likely to be a match\" else : mult = 1 / self . _bayes_factor return f \" { text } { mult : ,.2f } times less likely to be a match\" @property def _label_for_charts ( self ): return self . _level_dict . get ( \"label_for_charts\" , str ( self . _comparison_vector_value ) ) @property def _is_else_level ( self ): if self . _sql_condition . strip () . upper () == \"ELSE\" : return True @property def _has_tf_adjustments ( self ): col = self . _level_dict . get ( \"tf_adjustment_column\" ) return col is not None @property def _sql_read_dialect ( self ): read_dialect = None if self . _sql_dialect is not None : read_dialect = self . _sql_dialect return read_dialect def _validate_sql ( self ): sql = self . _sql_condition if self . _is_else_level : return True try : sqlglot . parse_one ( sql , read = self . _sql_read_dialect ) except sqlglot . ParseError as e : raise ValueError ( f \"Error parsing sql_statement: \\n { sql } \" ) from e return True @property def _input_columns_used_by_sql_condition ( self ) -> List [ InputColumn ]: # returns e.g. InputColumn(first_name), InputColumn(surname) if self . _is_else_level : return [] cols = get_columns_used_from_sql ( self . _sql_condition , dialect = self . _sql_read_dialect ) # Parsed order seems to be roughly in reverse order of apearance cols = cols [:: - 1 ] cols = [ re . sub ( r \"_L$|_R$\" , \"\" , c , flags = re . IGNORECASE ) for c in cols ] cols = dedupe_preserving_order ( cols ) input_cols = [] for c in cols : # We could have tf adjustments for surname on a dmeta_surname column # If so, we want to set the tf adjustments against the surname col, # not the dmeta_surname one if c == self . _tf_adjustment_input_column_name : input_cols . append ( InputColumn ( c , tf_adjustments = True , sql_dialect = self . _sql_dialect ) ) else : input_cols . append ( InputColumn ( c , tf_adjustments = False , sql_dialect = self . _sql_dialect ) ) return input_cols @property def _columns_to_select_for_blocking ( self ): # e.g. l.first_name as first_name_l, r.first_name as first_name_r output_cols = [] cols = self . _input_columns_used_by_sql_condition for c in cols : output_cols . extend ( c . l_r_names_as_l_r ()) output_cols . extend ( c . l_r_tf_names_as_l_r ()) return dedupe_preserving_order ( output_cols ) @property def _when_then_comparison_vector_value_sql ( self ): # e.g. when first_name_l = first_name_r then 1 if not hasattr ( self , \"_comparison_vector_value\" ): raise ValueError ( \"Cannot get the 'when .. then ...' sql expression because \" \"this comparison level does not belong to a parent Comparison. \" \"The comparison_vector_value is only defined in the \" \"context of a list of ComparisonLevels within a Comparison.\" ) if self . _is_else_level : return f \" { self . _sql_condition } { self . _comparison_vector_value } \" else : return f \"WHEN { self . _sql_condition } THEN { self . _comparison_vector_value } \" @property def _is_exact_match ( self ): if self . _is_else_level : return False sqls = re . split ( r \" and \" , self . _sql_condition , flags = re . IGNORECASE ) for sql in sqls : if not _is_exact_match ( sql ): return False return True @property def _exact_match_colnames ( self ): sqls = re . split ( r \" and \" , self . _sql_condition , flags = re . IGNORECASE ) for sql in sqls : if not _is_exact_match ( sql ): raise ValueError ( \"sql_cond not an exact match so can't get exact match column name\" ) cols = [] for sql in sqls : col = _exact_match_colname ( sql ) cols . append ( col ) return cols @property def _u_probability_corresponding_to_exact_match ( self ): levels = self . comparison . comparison_levels # Find a level with a single exact match colname # which is equal to the tf adjustment input colname for level in levels : if not level . _is_exact_match : continue colnames = level . _exact_match_colnames if len ( colnames ) != 1 : continue if colnames [ 0 ] == self . _tf_adjustment_input_column_name . lower (): return level . u_probability raise ValueError ( \"Could not find an exact match level for \" f \" { self . _tf_adjustment_input_column_name } .\" \" \\n An exact match level is required to make a term frequency adjustment \" \"on a comparison level that is not an exact match.\" ) @property def _bayes_factor_sql ( self ): sql = f \"\"\" WHEN { self . comparison . _gamma_column_name } = { self . _comparison_vector_value } THEN cast( { self . _bayes_factor } as double) \"\"\" return dedent ( sql ) @property def _tf_adjustment_sql ( self ): gamma_column_name = self . comparison . _gamma_column_name gamma_colname_value_is_this_level = ( f \" { gamma_column_name } = { self . _comparison_vector_value } \" ) # A tf adjustment of 1D is a multiplier of 1.0, i.e. no adjustment if self . _comparison_vector_value == - 1 : sql = f \"WHEN { gamma_colname_value_is_this_level } then cast(1 as double)\" elif not self . _has_tf_adjustments : sql = f \"WHEN { gamma_colname_value_is_this_level } then cast(1 as double)\" elif self . _tf_adjustment_weight == 0 : sql = f \"WHEN { gamma_colname_value_is_this_level } then cast(1 as double)\" elif self . _is_else_level : sql = f \"WHEN { gamma_colname_value_is_this_level } then cast(1 as double)\" else : tf_adj_col = self . _tf_adjustment_input_column coalesce_l_r = ( f \"coalesce( { tf_adj_col . tf_name_l () } , { tf_adj_col . tf_name_r () } )\" ) coalesce_r_l = ( f \"coalesce( { tf_adj_col . tf_name_r () } , { tf_adj_col . tf_name_l () } )\" ) tf_adjustment_exists = f \" { coalesce_l_r } is not null\" u_prob_exact_match = self . _u_probability_corresponding_to_exact_match # Using coalesce protects against one of the tf adjustments being null # Which would happen if the user provided their own tf adjustment table # That didn't contain some of the values in this data # In this case rather than taking the greater of the two, we take # whichever value exists if self . _tf_minimum_u_value == 0.0 : divisor_sql = f \"\"\" (CASE WHEN { coalesce_l_r } >= { coalesce_r_l } THEN { coalesce_l_r } ELSE { coalesce_r_l } END) \"\"\" else : # This sql works correctly even when the tf_minimum_u_value is 0.0 # but is less efficient to execute, hence the above if statement divisor_sql = f \"\"\" (CASE WHEN { coalesce_l_r } >= { coalesce_r_l } AND { coalesce_l_r } > cast( { self . _tf_minimum_u_value } as double) THEN { coalesce_l_r } WHEN { coalesce_r_l } > cast( { self . _tf_minimum_u_value } as double) THEN { coalesce_r_l } ELSE cast( { self . _tf_minimum_u_value } as double) END) \"\"\" sql = f \"\"\" WHEN { gamma_colname_value_is_this_level } then (CASE WHEN { tf_adjustment_exists } THEN POW( cast( { u_prob_exact_match } as double) / { divisor_sql } , cast( { self . _tf_adjustment_weight } as double) ) ELSE cast(1 as double) END) \"\"\" return dedent ( sql ) . strip () def as_dict ( self ): \"The minimal representation of this level to use as an input to Splink\" output = {} output [ \"sql_condition\" ] = self . _sql_condition if self . _level_dict . get ( \"label_for_charts\" ): output [ \"label_for_charts\" ] = self . _label_for_charts if self . _m_probability and self . _m_is_trained : output [ \"m_probability\" ] = self . m_probability if self . _u_probability and self . _u_is_trained : output [ \"u_probability\" ] = self . u_probability if self . _has_tf_adjustments : output [ \"tf_adjustment_column\" ] = self . _tf_adjustment_input_column . input_name if self . _tf_adjustment_weight != 0 : output [ \"tf_adjustment_weight\" ] = self . _tf_adjustment_weight if self . _is_null_level : output [ \"is_null_level\" ] = True return output def _as_completed_dict ( self ): comp_dict = self . as_dict () comp_dict [ \"comparison_vector_value\" ] = self . _comparison_vector_value return comp_dict @property def _as_detailed_record ( self ): \"A detailed representation of this level to describe it in charting outputs\" output = {} output [ \"sql_condition\" ] = self . _sql_condition output [ \"label_for_charts\" ] = self . _label_for_charts output [ \"m_probability\" ] = self . m_probability output [ \"u_probability\" ] = self . u_probability output [ \"m_probability_description\" ] = self . _m_probability_description output [ \"u_probability_description\" ] = self . _u_probability_description output [ \"has_tf_adjustments\" ] = self . _has_tf_adjustments if self . _has_tf_adjustments : output [ \"tf_adjustment_column\" ] = self . _tf_adjustment_input_column . input_name else : output [ \"tf_adjustment_column\" ] = None output [ \"tf_adjustment_weight\" ] = self . _tf_adjustment_weight output [ \"is_null_level\" ] = self . _is_null_level output [ \"bayes_factor\" ] = self . _bayes_factor output [ \"log2_bayes_factor\" ] = self . _log2_bayes_factor output [ \"comparison_vector_value\" ] = self . _comparison_vector_value output [ \"max_comparison_vector_value\" ] = self . comparison . _num_levels - 1 output [ \"bayes_factor_description\" ] = self . _bayes_factor_description return output @property def _parameter_estimates_as_records ( self ): output_records = [] cl_record = self . _as_detailed_record trained_values = self . _trained_u_probabilities + self . _trained_m_probabilities for trained_value in trained_values : record = {} record [ \"m_or_u\" ] = trained_value [ \"m_or_u\" ] p = trained_value [ \"probability\" ] record [ \"estimated_probability\" ] = p record [ \"estimate_description\" ] = trained_value [ \"description\" ] if p is not None and p > 0.0 : record [ \"estimated_probability_as_log_odds\" ] = math . log2 ( p / ( 1 - p )) else : record [ \"estimated_probability_as_log_odds\" ] = None record [ \"sql_condition\" ] = cl_record [ \"sql_condition\" ] record [ \"comparison_level_label\" ] = cl_record [ \"label_for_charts\" ] record [ \"comparison_vector_value\" ] = cl_record [ \"comparison_vector_value\" ] output_records . append ( record ) return output_records def _validate ( self ): self . _validate_sql () def _abbreviated_sql ( self , cutoff = 75 ): sql = self . _sql_condition sql = ( sql [: 75 ] + \"...\" ) if len ( sql ) > 75 else sql return sql def __repr__ ( self ): return f \"< { self . _human_readable_succinct } >\" @property def _human_readable_succinct ( self ): sql = self . _abbreviated_sql ( 75 ) return f \"Comparison level ' { self . _label_for_charts } ' using SQL rule: { sql } \" @property def human_readable_description ( self ): input_cols = join_list_with_commas_final_and ( [ c . name ( escape = False ) for c in self . _input_columns_used_by_sql_condition ] ) desc = ( f \"Comparison level: { self . _label_for_charts } of { input_cols } \\n \" \"Assesses similarity between pairwise comparisons of the input columns \" f \"using the following rule \\n { self . _sql_condition } \" ) return desc","title":"Documentation for ComparisonLevel object"},{"location":"comparison_level.html#splink.comparison_level.ComparisonLevel.__init__","text":"Source code in splink/comparison_level.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 def __init__ ( self , level_dict , comparison : \"Comparison\" = None , sql_dialect : str = None , ): # Protected, because we don't want to modify the original dict self . _level_dict = level_dict self . comparison : \"Comparison\" = comparison self . _sql_dialect = sql_dialect self . _sql_condition = self . _level_dict [ \"sql_condition\" ] self . _is_null_level = self . _level_dict_val_else_default ( \"is_null_level\" ) self . _tf_adjustment_weight = self . _level_dict_val_else_default ( \"tf_adjustment_weight\" ) self . _tf_minimum_u_value = self . _level_dict_val_else_default ( \"tf_minimum_u_value\" ) # Private values controlled with getter/setter self . _m_probability = self . _level_dict . get ( \"m_probability\" ) self . _u_probability = self . _level_dict . get ( \"u_probability\" ) # These will be set when the ComparisonLevel is passed into a Comparison self . _comparison_vector_value : int = None self . _max_level : bool = None # Enable the level to 'know' when it's been trained self . _trained_m_probabilities : list = [] self . _trained_u_probabilities : list = [] self . _validate ()","title":"__init__()"},{"location":"comparison_level.html#splink.comparison_level.ComparisonLevel.m_probability","text":"Source code in splink/comparison_level.py 182 183 184 185 186 187 188 189 190 191 @property def m_probability ( self ): if self . _is_null_level : return None if self . _m_probability == \"level not observed in training dataset\" : return 1e-6 if self . _m_probability is None and self . _has_comparison : vals = _default_m_values ( self . comparison . _num_levels ) return vals [ self . _comparison_vector_value ] return self . _m_probability","title":"m_probability()"},{"location":"comparison_level.html#splink.comparison_level.ComparisonLevel.u_probability","text":"Source code in splink/comparison_level.py 208 209 210 211 212 213 214 215 216 217 @property def u_probability ( self ): if self . _is_null_level : return None if self . _u_probability == \"level not observed in training dataset\" : return 1e-6 if self . _u_probability is None : vals = _default_u_values ( self . comparison . _num_levels ) return vals [ self . _comparison_vector_value ] return self . _u_probability","title":"u_probability()"},{"location":"comparison_level_library.html","tags":["API","comparisons"],"text":"Documentation for comparison_level_library \u00b6 distance_function_level ( col_name , distance_function_name , distance_threshold , higher_is_more_similar = True , m_probability = None ) \u00b6 Represents a comparison using a user-provided distance function, where the similarity Parameters: Name Type Description Default col_name str Input column name required distance_function_name str The name of the distance function required distance_threshold Union [ int , float ] The threshold to use to assess similarity required higher_is_more_similar bool If True, a higher value of the distance function indicates a higher similarity (e.g. jaro_winkler). If false, a higher value indicates a lower similarity (e.g. levenshtein). True m_probability float Starting value for m probability. Defaults to None. None Returns: Name Type Description ComparisonLevel ComparisonLevel A comparison level for a given distance function Source code in splink/comparison_level_library.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 def distance_function_level ( col_name : str , distance_function_name : str , distance_threshold : Union [ int , float ], higher_is_more_similar : bool = True , m_probability = None , ) -> ComparisonLevel : \"\"\"Represents a comparison using a user-provided distance function, where the similarity Args: col_name (str): Input column name distance_function_name (str): The name of the distance function distance_threshold (Union[int, float]): The threshold to use to assess similarity higher_is_more_similar (bool): If True, a higher value of the distance function indicates a higher similarity (e.g. jaro_winkler). If false, a higher value indicates a lower similarity (e.g. levenshtein). m_probability (float, optional): Starting value for m probability. Defaults to None. Returns: ComparisonLevel: A comparison level for a given distance function \"\"\" col = InputColumn ( col_name , sql_dialect = _mutable_params [ \"dialect\" ]) if higher_is_more_similar : operator = \">=\" else : operator = \"<=\" sql_cond = ( f \" { distance_function_name } ( { col . name_l () } , { col . name_r () } ) \" f \" { operator } { distance_threshold } \" ) level_dict = { \"sql_condition\" : sql_cond , \"label_for_charts\" : f \" { distance_function_name } { operator } { distance_threshold } \" , } if m_probability : level_dict [ \"m_probability\" ] = m_probability return ComparisonLevel ( level_dict , sql_dialect = _mutable_params [ \"dialect\" ]) null_level ( col_name ) \u00b6 Represents comparisons where one or both sides of the comparison contains null values so the similarity cannot be evaluated. Assumed to have a partial match weight of zero (null effect on overall match weight) Parameters: Name Type Description Default col_name str Input column name required Returns: Name Type Description ComparisonLevel ComparisonLevel Comparison level Source code in splink/comparison_level_library.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def null_level ( col_name ) -> ComparisonLevel : \"\"\"Represents comparisons where one or both sides of the comparison contains null values so the similarity cannot be evaluated. Assumed to have a partial match weight of zero (null effect on overall match weight) Args: col_name (str): Input column name Returns: ComparisonLevel: Comparison level \"\"\" col = InputColumn ( col_name , sql_dialect = _mutable_params [ \"dialect\" ]) level_dict = { \"sql_condition\" : f \" { col . name_l () } IS NULL OR { col . name_r () } IS NULL\" , \"label_for_charts\" : \"Null\" , \"is_null_level\" : True , } return ComparisonLevel ( level_dict , sql_dialect = _mutable_params [ \"dialect\" ]) exact_match_level ( col_name , m_probability = None , term_frequency_adjustments = False ) \u00b6 Source code in splink/comparison_level_library.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 def exact_match_level ( col_name , m_probability = None , term_frequency_adjustments = False ) -> ComparisonLevel : col = InputColumn ( col_name , sql_dialect = _mutable_params [ \"dialect\" ]) level_dict = { \"sql_condition\" : f \" { col . name_l () } = { col . name_r () } \" , \"label_for_charts\" : \"Exact match\" , } if m_probability : level_dict [ \"m_probability\" ] = m_probability if term_frequency_adjustments : level_dict [ \"tf_adjustment_column\" ] = col_name return ComparisonLevel ( level_dict , sql_dialect = _mutable_params [ \"dialect\" ]) levenshtein_level ( col_name , distance_threshold , m_probability = None ) \u00b6 Represents a comparison using a levenshtein distance function, Parameters: Name Type Description Default col_name str Input column name required distance_threshold Union [ int , float ] The threshold to use to assess similarity required m_probability float Starting value for m probability. Defaults to None. None Returns: Name Type Description ComparisonLevel ComparisonLevel A comparison level that evaluates the levenshtein similarity Source code in splink/comparison_level_library.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 def levenshtein_level ( col_name : str , distance_threshold : int , m_probability = None , ) -> ComparisonLevel : \"\"\"Represents a comparison using a levenshtein distance function, Args: col_name (str): Input column name distance_threshold (Union[int, float]): The threshold to use to assess similarity m_probability (float, optional): Starting value for m probability. Defaults to None. Returns: ComparisonLevel: A comparison level that evaluates the levenshtein similarity \"\"\" lev_name = _mutable_params [ \"levenshtein\" ] return distance_function_level ( col_name , lev_name , distance_threshold , False , m_probability = m_probability , ) jaccard_level ( col_name , distance_threshold , m_probability = None ) \u00b6 Represents a comparison using a jaccard distance function Parameters: Name Type Description Default col_name str Input column name required distance_threshold Union [ int , float ] The threshold to use to assess similarity required m_probability float Starting value for m probability. Defaults to None. None Returns: Name Type Description ComparisonLevel ComparisonLevel A comparison level that evaluates the jaccard similarity Source code in splink/comparison_level_library.py 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 def jaccard_level ( col_name : str , distance_threshold : Union [ int , float ], m_probability = None , ) -> ComparisonLevel : \"\"\"Represents a comparison using a jaccard distance function Args: col_name (str): Input column name distance_threshold (Union[int, float]): The threshold to use to assess similarity m_probability (float, optional): Starting value for m probability. Defaults to None. Returns: ComparisonLevel: A comparison level that evaluates the jaccard similarity \"\"\" return distance_function_level ( col_name , \"jaccard\" , distance_threshold , True , m_probability = m_probability , ) else_level ( m_probability = None ) \u00b6 Source code in splink/comparison_level_library.py 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 def else_level ( m_probability = None , ) -> ComparisonLevel : if isinstance ( m_probability , str ): raise ValueError ( \"You provided a string for the value of m probability when it should be \" \"numeric. Perhaps you passed a column name. Note that you do not need to \" \"pass a column name into the else level.\" ) level_dict = { \"sql_condition\" : \"ELSE\" , \"label_for_charts\" : \"All other comparisons\" , } if m_probability : level_dict [ \"m_probability\" ] = m_probability return ComparisonLevel ( level_dict ) columns_reversed_level ( col_name_1 , col_name_2 , m_probability = None , tf_adjustment_column = None ) \u00b6 Represents a comparison where the columns are reversed. For example, if surname is in the forename field and vice versa Parameters: Name Type Description Default col_name_1 str First column, e.g. forename required col_name_2 str Second column, e.g. surname required m_probability float Starting value for m probability. Defaults to None. None tf_adjustment_column str Column to use for term frequency adjustments if an exact match is observed. Defaults to None. None Returns: Name Type Description ComparisonLevel ComparisonLevel A comparison level that evaluates the exact match of two columns. Source code in splink/comparison_level_library.py 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 def columns_reversed_level ( col_name_1 : str , col_name_2 : str , m_probability = None , tf_adjustment_column = None ) -> ComparisonLevel : \"\"\"Represents a comparison where the columns are reversed. For example, if surname is in the forename field and vice versa Args: col_name_1 (str): First column, e.g. forename col_name_2 (str): Second column, e.g. surname m_probability (float, optional): Starting value for m probability. Defaults to None. tf_adjustment_column (str, optional): Column to use for term frequency adjustments if an exact match is observed. Defaults to None. Returns: ComparisonLevel: A comparison level that evaluates the exact match of two columns. \"\"\" col_1 = InputColumn ( col_name_1 , sql_dialect = _mutable_params [ \"dialect\" ]) col_2 = InputColumn ( col_name_2 , sql_dialect = _mutable_params [ \"dialect\" ]) s = f \" { col_1 . name_l () } = { col_2 . name_r () } and { col_1 . name_r () } = { col_2 . name_l () } \" level_dict = { \"sql_condition\" : s , \"label_for_charts\" : \"Exact match on reversed cols\" , } if m_probability : level_dict [ \"m_probability\" ] = m_probability if tf_adjustment_column : level_dict [ \"tf_adjustment_column\" ] = tf_adjustment_column return ComparisonLevel ( level_dict , sql_dialect = _mutable_params [ \"dialect\" ])","title":"Comparison Level Library"},{"location":"comparison_level_library.html#documentation-for-comparison_level_library","text":"","title":"Documentation for comparison_level_library"},{"location":"comparison_level_library.html#splink.comparison_level_library.distance_function_level","text":"Represents a comparison using a user-provided distance function, where the similarity Parameters: Name Type Description Default col_name str Input column name required distance_function_name str The name of the distance function required distance_threshold Union [ int , float ] The threshold to use to assess similarity required higher_is_more_similar bool If True, a higher value of the distance function indicates a higher similarity (e.g. jaro_winkler). If false, a higher value indicates a lower similarity (e.g. levenshtein). True m_probability float Starting value for m probability. Defaults to None. None Returns: Name Type Description ComparisonLevel ComparisonLevel A comparison level for a given distance function Source code in splink/comparison_level_library.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 def distance_function_level ( col_name : str , distance_function_name : str , distance_threshold : Union [ int , float ], higher_is_more_similar : bool = True , m_probability = None , ) -> ComparisonLevel : \"\"\"Represents a comparison using a user-provided distance function, where the similarity Args: col_name (str): Input column name distance_function_name (str): The name of the distance function distance_threshold (Union[int, float]): The threshold to use to assess similarity higher_is_more_similar (bool): If True, a higher value of the distance function indicates a higher similarity (e.g. jaro_winkler). If false, a higher value indicates a lower similarity (e.g. levenshtein). m_probability (float, optional): Starting value for m probability. Defaults to None. Returns: ComparisonLevel: A comparison level for a given distance function \"\"\" col = InputColumn ( col_name , sql_dialect = _mutable_params [ \"dialect\" ]) if higher_is_more_similar : operator = \">=\" else : operator = \"<=\" sql_cond = ( f \" { distance_function_name } ( { col . name_l () } , { col . name_r () } ) \" f \" { operator } { distance_threshold } \" ) level_dict = { \"sql_condition\" : sql_cond , \"label_for_charts\" : f \" { distance_function_name } { operator } { distance_threshold } \" , } if m_probability : level_dict [ \"m_probability\" ] = m_probability return ComparisonLevel ( level_dict , sql_dialect = _mutable_params [ \"dialect\" ])","title":"distance_function_level()"},{"location":"comparison_level_library.html#splink.comparison_level_library.null_level","text":"Represents comparisons where one or both sides of the comparison contains null values so the similarity cannot be evaluated. Assumed to have a partial match weight of zero (null effect on overall match weight) Parameters: Name Type Description Default col_name str Input column name required Returns: Name Type Description ComparisonLevel ComparisonLevel Comparison level Source code in splink/comparison_level_library.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def null_level ( col_name ) -> ComparisonLevel : \"\"\"Represents comparisons where one or both sides of the comparison contains null values so the similarity cannot be evaluated. Assumed to have a partial match weight of zero (null effect on overall match weight) Args: col_name (str): Input column name Returns: ComparisonLevel: Comparison level \"\"\" col = InputColumn ( col_name , sql_dialect = _mutable_params [ \"dialect\" ]) level_dict = { \"sql_condition\" : f \" { col . name_l () } IS NULL OR { col . name_r () } IS NULL\" , \"label_for_charts\" : \"Null\" , \"is_null_level\" : True , } return ComparisonLevel ( level_dict , sql_dialect = _mutable_params [ \"dialect\" ])","title":"null_level()"},{"location":"comparison_level_library.html#splink.comparison_level_library.exact_match_level","text":"Source code in splink/comparison_level_library.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 def exact_match_level ( col_name , m_probability = None , term_frequency_adjustments = False ) -> ComparisonLevel : col = InputColumn ( col_name , sql_dialect = _mutable_params [ \"dialect\" ]) level_dict = { \"sql_condition\" : f \" { col . name_l () } = { col . name_r () } \" , \"label_for_charts\" : \"Exact match\" , } if m_probability : level_dict [ \"m_probability\" ] = m_probability if term_frequency_adjustments : level_dict [ \"tf_adjustment_column\" ] = col_name return ComparisonLevel ( level_dict , sql_dialect = _mutable_params [ \"dialect\" ])","title":"exact_match_level()"},{"location":"comparison_level_library.html#splink.comparison_level_library.levenshtein_level","text":"Represents a comparison using a levenshtein distance function, Parameters: Name Type Description Default col_name str Input column name required distance_threshold Union [ int , float ] The threshold to use to assess similarity required m_probability float Starting value for m probability. Defaults to None. None Returns: Name Type Description ComparisonLevel ComparisonLevel A comparison level that evaluates the levenshtein similarity Source code in splink/comparison_level_library.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 def levenshtein_level ( col_name : str , distance_threshold : int , m_probability = None , ) -> ComparisonLevel : \"\"\"Represents a comparison using a levenshtein distance function, Args: col_name (str): Input column name distance_threshold (Union[int, float]): The threshold to use to assess similarity m_probability (float, optional): Starting value for m probability. Defaults to None. Returns: ComparisonLevel: A comparison level that evaluates the levenshtein similarity \"\"\" lev_name = _mutable_params [ \"levenshtein\" ] return distance_function_level ( col_name , lev_name , distance_threshold , False , m_probability = m_probability , )","title":"levenshtein_level()"},{"location":"comparison_level_library.html#splink.comparison_level_library.jaccard_level","text":"Represents a comparison using a jaccard distance function Parameters: Name Type Description Default col_name str Input column name required distance_threshold Union [ int , float ] The threshold to use to assess similarity required m_probability float Starting value for m probability. Defaults to None. None Returns: Name Type Description ComparisonLevel ComparisonLevel A comparison level that evaluates the jaccard similarity Source code in splink/comparison_level_library.py 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 def jaccard_level ( col_name : str , distance_threshold : Union [ int , float ], m_probability = None , ) -> ComparisonLevel : \"\"\"Represents a comparison using a jaccard distance function Args: col_name (str): Input column name distance_threshold (Union[int, float]): The threshold to use to assess similarity m_probability (float, optional): Starting value for m probability. Defaults to None. Returns: ComparisonLevel: A comparison level that evaluates the jaccard similarity \"\"\" return distance_function_level ( col_name , \"jaccard\" , distance_threshold , True , m_probability = m_probability , )","title":"jaccard_level()"},{"location":"comparison_level_library.html#splink.comparison_level_library.else_level","text":"Source code in splink/comparison_level_library.py 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 def else_level ( m_probability = None , ) -> ComparisonLevel : if isinstance ( m_probability , str ): raise ValueError ( \"You provided a string for the value of m probability when it should be \" \"numeric. Perhaps you passed a column name. Note that you do not need to \" \"pass a column name into the else level.\" ) level_dict = { \"sql_condition\" : \"ELSE\" , \"label_for_charts\" : \"All other comparisons\" , } if m_probability : level_dict [ \"m_probability\" ] = m_probability return ComparisonLevel ( level_dict )","title":"else_level()"},{"location":"comparison_level_library.html#splink.comparison_level_library.columns_reversed_level","text":"Represents a comparison where the columns are reversed. For example, if surname is in the forename field and vice versa Parameters: Name Type Description Default col_name_1 str First column, e.g. forename required col_name_2 str Second column, e.g. surname required m_probability float Starting value for m probability. Defaults to None. None tf_adjustment_column str Column to use for term frequency adjustments if an exact match is observed. Defaults to None. None Returns: Name Type Description ComparisonLevel ComparisonLevel A comparison level that evaluates the exact match of two columns. Source code in splink/comparison_level_library.py 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 def columns_reversed_level ( col_name_1 : str , col_name_2 : str , m_probability = None , tf_adjustment_column = None ) -> ComparisonLevel : \"\"\"Represents a comparison where the columns are reversed. For example, if surname is in the forename field and vice versa Args: col_name_1 (str): First column, e.g. forename col_name_2 (str): Second column, e.g. surname m_probability (float, optional): Starting value for m probability. Defaults to None. tf_adjustment_column (str, optional): Column to use for term frequency adjustments if an exact match is observed. Defaults to None. Returns: ComparisonLevel: A comparison level that evaluates the exact match of two columns. \"\"\" col_1 = InputColumn ( col_name_1 , sql_dialect = _mutable_params [ \"dialect\" ]) col_2 = InputColumn ( col_name_2 , sql_dialect = _mutable_params [ \"dialect\" ]) s = f \" { col_1 . name_l () } = { col_2 . name_r () } and { col_1 . name_r () } = { col_2 . name_l () } \" level_dict = { \"sql_condition\" : s , \"label_for_charts\" : \"Exact match on reversed cols\" , } if m_probability : level_dict [ \"m_probability\" ] = m_probability if tf_adjustment_column : level_dict [ \"tf_adjustment_column\" ] = tf_adjustment_column return ComparisonLevel ( level_dict , sql_dialect = _mutable_params [ \"dialect\" ])","title":"columns_reversed_level()"},{"location":"comparison_library.html","tags":["API","comparisons"],"text":"Documentation for comparison_library \u00b6 exact_match ( col_name , term_frequency_adjustments = False , m_probability_exact_match = None , m_probability_else = None ) \u00b6 A comparison of the data in col_name with two levels: - Exact match - Anything else Parameters: Name Type Description Default col_name str The name of the column to compare required term_frequency_adjustments bool If True, term frequency adjustments will be made on the exact match level. Defaults to False. False m_probability_exact_match _type_ If provided, overrides the default m probability for the exact match level. Defaults to None. None m_probability_else _type_ If provided, overrides the default m probability for the 'anything else' level. Defaults to None. None Returns: Name Type Description Comparison Comparison A comparison that can be inclued in the Splink settings dictionary Source code in splink/comparison_library.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 def exact_match ( col_name , term_frequency_adjustments = False , m_probability_exact_match = None , m_probability_else = None , ) -> Comparison : \"\"\"A comparison of the data in `col_name` with two levels: - Exact match - Anything else Args: col_name (str): The name of the column to compare term_frequency_adjustments (bool, optional): If True, term frequency adjustments will be made on the exact match level. Defaults to False. m_probability_exact_match (_type_, optional): If provided, overrides the default m probability for the exact match level. Defaults to None. m_probability_else (_type_, optional): If provided, overrides the default m probability for the 'anything else' level. Defaults to None. Returns: Comparison: A comparison that can be inclued in the Splink settings dictionary \"\"\" comparison_dict = { \"comparison_description\" : \"Exact match vs. anything else\" , \"comparison_levels\" : [ cl . null_level ( col_name ), cl . exact_match_level ( col_name , term_frequency_adjustments = term_frequency_adjustments , m_probability = m_probability_exact_match , ), cl . else_level ( m_probability = m_probability_else ), ], } return Comparison ( comparison_dict ) distance_function_at_thresholds ( col_name , distance_function_name , distance_threshold_or_thresholds , higher_is_more_similar = True , include_exact_match_level = True , term_frequency_adjustments = False , m_probability_exact_match = None , m_probability_or_probabilities_lev = None , m_probability_else = None ) \u00b6 A comparison of the data in col_name with a user-provided distance function used to assess middle similarity levels. The user-provided distance function must exist in the SQL backend. An example of the output with default arguments and setting distance_function_name to jaccard and distance_threshold_or_thresholds = [0.9,0.7] would be - Exact match - Jaccard distance <= 0.9 - Jaccard distance <= 0.7 - Anything else Parameters: Name Type Description Default col_name str The name of the column to compare required distance_function_name str The name of the distance function required distance_threshold_or_thresholds Union [ int , list ] The threshold(s) to use for the middle similarity level(s). Defaults to [1, 2]. required higher_is_more_similar bool If True, a higher value of the distance function indicates a higher similarity (e.g. jaro_winkler). If false, a higher value indicates a lower similarity (e.g. levenshtein). True include_exact_match_level bool If True, include an exact match level. Defaults to True. True term_frequency_adjustments bool If True, apply term frequency adjustments to the exact match level. Defaults to False. False m_probability_exact_match _type_ If provided, overrides the default m probability for the exact match level. Defaults to None. None m_probability_or_probabilities_lev Union [ float , list ] description . If provided, overrides the default m probabilities for the thresholds specified. Defaults to None. None m_probability_else _type_ If provided, overrides the default m probability for the 'anything else' level. Defaults to None. None Returns: Name Type Description Comparison Comparison Source code in splink/comparison_library.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 def distance_function_at_thresholds ( col_name : str , distance_function_name : str , distance_threshold_or_thresholds : Union [ int , list ], higher_is_more_similar : bool = True , include_exact_match_level = True , term_frequency_adjustments = False , m_probability_exact_match = None , m_probability_or_probabilities_lev : Union [ float , list ] = None , m_probability_else = None , ) -> Comparison : \"\"\"A comparison of the data in `col_name` with a user-provided distance function used to assess middle similarity levels. The user-provided distance function must exist in the SQL backend. An example of the output with default arguments and setting `distance_function_name` to `jaccard` and `distance_threshold_or_thresholds = [0.9,0.7]` would be - Exact match - Jaccard distance <= 0.9 - Jaccard distance <= 0.7 - Anything else Args: col_name (str): The name of the column to compare distance_function_name (str): The name of the distance function distance_threshold_or_thresholds (Union[int, list], optional): The threshold(s) to use for the middle similarity level(s). Defaults to [1, 2]. higher_is_more_similar (bool): If True, a higher value of the distance function indicates a higher similarity (e.g. jaro_winkler). If false, a higher value indicates a lower similarity (e.g. levenshtein). include_exact_match_level (bool, optional): If True, include an exact match level. Defaults to True. term_frequency_adjustments (bool, optional): If True, apply term frequency adjustments to the exact match level. Defaults to False. m_probability_exact_match (_type_, optional): If provided, overrides the default m probability for the exact match level. Defaults to None. m_probability_or_probabilities_lev (Union[float, list], optional): _description_. If provided, overrides the default m probabilities for the thresholds specified. Defaults to None. m_probability_else (_type_, optional): If provided, overrides the default m probability for the 'anything else' level. Defaults to None. Returns: Comparison: \"\"\" distance_thresholds = ensure_is_iterable ( distance_threshold_or_thresholds ) if m_probability_or_probabilities_lev is None : m_probability_or_probabilities_lev = [ None ] * len ( distance_thresholds ) m_probabilities = ensure_is_iterable ( m_probability_or_probabilities_lev ) comparison_levels = [] comparison_levels . append ( cl . null_level ( col_name )) if include_exact_match_level : level = cl . exact_match_level ( col_name , term_frequency_adjustments = term_frequency_adjustments , m_probability = m_probability_exact_match , ) comparison_levels . append ( level ) for thres , m_prob in zip ( distance_thresholds , m_probabilities ): level = cl . distance_function_level ( col_name , distance_function_name = distance_function_name , higher_is_more_similar = higher_is_more_similar , distance_threshold = thres , m_probability = m_prob , ) comparison_levels . append ( level ) comparison_levels . append ( cl . else_level ( m_probability = m_probability_else ), ) comparison_desc = \"\" if include_exact_match_level : comparison_desc += \"Exact match vs. \" thres_desc = \", \" . join ([ str ( d ) for d in distance_thresholds ]) plural = \"\" if len ( distance_thresholds ) == 1 else \"s\" comparison_desc += ( f \" { distance_function_name } at threshold { plural } { thres_desc } vs. \" ) comparison_desc += \"anything else\" comparison_dict = { \"comparison_description\" : comparison_desc , \"comparison_levels\" : comparison_levels , } return Comparison ( comparison_dict ) levenshtein_at_thresholds ( col_name , distance_threshold_or_thresholds = [ 1 , 2 ], include_exact_match_level = True , term_frequency_adjustments = False , m_probability_exact_match = None , m_probability_or_probabilities_lev = None , m_probability_else = None ) \u00b6 A comparison of the data in col_name with the levenshtein distance used to assess middle similarity levels. An example of the output with default arguments and setting distance_threshold_or_thresholds = [1,2] would be - Exact match - levenshtein distance <= 1 - levenshtein distance <= 2 - Anything else Parameters: Name Type Description Default col_name str The name of the column to compare required distance_threshold_or_thresholds Union [ int , list ] The threshold(s) to use for the middle similarity level(s). Defaults to [1, 2]. [1, 2] include_exact_match_level bool If True, include an exact match level. Defaults to True. True term_frequency_adjustments bool If True, apply term frequency adjustments to the exact match level. Defaults to False. False m_probability_exact_match _type_ If provided, overrides the default m probability for the exact match level. Defaults to None. None m_probability_or_probabilities_lev Union [ float , list ] description . If provided, overrides the default m probabilities for the thresholds specified. Defaults to None. None m_probability_else _type_ If provided, overrides the default m probability for the 'anything else' level. Defaults to None. None Returns: Name Type Description Comparison Comparison Source code in splink/comparison_library.py 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 def levenshtein_at_thresholds ( col_name : str , distance_threshold_or_thresholds : Union [ int , list ] = [ 1 , 2 ], include_exact_match_level = True , term_frequency_adjustments = False , m_probability_exact_match = None , m_probability_or_probabilities_lev : Union [ float , list ] = None , m_probability_else = None , ) -> Comparison : \"\"\"A comparison of the data in `col_name` with the levenshtein distance used to assess middle similarity levels. An example of the output with default arguments and setting `distance_threshold_or_thresholds = [1,2]` would be - Exact match - levenshtein distance <= 1 - levenshtein distance <= 2 - Anything else Args: col_name (str): The name of the column to compare distance_threshold_or_thresholds (Union[int, list], optional): The threshold(s) to use for the middle similarity level(s). Defaults to [1, 2]. include_exact_match_level (bool, optional): If True, include an exact match level. Defaults to True. term_frequency_adjustments (bool, optional): If True, apply term frequency adjustments to the exact match level. Defaults to False. m_probability_exact_match (_type_, optional): If provided, overrides the default m probability for the exact match level. Defaults to None. m_probability_or_probabilities_lev (Union[float, list], optional): _description_. If provided, overrides the default m probabilities for the thresholds specified. Defaults to None. m_probability_else (_type_, optional): If provided, overrides the default m probability for the 'anything else' level. Defaults to None. Returns: Comparison: \"\"\" return distance_function_at_thresholds ( col_name , cl . _mutable_params [ \"levenshtein\" ], distance_threshold_or_thresholds , False , include_exact_match_level , term_frequency_adjustments , m_probability_exact_match , m_probability_or_probabilities_lev , m_probability_else , ) jaccard_at_thresholds ( col_name , distance_threshold_or_thresholds = [ 0.9 , 0.7 ], include_exact_match_level = True , term_frequency_adjustments = False , m_probability_exact_match = None , m_probability_or_probabilities_lev = None , m_probability_else = None ) \u00b6 A comparison of the data in col_name with the jaccard distance used to assess middle similarity levels. An example of the output with default arguments and setting distance_threshold_or_thresholds = [1,2] would be - Exact match - Jaccard distance <= 0.9 - Jaccard distance <= 0.7 - Anything else Parameters: Name Type Description Default col_name str The name of the column to compare required distance_threshold_or_thresholds Union [ int , list ] The threshold(s) to use for the middle similarity level(s). Defaults to [0.9, 0.7]. [0.9, 0.7] include_exact_match_level bool If True, include an exact match level. Defaults to True. True term_frequency_adjustments bool If True, apply term frequency adjustments to the exact match level. Defaults to False. False m_probability_exact_match _type_ If provided, overrides the default m probability for the exact match level. Defaults to None. None m_probability_or_probabilities_lev Union [ float , list ] description . If provided, overrides the default m probabilities for the thresholds specified. Defaults to None. None m_probability_else _type_ If provided, overrides the default m probability for the 'anything else' level. Defaults to None. None Returns: Name Type Description Comparison Comparison Source code in splink/comparison_library.py 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 def jaccard_at_thresholds ( col_name : str , distance_threshold_or_thresholds : Union [ int , list ] = [ 0.9 , 0.7 ], include_exact_match_level = True , term_frequency_adjustments = False , m_probability_exact_match = None , m_probability_or_probabilities_lev : Union [ float , list ] = None , m_probability_else = None , ) -> Comparison : \"\"\"A comparison of the data in `col_name` with the jaccard distance used to assess middle similarity levels. An example of the output with default arguments and setting `distance_threshold_or_thresholds = [1,2]` would be - Exact match - Jaccard distance <= 0.9 - Jaccard distance <= 0.7 - Anything else Args: col_name (str): The name of the column to compare distance_threshold_or_thresholds (Union[int, list], optional): The threshold(s) to use for the middle similarity level(s). Defaults to [0.9, 0.7]. include_exact_match_level (bool, optional): If True, include an exact match level. Defaults to True. term_frequency_adjustments (bool, optional): If True, apply term frequency adjustments to the exact match level. Defaults to False. m_probability_exact_match (_type_, optional): If provided, overrides the default m probability for the exact match level. Defaults to None. m_probability_or_probabilities_lev (Union[float, list], optional): _description_. If provided, overrides the default m probabilities for the thresholds specified. Defaults to None. m_probability_else (_type_, optional): If provided, overrides the default m probability for the 'anything else' level. Defaults to None. Returns: Comparison: \"\"\" return distance_function_at_thresholds ( col_name , \"jaccard\" , distance_threshold_or_thresholds , True , include_exact_match_level , term_frequency_adjustments , m_probability_exact_match , m_probability_or_probabilities_lev , m_probability_else , )","title":"Comparison Library"},{"location":"comparison_library.html#documentation-for-comparison_library","text":"","title":"Documentation for comparison_library"},{"location":"comparison_library.html#splink.comparison_library.exact_match","text":"A comparison of the data in col_name with two levels: - Exact match - Anything else Parameters: Name Type Description Default col_name str The name of the column to compare required term_frequency_adjustments bool If True, term frequency adjustments will be made on the exact match level. Defaults to False. False m_probability_exact_match _type_ If provided, overrides the default m probability for the exact match level. Defaults to None. None m_probability_else _type_ If provided, overrides the default m probability for the 'anything else' level. Defaults to None. None Returns: Name Type Description Comparison Comparison A comparison that can be inclued in the Splink settings dictionary Source code in splink/comparison_library.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 def exact_match ( col_name , term_frequency_adjustments = False , m_probability_exact_match = None , m_probability_else = None , ) -> Comparison : \"\"\"A comparison of the data in `col_name` with two levels: - Exact match - Anything else Args: col_name (str): The name of the column to compare term_frequency_adjustments (bool, optional): If True, term frequency adjustments will be made on the exact match level. Defaults to False. m_probability_exact_match (_type_, optional): If provided, overrides the default m probability for the exact match level. Defaults to None. m_probability_else (_type_, optional): If provided, overrides the default m probability for the 'anything else' level. Defaults to None. Returns: Comparison: A comparison that can be inclued in the Splink settings dictionary \"\"\" comparison_dict = { \"comparison_description\" : \"Exact match vs. anything else\" , \"comparison_levels\" : [ cl . null_level ( col_name ), cl . exact_match_level ( col_name , term_frequency_adjustments = term_frequency_adjustments , m_probability = m_probability_exact_match , ), cl . else_level ( m_probability = m_probability_else ), ], } return Comparison ( comparison_dict )","title":"exact_match()"},{"location":"comparison_library.html#splink.comparison_library.distance_function_at_thresholds","text":"A comparison of the data in col_name with a user-provided distance function used to assess middle similarity levels. The user-provided distance function must exist in the SQL backend. An example of the output with default arguments and setting distance_function_name to jaccard and distance_threshold_or_thresholds = [0.9,0.7] would be - Exact match - Jaccard distance <= 0.9 - Jaccard distance <= 0.7 - Anything else Parameters: Name Type Description Default col_name str The name of the column to compare required distance_function_name str The name of the distance function required distance_threshold_or_thresholds Union [ int , list ] The threshold(s) to use for the middle similarity level(s). Defaults to [1, 2]. required higher_is_more_similar bool If True, a higher value of the distance function indicates a higher similarity (e.g. jaro_winkler). If false, a higher value indicates a lower similarity (e.g. levenshtein). True include_exact_match_level bool If True, include an exact match level. Defaults to True. True term_frequency_adjustments bool If True, apply term frequency adjustments to the exact match level. Defaults to False. False m_probability_exact_match _type_ If provided, overrides the default m probability for the exact match level. Defaults to None. None m_probability_or_probabilities_lev Union [ float , list ] description . If provided, overrides the default m probabilities for the thresholds specified. Defaults to None. None m_probability_else _type_ If provided, overrides the default m probability for the 'anything else' level. Defaults to None. None Returns: Name Type Description Comparison Comparison Source code in splink/comparison_library.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 def distance_function_at_thresholds ( col_name : str , distance_function_name : str , distance_threshold_or_thresholds : Union [ int , list ], higher_is_more_similar : bool = True , include_exact_match_level = True , term_frequency_adjustments = False , m_probability_exact_match = None , m_probability_or_probabilities_lev : Union [ float , list ] = None , m_probability_else = None , ) -> Comparison : \"\"\"A comparison of the data in `col_name` with a user-provided distance function used to assess middle similarity levels. The user-provided distance function must exist in the SQL backend. An example of the output with default arguments and setting `distance_function_name` to `jaccard` and `distance_threshold_or_thresholds = [0.9,0.7]` would be - Exact match - Jaccard distance <= 0.9 - Jaccard distance <= 0.7 - Anything else Args: col_name (str): The name of the column to compare distance_function_name (str): The name of the distance function distance_threshold_or_thresholds (Union[int, list], optional): The threshold(s) to use for the middle similarity level(s). Defaults to [1, 2]. higher_is_more_similar (bool): If True, a higher value of the distance function indicates a higher similarity (e.g. jaro_winkler). If false, a higher value indicates a lower similarity (e.g. levenshtein). include_exact_match_level (bool, optional): If True, include an exact match level. Defaults to True. term_frequency_adjustments (bool, optional): If True, apply term frequency adjustments to the exact match level. Defaults to False. m_probability_exact_match (_type_, optional): If provided, overrides the default m probability for the exact match level. Defaults to None. m_probability_or_probabilities_lev (Union[float, list], optional): _description_. If provided, overrides the default m probabilities for the thresholds specified. Defaults to None. m_probability_else (_type_, optional): If provided, overrides the default m probability for the 'anything else' level. Defaults to None. Returns: Comparison: \"\"\" distance_thresholds = ensure_is_iterable ( distance_threshold_or_thresholds ) if m_probability_or_probabilities_lev is None : m_probability_or_probabilities_lev = [ None ] * len ( distance_thresholds ) m_probabilities = ensure_is_iterable ( m_probability_or_probabilities_lev ) comparison_levels = [] comparison_levels . append ( cl . null_level ( col_name )) if include_exact_match_level : level = cl . exact_match_level ( col_name , term_frequency_adjustments = term_frequency_adjustments , m_probability = m_probability_exact_match , ) comparison_levels . append ( level ) for thres , m_prob in zip ( distance_thresholds , m_probabilities ): level = cl . distance_function_level ( col_name , distance_function_name = distance_function_name , higher_is_more_similar = higher_is_more_similar , distance_threshold = thres , m_probability = m_prob , ) comparison_levels . append ( level ) comparison_levels . append ( cl . else_level ( m_probability = m_probability_else ), ) comparison_desc = \"\" if include_exact_match_level : comparison_desc += \"Exact match vs. \" thres_desc = \", \" . join ([ str ( d ) for d in distance_thresholds ]) plural = \"\" if len ( distance_thresholds ) == 1 else \"s\" comparison_desc += ( f \" { distance_function_name } at threshold { plural } { thres_desc } vs. \" ) comparison_desc += \"anything else\" comparison_dict = { \"comparison_description\" : comparison_desc , \"comparison_levels\" : comparison_levels , } return Comparison ( comparison_dict )","title":"distance_function_at_thresholds()"},{"location":"comparison_library.html#splink.comparison_library.levenshtein_at_thresholds","text":"A comparison of the data in col_name with the levenshtein distance used to assess middle similarity levels. An example of the output with default arguments and setting distance_threshold_or_thresholds = [1,2] would be - Exact match - levenshtein distance <= 1 - levenshtein distance <= 2 - Anything else Parameters: Name Type Description Default col_name str The name of the column to compare required distance_threshold_or_thresholds Union [ int , list ] The threshold(s) to use for the middle similarity level(s). Defaults to [1, 2]. [1, 2] include_exact_match_level bool If True, include an exact match level. Defaults to True. True term_frequency_adjustments bool If True, apply term frequency adjustments to the exact match level. Defaults to False. False m_probability_exact_match _type_ If provided, overrides the default m probability for the exact match level. Defaults to None. None m_probability_or_probabilities_lev Union [ float , list ] description . If provided, overrides the default m probabilities for the thresholds specified. Defaults to None. None m_probability_else _type_ If provided, overrides the default m probability for the 'anything else' level. Defaults to None. None Returns: Name Type Description Comparison Comparison Source code in splink/comparison_library.py 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 def levenshtein_at_thresholds ( col_name : str , distance_threshold_or_thresholds : Union [ int , list ] = [ 1 , 2 ], include_exact_match_level = True , term_frequency_adjustments = False , m_probability_exact_match = None , m_probability_or_probabilities_lev : Union [ float , list ] = None , m_probability_else = None , ) -> Comparison : \"\"\"A comparison of the data in `col_name` with the levenshtein distance used to assess middle similarity levels. An example of the output with default arguments and setting `distance_threshold_or_thresholds = [1,2]` would be - Exact match - levenshtein distance <= 1 - levenshtein distance <= 2 - Anything else Args: col_name (str): The name of the column to compare distance_threshold_or_thresholds (Union[int, list], optional): The threshold(s) to use for the middle similarity level(s). Defaults to [1, 2]. include_exact_match_level (bool, optional): If True, include an exact match level. Defaults to True. term_frequency_adjustments (bool, optional): If True, apply term frequency adjustments to the exact match level. Defaults to False. m_probability_exact_match (_type_, optional): If provided, overrides the default m probability for the exact match level. Defaults to None. m_probability_or_probabilities_lev (Union[float, list], optional): _description_. If provided, overrides the default m probabilities for the thresholds specified. Defaults to None. m_probability_else (_type_, optional): If provided, overrides the default m probability for the 'anything else' level. Defaults to None. Returns: Comparison: \"\"\" return distance_function_at_thresholds ( col_name , cl . _mutable_params [ \"levenshtein\" ], distance_threshold_or_thresholds , False , include_exact_match_level , term_frequency_adjustments , m_probability_exact_match , m_probability_or_probabilities_lev , m_probability_else , )","title":"levenshtein_at_thresholds()"},{"location":"comparison_library.html#splink.comparison_library.jaccard_at_thresholds","text":"A comparison of the data in col_name with the jaccard distance used to assess middle similarity levels. An example of the output with default arguments and setting distance_threshold_or_thresholds = [1,2] would be - Exact match - Jaccard distance <= 0.9 - Jaccard distance <= 0.7 - Anything else Parameters: Name Type Description Default col_name str The name of the column to compare required distance_threshold_or_thresholds Union [ int , list ] The threshold(s) to use for the middle similarity level(s). Defaults to [0.9, 0.7]. [0.9, 0.7] include_exact_match_level bool If True, include an exact match level. Defaults to True. True term_frequency_adjustments bool If True, apply term frequency adjustments to the exact match level. Defaults to False. False m_probability_exact_match _type_ If provided, overrides the default m probability for the exact match level. Defaults to None. None m_probability_or_probabilities_lev Union [ float , list ] description . If provided, overrides the default m probabilities for the thresholds specified. Defaults to None. None m_probability_else _type_ If provided, overrides the default m probability for the 'anything else' level. Defaults to None. None Returns: Name Type Description Comparison Comparison Source code in splink/comparison_library.py 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 def jaccard_at_thresholds ( col_name : str , distance_threshold_or_thresholds : Union [ int , list ] = [ 0.9 , 0.7 ], include_exact_match_level = True , term_frequency_adjustments = False , m_probability_exact_match = None , m_probability_or_probabilities_lev : Union [ float , list ] = None , m_probability_else = None , ) -> Comparison : \"\"\"A comparison of the data in `col_name` with the jaccard distance used to assess middle similarity levels. An example of the output with default arguments and setting `distance_threshold_or_thresholds = [1,2]` would be - Exact match - Jaccard distance <= 0.9 - Jaccard distance <= 0.7 - Anything else Args: col_name (str): The name of the column to compare distance_threshold_or_thresholds (Union[int, list], optional): The threshold(s) to use for the middle similarity level(s). Defaults to [0.9, 0.7]. include_exact_match_level (bool, optional): If True, include an exact match level. Defaults to True. term_frequency_adjustments (bool, optional): If True, apply term frequency adjustments to the exact match level. Defaults to False. m_probability_exact_match (_type_, optional): If provided, overrides the default m probability for the exact match level. Defaults to None. m_probability_or_probabilities_lev (Union[float, list], optional): _description_. If provided, overrides the default m probabilities for the thresholds specified. Defaults to None. m_probability_else (_type_, optional): If provided, overrides the default m probability for the 'anything else' level. Defaults to None. Returns: Comparison: \"\"\" return distance_function_at_thresholds ( col_name , \"jaccard\" , distance_threshold_or_thresholds , True , include_exact_match_level , term_frequency_adjustments , m_probability_exact_match , m_probability_or_probabilities_lev , m_probability_else , )","title":"jaccard_at_thresholds()"},{"location":"em_training_session.html","tags":["API","Expectation Maximisation"],"text":"Documentation for EMTrainingSession object \u00b6 Manages training models using the Expectation Maximisation algorithm, and holds statistics on the evolution of parameter estimates. Plots diagnostic charts Source code in splink/em_training_session.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 class EMTrainingSession : \"\"\"Manages training models using the Expectation Maximisation algorithm, and holds statistics on the evolution of parameter estimates. Plots diagnostic charts \"\"\" def __init__ ( self , linker : \"Linker\" , blocking_rule_for_training : str , fix_u_probabilities : bool = False , fix_m_probabilities : bool = False , fix_probability_two_random_records_match : bool = False , comparisons_to_deactivate : List [ Comparison ] = None , comparison_levels_to_reverse_blocking_rule : List [ ComparisonLevel ] = None , ): logger . info ( \" \\n ----- Starting EM training session ----- \\n \" ) self . _original_settings_obj = linker . _settings_obj self . _original_linker = linker self . _training_linker = deepcopy ( linker ) self . _settings_obj = self . _training_linker . _settings_obj self . _settings_obj . _retain_matching_columns = False self . _settings_obj . _retain_intermediate_calculation_columns = False self . _settings_obj . _training_mode = True if not isinstance ( blocking_rule_for_training , BlockingRule ): blocking_rule = BlockingRule ( blocking_rule_for_training ) self . _settings_obj . _blocking_rule_for_training = blocking_rule self . _blocking_rule_for_training = blocking_rule if comparison_levels_to_reverse_blocking_rule : self . _comparison_levels_to_reverse_blocking_rule = ( comparison_levels_to_reverse_blocking_rule ) else : self . _comparison_levels_to_reverse_blocking_rule = self . _original_settings_obj . _get_comparison_levels_corresponding_to_training_blocking_rule ( # noqa blocking_rule_for_training ) self . _settings_obj . _probability_two_random_records_match = ( self . _blocking_adjusted_probability_two_random_records_match ) self . _training_fix_u_probabilities = fix_u_probabilities self . _training_fix_m_probabilities = fix_m_probabilities self . _training_fix_probability_two_random_records_match = ( fix_probability_two_random_records_match ) # Remove comparison columns which are either 'used up' by the blocking rules # or alternatively, if the user has manually provided a list to remove, # use this instead if not comparisons_to_deactivate : comparisons_to_deactivate = [] br_cols = get_columns_used_from_sql ( blocking_rule_for_training , self . _settings_obj . _sql_dialect ) for cc in self . _settings_obj . comparisons : cc_cols = cc . _input_columns_used_by_case_statement cc_cols = [ c . input_name for c in cc_cols ] if set ( br_cols ) . intersection ( cc_cols ): comparisons_to_deactivate . append ( cc ) cc_names_to_deactivate = [ cc . _output_column_name for cc in comparisons_to_deactivate ] self . _comparisons_that_cannot_be_estimated : List [ Comparison ] = comparisons_to_deactivate filtered_ccs = [ cc for cc in self . _settings_obj . comparisons if cc . _output_column_name not in cc_names_to_deactivate ] self . _settings_obj . comparisons = filtered_ccs self . _comparisons_that_can_be_estimated = filtered_ccs self . _settings_obj_history = [] # Add iteration 0 i.e. the starting parameters self . _add_iteration () def _training_log_message ( self ): not_estimated = [ cc . _output_column_name for cc in self . _comparisons_that_cannot_be_estimated ] not_estimated = \"\" . join ([ f \" \\n - { cc } \" for cc in not_estimated ]) estimated = [ cc . _output_column_name for cc in self . _comparisons_that_can_be_estimated ] estimated = \"\" . join ([ f \" \\n - { cc } \" for cc in estimated ]) if self . _training_fix_m_probabilities and self . _training_fix_u_probabilities : raise ValueError ( \"Can't train model if you fix both m and u probabilites\" ) elif self . _training_fix_u_probabilities : mu = \"m probabilities\" elif self . _training_fix_m_probabilities : mu = \"u probabilities\" else : mu = \"m and u probabilities\" blocking_rule = self . _blocking_rule_for_training . blocking_rule logger . info ( f \"Estimating the { mu } of the model by blocking on: \\n \" f \" { blocking_rule } \\n\\n \" \"Parameter estimates will be made for the following comparison(s):\" f \" { estimated } \\n \" \" \\n Parameter estimates cannot be made for the following comparison(s)\" f \" since they are used in the blocking rules: { not_estimated } \" ) def _comparison_vectors ( self ): self . _training_log_message () sql = block_using_rules_sql ( self . _training_linker ) self . _training_linker . _enqueue_sql ( sql , \"__splink__df_blocked\" ) # repartition after blocking only exists on the SparkLinker repartition_after_blocking = getattr ( self . _original_linker , \"repartition_after_blocking\" , False ) if repartition_after_blocking : df_blocked = self . _training_linker . _execute_sql_pipeline ([]) input_dataframes = [ df_blocked ] else : input_dataframes = [] sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _training_linker . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) return self . _training_linker . _execute_sql_pipeline ( input_dataframes ) def _train ( self ): cvv = self . _comparison_vectors () # Compute the new params, populating the paramters in the copied settings object # At this stage, we do not overwrite any of the parameters # in the original (main) setting object expectation_maximisation ( self , cvv ) rule = self . _blocking_rule_for_training . blocking_rule training_desc = f \"EM, blocked on: { rule } \" # Add m and u values to original settings for cc in self . _settings_obj . comparisons : orig_cc = self . _original_settings_obj . _get_comparison_by_output_column_name ( cc . _output_column_name ) for cl in cc . _comparison_levels_excluding_null : orig_cl = orig_cc . _get_comparison_level_by_comparison_vector_value ( cl . _comparison_vector_value ) if not self . _training_fix_m_probabilities : not_observed = \"level not observed in training dataset\" if cl . _m_probability == not_observed : orig_cl . _add_trained_m_probability ( not_observed , training_desc ) logger . info ( f \"m probability not trained for { cc . _output_column_name } - \" f \" { cl . _label_for_charts } (comparison vector value: \" f \" { cl . _comparison_vector_value } ). This usually means the \" \"comparison level was never observed in the training data.\" ) else : orig_cl . _add_trained_m_probability ( cl . m_probability , training_desc ) if not self . _training_fix_u_probabilities : not_observed = \"level not observed in training dataset\" if cl . _u_probability == not_observed : orig_cl . _add_trained_u_probability ( not_observed , training_desc ) logger . info ( f \"u probability not trained for { cc . _output_column_name } - \" f \" { cl . _label_for_charts } (comparison vector value: \" f \" { cl . _comparison_vector_value } ). This usually means the \" \"comparison level was never observed in the training data.\" ) else : orig_cl . _add_trained_u_probability ( cl . u_probability , training_desc ) self . _original_linker . _em_training_sessions . append ( self ) def _add_iteration ( self ): self . _settings_obj_history . append ( deepcopy ( self . _settings_obj )) @property def _blocking_adjusted_probability_two_random_records_match ( self ): orig_prop_m = self . _original_settings_obj . _probability_two_random_records_match adj_bayes_factor = prob_to_bayes_factor ( orig_prop_m ) logger . log ( 15 , f \"Original prob two random records match: { orig_prop_m : .3f } \" ) comp_levels = self . _comparison_levels_to_reverse_blocking_rule if not comp_levels : comp_levels = self . _original_settings_obj . _get_comparison_levels_corresponding_to_training_blocking_rule ( # noqa self . _blocking_rule_for_training . blocking_rule ) for cl in comp_levels : adj_bayes_factor = cl . _bayes_factor * adj_bayes_factor logger . log ( 15 , f \"Increasing prob two random records match using \" f \" { cl . comparison . _output_column_name } - { cl . _label_for_charts } \" f \" using bayes factor { cl . _bayes_factor : ,.3f } \" , ) adjusted_prop_m = bayes_factor_to_prob ( adj_bayes_factor ) logger . log ( 15 , f \" \\n Prob two random records match adjusted for blocking on \" f \" { self . _blocking_rule_for_training . blocking_rule } : \" f \" { adjusted_prop_m : .3f } \" , ) return adjusted_prop_m @property def _iteration_history_records ( self ): output_records = [] for iteration , settings_obj in enumerate ( self . _settings_obj_history ): records = settings_obj . _parameters_as_detailed_records for r in records : r [ \"iteration\" ] = iteration r [ \"probability_two_random_records_match\" ] = self . _settings_obj . _probability_two_random_records_match output_records . extend ( records ) return output_records @property def _lambda_history_records ( self ): output_records = [] for i , s in enumerate ( self . _settings_obj_history ): lam = s . _probability_two_random_records_match r = { \"probability_two_random_records_match\" : lam , \"probability_two_random_records_match_reciprocal\" : 1 / lam , \"iteration\" : i , } output_records . append ( r ) return output_records def probability_two_random_records_match_iteration_chart ( self ): records = self . _lambda_history_records return probability_two_random_records_match_iteration_chart ( records ) def match_weights_interactive_history_chart ( self ): records = self . _iteration_history_records return match_weights_interactive_history_chart ( records , blocking_rule = self . _blocking_rule_for_training ) def m_u_values_interactive_history_chart ( self ): records = self . _iteration_history_records return m_u_parameters_interactive_history_chart ( records ) def _max_change_message ( self , max_change_dict ): message = \"Largest change in params was\" if max_change_dict [ \"max_change_type\" ] == \"probability_two_random_records_match\" : message = ( f \" { message } { max_change_dict [ 'max_change_value' ] : ,.3g } in \" \"probability_two_random_records_match\" ) else : cl = max_change_dict [ \"current_comparison_level\" ] m_u = max_change_dict [ \"max_change_type\" ] cc_name = cl . comparison . _output_column_name cl_label = cl . _label_for_charts level_text = f \" { cc_name } , level ` { cl_label } `\" message = ( f \" { message } { max_change_dict [ 'max_change_value' ] : ,.3g } in \" f \"the { m_u } of { level_text } \" ) return message def _max_change_in_parameters_comparison_levels ( self ): previous_iteration = self . _settings_obj_history [ - 2 ] this_iteration = self . _settings_obj_history [ - 1 ] max_change = - 0.1 max_change_levels = { \"previous_iteration\" : None , \"this_iteration\" : None , \"max_change_type\" : None , \"max_change_value\" : None , } comparisons = zip ( previous_iteration . comparisons , this_iteration . comparisons ) for comparison in comparisons : prev_cc = comparison [ 0 ] this_cc = comparison [ 1 ] z_cls = zip ( prev_cc . comparison_levels , this_cc . comparison_levels ) for z_cl in z_cls : if z_cl [ 0 ] . _is_null_level : continue prev_cl = z_cl [ 0 ] this_cl = z_cl [ 1 ] change_m = this_cl . m_probability - prev_cl . m_probability change_u = this_cl . u_probability - prev_cl . u_probability change = max ( abs ( change_m ), abs ( change_u )) change_type = ( \"m_probability\" if abs ( change_m ) > abs ( change_u ) else \"u_probability\" ) change_value = change_m if abs ( change_m ) > abs ( change_u ) else change_u if change > max_change : max_change = change max_change_levels [ \"prev_comparison_level\" ] = prev_cl max_change_levels [ \"current_comparison_level\" ] = this_cl max_change_levels [ \"max_change_type\" ] = change_type max_change_levels [ \"max_change_value\" ] = change_value max_change_levels [ \"max_abs_change_value\" ] = abs ( change_value ) change_probability_two_random_records_match = ( this_iteration . _probability_two_random_records_match - previous_iteration . _probability_two_random_records_match ) if abs ( change_probability_two_random_records_match ) > max_change : max_change = abs ( change_probability_two_random_records_match ) max_change_levels [ \"prev_comparison_level\" ] = None max_change_levels [ \"current_comparison_level\" ] = None max_change_levels [ \"max_change_type\" ] = \"probability_two_random_records_match\" max_change_levels [ \"max_change_value\" ] = change_probability_two_random_records_match max_change_levels [ \"max_abs_change_value\" ] = abs ( change_probability_two_random_records_match ) max_change_levels [ \"message\" ] = self . _max_change_message ( max_change_levels ) return max_change_levels def __repr__ ( self ): deactivated_cols = \", \" . join ( [ cc . _output_column_name for cc in self . _comparisons_that_cannot_be_estimated ] ) blocking_rule = self . _blocking_rule_for_training . blocking_rule return ( f \"<EMTrainingSession, blocking on { blocking_rule } , \" f \"deactivating comparisons { deactivated_cols } >\" ) match_weights_interactive_history_chart () \u00b6 Source code in splink/em_training_session.py 291 292 293 294 295 def match_weights_interactive_history_chart ( self ): records = self . _iteration_history_records return match_weights_interactive_history_chart ( records , blocking_rule = self . _blocking_rule_for_training ) m_u_values_interactive_history_chart () \u00b6 Source code in splink/em_training_session.py 297 298 299 def m_u_values_interactive_history_chart ( self ): records = self . _iteration_history_records return m_u_parameters_interactive_history_chart ( records )","title":"EM Training Session API"},{"location":"em_training_session.html#documentation-for-emtrainingsession-object","text":"Manages training models using the Expectation Maximisation algorithm, and holds statistics on the evolution of parameter estimates. Plots diagnostic charts Source code in splink/em_training_session.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 class EMTrainingSession : \"\"\"Manages training models using the Expectation Maximisation algorithm, and holds statistics on the evolution of parameter estimates. Plots diagnostic charts \"\"\" def __init__ ( self , linker : \"Linker\" , blocking_rule_for_training : str , fix_u_probabilities : bool = False , fix_m_probabilities : bool = False , fix_probability_two_random_records_match : bool = False , comparisons_to_deactivate : List [ Comparison ] = None , comparison_levels_to_reverse_blocking_rule : List [ ComparisonLevel ] = None , ): logger . info ( \" \\n ----- Starting EM training session ----- \\n \" ) self . _original_settings_obj = linker . _settings_obj self . _original_linker = linker self . _training_linker = deepcopy ( linker ) self . _settings_obj = self . _training_linker . _settings_obj self . _settings_obj . _retain_matching_columns = False self . _settings_obj . _retain_intermediate_calculation_columns = False self . _settings_obj . _training_mode = True if not isinstance ( blocking_rule_for_training , BlockingRule ): blocking_rule = BlockingRule ( blocking_rule_for_training ) self . _settings_obj . _blocking_rule_for_training = blocking_rule self . _blocking_rule_for_training = blocking_rule if comparison_levels_to_reverse_blocking_rule : self . _comparison_levels_to_reverse_blocking_rule = ( comparison_levels_to_reverse_blocking_rule ) else : self . _comparison_levels_to_reverse_blocking_rule = self . _original_settings_obj . _get_comparison_levels_corresponding_to_training_blocking_rule ( # noqa blocking_rule_for_training ) self . _settings_obj . _probability_two_random_records_match = ( self . _blocking_adjusted_probability_two_random_records_match ) self . _training_fix_u_probabilities = fix_u_probabilities self . _training_fix_m_probabilities = fix_m_probabilities self . _training_fix_probability_two_random_records_match = ( fix_probability_two_random_records_match ) # Remove comparison columns which are either 'used up' by the blocking rules # or alternatively, if the user has manually provided a list to remove, # use this instead if not comparisons_to_deactivate : comparisons_to_deactivate = [] br_cols = get_columns_used_from_sql ( blocking_rule_for_training , self . _settings_obj . _sql_dialect ) for cc in self . _settings_obj . comparisons : cc_cols = cc . _input_columns_used_by_case_statement cc_cols = [ c . input_name for c in cc_cols ] if set ( br_cols ) . intersection ( cc_cols ): comparisons_to_deactivate . append ( cc ) cc_names_to_deactivate = [ cc . _output_column_name for cc in comparisons_to_deactivate ] self . _comparisons_that_cannot_be_estimated : List [ Comparison ] = comparisons_to_deactivate filtered_ccs = [ cc for cc in self . _settings_obj . comparisons if cc . _output_column_name not in cc_names_to_deactivate ] self . _settings_obj . comparisons = filtered_ccs self . _comparisons_that_can_be_estimated = filtered_ccs self . _settings_obj_history = [] # Add iteration 0 i.e. the starting parameters self . _add_iteration () def _training_log_message ( self ): not_estimated = [ cc . _output_column_name for cc in self . _comparisons_that_cannot_be_estimated ] not_estimated = \"\" . join ([ f \" \\n - { cc } \" for cc in not_estimated ]) estimated = [ cc . _output_column_name for cc in self . _comparisons_that_can_be_estimated ] estimated = \"\" . join ([ f \" \\n - { cc } \" for cc in estimated ]) if self . _training_fix_m_probabilities and self . _training_fix_u_probabilities : raise ValueError ( \"Can't train model if you fix both m and u probabilites\" ) elif self . _training_fix_u_probabilities : mu = \"m probabilities\" elif self . _training_fix_m_probabilities : mu = \"u probabilities\" else : mu = \"m and u probabilities\" blocking_rule = self . _blocking_rule_for_training . blocking_rule logger . info ( f \"Estimating the { mu } of the model by blocking on: \\n \" f \" { blocking_rule } \\n\\n \" \"Parameter estimates will be made for the following comparison(s):\" f \" { estimated } \\n \" \" \\n Parameter estimates cannot be made for the following comparison(s)\" f \" since they are used in the blocking rules: { not_estimated } \" ) def _comparison_vectors ( self ): self . _training_log_message () sql = block_using_rules_sql ( self . _training_linker ) self . _training_linker . _enqueue_sql ( sql , \"__splink__df_blocked\" ) # repartition after blocking only exists on the SparkLinker repartition_after_blocking = getattr ( self . _original_linker , \"repartition_after_blocking\" , False ) if repartition_after_blocking : df_blocked = self . _training_linker . _execute_sql_pipeline ([]) input_dataframes = [ df_blocked ] else : input_dataframes = [] sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _training_linker . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) return self . _training_linker . _execute_sql_pipeline ( input_dataframes ) def _train ( self ): cvv = self . _comparison_vectors () # Compute the new params, populating the paramters in the copied settings object # At this stage, we do not overwrite any of the parameters # in the original (main) setting object expectation_maximisation ( self , cvv ) rule = self . _blocking_rule_for_training . blocking_rule training_desc = f \"EM, blocked on: { rule } \" # Add m and u values to original settings for cc in self . _settings_obj . comparisons : orig_cc = self . _original_settings_obj . _get_comparison_by_output_column_name ( cc . _output_column_name ) for cl in cc . _comparison_levels_excluding_null : orig_cl = orig_cc . _get_comparison_level_by_comparison_vector_value ( cl . _comparison_vector_value ) if not self . _training_fix_m_probabilities : not_observed = \"level not observed in training dataset\" if cl . _m_probability == not_observed : orig_cl . _add_trained_m_probability ( not_observed , training_desc ) logger . info ( f \"m probability not trained for { cc . _output_column_name } - \" f \" { cl . _label_for_charts } (comparison vector value: \" f \" { cl . _comparison_vector_value } ). This usually means the \" \"comparison level was never observed in the training data.\" ) else : orig_cl . _add_trained_m_probability ( cl . m_probability , training_desc ) if not self . _training_fix_u_probabilities : not_observed = \"level not observed in training dataset\" if cl . _u_probability == not_observed : orig_cl . _add_trained_u_probability ( not_observed , training_desc ) logger . info ( f \"u probability not trained for { cc . _output_column_name } - \" f \" { cl . _label_for_charts } (comparison vector value: \" f \" { cl . _comparison_vector_value } ). This usually means the \" \"comparison level was never observed in the training data.\" ) else : orig_cl . _add_trained_u_probability ( cl . u_probability , training_desc ) self . _original_linker . _em_training_sessions . append ( self ) def _add_iteration ( self ): self . _settings_obj_history . append ( deepcopy ( self . _settings_obj )) @property def _blocking_adjusted_probability_two_random_records_match ( self ): orig_prop_m = self . _original_settings_obj . _probability_two_random_records_match adj_bayes_factor = prob_to_bayes_factor ( orig_prop_m ) logger . log ( 15 , f \"Original prob two random records match: { orig_prop_m : .3f } \" ) comp_levels = self . _comparison_levels_to_reverse_blocking_rule if not comp_levels : comp_levels = self . _original_settings_obj . _get_comparison_levels_corresponding_to_training_blocking_rule ( # noqa self . _blocking_rule_for_training . blocking_rule ) for cl in comp_levels : adj_bayes_factor = cl . _bayes_factor * adj_bayes_factor logger . log ( 15 , f \"Increasing prob two random records match using \" f \" { cl . comparison . _output_column_name } - { cl . _label_for_charts } \" f \" using bayes factor { cl . _bayes_factor : ,.3f } \" , ) adjusted_prop_m = bayes_factor_to_prob ( adj_bayes_factor ) logger . log ( 15 , f \" \\n Prob two random records match adjusted for blocking on \" f \" { self . _blocking_rule_for_training . blocking_rule } : \" f \" { adjusted_prop_m : .3f } \" , ) return adjusted_prop_m @property def _iteration_history_records ( self ): output_records = [] for iteration , settings_obj in enumerate ( self . _settings_obj_history ): records = settings_obj . _parameters_as_detailed_records for r in records : r [ \"iteration\" ] = iteration r [ \"probability_two_random_records_match\" ] = self . _settings_obj . _probability_two_random_records_match output_records . extend ( records ) return output_records @property def _lambda_history_records ( self ): output_records = [] for i , s in enumerate ( self . _settings_obj_history ): lam = s . _probability_two_random_records_match r = { \"probability_two_random_records_match\" : lam , \"probability_two_random_records_match_reciprocal\" : 1 / lam , \"iteration\" : i , } output_records . append ( r ) return output_records def probability_two_random_records_match_iteration_chart ( self ): records = self . _lambda_history_records return probability_two_random_records_match_iteration_chart ( records ) def match_weights_interactive_history_chart ( self ): records = self . _iteration_history_records return match_weights_interactive_history_chart ( records , blocking_rule = self . _blocking_rule_for_training ) def m_u_values_interactive_history_chart ( self ): records = self . _iteration_history_records return m_u_parameters_interactive_history_chart ( records ) def _max_change_message ( self , max_change_dict ): message = \"Largest change in params was\" if max_change_dict [ \"max_change_type\" ] == \"probability_two_random_records_match\" : message = ( f \" { message } { max_change_dict [ 'max_change_value' ] : ,.3g } in \" \"probability_two_random_records_match\" ) else : cl = max_change_dict [ \"current_comparison_level\" ] m_u = max_change_dict [ \"max_change_type\" ] cc_name = cl . comparison . _output_column_name cl_label = cl . _label_for_charts level_text = f \" { cc_name } , level ` { cl_label } `\" message = ( f \" { message } { max_change_dict [ 'max_change_value' ] : ,.3g } in \" f \"the { m_u } of { level_text } \" ) return message def _max_change_in_parameters_comparison_levels ( self ): previous_iteration = self . _settings_obj_history [ - 2 ] this_iteration = self . _settings_obj_history [ - 1 ] max_change = - 0.1 max_change_levels = { \"previous_iteration\" : None , \"this_iteration\" : None , \"max_change_type\" : None , \"max_change_value\" : None , } comparisons = zip ( previous_iteration . comparisons , this_iteration . comparisons ) for comparison in comparisons : prev_cc = comparison [ 0 ] this_cc = comparison [ 1 ] z_cls = zip ( prev_cc . comparison_levels , this_cc . comparison_levels ) for z_cl in z_cls : if z_cl [ 0 ] . _is_null_level : continue prev_cl = z_cl [ 0 ] this_cl = z_cl [ 1 ] change_m = this_cl . m_probability - prev_cl . m_probability change_u = this_cl . u_probability - prev_cl . u_probability change = max ( abs ( change_m ), abs ( change_u )) change_type = ( \"m_probability\" if abs ( change_m ) > abs ( change_u ) else \"u_probability\" ) change_value = change_m if abs ( change_m ) > abs ( change_u ) else change_u if change > max_change : max_change = change max_change_levels [ \"prev_comparison_level\" ] = prev_cl max_change_levels [ \"current_comparison_level\" ] = this_cl max_change_levels [ \"max_change_type\" ] = change_type max_change_levels [ \"max_change_value\" ] = change_value max_change_levels [ \"max_abs_change_value\" ] = abs ( change_value ) change_probability_two_random_records_match = ( this_iteration . _probability_two_random_records_match - previous_iteration . _probability_two_random_records_match ) if abs ( change_probability_two_random_records_match ) > max_change : max_change = abs ( change_probability_two_random_records_match ) max_change_levels [ \"prev_comparison_level\" ] = None max_change_levels [ \"current_comparison_level\" ] = None max_change_levels [ \"max_change_type\" ] = \"probability_two_random_records_match\" max_change_levels [ \"max_change_value\" ] = change_probability_two_random_records_match max_change_levels [ \"max_abs_change_value\" ] = abs ( change_probability_two_random_records_match ) max_change_levels [ \"message\" ] = self . _max_change_message ( max_change_levels ) return max_change_levels def __repr__ ( self ): deactivated_cols = \", \" . join ( [ cc . _output_column_name for cc in self . _comparisons_that_cannot_be_estimated ] ) blocking_rule = self . _blocking_rule_for_training . blocking_rule return ( f \"<EMTrainingSession, blocking on { blocking_rule } , \" f \"deactivating comparisons { deactivated_cols } >\" )","title":"Documentation for EMTrainingSession object"},{"location":"em_training_session.html#splink.em_training_session.EMTrainingSession.match_weights_interactive_history_chart","text":"Source code in splink/em_training_session.py 291 292 293 294 295 def match_weights_interactive_history_chart ( self ): records = self . _iteration_history_records return match_weights_interactive_history_chart ( records , blocking_rule = self . _blocking_rule_for_training )","title":"match_weights_interactive_history_chart()"},{"location":"em_training_session.html#splink.em_training_session.EMTrainingSession.m_u_values_interactive_history_chart","text":"Source code in splink/em_training_session.py 297 298 299 def m_u_values_interactive_history_chart ( self ): records = self . _iteration_history_records return m_u_parameters_interactive_history_chart ( records )","title":"m_u_values_interactive_history_chart()"},{"location":"linker.html","tags":["API"],"text":"Documentation for Linker object \u00b6 The Linker object manages the data linkage process and holds the data linkage model. Most of Splink's functionality can be accessed by calling methods (functions) on the linker, such as linker.predict() , linker.profile_columns() etc. The Linker class is intended for subclassing for specific backends, e.g. a DuckDBLinker . Source code in splink/linker.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 class Linker : \"\"\"The Linker object manages the data linkage process and holds the data linkage model. Most of Splink's functionality can be accessed by calling methods (functions) on the linker, such as `linker.predict()`, `linker.profile_columns()` etc. The Linker class is intended for subclassing for specific backends, e.g. a `DuckDBLinker`. \"\"\" def __init__ ( self , input_table_or_tables : Union [ str , list ], settings_dict : dict = None , set_up_basic_logging : bool = True , input_table_aliases : Union [ str , list ] = None , ): \"\"\"Initialise the linker object, which manages the data linkage process and holds the data linkage model. Examples: >>> # Example 1: DuckDB >>> df = pd.read_csv(\"data_to_dedupe.csv\") >>> linker = DuckDBLinker(df, settings_dict) >>> # Example 2: Spark >>> df_1 = spark.read.parquet(\"table_1/\") >>> df_2 = spark.read.parquet(\"table_2/\") >>> linker = SparkLinker( >>> [df_1, df_2], >>> settings_dict, >>> input_table_aliases=[\"customers\", \"contact_center_callers\"] >>> ) Args: input_table_or_tables (Union[str, list]): Input data into the linkage model. Either a single string (the name of a table in a database) for deduplication jobs, or a list of strings (the name of tables in a database) for link_only or link_and_dedupe. For some linkers, such as the DuckDBLinker and the SparkLinker, it's also possible to pass in dataframes (Pandas and Spark respectively) rather than strings. settings_dict (dict, optional): A Splink settings dictionary. If not provided when the object is created, can later be added using `linker.initialise_settings()` Defaults to None. set_up_basic_logging (bool, optional): If true, sets ups up basic logging so that Splink sends messages at INFO level to stdout. Defaults to True. input_table_aliases (Union[str, list], optional): Labels assigned to input tables in Splink outputs. If the names of the tables in the input database are long or unspecific, this argument can be used to attach more easily readable/interpretable names. Defaults to None. \"\"\" if set_up_basic_logging : logging . basicConfig ( format = \" %(message)s \" , ) splink_logger = logging . getLogger ( \"splink\" ) splink_logger . setLevel ( logging . INFO ) self . _pipeline = SQLPipeline () self . _settings_dict = settings_dict if settings_dict is None : self . _settings_obj_ = None else : self . _settings_obj_ = Settings ( settings_dict ) self . _input_tables_dict = self . _get_input_tables_dict ( input_table_or_tables , input_table_aliases ) self . _validate_input_dfs () self . _em_training_sessions = [] self . _names_of_tables_created_by_splink : list = [] self . _find_new_matches_mode = False self . _train_u_using_random_sample_mode = False self . _compare_two_records_mode = False self . _self_link_mode = False self . _output_schema = \"\" self . debug_mode = False @property def _settings_obj ( self ) -> Settings : if self . _settings_obj_ is None : raise ValueError ( \"You did not provide a settings dictionary when you \" \"created the linker. To continue, you need to provide a settings \" \"dictionary using the `initialise_settings()` method on your linker \" \"object. i.e. linker.initialise_settings(settings_dict)\" ) return self . _settings_obj_ @property def _input_tablename_l ( self ): if self . _find_new_matches_mode : return \"__splink__df_concat_with_tf\" if self . _self_link_mode : return \"__splink__df_concat_with_tf\" if self . _compare_two_records_mode : return \"__splink__compare_two_records_left_with_tf\" if self . _train_u_using_random_sample_mode : return \"__splink__df_concat_with_tf_sample\" if self . _two_dataset_link_only : return \"__splink_df_concat_with_tf_left\" return \"__splink__df_concat_with_tf\" @property def _input_tablename_r ( self ): if self . _find_new_matches_mode : return \"__splink__df_new_records_with_tf\" if self . _self_link_mode : return \"__splink__df_concat_with_tf\" if self . _compare_two_records_mode : return \"__splink__compare_two_records_right_with_tf\" if self . _train_u_using_random_sample_mode : return \"__splink__df_concat_with_tf_sample\" if self . _two_dataset_link_only : return \"__splink_df_concat_with_tf_right\" return \"__splink__df_concat_with_tf\" @property def _two_dataset_link_only ( self ): # Two dataset link only join is a special case where an inner join of the # two datasets is much more efficient than self-joining the vertically # concatenation of all input datasets if self . _find_new_matches_mode : return True if self . _compare_two_records_mode : return True if ( len ( self . _input_tables_dict ) == 2 and self . _settings_obj . _link_type == \"link_only\" ): return True else : return False def _prepend_schema_to_table_name ( self , table_name ): if self . _output_schema : return f \" { self . _output_schema } . { table_name } \" else : return table_name def _initialise_df_concat ( self , materialise = True ): if self . _table_exists_in_database ( \"__splink__df_concat\" ): return sql = vertically_concatenate_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_concat\" ) self . _execute_sql_pipeline ( materialise_as_hash = False ) def _initialise_df_concat_with_tf ( self , materialise = True ): if self . _table_exists_in_database ( \"__splink__df_concat_with_tf\" ): return sql = vertically_concatenate_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_concat\" ) sqls = compute_all_term_frequencies_sqls ( self ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) if self . _two_dataset_link_only : # If we do not materialise __splink_df_concat_with_tf # we'd have to run all the code up to this point twice self . _execute_sql_pipeline ( materialise_as_hash = False ) source_dataset_col = self . _settings_obj . _source_dataset_column_name # Need df_l to be the one with the lowest id to preeserve the property # that the left dataset is the one with the lowest concatenated id keys = self . _input_tables_dict . keys () keys = list ( sorted ( keys )) df_l = self . _input_tables_dict [ keys [ 0 ]] df_r = self . _input_tables_dict [ keys [ 1 ]] sql = f \"\"\" select * from __splink__df_concat_with_tf where { source_dataset_col } = ' { df_l . templated_name } ' \"\"\" self . _enqueue_sql ( sql , \"__splink_df_concat_with_tf_left\" ) self . _execute_sql_pipeline ( materialise_as_hash = False ) sql = f \"\"\" select * from __splink__df_concat_with_tf where { source_dataset_col } = ' { df_r . templated_name } ' \"\"\" self . _enqueue_sql ( sql , \"__splink_df_concat_with_tf_right\" ) self . _execute_sql_pipeline ( materialise_as_hash = False ) else : if materialise : self . _execute_sql_pipeline ( materialise_as_hash = False ) def _table_to_splink_dataframe ( self , templated_name , physical_name ) -> SplinkDataFrame : \"\"\"Create a SplinkDataframe from a table in the underlying database called `physical_name`. Associate a `templated_name` with this table, which signifies the purpose or 'meaning' of this table to splink. (e.g. `__splink__df_blocked`) Args: templated_name (str): The purpose of the table to Splink physical_name (str): The name of the table in the underlying databse \"\"\" raise NotImplementedError ( \"_table_to_splink_dataframe not implemented on this linker\" ) def _enqueue_sql ( self , sql , output_table_name ): \"\"\"Add sql to the current pipeline, but do not execute the pipeline.\"\"\" self . _pipeline . enqueue_sql ( sql , output_table_name ) def _execute_sql_pipeline ( self , input_dataframes : List [ SplinkDataFrame ] = [], materialise_as_hash = True , use_cache = True , transpile = True , ) -> SplinkDataFrame : \"\"\"Execute the SQL queued in the current pipeline as a single statement e.g. `with a as (), b as , c as (), select ... from c`, then execute the pipeline, returning the resultant table as a SplinkDataFrame Args: input_dataframes (List[SplinkDataFrame], optional): A 'starting point' of SplinkDataFrames if needed. Defaults to []. materialise_as_hash (bool, optional): If true, the output tablename will end in a unique identifer. Defaults to True. use_cache (bool, optional): If true, look at whether the SQL pipeline has been executed before, and if so, use the existing result. Defaults to True. transpile (bool, optional): Transpile the SQL using SQLGlot. Defaults to True. Returns: SplinkDataFrame: An abstraction representing the table created by the sql pipeline \"\"\" if not self . debug_mode : sql_gen = self . _pipeline . _generate_pipeline ( input_dataframes ) output_tablename_templated = self . _pipeline . queue [ - 1 ] . output_table_name dataframe = self . _sql_to_splink_dataframe_checking_cache ( sql_gen , output_tablename_templated , materialise_as_hash , use_cache , transpile , ) self . _pipeline . reset () return dataframe else : # In debug mode, we do not pipeline the sql and print the # results of each part of the pipeline for task in self . _pipeline . _generate_pipeline_parts ( input_dataframes ): output_tablename = task . output_table_name sql = task . sql print ( \"------\" ) print ( f \"--------Creating table: { output_tablename } --------\" ) dataframe = self . _sql_to_splink_dataframe_checking_cache ( sql , output_tablename , materialise_as_hash = False , use_cache = False , transpile = transpile , ) self . _pipeline . reset () return dataframe def _execute_sql_against_backend ( self , sql , templated_name , physical_name , transpile = True ): raise NotImplementedError ( f \"_execute_sql_against_backend not implemented for { type ( self ) } \" ) def _sql_to_splink_dataframe_checking_cache ( self , sql , output_tablename_templated , materialise_as_hash = True , use_cache = True , transpile = True , ) -> SplinkDataFrame : \"\"\"Execute sql, or if identical sql has been run before, return cached results. This function - is used by _execute_sql_pipeline to to execute SQL - or can be used directly if you have a single SQL statement that's not in a pipeline Return a SplinkDataFrame representing the results of the SQL \"\"\" hash = hashlib . sha256 ( sql . encode ()) . hexdigest ()[: 7 ] # Ensure hash is valid sql table name table_name_hash = f \" { output_tablename_templated } _ { hash } \" if use_cache : if self . _table_exists_in_database ( output_tablename_templated ): logger . debug ( f \"Using existing table { output_tablename_templated } \" ) return self . _table_to_splink_dataframe ( output_tablename_templated , output_tablename_templated ) if self . _table_exists_in_database ( table_name_hash ): logger . debug ( f \"Using cache for { output_tablename_templated } \" f \" with physical name { table_name_hash } \" ) return self . _table_to_splink_dataframe ( output_tablename_templated , table_name_hash ) if self . debug_mode : print ( sql ) if materialise_as_hash : splink_dataframe = self . _execute_sql_against_backend ( sql , output_tablename_templated , table_name_hash , transpile = transpile ) else : splink_dataframe = self . _execute_sql_against_backend ( sql , output_tablename_templated , output_tablename_templated , transpile = transpile , ) self . _names_of_tables_created_by_splink . append ( splink_dataframe . physical_name ) if self . debug_mode : df_pd = splink_dataframe . as_pandas_dataframe () try : from IPython.display import display display ( df_pd ) except ModuleNotFoundError : print ( df_pd ) return splink_dataframe def __deepcopy__ ( self , memo ): \"\"\"When we do EM training, we need a copy of the linker which is independent of the main linker e.g. setting parameters on the copy will not affect the main linker. This method implements ensures linker can be deepcopied. \"\"\" new_linker = copy ( self ) new_linker . _em_training_sessions = [] new_settings = deepcopy ( self . _settings_obj ) new_linker . _settings_obj_ = new_settings return new_linker def _ensure_aliases_populated_and_is_list ( self , input_table_or_tables , input_table_aliases ): if input_table_aliases is None : input_table_aliases = input_table_or_tables input_table_aliases = ensure_is_list ( input_table_aliases ) return input_table_aliases def _get_input_tables_dict ( self , input_table_or_tables , input_table_aliases ): input_table_or_tables = ensure_is_list ( input_table_or_tables ) input_table_aliases = self . _ensure_aliases_populated_and_is_list ( input_table_or_tables , input_table_aliases ) d = {} for table_name , table_alias in zip ( input_table_or_tables , input_table_aliases ): d [ table_alias ] = self . _table_to_splink_dataframe ( table_alias , table_name ) return d def _get_input_tf_dict ( self , df_dict ): d = {} for df_name , df_value in df_dict . items (): renamed = colname_to_tf_tablename ( df_name ) d [ renamed ] = self . _table_to_splink_dataframe ( renamed , df_value ) return d def _predict_warning ( self ): if not self . _settings_obj . _is_fully_trained : msg = ( \" \\n -- WARNING -- \\n \" \"You have called predict(), but there are some parameter \" \"estimates which have neither been estimated or specified in your \" \"settings dictionary. To produce predictions the following\" \" untrained trained parameters will use default values.\" ) messages = self . _settings_obj . _not_trained_messages () warn_message = \" \\n \" . join ([ msg ] + messages ) logger . warning ( warn_message ) def _table_exists_in_database ( self , table_name ): raise NotImplementedError ( f \"table_exists_in_database not implemented for { type ( self ) } \" ) def _validate_input_dfs ( self ): for df in self . _input_tables_dict . values (): df . validate () if self . _settings_obj_ is not None : if self . _settings_obj . _link_type == \"dedupe_only\" : if len ( self . _input_tables_dict ) > 1 : raise ValueError ( 'If link_type = \"dedupe only\" then input tables must contain ' \"only a single input table\" , ) def _populate_probability_two_random_records_match_from_trained_values ( self ): recip_prop_matches_estimates = [] logger . log ( 15 , ( \"---- Using training sessions to compute \" \"probability two random records match ----\" ), ) for em_training_session in self . _em_training_sessions : training_lambda = ( em_training_session . _settings_obj . _probability_two_random_records_match ) training_lambda_bf = prob_to_bayes_factor ( training_lambda ) reverse_levels = ( em_training_session . _comparison_levels_to_reverse_blocking_rule ) logger . log ( 15 , \" \\n \" f \"Probability two random records match from trained model blocking on \" f \" { em_training_session . _blocking_rule_for_training . blocking_rule } : \" f \" { training_lambda : ,.3f } \" , ) for reverse_level in reverse_levels : # Get comparison level on current settings obj cc = self . _settings_obj . _get_comparison_by_output_column_name ( reverse_level . comparison . _output_column_name ) cl = cc . _get_comparison_level_by_comparison_vector_value ( reverse_level . _comparison_vector_value ) if cl . _has_estimated_values : bf = cl . _trained_m_median / cl . _trained_u_median else : bf = cl . _bayes_factor logger . log ( 15 , f \"Reversing comparison level { cc . _output_column_name } \" f \" using bayes factor { bf : ,.3f } \" , ) training_lambda_bf = training_lambda_bf / bf as_prob = bayes_factor_to_prob ( training_lambda_bf ) logger . log ( 15 , ( \"This estimate of probability two random records match now: \" f \" { as_prob : ,.3f } \" f \"with reciprocal { ( 1 / as_prob ) : ,.3f } \" ), ) logger . log ( 15 , \" \\n ---------\" ) p = bayes_factor_to_prob ( training_lambda_bf ) recip_prop_matches_estimates . append ( 1 / p ) prop_matches_estimate = 1 / median ( recip_prop_matches_estimates ) self . _settings_obj . _probability_two_random_records_match = prop_matches_estimate logger . log ( 15 , \" \\n Median of prop of matches estimates: \" f \" { self . _settings_obj . _probability_two_random_records_match : ,.3f } \" \"reciprocal \" f \" { 1 / self . _settings_obj . _probability_two_random_records_match : ,.3f } \" , ) def _records_to_table ( records , as_table_name ): # Create table in database containing records # Probably quite difficult to implement correctly # Due to data type issues. raise NotImplementedError def _populate_m_u_from_trained_values ( self ): ccs = self . _settings_obj . comparisons for cc in ccs : for cl in cc . _comparison_levels_excluding_null : if cl . _has_estimated_u_values : cl . u_probability = cl . _trained_u_median if cl . _has_estimated_m_values : cl . m_probability = cl . _trained_m_median def _delete_tables_created_by_splink_from_db ( self , retain_term_frequency = True , retain_df_concat_with_tf = True ): tables_remaining = [] for name in self . _names_of_tables_created_by_splink : # Only delete tables explicitly marked as having been created by splink if \"__splink__\" not in name : tables_remaining . append ( name ) continue if name == \"__splink__df_concat_with_tf\" : if retain_df_concat_with_tf : tables_remaining . append ( name ) else : self . _delete_table_from_database ( name ) elif name . startswith ( \"__splink__df_tf_\" ): if retain_term_frequency : tables_remaining . append ( name ) else : self . _delete_table_from_database ( name ) else : self . _delete_table_from_database ( name ) self . _names_of_tables_created_by_splink = tables_remaining def _raise_error_if_necessary_waterfall_columns_not_computed ( self ): ricc = self . _settings_obj . _retain_intermediate_calculation_columns rmc = self . _settings_obj . _retain_matching_columns if not ( ricc and rmc ): raise ValueError ( \"retain_intermediate_calculation_columns and \" \"retain_matching_columns must both be set to True in your settings\" \" dictionary to use this function, because otherwise the necessary \" \"columns will not be available in the input records.\" f \" Their current values are { ricc } and { rmc } , respectively. \" \"Please re-run your linkage with them both set to True.\" ) def initialise_settings ( self , settings_dict : dict ): \"\"\"Initialise settings for the linker. To be used if settings were not passed to the linker on creation. Examples: >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.profile_columns([\"first_name\", \"surname\"]) >>> linker.initialise_settings(settings_dict) Args: settings_dict (dict): A Splink settings dictionary \"\"\" self . _settings_dict = settings_dict self . _settings_obj_ = Settings ( settings_dict ) self . _validate_input_dfs () def compute_tf_table ( self , column_name : str ) -> SplinkDataFrame : \"\"\"Compute a term frequency table for a given column and persist to the database This method is useful if you want to pre-compute term frequency tables e.g. so that real time linkage executes faster, or so that you can estimate various models without having to recompute term frequency tables each time Examples: >>> # Example 1: Real time linkage >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.load_settings_from_json(\"saved_settings.json\") >>> linker.compute_tf_table(\"surname\") >>> linker.compare_two_records(record_left, record_right) >>> # Example 2: Pre-computed term frequency tables in Spark >>> linker = SparkLinker(df) >>> df_first_name_tf = linker.compute_tf_table(\"first_name\") >>> df_first_name_tf.write.parquet(\"folder/first_name_tf\") >>> >>> # On subsequent data linking job, read this table rather than recompute >>> df_first_name_tf = spark.read.parquet(\"folder/first_name_tf\") >>> df_first_name_tf.createOrReplaceTempView(\"__splink__df_tf_first_name\") Args: column_name (str): The column name in the input table Returns: SplinkDataFrame: The resultant table as a splink data frame \"\"\" sql = vertically_concatenate_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_concat\" ) input_col = InputColumn ( column_name , tf_adjustments = True ) sql = term_frequencies_for_single_column_sql ( input_col ) self . _enqueue_sql ( sql , colname_to_tf_tablename ( input_col )) return self . _execute_sql_pipeline ( materialise_as_hash = False ) def deterministic_link ( self ) -> SplinkDataFrame : \"\"\"Uses the blocking rules specified by `blocking_rules_to_generate_predictions` in the settings dictionary to generate pairwise record comparisons. For deterministic linkage, this should be a list of blocking rules which are strict enough to generate only true links. Deterministic linkage, however, is likely to result in missed links (false negatives). Examples: >>> linker = DuckDBLinker(df) >>> >>> settings = { >>> \"link_type\": \"dedupe_only\", >>> \"blocking_rules_to_generate_predictions\": [ >>> \"l.first_name = r.first_name\", >>> \"l.surname = r.surname\", >>> ], >>> \"comparisons\": [] >>> } >>> >>> from splink.duckdb.duckdb_linker import DuckDBLinker >>> >>> linker = DuckDBLinker(df, settings) >>> df = linker.deterministic_link() Returns: SplinkDataFrame: A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. \"\"\" self . _initialise_df_concat_with_tf () sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) return self . _execute_sql_pipeline () def estimate_u_using_random_sampling ( self , target_rows : int ): \"\"\"Estimate the u parameters of the linkage model using random sampling. The u parameters represent the proportion of record comparisons that fall into each comparison level amongst truly non-matching records. This procedure takes a sample of the data and generates the cartesian product of pairwise record comparisons amongst the sampled records. The validity of the u values rests on the assumption that the resultant pairwise comparisons are non-matches (or at least, they are very unlikely to be matches). For large datasets, this is typically true. Args: target_rows (int): The target number of pairwise record comparisons from which to derive the u values. Larger will give more accurate estimates but lead to longer runtimes. In our experience at least 1e9 (one billion) gives best results but can take a long time to compute. 1e7 (ten million) is often adequate whilst testing different model specifications, before the final model is estimated. Examples: >>> linker.estimate_u_using_random_sampling(1e8) Returns: None: Updates the estimated u parameters within the linker object and returns nothing. \"\"\" self . _initialise_df_concat_with_tf ( materialise = True ) estimate_u_values ( self , target_rows ) self . _populate_m_u_from_trained_values () self . _settings_obj . _columns_without_estimated_parameters_message () def estimate_m_from_label_column ( self , label_colname : str ): \"\"\"Estimate the m parameters of the linkage model from a label (ground truth) column in the input dataframe(s). The m parameters represent the proportion of record comparisons that fall into each comparison level amongst truly matching records. The ground truth column is used to generate pairwise record comparisons which are then assumed to be matches. For example, if the entity being matched is persons, and your input dataset(s) contain social security number, this could be used to estimate the m values for the model. Note that this column does not need to be fully populated. A common case is where a unique identifier such as social security number is only partially populated. Args: label_colname (str): The name of the column containing the ground truth label in the input data. Examples: >>> linker.estimate_m_from_label_column(\"social_security_number\") Returns: Updates the estimated m parameters within the linker object and returns nothing. \"\"\" self . _initialise_df_concat_with_tf ( materialise = True ) estimate_m_values_from_label_column ( self , self . _input_tables_dict , label_colname ) self . _populate_m_u_from_trained_values () self . _settings_obj . _columns_without_estimated_parameters_message () def estimate_parameters_using_expectation_maximisation ( self , blocking_rule : str , comparisons_to_deactivate : List [ Union [ str , Comparison ]] = None , comparison_levels_to_reverse_blocking_rule : List [ ComparisonLevel ] = None , fix_probability_two_random_records_match : bool = False , fix_m_probabilities = False , fix_u_probabilities = True , ) -> EMTrainingSession : \"\"\"Estimate the parameters of the linkage model using expectation maximisation. By default, the m probabilities are estimated, but not the u probabilities, because good estiamtes for the u probabilities can be obtained from `linker.estimate_u_using_random_sampling()`. You can change this by setting `fix_u_probabilities` to False. The blocking rule provided is used to generate pairwise record comparisons. Usually, this should be a blocking rule that results in a dataframe where matches are between about 1% and 99% of the comparisons. By default, m parameters are estimated for all comparisons except those which are included in the blocking rule. For example, if the blocking rule is `l.first_name = r.first_name`, then parameter esimates will be made for all comparison except those which use `first_name` in their sql_condition By default, the probability two random records match is estimated for the blocked data, and then the m and u parameters for the columns specified in the blocking rules are used to estiamte the global probability two random records match. To control which comparisons should have their parameter estimated, and the process of 'reversing out' the global probability two random records match, the user may specify `comparisons_to_deactivate` and `comparison_levels_to_reverse_blocking_rule`. This is useful, for example if you block on the dmetaphone of a column but match on the original column. Examples: >>> # Default behaviour >>> br_training = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker.estimate_parameters_using_expectation_maximisation(br_training) >>> # Specify which comparisons to deactivate >>> br_training = \"l.dmeta_first_name = r.dmeta_first_name\" >>> settings_obj = linker._settings_obj >>> comp = settings_obj._get_comparison_by_output_column_name(\"first_name\") >>> dmeta_level = comp._get_comparison_level_by_comparison_vector_value(1) >>> linker.estimate_parameters_using_expectation_maximisation( >>> br_training, >>> comparisons_to_deactivate=[\"first_name\"], >>> comparison_levels_to_reverse_blocking_rule=[dmeta_level], >>> ) Args: blocking_rule (str): The blocking rule used to generate pairwise record comparisons. comparisons_to_deactivate (list, optional): By default, splink will analyse the blocking rule provided and estimate the m parameters for all comaprisons except those included in the blocking rule. If comparisons_to_deactivate are provided, spink will instead estimate m parameters for all comparison except those specified in the comparisons_to_deactivate list. This list can either contain the output_column_name of the Comparison as a string, or Comparison objects. Defaults to None. comparison_levels_to_reverse_blocking_rule (list, optional): By default, splink will analyse the blocking rule provided and adjust the global probability two random records match to account for the matches specified in the blocking rule. If provided, this argument will overrule this default behaviour. The user must provide a list of ComparisonLevel objects. Defaults to None. fix_probability_two_random_records_match (bool, optional): If True, do not update the probability two random records match after each iteration. Defaults to False. fix_m_probabilities (bool, optional): If True, do not update the m probabilities after each iteration. Defaults to False. fix_u_probabilities (bool, optional): If True, do not update the u probabilities after each iteration. Defaults to True. Examples: >>> blocking_rule = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker.estimate_parameters_using_expectation_maximisation(blocking_rule) Returns: EMTrainingSession: An object containing information about the training session such as how parameters changed during the iteration history \"\"\" self . _initialise_df_concat_with_tf ( materialise = True ) if comparisons_to_deactivate : # If user provided a string, convert to Comparison object comparisons_to_deactivate = [ self . _settings_obj . _get_comparison_by_output_column_name ( n ) if isinstance ( n , str ) else n for n in comparisons_to_deactivate ] if comparison_levels_to_reverse_blocking_rule is None : logger . warning ( \" \\n WARNING: \\n \" \"You have provided comparisons_to_deactivate but not \" \"comparison_levels_to_reverse_blocking_rule. \\n \" \"If comparisons_to_deactivate is provided, then \" \"you usually need to provide corresponding \" \"comparison_levels_to_reverse_blocking_rule. \" \"because each comparison to deactivate if effectively treated \" \"as an exact match.\" ) em_training_session = EMTrainingSession ( self , blocking_rule , fix_u_probabilities = fix_u_probabilities , fix_m_probabilities = fix_m_probabilities , fix_probability_two_random_records_match = fix_probability_two_random_records_match , # noqa 501 comparisons_to_deactivate = comparisons_to_deactivate , comparison_levels_to_reverse_blocking_rule = comparison_levels_to_reverse_blocking_rule , # noqa 501 ) em_training_session . _train () self . _populate_m_u_from_trained_values () self . _populate_probability_two_random_records_match_from_trained_values () self . _settings_obj . _columns_without_estimated_parameters_message () return em_training_session def predict ( self , threshold_match_probability : float = None , threshold_match_weight : float = None , ) -> SplinkDataFrame : \"\"\"Create a dataframe of scored pairwise comparisons using the parameters of the linkage model. Uses the blocking rules specified in the `blocking_rules_to_generate_predictions` of the settings dictionary to generate the pairwise comparisons. Args: threshold_match_probability (float, optional): If specified, filter the results to include only pairwise comparisons with a match_probability above this threshold. Defaults to None. threshold_match_weight (float, optional): If specified, filter the results to include only pairwise comparisons with a match_weight above this threshold. Defaults to None. Examples: >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.load_settings_from_json(\"saved_settings.json\") >>> df = linker.predict(threshold_match_probability=0.95) >>> df.as_pandas_dataframe(limit=5) Returns: SplinkDataFrame: A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. \"\"\" # If the user only calls predict, it runs as a single pipeline with no # materialisation of anything self . _initialise_df_concat_with_tf ( materialise = False ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) repartition_after_blocking = getattr ( self , \"repartition_after_blocking\" , False ) # repartition after blocking only exists on the SparkLinker if repartition_after_blocking : df_blocked = self . _execute_sql_pipeline () input_dataframes = [ df_blocked ] else : input_dataframes = [] sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj , threshold_match_probability , threshold_match_weight ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) predictions = self . _execute_sql_pipeline ( input_dataframes ) self . _predict_warning () return predictions def find_matches_to_new_records ( self , records_or_tablename , blocking_rules = [], match_weight_threshold =- 4 , ) -> SplinkDataFrame : \"\"\"Given one or more records, find records in the input dataset(s) which match and return in order of the splink prediction score. This effectively provides a way of searching the input datasets for given record(s) Args: records_or_tablename (List[dict]): Input search record(s) as list of dict, or a table registered to the database. blocking_rules (list, optional): Blocking rules to select which records to find and score. If [], do not use a blocking rule - meaning the input records will be compared to all records provided to the linker when it was instantiated. Defaults to []. match_weight_threshold (int, optional): Return matches with a match weight above this threshold. Defaults to -4. Examples: >>> linker = DuckDBLinker(df) >>> linker.load_settings_from_json(\"saved_settings.json\") >>> # Pre-compute tf tables for any tables with >>> # term frequency adjustments >>> linker.compute_tf_table(\"first_name\") >>> record = {'unique_id': 1, >>> 'first_name': \"John\", >>> 'surname': \"Smith\", >>> 'dob': \"1971-05-24\", >>> 'city': \"London\", >>> 'email': \"john@smith.net\" >>> } >>> df = linker.find_matches_to_new_records([record], blocking_rules=[]) Returns: SplinkDataFrame: The pairwise comparisons. \"\"\" original_blocking_rules = ( self . _settings_obj . _blocking_rules_to_generate_predictions ) original_link_type = self . _settings_obj . _link_type if not isinstance ( records_or_tablename , str ): self . _records_to_table ( records_or_tablename , \"__splink__df_new_records\" ) new_records_tablename = \"__splink__df_new_records\" else : new_records_tablename = records_or_tablename blocking_rules = [ BlockingRule ( r ) if not isinstance ( r , BlockingRule ) else r for r in blocking_rules ] self . _settings_obj . _blocking_rules_to_generate_predictions = blocking_rules self . _settings_obj . _link_type = \"link_only_find_matches_to_new_records\" self . _find_new_matches_mode = True sql = _join_tf_to_input_df_sql ( self ) sql = sql . replace ( \"__splink__df_concat\" , new_records_tablename ) self . _enqueue_sql ( sql , \"__splink__df_new_records_with_tf\" ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) sql = f \"\"\" select * from __splink__df_predict where match_weight > { match_weight_threshold } \"\"\" self . _enqueue_sql ( sql , \"__splink_find_matches_predictions\" ) predictions = self . _execute_sql_pipeline ( use_cache = False ) self . _settings_obj . _blocking_rules_to_generate_predictions = ( original_blocking_rules ) self . _settings_obj . _link_type = original_link_type self . _find_new_matches_mode = False return predictions def compare_two_records ( self , record_1 : dict , record_2 : dict ): \"\"\"Use the linkage model to compare and score a pairwise record comparison based on the two input records provided Args: record_1 (dict): dictionary representing the first record. Columns names and data types must be the same as the columns in the settings object record_2 (dict): dictionary representing the second record. Columns names and data types must be the same as the columns in the settings object Examples: >>> linker = DuckDBLinker(df) >>> linker.load_settings_from_json(\"saved_settings.json\") >>> linker.compare_two_records(record_left, record_right) Returns: SplinkDataFrame: Pairwise comparison with scored prediction \"\"\" original_blocking_rules = ( self . _settings_obj . _blocking_rules_to_generate_predictions ) original_link_type = self . _settings_obj . _link_type self . _compare_two_records_mode = True self . _settings_obj . _blocking_rules_to_generate_predictions = [] self . _records_to_table ([ record_1 ], \"__splink__compare_two_records_left\" ) self . _records_to_table ([ record_2 ], \"__splink__compare_two_records_right\" ) sql_join_tf = _join_tf_to_input_df_sql ( self ) sql_join_tf = sql_join_tf . replace ( \"__splink__df_concat\" , \"__splink__compare_two_records_left\" ) self . _enqueue_sql ( sql_join_tf , \"__splink__compare_two_records_left_with_tf\" ) sql_join_tf = sql_join_tf . replace ( \"__splink__compare_two_records_left\" , \"__splink__compare_two_records_right\" ) self . _enqueue_sql ( sql_join_tf , \"__splink__compare_two_records_right_with_tf\" ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) predictions = self . _execute_sql_pipeline ( use_cache = False ) self . _settings_obj . _blocking_rules_to_generate_predictions = ( original_blocking_rules ) self . _settings_obj . _link_type = original_link_type self . _compare_two_records_mode = False return predictions def _self_link ( self ) -> SplinkDataFrame : \"\"\"Use the linkage model to compare and score all records in our input df with themselves. Returns: SplinkDataFrame: Scored pairwise comparisons of the input records to themselves. \"\"\" original_blocking_rules = ( self . _settings_obj . _blocking_rules_to_generate_predictions ) original_link_type = self . _settings_obj . _link_type # Changes our sql to allow for a self link. # This is used in `_sql_gen_where_condition` in blocking.py # to remove any 'where' clauses when blocking (normally when blocking # we want to *remove* self links!) self . _self_link_mode = True # Block on uid i.e. create pairwise record comparisons where the uid matches uid_cols = self . _settings_obj . _unique_id_input_columns uid_l = _composite_unique_id_from_edges_sql ( uid_cols , None , \"l\" ) uid_r = _composite_unique_id_from_edges_sql ( uid_cols , None , \"r\" ) self . _settings_obj . _blocking_rules_to_generate_predictions = [ BlockingRule ( f \" { uid_l } = { uid_r } \" ) ] self . _initialise_df_concat_with_tf () sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) predictions = self . _execute_sql_pipeline ( use_cache = False ) self . _settings_obj . _blocking_rules_to_generate_predictions = ( original_blocking_rules ) self . _settings_obj . _link_type = original_link_type self . _self_link_mode = False return predictions def cluster_pairwise_predictions_at_threshold ( self , df_predict : SplinkDataFrame , threshold_match_probability : float ) -> SplinkDataFrame : \"\"\"Clusters the pairwise match predictions that result from `linker.predict()` into groups of connected record using the connected components graph clustering algorithm Records with an estimated `match_probability` above `threshold_match_probability` are considered to be a match (i.e. they represent the same entity). Args: df_predict (SplinkDataFrame): The results of `linker.predict()` threshold_match_probability (float): Filter the pairwise match predictions to include only pairwise comparisons with a match_probability above this threshold. This dataframe is then fed into the clustering algorithm. Returns: SplinkDataFrame: A SplinkDataFrame containing a list of all IDs, clustered into groups based on the desired match threshold. \"\"\" self . _initialise_df_concat_with_tf ( df_predict ) edges_table = _cc_create_unique_id_cols ( self , df_predict , threshold_match_probability , ) cc = solve_connected_components ( self , edges_table ) return cc def profile_columns ( self , column_expressions : Union [ str , List [ str ]], top_n = 10 , bottom_n = 10 ): return profile_columns ( self , column_expressions , top_n = top_n , bottom_n = bottom_n ) def estimate_m_from_pairwise_labels ( self , table_name ): self . _initialise_df_concat_with_tf ( materialise = True ) estimate_m_from_pairwise_labels ( self , table_name ) def roc_chart_from_labels ( self , labels_tablename , threshold_actual = 0.5 , match_weight_round_to_nearest : float = None , ): \"\"\"Generate a ROC chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered with your database: |source_dataset_l|unique_id_l|source_dataset_r|unique_id_r|clerical_match_score| |----------------|-----------|----------------|-----------|--------------------| |df_1 |1 |df_2 |2 |0.99 | |df_1 |1 |df_2 |3 |0.2 | Note that `source_dataset` and `unique_id` should correspond to the values specified in the settings dict, and the `input_table_aliases` passed to the `linker` object. For `dedupe_only` links, the `source_dataset` columns can be ommitted. Args: labels_tablename (str): Name of table containing labels in the database threshold_actual (float, optional): Where the `clerical_match_score` provided by the user is a probability rather than binary, this value is used as the threshold to classify `clerical_match_score`s as binary matches or non matches. Defaults to 0.5. match_weight_round_to_nearest (float, optional): When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. Examples: >>> # DuckDBLinker >>> labels = pd.read_csv(\"my_labels.csv\") >>> linker._con.register(\"labels\", labels) >>> linker.roc_chart_from_labels(\"labels\") >>> >>> # SparkLinker >>> labels = spark.read.csv(\"my_labels.csv\", header=True) >>> labels.createDataFrame(\"labels\") >>> linker.roc_chart_from_labels(\"labels\") Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" df_truth_space = roc_table ( self , labels_tablename , threshold_actual = threshold_actual , match_weight_round_to_nearest = match_weight_round_to_nearest , ) recs = df_truth_space . as_record_dict () return roc_chart ( recs ) def precision_recall_chart_from_labels ( self , labels_tablename ): \"\"\"Generate a precision-recall chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered as a table with your database: |source_dataset_l|unique_id_l|source_dataset_r|unique_id_r|clerical_match_score| |----------------|-----------|----------------|-----------|--------------------| |df_1 |1 |df_2 |2 |0.99 | |df_1 |1 |df_2 |3 |0.2 | Note that `source_dataset` and `unique_id` should correspond to the values specified in the settings dict, and the `input_table_aliases` passed to the `linker` object. For `dedupe_only` links, the `source_dataset` columns can be ommitted. Args: labels_tablename (str): Name of table containing labels in the database threshold_actual (float, optional): Where the `clerical_match_score` provided by the user is a probability rather than binary, this value is used as the threshold to classify `clerical_match_score`s as binary matches or non matches. Defaults to 0.5. match_weight_round_to_nearest (float, optional): When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. Examples: >>> # DuckDBLinker >>> labels = pd.read_csv(\"my_labels.csv\") >>> linker._con.register(\"labels\", labels) >>> linker.precision_recall_chart_from_labels(\"labels\") >>> >>> # SparkLinker >>> labels = spark.read.csv(\"my_labels.csv\", header=True) >>> labels.createDataFrame(\"labels\") >>> linker.precision_recall_chart_from_labels(\"labels\") Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" df_truth_space = roc_table ( self , labels_tablename ) recs = df_truth_space . as_record_dict () return precision_recall_chart ( recs ) def roc_table_from_labels ( self , labels_tablename , threshold_actual = 0.5 , match_weight_round_to_nearest : float = None , ) -> SplinkDataFrame : \"\"\"Generate truth statistics (false positive etc.) for each threshold value of match_probability, suitable for plotting a ROC chart. The table of labels should be in the following format, and should be registered with your database: |source_dataset_l|unique_id_l|source_dataset_r|unique_id_r|clerical_match_score| |----------------|-----------|----------------|-----------|--------------------| |df_1 |1 |df_2 |2 |0.99 | |df_1 |1 |df_2 |3 |0.2 | Note that `source_dataset` and `unique_id` should correspond to the values specified in the settings dict, and the `input_table_aliases` passed to the `linker` object. For `dedupe_only` links, the `source_dataset` columns can be ommitted. Args: labels_tablename (str): Name of table containing labels in the database threshold_actual (float, optional): Where the `clerical_match_score` provided by the user is a probability rather than binary, this value is used as the threshold to classify `clerical_match_score`s as binary matches or non matches. Defaults to 0.5. match_weight_round_to_nearest (float, optional): When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. Examples: >>> # DuckDBLinker >>> labels = pd.read_csv(\"my_labels.csv\") >>> linker._con.register(\"labels\", labels) >>> linker.roc_table_from_labels(\"labels\") >>> >>> # SparkLinker >>> labels = spark.read.csv(\"my_labels.csv\", header=True) >>> labels.createDataFrame(\"labels\") >>> linker.roc_table_from_labels(\"labels\") Returns: SplinkDataFrame: Table of truth statistics \"\"\" return roc_table ( self , labels_tablename , threshold_actual = threshold_actual , match_weight_round_to_nearest = match_weight_round_to_nearest , ) def match_weights_histogram ( self , df_predict : SplinkDataFrame , target_bins : int = 30 , width = 600 , height = 250 ): \"\"\"Generate a histogram that shows the distribution of match weights in `df_predict` Args: df_predict (SplinkDataFrame): Output of `linker.predict()` target_bins (int, optional): Target number of bins in histogram. Defaults to 30. width (int, optional): Width of output. Defaults to 600. height (int, optional): Height of output chart. Defaults to 250. Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" df = histogram_data ( self , df_predict , target_bins ) recs = df . as_record_dict () return match_weights_histogram ( recs , width = width , height = height ) def waterfall_chart ( self , records : List [ dict ], filter_nulls = True ): \"\"\"Visualise how the final match weight is computed for the provided pairwise record comparisons. Records must be provided as a list of dictionaries. This would usually be obtained from `df.as_record_dict(limit=n)` where `df` is a SplinkDataFrame. Examples: >>> df = linker.predict(threshold_match_weight=2) >>> records = df.as_record_dict(limit=10) >>> linker.waterfall_chart(records) Args: records (List[dict]): Usually be obtained from `df.as_record_dict(limit=n)` where `df` is a SplinkDataFrame. filter_nulls (bool, optional): Whether the visualiation shows null comparisons, which have no effect on final match weight. Defaults to True. Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" self . _raise_error_if_necessary_waterfall_columns_not_computed () return waterfall_chart ( records , self . _settings_obj , filter_nulls ) def unlinkables_chart ( self , x_col = \"match_weight\" , source_dataset = None , as_dict = False , ): \"\"\"Generate an interactive chart displaying the proportion of records that are \"unlinkable\" for a given splink score threshold and model parameters. Unlinkable records are those that, even when compared with themselves, do not contain enough information to confirm a match. Args: x_col (str, optional): Column to use for the x-axis. Defaults to \"match_weight\". source_dataset (str, optional): Name of the source dataset to use for the title of the output chart. as_dict (bool, optional): If True, return a dict version of the chart. Examples: >>> # For the simplest code pipeline, load a pre-trained model >>> # and run this against the test data. >>> df = pd.read_csv(\"./tests/datasets/fake_1000_from_splink_demos.csv\") >>> linker = DuckDBLinker(df) >>> linker.load_settings_from_json(\"saved_settings.json\") >>> linker.unlinkables_chart() >>> >>> # For more complex code pipelines, you can run an entire pipeline >>> # that estimates your m and u values, before `unlinkables_chart(). Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" # Link our initial df on itself and calculate the % of unlinkable entries records = unlinkables_data ( self , x_col ) return unlinkables_chart ( records , x_col , source_dataset ) def comparison_viewer_dashboard ( self , df_predict : SplinkDataFrame , out_path : str , overwrite = False , num_example_rows = 2 , return_html_as_string = False , ): \"\"\"Generate an interactive html visualization of the linker's predictions and save to `out_path`. For more information see [this video](https://www.youtube.com/watch?v=DNvCMqjipis) Args: df_predict (SplinkDataFrame): The outputs of `linker.predict()` out_path (str): The path (including filename) to save the html file to. overwrite (bool, optional): Overwrite the html file if it already exists? Defaults to False. num_example_rows (int, optional): Number of example rows per comparison vector. Defaults to 2. return_html_as_string: If True, return the html as a string Examples: >>> df_predictions = linker.predict() >>> linker.comparison_viewer_dashboard(df_predictions, \"scv.html\", True, 2) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame(src=\"./scv.html\", width=\"100%\", height=1200) \"\"\" self . _raise_error_if_necessary_waterfall_columns_not_computed () sql = comparison_vector_distribution_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vector_distribution\" ) sqls = comparison_viewer_table_sqls ( self , num_example_rows ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) df = self . _execute_sql_pipeline ([ df_predict ]) rendered = render_splink_comparison_viewer_html ( df . as_record_dict (), self . _settings_obj . _as_completed_dict (), out_path , overwrite , ) if return_html_as_string : return rendered def parameter_estimate_comparisons_chart ( self , include_m = True , include_u = True ): \"\"\"Show a chart that shows how parameter estimates have differed across the different estimation methods you have used. For example, if you have run two EM estimation sessions, blocking on different variables, and both result in parameter estimates for first_name, this chart will enable easy comparison of the different estimates Args: include_m (bool, optional): Show different estimates of m values. Defaults to True. include_u (bool, optional): Show different estimates of u values. Defaults to True. \"\"\" records = self . _settings_obj . _parameter_estimates_as_records to_retain = [] if include_m : to_retain . append ( \"m\" ) if include_u : to_retain . append ( \"u\" ) records = [ r for r in records if r [ \"m_or_u\" ] in to_retain ] return parameter_estimate_comparisons ( records ) def missingness_chart ( self , input_dataset : str = None ): \"\"\"Generate a summary chart of the missingness (prevalence of nulls) of columns in the input datasets. By default, missingness is assessed across all input datasets Args: input_dataset (str, optional): Name of one of the input tables in the database. If provided, missingness will be computed for this table alone. Defaults to None. Examples: >>> linker.missingness_chart() >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker.missingness_chart() >>> save_offline_chart(c.spec, \"test_chart.html\") >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame(src=\"./test_chart.html\", width=1000, height=500 \"\"\" records = missingness_data ( self , input_dataset ) return missingness_chart ( records , input_dataset ) def completeness_chart ( self , input_dataset : str = None , cols : List [ str ] = None ): \"\"\"Generate a summary chart of the completeness (proportion of non-nulls) of columns in each of the input datasets. By default, completeness is assessed for all column in the input data. Args: input_dataset (str, optional): Name of one of the input tables in the database. If provided, completeness will be computed for this table alone. Defaults to None. cols (List[str], optional): List of column names to calculate completeness. Default to None. Examples: >>> linker.completeness_chart() >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker.completeness_chart() >>> save_offline_chart(c.spec, \"test_chart.html\") >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame(src=\"./test_chart.html\", width=1000, height=500 \"\"\" records = completeness_data ( self , input_dataset , cols ) return completeness_chart ( records , input_dataset ) def count_num_comparisons_from_blocking_rule ( self , blocking_rule : str , link_type : str = None , unique_id_column_name : str = None , ) -> int : \"\"\"Compute the number of pairwise record comparisons that would be generated by a blocking rule Args: blocking_rule (str): The blocking rule to analyse link_type (str, optional): The link type. This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. unique_id_column_name (str, optional): This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. Examples: >>> br = \"l.first_name = r.first_name\" >>> linker.count_num_comparisons_from_blocking_rule(br) 19387 >>> br = \"l.name = r.name and substr(l.dob,1,4) = substr(r.dob,1,4)\" >>> linker.count_num_comparisons_from_blocking_rule(br) 394 Returns: int: The number of comparisons generated by the blocking rule \"\"\" sql = vertically_concatenate_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_concat\" ) sql = number_of_comparisons_generated_by_blocking_rule_sql ( self , blocking_rule , link_type , unique_id_column_name ) self . _enqueue_sql ( sql , \"__splink__analyse_blocking_rule\" ) res = self . _execute_sql_pipeline () . as_record_dict ()[ 0 ] return res [ \"count_of_pairwise_comparisons_generated\" ] def cumulative_num_comparisons_from_blocking_rules_chart ( self , blocking_rules : str or list = None , link_type : str = None , unique_id_column_name : str = None , ): \"\"\"Display a chart with the cumulative number of comparisons generated by a selection of blocking rules. This is equivalent to the output size of df_predict and details how many comparisons each of your individual blocking rules will contribute to the total. Args: blocking_rules (str or list): The blocking rule(s) to compute comparisons for. If null, the rules set out in your settings object will be used. link_type (str, optional): The link type. This defaults to the link type outlined in your settings object. unique_id_column_name (str, optional): This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. Examples: >>> linker_settings = DuckDBLinker(df, settings) >>> # Compute the cumulative number of comparisons generated by the rules >>> # in your settings object. >>> linker_settings.cumulative_num_comparisons_from_blocking_rules_chart() >>> >>> # Generate total comparisons with custom blocking rules. >>> blocking_rules = [ >>> \"l.surname = r.surname\", >>> \"l.first_name = r.first_name >>> and substr(l.dob,1,4) = substr(r.dob,1,4)\" >>> ] >>> >>> linker.cumulative_num_comparisons_from_blocking_rules_chart( >>> blocking_rules >>> ) Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" if blocking_rules : blocking_rules = ensure_is_list ( blocking_rules ) records = cumulative_comparisons_generated_by_blocking_rules ( self , blocking_rules , link_type , unique_id_column_name , ) return cumulative_blocking_rule_comparisons_generated ( records ) def count_num_comparisons_from_blocking_rules_for_prediction ( self , df_predict ): \"\"\"Counts the maginal number of edges created from each of the blocking rules in `blocking_rules_to_generate_predictions` This is different to `count_num_comparisons_from_blocking_rule` because it (a) analyses multiple blocking rules rather than a single rule, and (b) deduplicates any comparisons that are generated, to tell you the marginal effect of each entry in `blocking_rules_to_generate_predictions` Args: df_predict (SplinkDataFrame): SplinkDataFrame with match weights and probabilities of rows matching Examples: >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.load_settings_from_json(\"saved_settings.json\") >>> df_predict = linker.predict(threshold_match_probability=0.95) >>> count_pairwise = linker.count_num_comparisons_from_blocking_rules_for_prediction(df_predict) >>> count_pairwise.as_pandas_dataframe(limit=5) Returns: SplinkDataFrame: A SplinkDataFrame of the pairwise comparisons and estimated pairwise comparisons generated by the blocking rules. \"\"\" # noqa: E501 sql = count_num_comparisons_from_blocking_rules_for_prediction_sql ( df_predict ) match_key_analysis = self . _sql_to_splink_dataframe_checking_cache ( sql , \"__splink__match_key_analysis\" ) return match_key_analysis def match_weights_chart ( self ): \"\"\"Display a chart of the (partial) match weights of the linkage model Examples: >>> linker.match_weights_chart() >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker.match_weights_chart() >>> save_offline_chart(c.spec, \"test_chart.html\") >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame(src=\"./test_chart.html\", width=1000, height=500) Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" return self . _settings_obj . match_weights_chart () def m_u_parameters_chart ( self ): \"\"\"Display a chart of the m and u parameters of the linkage model Examples: >>> linker.m_u_parameters_chart() >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker.match_weights_chart() >>> save_offline_chart(c.spec, \"test_chart.html\") >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame(src=\"./test_chart.html\", width=1000, height=500) Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" return self . _settings_obj . m_u_parameters_chart () def cluster_studio_dashboard ( self , df_predict : SplinkDataFrame , df_clustered : SplinkDataFrame , out_path : str , sampling_method = \"random\" , sample_size : int = 10 , cluster_ids : list = None , cluster_names : list = None , overwrite : bool = False , return_html_as_string = False , ): \"\"\"Generate an interactive html visualization of the predicted cluster and save to `out_path`. Args: df_predict (SplinkDataFrame): The outputs of `linker.predict()` df_clustered (SplinkDataFrame): The outputs of `linker.cluster_pairwise_predictions_at_threshold()` out_path (str): The path (including filename) to save the html file to. sampling_method (str, optional): `random` or `by_cluster_size`. Defaults to `random`. sample_size (int, optional): Number of clusters to show in the dahboard. Defaults to 10. cluster_ids (list): The IDs of the clusters that will be displayed in the dashboard. If provided, ignore the `sampling_method` and `sample_size` arguments. Defaults to None. overwrite (bool, optional): Overwrite the html file if it already exists? Defaults to False. cluster_names (list, optional): If provided, the dashboard will display these names in the selection box. Ony works in conjunction with `cluster_ids`. Defaults to None. return_html_as_string: If True, return the html as a string Examples: >>> df_p = linker.predict() >>> df_c = linker.cluster_pairwise_predictions_at_threshold(df_p, 0.5) >>> linker.cluster_studio_dashboard( >>> df_p, df_c, [0, 4, 7], \"cluster_studio.html\" >>> ) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame(src=\"./cluster_studio.html\", width=\"100%\", height=1200) \"\"\" self . _raise_error_if_necessary_waterfall_columns_not_computed () rendered = render_splink_cluster_studio_html ( self , df_predict , df_clustered , out_path , sampling_method = sampling_method , sample_size = sample_size , cluster_ids = cluster_ids , overwrite = overwrite , cluster_names = cluster_names , ) if return_html_as_string : return rendered def save_settings_to_json ( self , out_path : str , overwrite = False ) -> dict : \"\"\"Save the configuration and parameters the linkage model to a `.json` file. The model can later be loaded back in using `linker.load_settings_from_json()` Examples: >>> linker.save_settings_to_json(\"my_settings.json\", overwrite=True) Args: out_path (str): File path for json file overwrite (bool, optional): Overwrite if already exists? Defaults to False. \"\"\" model_dict = self . _settings_obj . as_dict () if out_path : if os . path . isfile ( out_path ) and not overwrite : raise ValueError ( f \"The path { out_path } already exists. Please provide a different \" \"path or set overwrite=True\" ) with open ( out_path , \"w\" , encoding = \"utf-8\" ) as f : json . dump ( model_dict , f , indent = 4 ) def load_settings_from_json ( self , in_path : str ): \"\"\"Load settings from a `.json` file. This `.json` file would usually be the output of `linker.save_settings_to_json()` Examples: >>> linker.load_settings_from_json(\"my_settings.json\") Args: in_path (str): Path to settings json file \"\"\" with open ( in_path , \"r\" ) as f : model_dict = json . load ( f ) self . initialise_settings ( model_dict ) __init__ ( input_table_or_tables , settings_dict = None , set_up_basic_logging = True , input_table_aliases = None ) \u00b6 Initialise the linker object, which manages the data linkage process and holds the data linkage model. Examples: >>> # Example 1: DuckDB >>> df = pd . read_csv ( \"data_to_dedupe.csv\" ) >>> linker = DuckDBLinker ( df , settings_dict ) >>> # Example 2: Spark >>> df_1 = spark . read . parquet ( \"table_1/\" ) >>> df_2 = spark . read . parquet ( \"table_2/\" ) >>> linker = SparkLinker ( >>> [ df_1 , df_2 ], >>> settings_dict , >>> input_table_aliases = [ \"customers\" , \"contact_center_callers\" ] >>> ) Parameters: Name Type Description Default input_table_or_tables Union [ str , list ] Input data into the linkage model. Either a single string (the name of a table in a database) for deduplication jobs, or a list of strings (the name of tables in a database) for link_only or link_and_dedupe. For some linkers, such as the DuckDBLinker and the SparkLinker, it's also possible to pass in dataframes (Pandas and Spark respectively) rather than strings. required settings_dict dict A Splink settings dictionary. If not provided when the object is created, can later be added using linker.initialise_settings() Defaults to None. None set_up_basic_logging bool If true, sets ups up basic logging so that Splink sends messages at INFO level to stdout. Defaults to True. True input_table_aliases Union [ str , list ] Labels assigned to input tables in Splink outputs. If the names of the tables in the input database are long or unspecific, this argument can be used to attach more easily readable/interpretable names. Defaults to None. None Source code in splink/linker.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 def __init__ ( self , input_table_or_tables : Union [ str , list ], settings_dict : dict = None , set_up_basic_logging : bool = True , input_table_aliases : Union [ str , list ] = None , ): \"\"\"Initialise the linker object, which manages the data linkage process and holds the data linkage model. Examples: >>> # Example 1: DuckDB >>> df = pd.read_csv(\"data_to_dedupe.csv\") >>> linker = DuckDBLinker(df, settings_dict) >>> # Example 2: Spark >>> df_1 = spark.read.parquet(\"table_1/\") >>> df_2 = spark.read.parquet(\"table_2/\") >>> linker = SparkLinker( >>> [df_1, df_2], >>> settings_dict, >>> input_table_aliases=[\"customers\", \"contact_center_callers\"] >>> ) Args: input_table_or_tables (Union[str, list]): Input data into the linkage model. Either a single string (the name of a table in a database) for deduplication jobs, or a list of strings (the name of tables in a database) for link_only or link_and_dedupe. For some linkers, such as the DuckDBLinker and the SparkLinker, it's also possible to pass in dataframes (Pandas and Spark respectively) rather than strings. settings_dict (dict, optional): A Splink settings dictionary. If not provided when the object is created, can later be added using `linker.initialise_settings()` Defaults to None. set_up_basic_logging (bool, optional): If true, sets ups up basic logging so that Splink sends messages at INFO level to stdout. Defaults to True. input_table_aliases (Union[str, list], optional): Labels assigned to input tables in Splink outputs. If the names of the tables in the input database are long or unspecific, this argument can be used to attach more easily readable/interpretable names. Defaults to None. \"\"\" if set_up_basic_logging : logging . basicConfig ( format = \" %(message)s \" , ) splink_logger = logging . getLogger ( \"splink\" ) splink_logger . setLevel ( logging . INFO ) self . _pipeline = SQLPipeline () self . _settings_dict = settings_dict if settings_dict is None : self . _settings_obj_ = None else : self . _settings_obj_ = Settings ( settings_dict ) self . _input_tables_dict = self . _get_input_tables_dict ( input_table_or_tables , input_table_aliases ) self . _validate_input_dfs () self . _em_training_sessions = [] self . _names_of_tables_created_by_splink : list = [] self . _find_new_matches_mode = False self . _train_u_using_random_sample_mode = False self . _compare_two_records_mode = False self . _self_link_mode = False self . _output_schema = \"\" self . debug_mode = False cluster_pairwise_predictions_at_threshold ( df_predict , threshold_match_probability ) \u00b6 Clusters the pairwise match predictions that result from linker.predict() into groups of connected record using the connected components graph clustering algorithm Records with an estimated match_probability above threshold_match_probability are considered to be a match (i.e. they represent the same entity). Parameters: Name Type Description Default df_predict SplinkDataFrame The results of linker.predict() required threshold_match_probability float Filter the pairwise match predictions to include only pairwise comparisons with a match_probability above this threshold. This dataframe is then fed into the clustering algorithm. required Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame containing a list of all IDs, clustered into groups based on the desired match threshold. Source code in splink/linker.py 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 def cluster_pairwise_predictions_at_threshold ( self , df_predict : SplinkDataFrame , threshold_match_probability : float ) -> SplinkDataFrame : \"\"\"Clusters the pairwise match predictions that result from `linker.predict()` into groups of connected record using the connected components graph clustering algorithm Records with an estimated `match_probability` above `threshold_match_probability` are considered to be a match (i.e. they represent the same entity). Args: df_predict (SplinkDataFrame): The results of `linker.predict()` threshold_match_probability (float): Filter the pairwise match predictions to include only pairwise comparisons with a match_probability above this threshold. This dataframe is then fed into the clustering algorithm. Returns: SplinkDataFrame: A SplinkDataFrame containing a list of all IDs, clustered into groups based on the desired match threshold. \"\"\" self . _initialise_df_concat_with_tf ( df_predict ) edges_table = _cc_create_unique_id_cols ( self , df_predict , threshold_match_probability , ) cc = solve_connected_components ( self , edges_table ) return cc cluster_studio_dashboard ( df_predict , df_clustered , out_path , sampling_method = 'random' , sample_size = 10 , cluster_ids = None , cluster_names = None , overwrite = False , return_html_as_string = False ) \u00b6 Generate an interactive html visualization of the predicted cluster and save to out_path . Parameters: Name Type Description Default df_predict SplinkDataFrame The outputs of linker.predict() required df_clustered SplinkDataFrame The outputs of linker.cluster_pairwise_predictions_at_threshold() required out_path str The path (including filename) to save the html file to. required sampling_method str random or by_cluster_size . Defaults to random . 'random' sample_size int Number of clusters to show in the dahboard. Defaults to 10. 10 cluster_ids list The IDs of the clusters that will be displayed in the dashboard. If provided, ignore the sampling_method and sample_size arguments. Defaults to None. None overwrite bool Overwrite the html file if it already exists? Defaults to False. False cluster_names list If provided, the dashboard will display these names in the selection box. Ony works in conjunction with cluster_ids . Defaults to None. None return_html_as_string If True, return the html as a string False Examples: >>> df_p = linker . predict () >>> df_c = linker . cluster_pairwise_predictions_at_threshold ( df_p , 0.5 ) >>> linker . cluster_studio_dashboard ( >>> df_p , df_c , [ 0 , 4 , 7 ], \"cluster_studio.html\" >>> ) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame ( src = \"./cluster_studio.html\" , width = \"100%\" , height = 1200 ) Source code in splink/linker.py 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 def cluster_studio_dashboard ( self , df_predict : SplinkDataFrame , df_clustered : SplinkDataFrame , out_path : str , sampling_method = \"random\" , sample_size : int = 10 , cluster_ids : list = None , cluster_names : list = None , overwrite : bool = False , return_html_as_string = False , ): \"\"\"Generate an interactive html visualization of the predicted cluster and save to `out_path`. Args: df_predict (SplinkDataFrame): The outputs of `linker.predict()` df_clustered (SplinkDataFrame): The outputs of `linker.cluster_pairwise_predictions_at_threshold()` out_path (str): The path (including filename) to save the html file to. sampling_method (str, optional): `random` or `by_cluster_size`. Defaults to `random`. sample_size (int, optional): Number of clusters to show in the dahboard. Defaults to 10. cluster_ids (list): The IDs of the clusters that will be displayed in the dashboard. If provided, ignore the `sampling_method` and `sample_size` arguments. Defaults to None. overwrite (bool, optional): Overwrite the html file if it already exists? Defaults to False. cluster_names (list, optional): If provided, the dashboard will display these names in the selection box. Ony works in conjunction with `cluster_ids`. Defaults to None. return_html_as_string: If True, return the html as a string Examples: >>> df_p = linker.predict() >>> df_c = linker.cluster_pairwise_predictions_at_threshold(df_p, 0.5) >>> linker.cluster_studio_dashboard( >>> df_p, df_c, [0, 4, 7], \"cluster_studio.html\" >>> ) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame(src=\"./cluster_studio.html\", width=\"100%\", height=1200) \"\"\" self . _raise_error_if_necessary_waterfall_columns_not_computed () rendered = render_splink_cluster_studio_html ( self , df_predict , df_clustered , out_path , sampling_method = sampling_method , sample_size = sample_size , cluster_ids = cluster_ids , overwrite = overwrite , cluster_names = cluster_names , ) if return_html_as_string : return rendered compare_two_records ( record_1 , record_2 ) \u00b6 Use the linkage model to compare and score a pairwise record comparison based on the two input records provided Parameters: Name Type Description Default record_1 dict dictionary representing the first record. Columns names and data types must be the same as the columns in the settings object required record_2 dict dictionary representing the second record. Columns names and data types must be the same as the columns in the settings object required Examples: >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . compare_two_records ( record_left , record_right ) Returns: Name Type Description SplinkDataFrame Pairwise comparison with scored prediction Source code in splink/linker.py 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 def compare_two_records ( self , record_1 : dict , record_2 : dict ): \"\"\"Use the linkage model to compare and score a pairwise record comparison based on the two input records provided Args: record_1 (dict): dictionary representing the first record. Columns names and data types must be the same as the columns in the settings object record_2 (dict): dictionary representing the second record. Columns names and data types must be the same as the columns in the settings object Examples: >>> linker = DuckDBLinker(df) >>> linker.load_settings_from_json(\"saved_settings.json\") >>> linker.compare_two_records(record_left, record_right) Returns: SplinkDataFrame: Pairwise comparison with scored prediction \"\"\" original_blocking_rules = ( self . _settings_obj . _blocking_rules_to_generate_predictions ) original_link_type = self . _settings_obj . _link_type self . _compare_two_records_mode = True self . _settings_obj . _blocking_rules_to_generate_predictions = [] self . _records_to_table ([ record_1 ], \"__splink__compare_two_records_left\" ) self . _records_to_table ([ record_2 ], \"__splink__compare_two_records_right\" ) sql_join_tf = _join_tf_to_input_df_sql ( self ) sql_join_tf = sql_join_tf . replace ( \"__splink__df_concat\" , \"__splink__compare_two_records_left\" ) self . _enqueue_sql ( sql_join_tf , \"__splink__compare_two_records_left_with_tf\" ) sql_join_tf = sql_join_tf . replace ( \"__splink__compare_two_records_left\" , \"__splink__compare_two_records_right\" ) self . _enqueue_sql ( sql_join_tf , \"__splink__compare_two_records_right_with_tf\" ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) predictions = self . _execute_sql_pipeline ( use_cache = False ) self . _settings_obj . _blocking_rules_to_generate_predictions = ( original_blocking_rules ) self . _settings_obj . _link_type = original_link_type self . _compare_two_records_mode = False return predictions comparison_viewer_dashboard ( df_predict , out_path , overwrite = False , num_example_rows = 2 , return_html_as_string = False ) \u00b6 Generate an interactive html visualization of the linker's predictions and save to out_path . For more information see this video Parameters: Name Type Description Default df_predict SplinkDataFrame The outputs of linker.predict() required out_path str The path (including filename) to save the html file to. required overwrite bool Overwrite the html file if it already exists? Defaults to False. False num_example_rows int Number of example rows per comparison vector. Defaults to 2. 2 return_html_as_string If True, return the html as a string False Examples: >>> df_predictions = linker . predict () >>> linker . comparison_viewer_dashboard ( df_predictions , \"scv.html\" , True , 2 ) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame ( src = \"./scv.html\" , width = \"100%\" , height = 1200 ) Source code in splink/linker.py 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 def comparison_viewer_dashboard ( self , df_predict : SplinkDataFrame , out_path : str , overwrite = False , num_example_rows = 2 , return_html_as_string = False , ): \"\"\"Generate an interactive html visualization of the linker's predictions and save to `out_path`. For more information see [this video](https://www.youtube.com/watch?v=DNvCMqjipis) Args: df_predict (SplinkDataFrame): The outputs of `linker.predict()` out_path (str): The path (including filename) to save the html file to. overwrite (bool, optional): Overwrite the html file if it already exists? Defaults to False. num_example_rows (int, optional): Number of example rows per comparison vector. Defaults to 2. return_html_as_string: If True, return the html as a string Examples: >>> df_predictions = linker.predict() >>> linker.comparison_viewer_dashboard(df_predictions, \"scv.html\", True, 2) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame(src=\"./scv.html\", width=\"100%\", height=1200) \"\"\" self . _raise_error_if_necessary_waterfall_columns_not_computed () sql = comparison_vector_distribution_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vector_distribution\" ) sqls = comparison_viewer_table_sqls ( self , num_example_rows ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) df = self . _execute_sql_pipeline ([ df_predict ]) rendered = render_splink_comparison_viewer_html ( df . as_record_dict (), self . _settings_obj . _as_completed_dict (), out_path , overwrite , ) if return_html_as_string : return rendered count_num_comparisons_from_blocking_rule ( blocking_rule , link_type = None , unique_id_column_name = None ) \u00b6 Compute the number of pairwise record comparisons that would be generated by a blocking rule Parameters: Name Type Description Default blocking_rule str The blocking rule to analyse required link_type str The link type. This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None unique_id_column_name str This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None Examples: >>> br = \"l.first_name = r.first_name\" >>> linker . count_num_comparisons_from_blocking_rule ( br ) 19387 >>> br = \"l.name = r.name and substr(l.dob,1,4) = substr(r.dob,1,4)\" >>> linker . count_num_comparisons_from_blocking_rule ( br ) 394 Returns: Name Type Description int int The number of comparisons generated by the blocking rule Source code in splink/linker.py 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 def count_num_comparisons_from_blocking_rule ( self , blocking_rule : str , link_type : str = None , unique_id_column_name : str = None , ) -> int : \"\"\"Compute the number of pairwise record comparisons that would be generated by a blocking rule Args: blocking_rule (str): The blocking rule to analyse link_type (str, optional): The link type. This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. unique_id_column_name (str, optional): This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. Examples: >>> br = \"l.first_name = r.first_name\" >>> linker.count_num_comparisons_from_blocking_rule(br) 19387 >>> br = \"l.name = r.name and substr(l.dob,1,4) = substr(r.dob,1,4)\" >>> linker.count_num_comparisons_from_blocking_rule(br) 394 Returns: int: The number of comparisons generated by the blocking rule \"\"\" sql = vertically_concatenate_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_concat\" ) sql = number_of_comparisons_generated_by_blocking_rule_sql ( self , blocking_rule , link_type , unique_id_column_name ) self . _enqueue_sql ( sql , \"__splink__analyse_blocking_rule\" ) res = self . _execute_sql_pipeline () . as_record_dict ()[ 0 ] return res [ \"count_of_pairwise_comparisons_generated\" ] count_num_comparisons_from_blocking_rules_for_prediction ( df_predict ) \u00b6 Counts the maginal number of edges created from each of the blocking rules in blocking_rules_to_generate_predictions This is different to count_num_comparisons_from_blocking_rule because it (a) analyses multiple blocking rules rather than a single rule, and (b) deduplicates any comparisons that are generated, to tell you the marginal effect of each entry in blocking_rules_to_generate_predictions Parameters: Name Type Description Default df_predict SplinkDataFrame SplinkDataFrame with match weights required Examples: >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> df_predict = linker . predict ( threshold_match_probability = 0.95 ) >>> count_pairwise = linker . count_num_comparisons_from_blocking_rules_for_prediction ( df_predict ) >>> count_pairwise . as_pandas_dataframe ( limit = 5 ) Returns: Name Type Description SplinkDataFrame A SplinkDataFrame of the pairwise comparisons and estimated pairwise comparisons generated by the blocking rules. Source code in splink/linker.py 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 def count_num_comparisons_from_blocking_rules_for_prediction ( self , df_predict ): \"\"\"Counts the maginal number of edges created from each of the blocking rules in `blocking_rules_to_generate_predictions` This is different to `count_num_comparisons_from_blocking_rule` because it (a) analyses multiple blocking rules rather than a single rule, and (b) deduplicates any comparisons that are generated, to tell you the marginal effect of each entry in `blocking_rules_to_generate_predictions` Args: df_predict (SplinkDataFrame): SplinkDataFrame with match weights and probabilities of rows matching Examples: >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.load_settings_from_json(\"saved_settings.json\") >>> df_predict = linker.predict(threshold_match_probability=0.95) >>> count_pairwise = linker.count_num_comparisons_from_blocking_rules_for_prediction(df_predict) >>> count_pairwise.as_pandas_dataframe(limit=5) Returns: SplinkDataFrame: A SplinkDataFrame of the pairwise comparisons and estimated pairwise comparisons generated by the blocking rules. \"\"\" # noqa: E501 sql = count_num_comparisons_from_blocking_rules_for_prediction_sql ( df_predict ) match_key_analysis = self . _sql_to_splink_dataframe_checking_cache ( sql , \"__splink__match_key_analysis\" ) return match_key_analysis compute_tf_table ( column_name ) \u00b6 Compute a term frequency table for a given column and persist to the database This method is useful if you want to pre-compute term frequency tables e.g. so that real time linkage executes faster, or so that you can estimate various models without having to recompute term frequency tables each time Examples: >>> # Example 1: Real time linkage >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . compute_tf_table ( \"surname\" ) >>> linker . compare_two_records ( record_left , record_right ) >>> # Example 2: Pre-computed term frequency tables in Spark >>> linker = SparkLinker ( df ) >>> df_first_name_tf = linker . compute_tf_table ( \"first_name\" ) >>> df_first_name_tf . write . parquet ( \"folder/first_name_tf\" ) >>> >>> # On subsequent data linking job, read this table rather than recompute >>> df_first_name_tf = spark . read . parquet ( \"folder/first_name_tf\" ) >>> df_first_name_tf . createOrReplaceTempView ( \"__splink__df_tf_first_name\" ) Parameters: Name Type Description Default column_name str The column name in the input table required Returns: Name Type Description SplinkDataFrame SplinkDataFrame The resultant table as a splink data frame Source code in splink/linker.py 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 def compute_tf_table ( self , column_name : str ) -> SplinkDataFrame : \"\"\"Compute a term frequency table for a given column and persist to the database This method is useful if you want to pre-compute term frequency tables e.g. so that real time linkage executes faster, or so that you can estimate various models without having to recompute term frequency tables each time Examples: >>> # Example 1: Real time linkage >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.load_settings_from_json(\"saved_settings.json\") >>> linker.compute_tf_table(\"surname\") >>> linker.compare_two_records(record_left, record_right) >>> # Example 2: Pre-computed term frequency tables in Spark >>> linker = SparkLinker(df) >>> df_first_name_tf = linker.compute_tf_table(\"first_name\") >>> df_first_name_tf.write.parquet(\"folder/first_name_tf\") >>> >>> # On subsequent data linking job, read this table rather than recompute >>> df_first_name_tf = spark.read.parquet(\"folder/first_name_tf\") >>> df_first_name_tf.createOrReplaceTempView(\"__splink__df_tf_first_name\") Args: column_name (str): The column name in the input table Returns: SplinkDataFrame: The resultant table as a splink data frame \"\"\" sql = vertically_concatenate_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_concat\" ) input_col = InputColumn ( column_name , tf_adjustments = True ) sql = term_frequencies_for_single_column_sql ( input_col ) self . _enqueue_sql ( sql , colname_to_tf_tablename ( input_col )) return self . _execute_sql_pipeline ( materialise_as_hash = False ) cumulative_num_comparisons_from_blocking_rules_chart ( blocking_rules = None , link_type = None , unique_id_column_name = None ) \u00b6 Display a chart with the cumulative number of comparisons generated by a selection of blocking rules. This is equivalent to the output size of df_predict and details how many comparisons each of your individual blocking rules will contribute to the total. Parameters: Name Type Description Default blocking_rules str or list The blocking rule(s) to compute comparisons for. If null, the rules set out in your settings object will be used. None link_type str The link type. This defaults to the link type outlined in your settings object. None unique_id_column_name str This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None Examples: >>> linker_settings = DuckDBLinker ( df , settings ) >>> # Compute the cumulative number of comparisons generated by the rules >>> # in your settings object. >>> linker_settings . cumulative_num_comparisons_from_blocking_rules_chart () >>> >>> # Generate total comparisons with custom blocking rules. >>> blocking_rules = [ >>> \"l.surname = r.surname\" , >>> \"l.first_name = r.first_name >>> and substr ( l . dob , 1 , 4 ) = substr ( r . dob , 1 , 4 ) \" >>> ] >>> >>> linker . cumulative_num_comparisons_from_blocking_rules_chart ( >>> blocking_rules >>> ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. Source code in splink/linker.py 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 def cumulative_num_comparisons_from_blocking_rules_chart ( self , blocking_rules : str or list = None , link_type : str = None , unique_id_column_name : str = None , ): \"\"\"Display a chart with the cumulative number of comparisons generated by a selection of blocking rules. This is equivalent to the output size of df_predict and details how many comparisons each of your individual blocking rules will contribute to the total. Args: blocking_rules (str or list): The blocking rule(s) to compute comparisons for. If null, the rules set out in your settings object will be used. link_type (str, optional): The link type. This defaults to the link type outlined in your settings object. unique_id_column_name (str, optional): This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. Examples: >>> linker_settings = DuckDBLinker(df, settings) >>> # Compute the cumulative number of comparisons generated by the rules >>> # in your settings object. >>> linker_settings.cumulative_num_comparisons_from_blocking_rules_chart() >>> >>> # Generate total comparisons with custom blocking rules. >>> blocking_rules = [ >>> \"l.surname = r.surname\", >>> \"l.first_name = r.first_name >>> and substr(l.dob,1,4) = substr(r.dob,1,4)\" >>> ] >>> >>> linker.cumulative_num_comparisons_from_blocking_rules_chart( >>> blocking_rules >>> ) Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" if blocking_rules : blocking_rules = ensure_is_list ( blocking_rules ) records = cumulative_comparisons_generated_by_blocking_rules ( self , blocking_rules , link_type , unique_id_column_name , ) return cumulative_blocking_rule_comparisons_generated ( records ) deterministic_link () \u00b6 Uses the blocking rules specified by blocking_rules_to_generate_predictions in the settings dictionary to generate pairwise record comparisons. For deterministic linkage, this should be a list of blocking rules which are strict enough to generate only true links. Deterministic linkage, however, is likely to result in missed links (false negatives). Examples: >>> linker = DuckDBLinker ( df ) >>> >>> settings = { >>> \"link_type\" : \"dedupe_only\" , >>> \"blocking_rules_to_generate_predictions\" : [ >>> \"l.first_name = r.first_name\" , >>> \"l.surname = r.surname\" , >>> ], >>> \"comparisons\" : [] >>> } >>> >>> from splink.duckdb.duckdb_linker import DuckDBLinker >>> >>> linker = DuckDBLinker ( df , settings ) >>> df = linker . deterministic_link () Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. Source code in splink/linker.py 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 def deterministic_link ( self ) -> SplinkDataFrame : \"\"\"Uses the blocking rules specified by `blocking_rules_to_generate_predictions` in the settings dictionary to generate pairwise record comparisons. For deterministic linkage, this should be a list of blocking rules which are strict enough to generate only true links. Deterministic linkage, however, is likely to result in missed links (false negatives). Examples: >>> linker = DuckDBLinker(df) >>> >>> settings = { >>> \"link_type\": \"dedupe_only\", >>> \"blocking_rules_to_generate_predictions\": [ >>> \"l.first_name = r.first_name\", >>> \"l.surname = r.surname\", >>> ], >>> \"comparisons\": [] >>> } >>> >>> from splink.duckdb.duckdb_linker import DuckDBLinker >>> >>> linker = DuckDBLinker(df, settings) >>> df = linker.deterministic_link() Returns: SplinkDataFrame: A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. \"\"\" self . _initialise_df_concat_with_tf () sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) return self . _execute_sql_pipeline () estimate_m_from_label_column ( label_colname ) \u00b6 Estimate the m parameters of the linkage model from a label (ground truth) column in the input dataframe(s). The m parameters represent the proportion of record comparisons that fall into each comparison level amongst truly matching records. The ground truth column is used to generate pairwise record comparisons which are then assumed to be matches. For example, if the entity being matched is persons, and your input dataset(s) contain social security number, this could be used to estimate the m values for the model. Note that this column does not need to be fully populated. A common case is where a unique identifier such as social security number is only partially populated. Parameters: Name Type Description Default label_colname str The name of the column containing the ground truth label in the input data. required Examples: >>> linker . estimate_m_from_label_column ( \"social_security_number\" ) Returns: Type Description Updates the estimated m parameters within the linker object and returns nothing. Source code in splink/linker.py 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 def estimate_m_from_label_column ( self , label_colname : str ): \"\"\"Estimate the m parameters of the linkage model from a label (ground truth) column in the input dataframe(s). The m parameters represent the proportion of record comparisons that fall into each comparison level amongst truly matching records. The ground truth column is used to generate pairwise record comparisons which are then assumed to be matches. For example, if the entity being matched is persons, and your input dataset(s) contain social security number, this could be used to estimate the m values for the model. Note that this column does not need to be fully populated. A common case is where a unique identifier such as social security number is only partially populated. Args: label_colname (str): The name of the column containing the ground truth label in the input data. Examples: >>> linker.estimate_m_from_label_column(\"social_security_number\") Returns: Updates the estimated m parameters within the linker object and returns nothing. \"\"\" self . _initialise_df_concat_with_tf ( materialise = True ) estimate_m_values_from_label_column ( self , self . _input_tables_dict , label_colname ) self . _populate_m_u_from_trained_values () self . _settings_obj . _columns_without_estimated_parameters_message () estimate_parameters_using_expectation_maximisation ( blocking_rule , comparisons_to_deactivate = None , comparison_levels_to_reverse_blocking_rule = None , fix_probability_two_random_records_match = False , fix_m_probabilities = False , fix_u_probabilities = True ) \u00b6 Estimate the parameters of the linkage model using expectation maximisation. By default, the m probabilities are estimated, but not the u probabilities, because good estiamtes for the u probabilities can be obtained from linker.estimate_u_using_random_sampling() . You can change this by setting fix_u_probabilities to False. The blocking rule provided is used to generate pairwise record comparisons. Usually, this should be a blocking rule that results in a dataframe where matches are between about 1% and 99% of the comparisons. By default, m parameters are estimated for all comparisons except those which are included in the blocking rule. For example, if the blocking rule is l.first_name = r.first_name , then parameter esimates will be made for all comparison except those which use first_name in their sql_condition By default, the probability two random records match is estimated for the blocked data, and then the m and u parameters for the columns specified in the blocking rules are used to estiamte the global probability two random records match. To control which comparisons should have their parameter estimated, and the process of 'reversing out' the global probability two random records match, the user may specify comparisons_to_deactivate and comparison_levels_to_reverse_blocking_rule . This is useful, for example if you block on the dmetaphone of a column but match on the original column. Examples: >>> # Default behaviour >>> br_training = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker . estimate_parameters_using_expectation_maximisation ( br_training ) >>> # Specify which comparisons to deactivate >>> br_training = \"l.dmeta_first_name = r.dmeta_first_name\" >>> settings_obj = linker . _settings_obj >>> comp = settings_obj . _get_comparison_by_output_column_name ( \"first_name\" ) >>> dmeta_level = comp . _get_comparison_level_by_comparison_vector_value ( 1 ) >>> linker . estimate_parameters_using_expectation_maximisation ( >>> br_training , >>> comparisons_to_deactivate = [ \"first_name\" ], >>> comparison_levels_to_reverse_blocking_rule = [ dmeta_level ], >>> ) Parameters: Name Type Description Default blocking_rule str The blocking rule used to generate pairwise record comparisons. required comparisons_to_deactivate list By default, splink will analyse the blocking rule provided and estimate the m parameters for all comaprisons except those included in the blocking rule. If comparisons_to_deactivate are provided, spink will instead estimate m parameters for all comparison except those specified in the comparisons_to_deactivate list. This list can either contain the output_column_name of the Comparison as a string, or Comparison objects. Defaults to None. None comparison_levels_to_reverse_blocking_rule list By default, splink will analyse the blocking rule provided and adjust the global probability two random records match to account for the matches specified in the blocking rule. If provided, this argument will overrule this default behaviour. The user must provide a list of ComparisonLevel objects. Defaults to None. None fix_probability_two_random_records_match bool If True, do not update the probability two random records match after each iteration. Defaults to False. False fix_m_probabilities bool If True, do not update the m probabilities after each iteration. Defaults to False. False fix_u_probabilities bool If True, do not update the u probabilities after each iteration. Defaults to True. True Examples: >>> blocking_rule = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker . estimate_parameters_using_expectation_maximisation ( blocking_rule ) Returns: Name Type Description EMTrainingSession EMTrainingSession An object containing information about the training session such as how parameters changed during the iteration history Source code in splink/linker.py 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 def estimate_parameters_using_expectation_maximisation ( self , blocking_rule : str , comparisons_to_deactivate : List [ Union [ str , Comparison ]] = None , comparison_levels_to_reverse_blocking_rule : List [ ComparisonLevel ] = None , fix_probability_two_random_records_match : bool = False , fix_m_probabilities = False , fix_u_probabilities = True , ) -> EMTrainingSession : \"\"\"Estimate the parameters of the linkage model using expectation maximisation. By default, the m probabilities are estimated, but not the u probabilities, because good estiamtes for the u probabilities can be obtained from `linker.estimate_u_using_random_sampling()`. You can change this by setting `fix_u_probabilities` to False. The blocking rule provided is used to generate pairwise record comparisons. Usually, this should be a blocking rule that results in a dataframe where matches are between about 1% and 99% of the comparisons. By default, m parameters are estimated for all comparisons except those which are included in the blocking rule. For example, if the blocking rule is `l.first_name = r.first_name`, then parameter esimates will be made for all comparison except those which use `first_name` in their sql_condition By default, the probability two random records match is estimated for the blocked data, and then the m and u parameters for the columns specified in the blocking rules are used to estiamte the global probability two random records match. To control which comparisons should have their parameter estimated, and the process of 'reversing out' the global probability two random records match, the user may specify `comparisons_to_deactivate` and `comparison_levels_to_reverse_blocking_rule`. This is useful, for example if you block on the dmetaphone of a column but match on the original column. Examples: >>> # Default behaviour >>> br_training = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker.estimate_parameters_using_expectation_maximisation(br_training) >>> # Specify which comparisons to deactivate >>> br_training = \"l.dmeta_first_name = r.dmeta_first_name\" >>> settings_obj = linker._settings_obj >>> comp = settings_obj._get_comparison_by_output_column_name(\"first_name\") >>> dmeta_level = comp._get_comparison_level_by_comparison_vector_value(1) >>> linker.estimate_parameters_using_expectation_maximisation( >>> br_training, >>> comparisons_to_deactivate=[\"first_name\"], >>> comparison_levels_to_reverse_blocking_rule=[dmeta_level], >>> ) Args: blocking_rule (str): The blocking rule used to generate pairwise record comparisons. comparisons_to_deactivate (list, optional): By default, splink will analyse the blocking rule provided and estimate the m parameters for all comaprisons except those included in the blocking rule. If comparisons_to_deactivate are provided, spink will instead estimate m parameters for all comparison except those specified in the comparisons_to_deactivate list. This list can either contain the output_column_name of the Comparison as a string, or Comparison objects. Defaults to None. comparison_levels_to_reverse_blocking_rule (list, optional): By default, splink will analyse the blocking rule provided and adjust the global probability two random records match to account for the matches specified in the blocking rule. If provided, this argument will overrule this default behaviour. The user must provide a list of ComparisonLevel objects. Defaults to None. fix_probability_two_random_records_match (bool, optional): If True, do not update the probability two random records match after each iteration. Defaults to False. fix_m_probabilities (bool, optional): If True, do not update the m probabilities after each iteration. Defaults to False. fix_u_probabilities (bool, optional): If True, do not update the u probabilities after each iteration. Defaults to True. Examples: >>> blocking_rule = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker.estimate_parameters_using_expectation_maximisation(blocking_rule) Returns: EMTrainingSession: An object containing information about the training session such as how parameters changed during the iteration history \"\"\" self . _initialise_df_concat_with_tf ( materialise = True ) if comparisons_to_deactivate : # If user provided a string, convert to Comparison object comparisons_to_deactivate = [ self . _settings_obj . _get_comparison_by_output_column_name ( n ) if isinstance ( n , str ) else n for n in comparisons_to_deactivate ] if comparison_levels_to_reverse_blocking_rule is None : logger . warning ( \" \\n WARNING: \\n \" \"You have provided comparisons_to_deactivate but not \" \"comparison_levels_to_reverse_blocking_rule. \\n \" \"If comparisons_to_deactivate is provided, then \" \"you usually need to provide corresponding \" \"comparison_levels_to_reverse_blocking_rule. \" \"because each comparison to deactivate if effectively treated \" \"as an exact match.\" ) em_training_session = EMTrainingSession ( self , blocking_rule , fix_u_probabilities = fix_u_probabilities , fix_m_probabilities = fix_m_probabilities , fix_probability_two_random_records_match = fix_probability_two_random_records_match , # noqa 501 comparisons_to_deactivate = comparisons_to_deactivate , comparison_levels_to_reverse_blocking_rule = comparison_levels_to_reverse_blocking_rule , # noqa 501 ) em_training_session . _train () self . _populate_m_u_from_trained_values () self . _populate_probability_two_random_records_match_from_trained_values () self . _settings_obj . _columns_without_estimated_parameters_message () return em_training_session estimate_u_using_random_sampling ( target_rows ) \u00b6 Estimate the u parameters of the linkage model using random sampling. The u parameters represent the proportion of record comparisons that fall into each comparison level amongst truly non-matching records. This procedure takes a sample of the data and generates the cartesian product of pairwise record comparisons amongst the sampled records. The validity of the u values rests on the assumption that the resultant pairwise comparisons are non-matches (or at least, they are very unlikely to be matches). For large datasets, this is typically true. Parameters: Name Type Description Default target_rows int The target number of pairwise record comparisons from required Examples: >>> linker . estimate_u_using_random_sampling ( 1e8 ) Returns: Name Type Description None Updates the estimated u parameters within the linker object and returns nothing. Source code in splink/linker.py 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 def estimate_u_using_random_sampling ( self , target_rows : int ): \"\"\"Estimate the u parameters of the linkage model using random sampling. The u parameters represent the proportion of record comparisons that fall into each comparison level amongst truly non-matching records. This procedure takes a sample of the data and generates the cartesian product of pairwise record comparisons amongst the sampled records. The validity of the u values rests on the assumption that the resultant pairwise comparisons are non-matches (or at least, they are very unlikely to be matches). For large datasets, this is typically true. Args: target_rows (int): The target number of pairwise record comparisons from which to derive the u values. Larger will give more accurate estimates but lead to longer runtimes. In our experience at least 1e9 (one billion) gives best results but can take a long time to compute. 1e7 (ten million) is often adequate whilst testing different model specifications, before the final model is estimated. Examples: >>> linker.estimate_u_using_random_sampling(1e8) Returns: None: Updates the estimated u parameters within the linker object and returns nothing. \"\"\" self . _initialise_df_concat_with_tf ( materialise = True ) estimate_u_values ( self , target_rows ) self . _populate_m_u_from_trained_values () self . _settings_obj . _columns_without_estimated_parameters_message () find_matches_to_new_records ( records_or_tablename , blocking_rules = [], match_weight_threshold =- 4 ) \u00b6 Given one or more records, find records in the input dataset(s) which match and return in order of the splink prediction score. This effectively provides a way of searching the input datasets for given record(s) Parameters: Name Type Description Default records_or_tablename List [ dict ] Input search record(s) as list of dict, or a table registered to the database. required blocking_rules list Blocking rules to select which records to find and score. If [], do not use a blocking rule - meaning the input records will be compared to all records provided to the linker when it was instantiated. Defaults to []. [] match_weight_threshold int Return matches with a match weight above this threshold. Defaults to -4. -4 Examples: >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> # Pre-compute tf tables for any tables with >>> # term frequency adjustments >>> linker . compute_tf_table ( \"first_name\" ) >>> record = { 'unique_id' : 1 , >>> 'first_name' : \"John\" , >>> 'surname' : \"Smith\" , >>> 'dob' : \"1971-05-24\" , >>> 'city' : \"London\" , >>> 'email' : \"john@smith.net\" >>> } >>> df = linker . find_matches_to_new_records ([ record ], blocking_rules = []) Returns: Name Type Description SplinkDataFrame SplinkDataFrame The pairwise comparisons. Source code in splink/linker.py 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 def find_matches_to_new_records ( self , records_or_tablename , blocking_rules = [], match_weight_threshold =- 4 , ) -> SplinkDataFrame : \"\"\"Given one or more records, find records in the input dataset(s) which match and return in order of the splink prediction score. This effectively provides a way of searching the input datasets for given record(s) Args: records_or_tablename (List[dict]): Input search record(s) as list of dict, or a table registered to the database. blocking_rules (list, optional): Blocking rules to select which records to find and score. If [], do not use a blocking rule - meaning the input records will be compared to all records provided to the linker when it was instantiated. Defaults to []. match_weight_threshold (int, optional): Return matches with a match weight above this threshold. Defaults to -4. Examples: >>> linker = DuckDBLinker(df) >>> linker.load_settings_from_json(\"saved_settings.json\") >>> # Pre-compute tf tables for any tables with >>> # term frequency adjustments >>> linker.compute_tf_table(\"first_name\") >>> record = {'unique_id': 1, >>> 'first_name': \"John\", >>> 'surname': \"Smith\", >>> 'dob': \"1971-05-24\", >>> 'city': \"London\", >>> 'email': \"john@smith.net\" >>> } >>> df = linker.find_matches_to_new_records([record], blocking_rules=[]) Returns: SplinkDataFrame: The pairwise comparisons. \"\"\" original_blocking_rules = ( self . _settings_obj . _blocking_rules_to_generate_predictions ) original_link_type = self . _settings_obj . _link_type if not isinstance ( records_or_tablename , str ): self . _records_to_table ( records_or_tablename , \"__splink__df_new_records\" ) new_records_tablename = \"__splink__df_new_records\" else : new_records_tablename = records_or_tablename blocking_rules = [ BlockingRule ( r ) if not isinstance ( r , BlockingRule ) else r for r in blocking_rules ] self . _settings_obj . _blocking_rules_to_generate_predictions = blocking_rules self . _settings_obj . _link_type = \"link_only_find_matches_to_new_records\" self . _find_new_matches_mode = True sql = _join_tf_to_input_df_sql ( self ) sql = sql . replace ( \"__splink__df_concat\" , new_records_tablename ) self . _enqueue_sql ( sql , \"__splink__df_new_records_with_tf\" ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) sql = f \"\"\" select * from __splink__df_predict where match_weight > { match_weight_threshold } \"\"\" self . _enqueue_sql ( sql , \"__splink_find_matches_predictions\" ) predictions = self . _execute_sql_pipeline ( use_cache = False ) self . _settings_obj . _blocking_rules_to_generate_predictions = ( original_blocking_rules ) self . _settings_obj . _link_type = original_link_type self . _find_new_matches_mode = False return predictions initialise_settings ( settings_dict ) \u00b6 Initialise settings for the linker. To be used if settings were not passed to the linker on creation. Examples: >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . profile_columns ([ \"first_name\" , \"surname\" ]) >>> linker . initialise_settings ( settings_dict ) Parameters: Name Type Description Default settings_dict dict A Splink settings dictionary required Source code in splink/linker.py 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 def initialise_settings ( self , settings_dict : dict ): \"\"\"Initialise settings for the linker. To be used if settings were not passed to the linker on creation. Examples: >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.profile_columns([\"first_name\", \"surname\"]) >>> linker.initialise_settings(settings_dict) Args: settings_dict (dict): A Splink settings dictionary \"\"\" self . _settings_dict = settings_dict self . _settings_obj_ = Settings ( settings_dict ) self . _validate_input_dfs () load_settings_from_json ( in_path ) \u00b6 Load settings from a .json file. This .json file would usually be the output of linker.save_settings_to_json() Examples: >>> linker . load_settings_from_json ( \"my_settings.json\" ) Parameters: Name Type Description Default in_path str Path to settings json file required Source code in splink/linker.py 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 def load_settings_from_json ( self , in_path : str ): \"\"\"Load settings from a `.json` file. This `.json` file would usually be the output of `linker.save_settings_to_json()` Examples: >>> linker.load_settings_from_json(\"my_settings.json\") Args: in_path (str): Path to settings json file \"\"\" with open ( in_path , \"r\" ) as f : model_dict = json . load ( f ) self . initialise_settings ( model_dict ) m_u_parameters_chart () \u00b6 Display a chart of the m and u parameters of the linkage model Examples: >>> linker . m_u_parameters_chart () >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . match_weights_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500 ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. Source code in splink/linker.py 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 def m_u_parameters_chart ( self ): \"\"\"Display a chart of the m and u parameters of the linkage model Examples: >>> linker.m_u_parameters_chart() >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker.match_weights_chart() >>> save_offline_chart(c.spec, \"test_chart.html\") >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame(src=\"./test_chart.html\", width=1000, height=500) Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" return self . _settings_obj . m_u_parameters_chart () match_weights_chart () \u00b6 Display a chart of the (partial) match weights of the linkage model Examples: >>> linker . match_weights_chart () >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . match_weights_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500 ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. Source code in splink/linker.py 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 def match_weights_chart ( self ): \"\"\"Display a chart of the (partial) match weights of the linkage model Examples: >>> linker.match_weights_chart() >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker.match_weights_chart() >>> save_offline_chart(c.spec, \"test_chart.html\") >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame(src=\"./test_chart.html\", width=1000, height=500) Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" return self . _settings_obj . match_weights_chart () missingness_chart ( input_dataset = None ) \u00b6 Generate a summary chart of the missingness (prevalence of nulls) of columns in the input datasets. By default, missingness is assessed across all input datasets Parameters: Name Type Description Default input_dataset str Name of one of the input tables in the None Examples: >>> linker . missingness_chart () >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . missingness_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500 Source code in splink/linker.py 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 def missingness_chart ( self , input_dataset : str = None ): \"\"\"Generate a summary chart of the missingness (prevalence of nulls) of columns in the input datasets. By default, missingness is assessed across all input datasets Args: input_dataset (str, optional): Name of one of the input tables in the database. If provided, missingness will be computed for this table alone. Defaults to None. Examples: >>> linker.missingness_chart() >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker.missingness_chart() >>> save_offline_chart(c.spec, \"test_chart.html\") >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame(src=\"./test_chart.html\", width=1000, height=500 \"\"\" records = missingness_data ( self , input_dataset ) return missingness_chart ( records , input_dataset ) parameter_estimate_comparisons_chart ( include_m = True , include_u = True ) \u00b6 Show a chart that shows how parameter estimates have differed across the different estimation methods you have used. For example, if you have run two EM estimation sessions, blocking on different variables, and both result in parameter estimates for first_name, this chart will enable easy comparison of the different estimates Parameters: Name Type Description Default include_m bool Show different estimates of m values. Defaults to True. True include_u bool Show different estimates of u values. Defaults to True. True Source code in splink/linker.py 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 def parameter_estimate_comparisons_chart ( self , include_m = True , include_u = True ): \"\"\"Show a chart that shows how parameter estimates have differed across the different estimation methods you have used. For example, if you have run two EM estimation sessions, blocking on different variables, and both result in parameter estimates for first_name, this chart will enable easy comparison of the different estimates Args: include_m (bool, optional): Show different estimates of m values. Defaults to True. include_u (bool, optional): Show different estimates of u values. Defaults to True. \"\"\" records = self . _settings_obj . _parameter_estimates_as_records to_retain = [] if include_m : to_retain . append ( \"m\" ) if include_u : to_retain . append ( \"u\" ) records = [ r for r in records if r [ \"m_or_u\" ] in to_retain ] return parameter_estimate_comparisons ( records ) precision_recall_chart_from_labels ( labels_tablename ) \u00b6 Generate a precision-recall chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered as a table with your database: source_dataset_l unique_id_l source_dataset_r unique_id_r clerical_match_score df_1 1 df_2 2 0.99 df_1 1 df_2 3 0.2 Note that source_dataset and unique_id should correspond to the values specified in the settings dict, and the input_table_aliases passed to the linker object. For dedupe_only links, the source_dataset columns can be ommitted. Parameters: Name Type Description Default labels_tablename str Name of table containing labels in the database required threshold_actual float Where the clerical_match_score provided by the user is a probability rather than binary, this value is used as the threshold to classify clerical_match_score s as binary matches or non matches. Defaults to 0.5. required match_weight_round_to_nearest float When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. required Examples: >>> # DuckDBLinker >>> labels = pd . read_csv ( \"my_labels.csv\" ) >>> linker . _con . register ( \"labels\" , labels ) >>> linker . precision_recall_chart_from_labels ( \"labels\" ) >>> >>> # SparkLinker >>> labels = spark . read . csv ( \"my_labels.csv\" , header = True ) >>> labels . createDataFrame ( \"labels\" ) >>> linker . precision_recall_chart_from_labels ( \"labels\" ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. Source code in splink/linker.py 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 def precision_recall_chart_from_labels ( self , labels_tablename ): \"\"\"Generate a precision-recall chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered as a table with your database: |source_dataset_l|unique_id_l|source_dataset_r|unique_id_r|clerical_match_score| |----------------|-----------|----------------|-----------|--------------------| |df_1 |1 |df_2 |2 |0.99 | |df_1 |1 |df_2 |3 |0.2 | Note that `source_dataset` and `unique_id` should correspond to the values specified in the settings dict, and the `input_table_aliases` passed to the `linker` object. For `dedupe_only` links, the `source_dataset` columns can be ommitted. Args: labels_tablename (str): Name of table containing labels in the database threshold_actual (float, optional): Where the `clerical_match_score` provided by the user is a probability rather than binary, this value is used as the threshold to classify `clerical_match_score`s as binary matches or non matches. Defaults to 0.5. match_weight_round_to_nearest (float, optional): When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. Examples: >>> # DuckDBLinker >>> labels = pd.read_csv(\"my_labels.csv\") >>> linker._con.register(\"labels\", labels) >>> linker.precision_recall_chart_from_labels(\"labels\") >>> >>> # SparkLinker >>> labels = spark.read.csv(\"my_labels.csv\", header=True) >>> labels.createDataFrame(\"labels\") >>> linker.precision_recall_chart_from_labels(\"labels\") Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" df_truth_space = roc_table ( self , labels_tablename ) recs = df_truth_space . as_record_dict () return precision_recall_chart ( recs ) predict ( threshold_match_probability = None , threshold_match_weight = None ) \u00b6 Create a dataframe of scored pairwise comparisons using the parameters of the linkage model. Uses the blocking rules specified in the blocking_rules_to_generate_predictions of the settings dictionary to generate the pairwise comparisons. Parameters: Name Type Description Default threshold_match_probability float If specified, filter the results to include only pairwise comparisons with a match_probability above this threshold. Defaults to None. None threshold_match_weight float If specified, filter the results to include only pairwise comparisons with a match_weight above this threshold. Defaults to None. None Examples: >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> df = linker . predict ( threshold_match_probability = 0.95 ) >>> df . as_pandas_dataframe ( limit = 5 ) Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. Source code in splink/linker.py 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 def predict ( self , threshold_match_probability : float = None , threshold_match_weight : float = None , ) -> SplinkDataFrame : \"\"\"Create a dataframe of scored pairwise comparisons using the parameters of the linkage model. Uses the blocking rules specified in the `blocking_rules_to_generate_predictions` of the settings dictionary to generate the pairwise comparisons. Args: threshold_match_probability (float, optional): If specified, filter the results to include only pairwise comparisons with a match_probability above this threshold. Defaults to None. threshold_match_weight (float, optional): If specified, filter the results to include only pairwise comparisons with a match_weight above this threshold. Defaults to None. Examples: >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.load_settings_from_json(\"saved_settings.json\") >>> df = linker.predict(threshold_match_probability=0.95) >>> df.as_pandas_dataframe(limit=5) Returns: SplinkDataFrame: A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. \"\"\" # If the user only calls predict, it runs as a single pipeline with no # materialisation of anything self . _initialise_df_concat_with_tf ( materialise = False ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) repartition_after_blocking = getattr ( self , \"repartition_after_blocking\" , False ) # repartition after blocking only exists on the SparkLinker if repartition_after_blocking : df_blocked = self . _execute_sql_pipeline () input_dataframes = [ df_blocked ] else : input_dataframes = [] sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj , threshold_match_probability , threshold_match_weight ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) predictions = self . _execute_sql_pipeline ( input_dataframes ) self . _predict_warning () return predictions profile_columns ( column_expressions , top_n = 10 , bottom_n = 10 ) \u00b6 Source code in splink/linker.py 1248 1249 1250 1251 1252 def profile_columns ( self , column_expressions : Union [ str , List [ str ]], top_n = 10 , bottom_n = 10 ): return profile_columns ( self , column_expressions , top_n = top_n , bottom_n = bottom_n ) roc_chart_from_labels ( labels_tablename , threshold_actual = 0.5 , match_weight_round_to_nearest = None ) \u00b6 Generate a ROC chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered with your database: source_dataset_l unique_id_l source_dataset_r unique_id_r clerical_match_score df_1 1 df_2 2 0.99 df_1 1 df_2 3 0.2 Note that source_dataset and unique_id should correspond to the values specified in the settings dict, and the input_table_aliases passed to the linker object. For dedupe_only links, the source_dataset columns can be ommitted. Parameters: Name Type Description Default labels_tablename str Name of table containing labels in the database required threshold_actual float Where the clerical_match_score provided by the user is a probability rather than binary, this value is used as the threshold to classify clerical_match_score s as binary matches or non matches. Defaults to 0.5. 0.5 match_weight_round_to_nearest float When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. None Examples: >>> # DuckDBLinker >>> labels = pd . read_csv ( \"my_labels.csv\" ) >>> linker . _con . register ( \"labels\" , labels ) >>> linker . roc_chart_from_labels ( \"labels\" ) >>> >>> # SparkLinker >>> labels = spark . read . csv ( \"my_labels.csv\" , header = True ) >>> labels . createDataFrame ( \"labels\" ) >>> linker . roc_chart_from_labels ( \"labels\" ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. Source code in splink/linker.py 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 def roc_chart_from_labels ( self , labels_tablename , threshold_actual = 0.5 , match_weight_round_to_nearest : float = None , ): \"\"\"Generate a ROC chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered with your database: |source_dataset_l|unique_id_l|source_dataset_r|unique_id_r|clerical_match_score| |----------------|-----------|----------------|-----------|--------------------| |df_1 |1 |df_2 |2 |0.99 | |df_1 |1 |df_2 |3 |0.2 | Note that `source_dataset` and `unique_id` should correspond to the values specified in the settings dict, and the `input_table_aliases` passed to the `linker` object. For `dedupe_only` links, the `source_dataset` columns can be ommitted. Args: labels_tablename (str): Name of table containing labels in the database threshold_actual (float, optional): Where the `clerical_match_score` provided by the user is a probability rather than binary, this value is used as the threshold to classify `clerical_match_score`s as binary matches or non matches. Defaults to 0.5. match_weight_round_to_nearest (float, optional): When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. Examples: >>> # DuckDBLinker >>> labels = pd.read_csv(\"my_labels.csv\") >>> linker._con.register(\"labels\", labels) >>> linker.roc_chart_from_labels(\"labels\") >>> >>> # SparkLinker >>> labels = spark.read.csv(\"my_labels.csv\", header=True) >>> labels.createDataFrame(\"labels\") >>> linker.roc_chart_from_labels(\"labels\") Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" df_truth_space = roc_table ( self , labels_tablename , threshold_actual = threshold_actual , match_weight_round_to_nearest = match_weight_round_to_nearest , ) recs = df_truth_space . as_record_dict () return roc_chart ( recs ) roc_table_from_labels ( labels_tablename , threshold_actual = 0.5 , match_weight_round_to_nearest = None ) \u00b6 Generate truth statistics (false positive etc.) for each threshold value of match_probability, suitable for plotting a ROC chart. The table of labels should be in the following format, and should be registered with your database: source_dataset_l unique_id_l source_dataset_r unique_id_r clerical_match_score df_1 1 df_2 2 0.99 df_1 1 df_2 3 0.2 Note that source_dataset and unique_id should correspond to the values specified in the settings dict, and the input_table_aliases passed to the linker object. For dedupe_only links, the source_dataset columns can be ommitted. Parameters: Name Type Description Default labels_tablename str Name of table containing labels in the database required threshold_actual float Where the clerical_match_score provided by the user is a probability rather than binary, this value is used as the threshold to classify clerical_match_score s as binary matches or non matches. Defaults to 0.5. 0.5 match_weight_round_to_nearest float When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. None Examples: >>> # DuckDBLinker >>> labels = pd . read_csv ( \"my_labels.csv\" ) >>> linker . _con . register ( \"labels\" , labels ) >>> linker . roc_table_from_labels ( \"labels\" ) >>> >>> # SparkLinker >>> labels = spark . read . csv ( \"my_labels.csv\" , header = True ) >>> labels . createDataFrame ( \"labels\" ) >>> linker . roc_table_from_labels ( \"labels\" ) Returns: Name Type Description SplinkDataFrame SplinkDataFrame Table of truth statistics Source code in splink/linker.py 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 def roc_table_from_labels ( self , labels_tablename , threshold_actual = 0.5 , match_weight_round_to_nearest : float = None , ) -> SplinkDataFrame : \"\"\"Generate truth statistics (false positive etc.) for each threshold value of match_probability, suitable for plotting a ROC chart. The table of labels should be in the following format, and should be registered with your database: |source_dataset_l|unique_id_l|source_dataset_r|unique_id_r|clerical_match_score| |----------------|-----------|----------------|-----------|--------------------| |df_1 |1 |df_2 |2 |0.99 | |df_1 |1 |df_2 |3 |0.2 | Note that `source_dataset` and `unique_id` should correspond to the values specified in the settings dict, and the `input_table_aliases` passed to the `linker` object. For `dedupe_only` links, the `source_dataset` columns can be ommitted. Args: labels_tablename (str): Name of table containing labels in the database threshold_actual (float, optional): Where the `clerical_match_score` provided by the user is a probability rather than binary, this value is used as the threshold to classify `clerical_match_score`s as binary matches or non matches. Defaults to 0.5. match_weight_round_to_nearest (float, optional): When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. Examples: >>> # DuckDBLinker >>> labels = pd.read_csv(\"my_labels.csv\") >>> linker._con.register(\"labels\", labels) >>> linker.roc_table_from_labels(\"labels\") >>> >>> # SparkLinker >>> labels = spark.read.csv(\"my_labels.csv\", header=True) >>> labels.createDataFrame(\"labels\") >>> linker.roc_table_from_labels(\"labels\") Returns: SplinkDataFrame: Table of truth statistics \"\"\" return roc_table ( self , labels_tablename , threshold_actual = threshold_actual , match_weight_round_to_nearest = match_weight_round_to_nearest , ) save_settings_to_json ( out_path , overwrite = False ) \u00b6 Save the configuration and parameters the linkage model to a .json file. The model can later be loaded back in using linker.load_settings_from_json() Examples: >>> linker . save_settings_to_json ( \"my_settings.json\" , overwrite = True ) Parameters: Name Type Description Default out_path str File path for json file required overwrite bool Overwrite if already exists? Defaults to False. False Source code in splink/linker.py 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 def save_settings_to_json ( self , out_path : str , overwrite = False ) -> dict : \"\"\"Save the configuration and parameters the linkage model to a `.json` file. The model can later be loaded back in using `linker.load_settings_from_json()` Examples: >>> linker.save_settings_to_json(\"my_settings.json\", overwrite=True) Args: out_path (str): File path for json file overwrite (bool, optional): Overwrite if already exists? Defaults to False. \"\"\" model_dict = self . _settings_obj . as_dict () if out_path : if os . path . isfile ( out_path ) and not overwrite : raise ValueError ( f \"The path { out_path } already exists. Please provide a different \" \"path or set overwrite=True\" ) with open ( out_path , \"w\" , encoding = \"utf-8\" ) as f : json . dump ( model_dict , f , indent = 4 ) unlinkables_chart ( x_col = 'match_weight' , source_dataset = None , as_dict = False ) \u00b6 Generate an interactive chart displaying the proportion of records that are \"unlinkable\" for a given splink score threshold and model parameters. Unlinkable records are those that, even when compared with themselves, do not contain enough information to confirm a match. Parameters: Name Type Description Default x_col str Column to use for the x-axis. Defaults to \"match_weight\". 'match_weight' source_dataset str Name of the source dataset to use for the title of the output chart. None as_dict bool If True, return a dict version of the chart. False Examples: >>> # For the simplest code pipeline, load a pre-trained model >>> # and run this against the test data. >>> df = pd . read_csv ( \"./tests/datasets/fake_1000_from_splink_demos.csv\" ) >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . unlinkables_chart () >>> >>> # For more complex code pipelines, you can run an entire pipeline >>> # that estimates your m and u values, before `unlinkables_chart(). Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. Source code in splink/linker.py 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 def unlinkables_chart ( self , x_col = \"match_weight\" , source_dataset = None , as_dict = False , ): \"\"\"Generate an interactive chart displaying the proportion of records that are \"unlinkable\" for a given splink score threshold and model parameters. Unlinkable records are those that, even when compared with themselves, do not contain enough information to confirm a match. Args: x_col (str, optional): Column to use for the x-axis. Defaults to \"match_weight\". source_dataset (str, optional): Name of the source dataset to use for the title of the output chart. as_dict (bool, optional): If True, return a dict version of the chart. Examples: >>> # For the simplest code pipeline, load a pre-trained model >>> # and run this against the test data. >>> df = pd.read_csv(\"./tests/datasets/fake_1000_from_splink_demos.csv\") >>> linker = DuckDBLinker(df) >>> linker.load_settings_from_json(\"saved_settings.json\") >>> linker.unlinkables_chart() >>> >>> # For more complex code pipelines, you can run an entire pipeline >>> # that estimates your m and u values, before `unlinkables_chart(). Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" # Link our initial df on itself and calculate the % of unlinkable entries records = unlinkables_data ( self , x_col ) return unlinkables_chart ( records , x_col , source_dataset ) waterfall_chart ( records , filter_nulls = True ) \u00b6 Visualise how the final match weight is computed for the provided pairwise record comparisons. Records must be provided as a list of dictionaries. This would usually be obtained from df.as_record_dict(limit=n) where df is a SplinkDataFrame. Examples: >>> df = linker . predict ( threshold_match_weight = 2 ) >>> records = df . as_record_dict ( limit = 10 ) >>> linker . waterfall_chart ( records ) Parameters: Name Type Description Default records List [ dict ] Usually be obtained from df.as_record_dict(limit=n) where df is a SplinkDataFrame. required filter_nulls bool Whether the visualiation shows null comparisons, which have no effect on final match weight. Defaults to True. True Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. Source code in splink/linker.py 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 def waterfall_chart ( self , records : List [ dict ], filter_nulls = True ): \"\"\"Visualise how the final match weight is computed for the provided pairwise record comparisons. Records must be provided as a list of dictionaries. This would usually be obtained from `df.as_record_dict(limit=n)` where `df` is a SplinkDataFrame. Examples: >>> df = linker.predict(threshold_match_weight=2) >>> records = df.as_record_dict(limit=10) >>> linker.waterfall_chart(records) Args: records (List[dict]): Usually be obtained from `df.as_record_dict(limit=n)` where `df` is a SplinkDataFrame. filter_nulls (bool, optional): Whether the visualiation shows null comparisons, which have no effect on final match weight. Defaults to True. Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" self . _raise_error_if_necessary_waterfall_columns_not_computed () return waterfall_chart ( records , self . _settings_obj , filter_nulls )","title":"Full API"},{"location":"linker.html#documentation-for-linker-object","text":"The Linker object manages the data linkage process and holds the data linkage model. Most of Splink's functionality can be accessed by calling methods (functions) on the linker, such as linker.predict() , linker.profile_columns() etc. The Linker class is intended for subclassing for specific backends, e.g. a DuckDBLinker . Source code in splink/linker.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 class Linker : \"\"\"The Linker object manages the data linkage process and holds the data linkage model. Most of Splink's functionality can be accessed by calling methods (functions) on the linker, such as `linker.predict()`, `linker.profile_columns()` etc. The Linker class is intended for subclassing for specific backends, e.g. a `DuckDBLinker`. \"\"\" def __init__ ( self , input_table_or_tables : Union [ str , list ], settings_dict : dict = None , set_up_basic_logging : bool = True , input_table_aliases : Union [ str , list ] = None , ): \"\"\"Initialise the linker object, which manages the data linkage process and holds the data linkage model. Examples: >>> # Example 1: DuckDB >>> df = pd.read_csv(\"data_to_dedupe.csv\") >>> linker = DuckDBLinker(df, settings_dict) >>> # Example 2: Spark >>> df_1 = spark.read.parquet(\"table_1/\") >>> df_2 = spark.read.parquet(\"table_2/\") >>> linker = SparkLinker( >>> [df_1, df_2], >>> settings_dict, >>> input_table_aliases=[\"customers\", \"contact_center_callers\"] >>> ) Args: input_table_or_tables (Union[str, list]): Input data into the linkage model. Either a single string (the name of a table in a database) for deduplication jobs, or a list of strings (the name of tables in a database) for link_only or link_and_dedupe. For some linkers, such as the DuckDBLinker and the SparkLinker, it's also possible to pass in dataframes (Pandas and Spark respectively) rather than strings. settings_dict (dict, optional): A Splink settings dictionary. If not provided when the object is created, can later be added using `linker.initialise_settings()` Defaults to None. set_up_basic_logging (bool, optional): If true, sets ups up basic logging so that Splink sends messages at INFO level to stdout. Defaults to True. input_table_aliases (Union[str, list], optional): Labels assigned to input tables in Splink outputs. If the names of the tables in the input database are long or unspecific, this argument can be used to attach more easily readable/interpretable names. Defaults to None. \"\"\" if set_up_basic_logging : logging . basicConfig ( format = \" %(message)s \" , ) splink_logger = logging . getLogger ( \"splink\" ) splink_logger . setLevel ( logging . INFO ) self . _pipeline = SQLPipeline () self . _settings_dict = settings_dict if settings_dict is None : self . _settings_obj_ = None else : self . _settings_obj_ = Settings ( settings_dict ) self . _input_tables_dict = self . _get_input_tables_dict ( input_table_or_tables , input_table_aliases ) self . _validate_input_dfs () self . _em_training_sessions = [] self . _names_of_tables_created_by_splink : list = [] self . _find_new_matches_mode = False self . _train_u_using_random_sample_mode = False self . _compare_two_records_mode = False self . _self_link_mode = False self . _output_schema = \"\" self . debug_mode = False @property def _settings_obj ( self ) -> Settings : if self . _settings_obj_ is None : raise ValueError ( \"You did not provide a settings dictionary when you \" \"created the linker. To continue, you need to provide a settings \" \"dictionary using the `initialise_settings()` method on your linker \" \"object. i.e. linker.initialise_settings(settings_dict)\" ) return self . _settings_obj_ @property def _input_tablename_l ( self ): if self . _find_new_matches_mode : return \"__splink__df_concat_with_tf\" if self . _self_link_mode : return \"__splink__df_concat_with_tf\" if self . _compare_two_records_mode : return \"__splink__compare_two_records_left_with_tf\" if self . _train_u_using_random_sample_mode : return \"__splink__df_concat_with_tf_sample\" if self . _two_dataset_link_only : return \"__splink_df_concat_with_tf_left\" return \"__splink__df_concat_with_tf\" @property def _input_tablename_r ( self ): if self . _find_new_matches_mode : return \"__splink__df_new_records_with_tf\" if self . _self_link_mode : return \"__splink__df_concat_with_tf\" if self . _compare_two_records_mode : return \"__splink__compare_two_records_right_with_tf\" if self . _train_u_using_random_sample_mode : return \"__splink__df_concat_with_tf_sample\" if self . _two_dataset_link_only : return \"__splink_df_concat_with_tf_right\" return \"__splink__df_concat_with_tf\" @property def _two_dataset_link_only ( self ): # Two dataset link only join is a special case where an inner join of the # two datasets is much more efficient than self-joining the vertically # concatenation of all input datasets if self . _find_new_matches_mode : return True if self . _compare_two_records_mode : return True if ( len ( self . _input_tables_dict ) == 2 and self . _settings_obj . _link_type == \"link_only\" ): return True else : return False def _prepend_schema_to_table_name ( self , table_name ): if self . _output_schema : return f \" { self . _output_schema } . { table_name } \" else : return table_name def _initialise_df_concat ( self , materialise = True ): if self . _table_exists_in_database ( \"__splink__df_concat\" ): return sql = vertically_concatenate_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_concat\" ) self . _execute_sql_pipeline ( materialise_as_hash = False ) def _initialise_df_concat_with_tf ( self , materialise = True ): if self . _table_exists_in_database ( \"__splink__df_concat_with_tf\" ): return sql = vertically_concatenate_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_concat\" ) sqls = compute_all_term_frequencies_sqls ( self ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) if self . _two_dataset_link_only : # If we do not materialise __splink_df_concat_with_tf # we'd have to run all the code up to this point twice self . _execute_sql_pipeline ( materialise_as_hash = False ) source_dataset_col = self . _settings_obj . _source_dataset_column_name # Need df_l to be the one with the lowest id to preeserve the property # that the left dataset is the one with the lowest concatenated id keys = self . _input_tables_dict . keys () keys = list ( sorted ( keys )) df_l = self . _input_tables_dict [ keys [ 0 ]] df_r = self . _input_tables_dict [ keys [ 1 ]] sql = f \"\"\" select * from __splink__df_concat_with_tf where { source_dataset_col } = ' { df_l . templated_name } ' \"\"\" self . _enqueue_sql ( sql , \"__splink_df_concat_with_tf_left\" ) self . _execute_sql_pipeline ( materialise_as_hash = False ) sql = f \"\"\" select * from __splink__df_concat_with_tf where { source_dataset_col } = ' { df_r . templated_name } ' \"\"\" self . _enqueue_sql ( sql , \"__splink_df_concat_with_tf_right\" ) self . _execute_sql_pipeline ( materialise_as_hash = False ) else : if materialise : self . _execute_sql_pipeline ( materialise_as_hash = False ) def _table_to_splink_dataframe ( self , templated_name , physical_name ) -> SplinkDataFrame : \"\"\"Create a SplinkDataframe from a table in the underlying database called `physical_name`. Associate a `templated_name` with this table, which signifies the purpose or 'meaning' of this table to splink. (e.g. `__splink__df_blocked`) Args: templated_name (str): The purpose of the table to Splink physical_name (str): The name of the table in the underlying databse \"\"\" raise NotImplementedError ( \"_table_to_splink_dataframe not implemented on this linker\" ) def _enqueue_sql ( self , sql , output_table_name ): \"\"\"Add sql to the current pipeline, but do not execute the pipeline.\"\"\" self . _pipeline . enqueue_sql ( sql , output_table_name ) def _execute_sql_pipeline ( self , input_dataframes : List [ SplinkDataFrame ] = [], materialise_as_hash = True , use_cache = True , transpile = True , ) -> SplinkDataFrame : \"\"\"Execute the SQL queued in the current pipeline as a single statement e.g. `with a as (), b as , c as (), select ... from c`, then execute the pipeline, returning the resultant table as a SplinkDataFrame Args: input_dataframes (List[SplinkDataFrame], optional): A 'starting point' of SplinkDataFrames if needed. Defaults to []. materialise_as_hash (bool, optional): If true, the output tablename will end in a unique identifer. Defaults to True. use_cache (bool, optional): If true, look at whether the SQL pipeline has been executed before, and if so, use the existing result. Defaults to True. transpile (bool, optional): Transpile the SQL using SQLGlot. Defaults to True. Returns: SplinkDataFrame: An abstraction representing the table created by the sql pipeline \"\"\" if not self . debug_mode : sql_gen = self . _pipeline . _generate_pipeline ( input_dataframes ) output_tablename_templated = self . _pipeline . queue [ - 1 ] . output_table_name dataframe = self . _sql_to_splink_dataframe_checking_cache ( sql_gen , output_tablename_templated , materialise_as_hash , use_cache , transpile , ) self . _pipeline . reset () return dataframe else : # In debug mode, we do not pipeline the sql and print the # results of each part of the pipeline for task in self . _pipeline . _generate_pipeline_parts ( input_dataframes ): output_tablename = task . output_table_name sql = task . sql print ( \"------\" ) print ( f \"--------Creating table: { output_tablename } --------\" ) dataframe = self . _sql_to_splink_dataframe_checking_cache ( sql , output_tablename , materialise_as_hash = False , use_cache = False , transpile = transpile , ) self . _pipeline . reset () return dataframe def _execute_sql_against_backend ( self , sql , templated_name , physical_name , transpile = True ): raise NotImplementedError ( f \"_execute_sql_against_backend not implemented for { type ( self ) } \" ) def _sql_to_splink_dataframe_checking_cache ( self , sql , output_tablename_templated , materialise_as_hash = True , use_cache = True , transpile = True , ) -> SplinkDataFrame : \"\"\"Execute sql, or if identical sql has been run before, return cached results. This function - is used by _execute_sql_pipeline to to execute SQL - or can be used directly if you have a single SQL statement that's not in a pipeline Return a SplinkDataFrame representing the results of the SQL \"\"\" hash = hashlib . sha256 ( sql . encode ()) . hexdigest ()[: 7 ] # Ensure hash is valid sql table name table_name_hash = f \" { output_tablename_templated } _ { hash } \" if use_cache : if self . _table_exists_in_database ( output_tablename_templated ): logger . debug ( f \"Using existing table { output_tablename_templated } \" ) return self . _table_to_splink_dataframe ( output_tablename_templated , output_tablename_templated ) if self . _table_exists_in_database ( table_name_hash ): logger . debug ( f \"Using cache for { output_tablename_templated } \" f \" with physical name { table_name_hash } \" ) return self . _table_to_splink_dataframe ( output_tablename_templated , table_name_hash ) if self . debug_mode : print ( sql ) if materialise_as_hash : splink_dataframe = self . _execute_sql_against_backend ( sql , output_tablename_templated , table_name_hash , transpile = transpile ) else : splink_dataframe = self . _execute_sql_against_backend ( sql , output_tablename_templated , output_tablename_templated , transpile = transpile , ) self . _names_of_tables_created_by_splink . append ( splink_dataframe . physical_name ) if self . debug_mode : df_pd = splink_dataframe . as_pandas_dataframe () try : from IPython.display import display display ( df_pd ) except ModuleNotFoundError : print ( df_pd ) return splink_dataframe def __deepcopy__ ( self , memo ): \"\"\"When we do EM training, we need a copy of the linker which is independent of the main linker e.g. setting parameters on the copy will not affect the main linker. This method implements ensures linker can be deepcopied. \"\"\" new_linker = copy ( self ) new_linker . _em_training_sessions = [] new_settings = deepcopy ( self . _settings_obj ) new_linker . _settings_obj_ = new_settings return new_linker def _ensure_aliases_populated_and_is_list ( self , input_table_or_tables , input_table_aliases ): if input_table_aliases is None : input_table_aliases = input_table_or_tables input_table_aliases = ensure_is_list ( input_table_aliases ) return input_table_aliases def _get_input_tables_dict ( self , input_table_or_tables , input_table_aliases ): input_table_or_tables = ensure_is_list ( input_table_or_tables ) input_table_aliases = self . _ensure_aliases_populated_and_is_list ( input_table_or_tables , input_table_aliases ) d = {} for table_name , table_alias in zip ( input_table_or_tables , input_table_aliases ): d [ table_alias ] = self . _table_to_splink_dataframe ( table_alias , table_name ) return d def _get_input_tf_dict ( self , df_dict ): d = {} for df_name , df_value in df_dict . items (): renamed = colname_to_tf_tablename ( df_name ) d [ renamed ] = self . _table_to_splink_dataframe ( renamed , df_value ) return d def _predict_warning ( self ): if not self . _settings_obj . _is_fully_trained : msg = ( \" \\n -- WARNING -- \\n \" \"You have called predict(), but there are some parameter \" \"estimates which have neither been estimated or specified in your \" \"settings dictionary. To produce predictions the following\" \" untrained trained parameters will use default values.\" ) messages = self . _settings_obj . _not_trained_messages () warn_message = \" \\n \" . join ([ msg ] + messages ) logger . warning ( warn_message ) def _table_exists_in_database ( self , table_name ): raise NotImplementedError ( f \"table_exists_in_database not implemented for { type ( self ) } \" ) def _validate_input_dfs ( self ): for df in self . _input_tables_dict . values (): df . validate () if self . _settings_obj_ is not None : if self . _settings_obj . _link_type == \"dedupe_only\" : if len ( self . _input_tables_dict ) > 1 : raise ValueError ( 'If link_type = \"dedupe only\" then input tables must contain ' \"only a single input table\" , ) def _populate_probability_two_random_records_match_from_trained_values ( self ): recip_prop_matches_estimates = [] logger . log ( 15 , ( \"---- Using training sessions to compute \" \"probability two random records match ----\" ), ) for em_training_session in self . _em_training_sessions : training_lambda = ( em_training_session . _settings_obj . _probability_two_random_records_match ) training_lambda_bf = prob_to_bayes_factor ( training_lambda ) reverse_levels = ( em_training_session . _comparison_levels_to_reverse_blocking_rule ) logger . log ( 15 , \" \\n \" f \"Probability two random records match from trained model blocking on \" f \" { em_training_session . _blocking_rule_for_training . blocking_rule } : \" f \" { training_lambda : ,.3f } \" , ) for reverse_level in reverse_levels : # Get comparison level on current settings obj cc = self . _settings_obj . _get_comparison_by_output_column_name ( reverse_level . comparison . _output_column_name ) cl = cc . _get_comparison_level_by_comparison_vector_value ( reverse_level . _comparison_vector_value ) if cl . _has_estimated_values : bf = cl . _trained_m_median / cl . _trained_u_median else : bf = cl . _bayes_factor logger . log ( 15 , f \"Reversing comparison level { cc . _output_column_name } \" f \" using bayes factor { bf : ,.3f } \" , ) training_lambda_bf = training_lambda_bf / bf as_prob = bayes_factor_to_prob ( training_lambda_bf ) logger . log ( 15 , ( \"This estimate of probability two random records match now: \" f \" { as_prob : ,.3f } \" f \"with reciprocal { ( 1 / as_prob ) : ,.3f } \" ), ) logger . log ( 15 , \" \\n ---------\" ) p = bayes_factor_to_prob ( training_lambda_bf ) recip_prop_matches_estimates . append ( 1 / p ) prop_matches_estimate = 1 / median ( recip_prop_matches_estimates ) self . _settings_obj . _probability_two_random_records_match = prop_matches_estimate logger . log ( 15 , \" \\n Median of prop of matches estimates: \" f \" { self . _settings_obj . _probability_two_random_records_match : ,.3f } \" \"reciprocal \" f \" { 1 / self . _settings_obj . _probability_two_random_records_match : ,.3f } \" , ) def _records_to_table ( records , as_table_name ): # Create table in database containing records # Probably quite difficult to implement correctly # Due to data type issues. raise NotImplementedError def _populate_m_u_from_trained_values ( self ): ccs = self . _settings_obj . comparisons for cc in ccs : for cl in cc . _comparison_levels_excluding_null : if cl . _has_estimated_u_values : cl . u_probability = cl . _trained_u_median if cl . _has_estimated_m_values : cl . m_probability = cl . _trained_m_median def _delete_tables_created_by_splink_from_db ( self , retain_term_frequency = True , retain_df_concat_with_tf = True ): tables_remaining = [] for name in self . _names_of_tables_created_by_splink : # Only delete tables explicitly marked as having been created by splink if \"__splink__\" not in name : tables_remaining . append ( name ) continue if name == \"__splink__df_concat_with_tf\" : if retain_df_concat_with_tf : tables_remaining . append ( name ) else : self . _delete_table_from_database ( name ) elif name . startswith ( \"__splink__df_tf_\" ): if retain_term_frequency : tables_remaining . append ( name ) else : self . _delete_table_from_database ( name ) else : self . _delete_table_from_database ( name ) self . _names_of_tables_created_by_splink = tables_remaining def _raise_error_if_necessary_waterfall_columns_not_computed ( self ): ricc = self . _settings_obj . _retain_intermediate_calculation_columns rmc = self . _settings_obj . _retain_matching_columns if not ( ricc and rmc ): raise ValueError ( \"retain_intermediate_calculation_columns and \" \"retain_matching_columns must both be set to True in your settings\" \" dictionary to use this function, because otherwise the necessary \" \"columns will not be available in the input records.\" f \" Their current values are { ricc } and { rmc } , respectively. \" \"Please re-run your linkage with them both set to True.\" ) def initialise_settings ( self , settings_dict : dict ): \"\"\"Initialise settings for the linker. To be used if settings were not passed to the linker on creation. Examples: >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.profile_columns([\"first_name\", \"surname\"]) >>> linker.initialise_settings(settings_dict) Args: settings_dict (dict): A Splink settings dictionary \"\"\" self . _settings_dict = settings_dict self . _settings_obj_ = Settings ( settings_dict ) self . _validate_input_dfs () def compute_tf_table ( self , column_name : str ) -> SplinkDataFrame : \"\"\"Compute a term frequency table for a given column and persist to the database This method is useful if you want to pre-compute term frequency tables e.g. so that real time linkage executes faster, or so that you can estimate various models without having to recompute term frequency tables each time Examples: >>> # Example 1: Real time linkage >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.load_settings_from_json(\"saved_settings.json\") >>> linker.compute_tf_table(\"surname\") >>> linker.compare_two_records(record_left, record_right) >>> # Example 2: Pre-computed term frequency tables in Spark >>> linker = SparkLinker(df) >>> df_first_name_tf = linker.compute_tf_table(\"first_name\") >>> df_first_name_tf.write.parquet(\"folder/first_name_tf\") >>> >>> # On subsequent data linking job, read this table rather than recompute >>> df_first_name_tf = spark.read.parquet(\"folder/first_name_tf\") >>> df_first_name_tf.createOrReplaceTempView(\"__splink__df_tf_first_name\") Args: column_name (str): The column name in the input table Returns: SplinkDataFrame: The resultant table as a splink data frame \"\"\" sql = vertically_concatenate_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_concat\" ) input_col = InputColumn ( column_name , tf_adjustments = True ) sql = term_frequencies_for_single_column_sql ( input_col ) self . _enqueue_sql ( sql , colname_to_tf_tablename ( input_col )) return self . _execute_sql_pipeline ( materialise_as_hash = False ) def deterministic_link ( self ) -> SplinkDataFrame : \"\"\"Uses the blocking rules specified by `blocking_rules_to_generate_predictions` in the settings dictionary to generate pairwise record comparisons. For deterministic linkage, this should be a list of blocking rules which are strict enough to generate only true links. Deterministic linkage, however, is likely to result in missed links (false negatives). Examples: >>> linker = DuckDBLinker(df) >>> >>> settings = { >>> \"link_type\": \"dedupe_only\", >>> \"blocking_rules_to_generate_predictions\": [ >>> \"l.first_name = r.first_name\", >>> \"l.surname = r.surname\", >>> ], >>> \"comparisons\": [] >>> } >>> >>> from splink.duckdb.duckdb_linker import DuckDBLinker >>> >>> linker = DuckDBLinker(df, settings) >>> df = linker.deterministic_link() Returns: SplinkDataFrame: A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. \"\"\" self . _initialise_df_concat_with_tf () sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) return self . _execute_sql_pipeline () def estimate_u_using_random_sampling ( self , target_rows : int ): \"\"\"Estimate the u parameters of the linkage model using random sampling. The u parameters represent the proportion of record comparisons that fall into each comparison level amongst truly non-matching records. This procedure takes a sample of the data and generates the cartesian product of pairwise record comparisons amongst the sampled records. The validity of the u values rests on the assumption that the resultant pairwise comparisons are non-matches (or at least, they are very unlikely to be matches). For large datasets, this is typically true. Args: target_rows (int): The target number of pairwise record comparisons from which to derive the u values. Larger will give more accurate estimates but lead to longer runtimes. In our experience at least 1e9 (one billion) gives best results but can take a long time to compute. 1e7 (ten million) is often adequate whilst testing different model specifications, before the final model is estimated. Examples: >>> linker.estimate_u_using_random_sampling(1e8) Returns: None: Updates the estimated u parameters within the linker object and returns nothing. \"\"\" self . _initialise_df_concat_with_tf ( materialise = True ) estimate_u_values ( self , target_rows ) self . _populate_m_u_from_trained_values () self . _settings_obj . _columns_without_estimated_parameters_message () def estimate_m_from_label_column ( self , label_colname : str ): \"\"\"Estimate the m parameters of the linkage model from a label (ground truth) column in the input dataframe(s). The m parameters represent the proportion of record comparisons that fall into each comparison level amongst truly matching records. The ground truth column is used to generate pairwise record comparisons which are then assumed to be matches. For example, if the entity being matched is persons, and your input dataset(s) contain social security number, this could be used to estimate the m values for the model. Note that this column does not need to be fully populated. A common case is where a unique identifier such as social security number is only partially populated. Args: label_colname (str): The name of the column containing the ground truth label in the input data. Examples: >>> linker.estimate_m_from_label_column(\"social_security_number\") Returns: Updates the estimated m parameters within the linker object and returns nothing. \"\"\" self . _initialise_df_concat_with_tf ( materialise = True ) estimate_m_values_from_label_column ( self , self . _input_tables_dict , label_colname ) self . _populate_m_u_from_trained_values () self . _settings_obj . _columns_without_estimated_parameters_message () def estimate_parameters_using_expectation_maximisation ( self , blocking_rule : str , comparisons_to_deactivate : List [ Union [ str , Comparison ]] = None , comparison_levels_to_reverse_blocking_rule : List [ ComparisonLevel ] = None , fix_probability_two_random_records_match : bool = False , fix_m_probabilities = False , fix_u_probabilities = True , ) -> EMTrainingSession : \"\"\"Estimate the parameters of the linkage model using expectation maximisation. By default, the m probabilities are estimated, but not the u probabilities, because good estiamtes for the u probabilities can be obtained from `linker.estimate_u_using_random_sampling()`. You can change this by setting `fix_u_probabilities` to False. The blocking rule provided is used to generate pairwise record comparisons. Usually, this should be a blocking rule that results in a dataframe where matches are between about 1% and 99% of the comparisons. By default, m parameters are estimated for all comparisons except those which are included in the blocking rule. For example, if the blocking rule is `l.first_name = r.first_name`, then parameter esimates will be made for all comparison except those which use `first_name` in their sql_condition By default, the probability two random records match is estimated for the blocked data, and then the m and u parameters for the columns specified in the blocking rules are used to estiamte the global probability two random records match. To control which comparisons should have their parameter estimated, and the process of 'reversing out' the global probability two random records match, the user may specify `comparisons_to_deactivate` and `comparison_levels_to_reverse_blocking_rule`. This is useful, for example if you block on the dmetaphone of a column but match on the original column. Examples: >>> # Default behaviour >>> br_training = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker.estimate_parameters_using_expectation_maximisation(br_training) >>> # Specify which comparisons to deactivate >>> br_training = \"l.dmeta_first_name = r.dmeta_first_name\" >>> settings_obj = linker._settings_obj >>> comp = settings_obj._get_comparison_by_output_column_name(\"first_name\") >>> dmeta_level = comp._get_comparison_level_by_comparison_vector_value(1) >>> linker.estimate_parameters_using_expectation_maximisation( >>> br_training, >>> comparisons_to_deactivate=[\"first_name\"], >>> comparison_levels_to_reverse_blocking_rule=[dmeta_level], >>> ) Args: blocking_rule (str): The blocking rule used to generate pairwise record comparisons. comparisons_to_deactivate (list, optional): By default, splink will analyse the blocking rule provided and estimate the m parameters for all comaprisons except those included in the blocking rule. If comparisons_to_deactivate are provided, spink will instead estimate m parameters for all comparison except those specified in the comparisons_to_deactivate list. This list can either contain the output_column_name of the Comparison as a string, or Comparison objects. Defaults to None. comparison_levels_to_reverse_blocking_rule (list, optional): By default, splink will analyse the blocking rule provided and adjust the global probability two random records match to account for the matches specified in the blocking rule. If provided, this argument will overrule this default behaviour. The user must provide a list of ComparisonLevel objects. Defaults to None. fix_probability_two_random_records_match (bool, optional): If True, do not update the probability two random records match after each iteration. Defaults to False. fix_m_probabilities (bool, optional): If True, do not update the m probabilities after each iteration. Defaults to False. fix_u_probabilities (bool, optional): If True, do not update the u probabilities after each iteration. Defaults to True. Examples: >>> blocking_rule = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker.estimate_parameters_using_expectation_maximisation(blocking_rule) Returns: EMTrainingSession: An object containing information about the training session such as how parameters changed during the iteration history \"\"\" self . _initialise_df_concat_with_tf ( materialise = True ) if comparisons_to_deactivate : # If user provided a string, convert to Comparison object comparisons_to_deactivate = [ self . _settings_obj . _get_comparison_by_output_column_name ( n ) if isinstance ( n , str ) else n for n in comparisons_to_deactivate ] if comparison_levels_to_reverse_blocking_rule is None : logger . warning ( \" \\n WARNING: \\n \" \"You have provided comparisons_to_deactivate but not \" \"comparison_levels_to_reverse_blocking_rule. \\n \" \"If comparisons_to_deactivate is provided, then \" \"you usually need to provide corresponding \" \"comparison_levels_to_reverse_blocking_rule. \" \"because each comparison to deactivate if effectively treated \" \"as an exact match.\" ) em_training_session = EMTrainingSession ( self , blocking_rule , fix_u_probabilities = fix_u_probabilities , fix_m_probabilities = fix_m_probabilities , fix_probability_two_random_records_match = fix_probability_two_random_records_match , # noqa 501 comparisons_to_deactivate = comparisons_to_deactivate , comparison_levels_to_reverse_blocking_rule = comparison_levels_to_reverse_blocking_rule , # noqa 501 ) em_training_session . _train () self . _populate_m_u_from_trained_values () self . _populate_probability_two_random_records_match_from_trained_values () self . _settings_obj . _columns_without_estimated_parameters_message () return em_training_session def predict ( self , threshold_match_probability : float = None , threshold_match_weight : float = None , ) -> SplinkDataFrame : \"\"\"Create a dataframe of scored pairwise comparisons using the parameters of the linkage model. Uses the blocking rules specified in the `blocking_rules_to_generate_predictions` of the settings dictionary to generate the pairwise comparisons. Args: threshold_match_probability (float, optional): If specified, filter the results to include only pairwise comparisons with a match_probability above this threshold. Defaults to None. threshold_match_weight (float, optional): If specified, filter the results to include only pairwise comparisons with a match_weight above this threshold. Defaults to None. Examples: >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.load_settings_from_json(\"saved_settings.json\") >>> df = linker.predict(threshold_match_probability=0.95) >>> df.as_pandas_dataframe(limit=5) Returns: SplinkDataFrame: A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. \"\"\" # If the user only calls predict, it runs as a single pipeline with no # materialisation of anything self . _initialise_df_concat_with_tf ( materialise = False ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) repartition_after_blocking = getattr ( self , \"repartition_after_blocking\" , False ) # repartition after blocking only exists on the SparkLinker if repartition_after_blocking : df_blocked = self . _execute_sql_pipeline () input_dataframes = [ df_blocked ] else : input_dataframes = [] sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj , threshold_match_probability , threshold_match_weight ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) predictions = self . _execute_sql_pipeline ( input_dataframes ) self . _predict_warning () return predictions def find_matches_to_new_records ( self , records_or_tablename , blocking_rules = [], match_weight_threshold =- 4 , ) -> SplinkDataFrame : \"\"\"Given one or more records, find records in the input dataset(s) which match and return in order of the splink prediction score. This effectively provides a way of searching the input datasets for given record(s) Args: records_or_tablename (List[dict]): Input search record(s) as list of dict, or a table registered to the database. blocking_rules (list, optional): Blocking rules to select which records to find and score. If [], do not use a blocking rule - meaning the input records will be compared to all records provided to the linker when it was instantiated. Defaults to []. match_weight_threshold (int, optional): Return matches with a match weight above this threshold. Defaults to -4. Examples: >>> linker = DuckDBLinker(df) >>> linker.load_settings_from_json(\"saved_settings.json\") >>> # Pre-compute tf tables for any tables with >>> # term frequency adjustments >>> linker.compute_tf_table(\"first_name\") >>> record = {'unique_id': 1, >>> 'first_name': \"John\", >>> 'surname': \"Smith\", >>> 'dob': \"1971-05-24\", >>> 'city': \"London\", >>> 'email': \"john@smith.net\" >>> } >>> df = linker.find_matches_to_new_records([record], blocking_rules=[]) Returns: SplinkDataFrame: The pairwise comparisons. \"\"\" original_blocking_rules = ( self . _settings_obj . _blocking_rules_to_generate_predictions ) original_link_type = self . _settings_obj . _link_type if not isinstance ( records_or_tablename , str ): self . _records_to_table ( records_or_tablename , \"__splink__df_new_records\" ) new_records_tablename = \"__splink__df_new_records\" else : new_records_tablename = records_or_tablename blocking_rules = [ BlockingRule ( r ) if not isinstance ( r , BlockingRule ) else r for r in blocking_rules ] self . _settings_obj . _blocking_rules_to_generate_predictions = blocking_rules self . _settings_obj . _link_type = \"link_only_find_matches_to_new_records\" self . _find_new_matches_mode = True sql = _join_tf_to_input_df_sql ( self ) sql = sql . replace ( \"__splink__df_concat\" , new_records_tablename ) self . _enqueue_sql ( sql , \"__splink__df_new_records_with_tf\" ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) sql = f \"\"\" select * from __splink__df_predict where match_weight > { match_weight_threshold } \"\"\" self . _enqueue_sql ( sql , \"__splink_find_matches_predictions\" ) predictions = self . _execute_sql_pipeline ( use_cache = False ) self . _settings_obj . _blocking_rules_to_generate_predictions = ( original_blocking_rules ) self . _settings_obj . _link_type = original_link_type self . _find_new_matches_mode = False return predictions def compare_two_records ( self , record_1 : dict , record_2 : dict ): \"\"\"Use the linkage model to compare and score a pairwise record comparison based on the two input records provided Args: record_1 (dict): dictionary representing the first record. Columns names and data types must be the same as the columns in the settings object record_2 (dict): dictionary representing the second record. Columns names and data types must be the same as the columns in the settings object Examples: >>> linker = DuckDBLinker(df) >>> linker.load_settings_from_json(\"saved_settings.json\") >>> linker.compare_two_records(record_left, record_right) Returns: SplinkDataFrame: Pairwise comparison with scored prediction \"\"\" original_blocking_rules = ( self . _settings_obj . _blocking_rules_to_generate_predictions ) original_link_type = self . _settings_obj . _link_type self . _compare_two_records_mode = True self . _settings_obj . _blocking_rules_to_generate_predictions = [] self . _records_to_table ([ record_1 ], \"__splink__compare_two_records_left\" ) self . _records_to_table ([ record_2 ], \"__splink__compare_two_records_right\" ) sql_join_tf = _join_tf_to_input_df_sql ( self ) sql_join_tf = sql_join_tf . replace ( \"__splink__df_concat\" , \"__splink__compare_two_records_left\" ) self . _enqueue_sql ( sql_join_tf , \"__splink__compare_two_records_left_with_tf\" ) sql_join_tf = sql_join_tf . replace ( \"__splink__compare_two_records_left\" , \"__splink__compare_two_records_right\" ) self . _enqueue_sql ( sql_join_tf , \"__splink__compare_two_records_right_with_tf\" ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) predictions = self . _execute_sql_pipeline ( use_cache = False ) self . _settings_obj . _blocking_rules_to_generate_predictions = ( original_blocking_rules ) self . _settings_obj . _link_type = original_link_type self . _compare_two_records_mode = False return predictions def _self_link ( self ) -> SplinkDataFrame : \"\"\"Use the linkage model to compare and score all records in our input df with themselves. Returns: SplinkDataFrame: Scored pairwise comparisons of the input records to themselves. \"\"\" original_blocking_rules = ( self . _settings_obj . _blocking_rules_to_generate_predictions ) original_link_type = self . _settings_obj . _link_type # Changes our sql to allow for a self link. # This is used in `_sql_gen_where_condition` in blocking.py # to remove any 'where' clauses when blocking (normally when blocking # we want to *remove* self links!) self . _self_link_mode = True # Block on uid i.e. create pairwise record comparisons where the uid matches uid_cols = self . _settings_obj . _unique_id_input_columns uid_l = _composite_unique_id_from_edges_sql ( uid_cols , None , \"l\" ) uid_r = _composite_unique_id_from_edges_sql ( uid_cols , None , \"r\" ) self . _settings_obj . _blocking_rules_to_generate_predictions = [ BlockingRule ( f \" { uid_l } = { uid_r } \" ) ] self . _initialise_df_concat_with_tf () sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) predictions = self . _execute_sql_pipeline ( use_cache = False ) self . _settings_obj . _blocking_rules_to_generate_predictions = ( original_blocking_rules ) self . _settings_obj . _link_type = original_link_type self . _self_link_mode = False return predictions def cluster_pairwise_predictions_at_threshold ( self , df_predict : SplinkDataFrame , threshold_match_probability : float ) -> SplinkDataFrame : \"\"\"Clusters the pairwise match predictions that result from `linker.predict()` into groups of connected record using the connected components graph clustering algorithm Records with an estimated `match_probability` above `threshold_match_probability` are considered to be a match (i.e. they represent the same entity). Args: df_predict (SplinkDataFrame): The results of `linker.predict()` threshold_match_probability (float): Filter the pairwise match predictions to include only pairwise comparisons with a match_probability above this threshold. This dataframe is then fed into the clustering algorithm. Returns: SplinkDataFrame: A SplinkDataFrame containing a list of all IDs, clustered into groups based on the desired match threshold. \"\"\" self . _initialise_df_concat_with_tf ( df_predict ) edges_table = _cc_create_unique_id_cols ( self , df_predict , threshold_match_probability , ) cc = solve_connected_components ( self , edges_table ) return cc def profile_columns ( self , column_expressions : Union [ str , List [ str ]], top_n = 10 , bottom_n = 10 ): return profile_columns ( self , column_expressions , top_n = top_n , bottom_n = bottom_n ) def estimate_m_from_pairwise_labels ( self , table_name ): self . _initialise_df_concat_with_tf ( materialise = True ) estimate_m_from_pairwise_labels ( self , table_name ) def roc_chart_from_labels ( self , labels_tablename , threshold_actual = 0.5 , match_weight_round_to_nearest : float = None , ): \"\"\"Generate a ROC chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered with your database: |source_dataset_l|unique_id_l|source_dataset_r|unique_id_r|clerical_match_score| |----------------|-----------|----------------|-----------|--------------------| |df_1 |1 |df_2 |2 |0.99 | |df_1 |1 |df_2 |3 |0.2 | Note that `source_dataset` and `unique_id` should correspond to the values specified in the settings dict, and the `input_table_aliases` passed to the `linker` object. For `dedupe_only` links, the `source_dataset` columns can be ommitted. Args: labels_tablename (str): Name of table containing labels in the database threshold_actual (float, optional): Where the `clerical_match_score` provided by the user is a probability rather than binary, this value is used as the threshold to classify `clerical_match_score`s as binary matches or non matches. Defaults to 0.5. match_weight_round_to_nearest (float, optional): When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. Examples: >>> # DuckDBLinker >>> labels = pd.read_csv(\"my_labels.csv\") >>> linker._con.register(\"labels\", labels) >>> linker.roc_chart_from_labels(\"labels\") >>> >>> # SparkLinker >>> labels = spark.read.csv(\"my_labels.csv\", header=True) >>> labels.createDataFrame(\"labels\") >>> linker.roc_chart_from_labels(\"labels\") Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" df_truth_space = roc_table ( self , labels_tablename , threshold_actual = threshold_actual , match_weight_round_to_nearest = match_weight_round_to_nearest , ) recs = df_truth_space . as_record_dict () return roc_chart ( recs ) def precision_recall_chart_from_labels ( self , labels_tablename ): \"\"\"Generate a precision-recall chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered as a table with your database: |source_dataset_l|unique_id_l|source_dataset_r|unique_id_r|clerical_match_score| |----------------|-----------|----------------|-----------|--------------------| |df_1 |1 |df_2 |2 |0.99 | |df_1 |1 |df_2 |3 |0.2 | Note that `source_dataset` and `unique_id` should correspond to the values specified in the settings dict, and the `input_table_aliases` passed to the `linker` object. For `dedupe_only` links, the `source_dataset` columns can be ommitted. Args: labels_tablename (str): Name of table containing labels in the database threshold_actual (float, optional): Where the `clerical_match_score` provided by the user is a probability rather than binary, this value is used as the threshold to classify `clerical_match_score`s as binary matches or non matches. Defaults to 0.5. match_weight_round_to_nearest (float, optional): When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. Examples: >>> # DuckDBLinker >>> labels = pd.read_csv(\"my_labels.csv\") >>> linker._con.register(\"labels\", labels) >>> linker.precision_recall_chart_from_labels(\"labels\") >>> >>> # SparkLinker >>> labels = spark.read.csv(\"my_labels.csv\", header=True) >>> labels.createDataFrame(\"labels\") >>> linker.precision_recall_chart_from_labels(\"labels\") Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" df_truth_space = roc_table ( self , labels_tablename ) recs = df_truth_space . as_record_dict () return precision_recall_chart ( recs ) def roc_table_from_labels ( self , labels_tablename , threshold_actual = 0.5 , match_weight_round_to_nearest : float = None , ) -> SplinkDataFrame : \"\"\"Generate truth statistics (false positive etc.) for each threshold value of match_probability, suitable for plotting a ROC chart. The table of labels should be in the following format, and should be registered with your database: |source_dataset_l|unique_id_l|source_dataset_r|unique_id_r|clerical_match_score| |----------------|-----------|----------------|-----------|--------------------| |df_1 |1 |df_2 |2 |0.99 | |df_1 |1 |df_2 |3 |0.2 | Note that `source_dataset` and `unique_id` should correspond to the values specified in the settings dict, and the `input_table_aliases` passed to the `linker` object. For `dedupe_only` links, the `source_dataset` columns can be ommitted. Args: labels_tablename (str): Name of table containing labels in the database threshold_actual (float, optional): Where the `clerical_match_score` provided by the user is a probability rather than binary, this value is used as the threshold to classify `clerical_match_score`s as binary matches or non matches. Defaults to 0.5. match_weight_round_to_nearest (float, optional): When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. Examples: >>> # DuckDBLinker >>> labels = pd.read_csv(\"my_labels.csv\") >>> linker._con.register(\"labels\", labels) >>> linker.roc_table_from_labels(\"labels\") >>> >>> # SparkLinker >>> labels = spark.read.csv(\"my_labels.csv\", header=True) >>> labels.createDataFrame(\"labels\") >>> linker.roc_table_from_labels(\"labels\") Returns: SplinkDataFrame: Table of truth statistics \"\"\" return roc_table ( self , labels_tablename , threshold_actual = threshold_actual , match_weight_round_to_nearest = match_weight_round_to_nearest , ) def match_weights_histogram ( self , df_predict : SplinkDataFrame , target_bins : int = 30 , width = 600 , height = 250 ): \"\"\"Generate a histogram that shows the distribution of match weights in `df_predict` Args: df_predict (SplinkDataFrame): Output of `linker.predict()` target_bins (int, optional): Target number of bins in histogram. Defaults to 30. width (int, optional): Width of output. Defaults to 600. height (int, optional): Height of output chart. Defaults to 250. Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" df = histogram_data ( self , df_predict , target_bins ) recs = df . as_record_dict () return match_weights_histogram ( recs , width = width , height = height ) def waterfall_chart ( self , records : List [ dict ], filter_nulls = True ): \"\"\"Visualise how the final match weight is computed for the provided pairwise record comparisons. Records must be provided as a list of dictionaries. This would usually be obtained from `df.as_record_dict(limit=n)` where `df` is a SplinkDataFrame. Examples: >>> df = linker.predict(threshold_match_weight=2) >>> records = df.as_record_dict(limit=10) >>> linker.waterfall_chart(records) Args: records (List[dict]): Usually be obtained from `df.as_record_dict(limit=n)` where `df` is a SplinkDataFrame. filter_nulls (bool, optional): Whether the visualiation shows null comparisons, which have no effect on final match weight. Defaults to True. Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" self . _raise_error_if_necessary_waterfall_columns_not_computed () return waterfall_chart ( records , self . _settings_obj , filter_nulls ) def unlinkables_chart ( self , x_col = \"match_weight\" , source_dataset = None , as_dict = False , ): \"\"\"Generate an interactive chart displaying the proportion of records that are \"unlinkable\" for a given splink score threshold and model parameters. Unlinkable records are those that, even when compared with themselves, do not contain enough information to confirm a match. Args: x_col (str, optional): Column to use for the x-axis. Defaults to \"match_weight\". source_dataset (str, optional): Name of the source dataset to use for the title of the output chart. as_dict (bool, optional): If True, return a dict version of the chart. Examples: >>> # For the simplest code pipeline, load a pre-trained model >>> # and run this against the test data. >>> df = pd.read_csv(\"./tests/datasets/fake_1000_from_splink_demos.csv\") >>> linker = DuckDBLinker(df) >>> linker.load_settings_from_json(\"saved_settings.json\") >>> linker.unlinkables_chart() >>> >>> # For more complex code pipelines, you can run an entire pipeline >>> # that estimates your m and u values, before `unlinkables_chart(). Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" # Link our initial df on itself and calculate the % of unlinkable entries records = unlinkables_data ( self , x_col ) return unlinkables_chart ( records , x_col , source_dataset ) def comparison_viewer_dashboard ( self , df_predict : SplinkDataFrame , out_path : str , overwrite = False , num_example_rows = 2 , return_html_as_string = False , ): \"\"\"Generate an interactive html visualization of the linker's predictions and save to `out_path`. For more information see [this video](https://www.youtube.com/watch?v=DNvCMqjipis) Args: df_predict (SplinkDataFrame): The outputs of `linker.predict()` out_path (str): The path (including filename) to save the html file to. overwrite (bool, optional): Overwrite the html file if it already exists? Defaults to False. num_example_rows (int, optional): Number of example rows per comparison vector. Defaults to 2. return_html_as_string: If True, return the html as a string Examples: >>> df_predictions = linker.predict() >>> linker.comparison_viewer_dashboard(df_predictions, \"scv.html\", True, 2) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame(src=\"./scv.html\", width=\"100%\", height=1200) \"\"\" self . _raise_error_if_necessary_waterfall_columns_not_computed () sql = comparison_vector_distribution_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vector_distribution\" ) sqls = comparison_viewer_table_sqls ( self , num_example_rows ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) df = self . _execute_sql_pipeline ([ df_predict ]) rendered = render_splink_comparison_viewer_html ( df . as_record_dict (), self . _settings_obj . _as_completed_dict (), out_path , overwrite , ) if return_html_as_string : return rendered def parameter_estimate_comparisons_chart ( self , include_m = True , include_u = True ): \"\"\"Show a chart that shows how parameter estimates have differed across the different estimation methods you have used. For example, if you have run two EM estimation sessions, blocking on different variables, and both result in parameter estimates for first_name, this chart will enable easy comparison of the different estimates Args: include_m (bool, optional): Show different estimates of m values. Defaults to True. include_u (bool, optional): Show different estimates of u values. Defaults to True. \"\"\" records = self . _settings_obj . _parameter_estimates_as_records to_retain = [] if include_m : to_retain . append ( \"m\" ) if include_u : to_retain . append ( \"u\" ) records = [ r for r in records if r [ \"m_or_u\" ] in to_retain ] return parameter_estimate_comparisons ( records ) def missingness_chart ( self , input_dataset : str = None ): \"\"\"Generate a summary chart of the missingness (prevalence of nulls) of columns in the input datasets. By default, missingness is assessed across all input datasets Args: input_dataset (str, optional): Name of one of the input tables in the database. If provided, missingness will be computed for this table alone. Defaults to None. Examples: >>> linker.missingness_chart() >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker.missingness_chart() >>> save_offline_chart(c.spec, \"test_chart.html\") >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame(src=\"./test_chart.html\", width=1000, height=500 \"\"\" records = missingness_data ( self , input_dataset ) return missingness_chart ( records , input_dataset ) def completeness_chart ( self , input_dataset : str = None , cols : List [ str ] = None ): \"\"\"Generate a summary chart of the completeness (proportion of non-nulls) of columns in each of the input datasets. By default, completeness is assessed for all column in the input data. Args: input_dataset (str, optional): Name of one of the input tables in the database. If provided, completeness will be computed for this table alone. Defaults to None. cols (List[str], optional): List of column names to calculate completeness. Default to None. Examples: >>> linker.completeness_chart() >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker.completeness_chart() >>> save_offline_chart(c.spec, \"test_chart.html\") >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame(src=\"./test_chart.html\", width=1000, height=500 \"\"\" records = completeness_data ( self , input_dataset , cols ) return completeness_chart ( records , input_dataset ) def count_num_comparisons_from_blocking_rule ( self , blocking_rule : str , link_type : str = None , unique_id_column_name : str = None , ) -> int : \"\"\"Compute the number of pairwise record comparisons that would be generated by a blocking rule Args: blocking_rule (str): The blocking rule to analyse link_type (str, optional): The link type. This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. unique_id_column_name (str, optional): This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. Examples: >>> br = \"l.first_name = r.first_name\" >>> linker.count_num_comparisons_from_blocking_rule(br) 19387 >>> br = \"l.name = r.name and substr(l.dob,1,4) = substr(r.dob,1,4)\" >>> linker.count_num_comparisons_from_blocking_rule(br) 394 Returns: int: The number of comparisons generated by the blocking rule \"\"\" sql = vertically_concatenate_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_concat\" ) sql = number_of_comparisons_generated_by_blocking_rule_sql ( self , blocking_rule , link_type , unique_id_column_name ) self . _enqueue_sql ( sql , \"__splink__analyse_blocking_rule\" ) res = self . _execute_sql_pipeline () . as_record_dict ()[ 0 ] return res [ \"count_of_pairwise_comparisons_generated\" ] def cumulative_num_comparisons_from_blocking_rules_chart ( self , blocking_rules : str or list = None , link_type : str = None , unique_id_column_name : str = None , ): \"\"\"Display a chart with the cumulative number of comparisons generated by a selection of blocking rules. This is equivalent to the output size of df_predict and details how many comparisons each of your individual blocking rules will contribute to the total. Args: blocking_rules (str or list): The blocking rule(s) to compute comparisons for. If null, the rules set out in your settings object will be used. link_type (str, optional): The link type. This defaults to the link type outlined in your settings object. unique_id_column_name (str, optional): This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. Examples: >>> linker_settings = DuckDBLinker(df, settings) >>> # Compute the cumulative number of comparisons generated by the rules >>> # in your settings object. >>> linker_settings.cumulative_num_comparisons_from_blocking_rules_chart() >>> >>> # Generate total comparisons with custom blocking rules. >>> blocking_rules = [ >>> \"l.surname = r.surname\", >>> \"l.first_name = r.first_name >>> and substr(l.dob,1,4) = substr(r.dob,1,4)\" >>> ] >>> >>> linker.cumulative_num_comparisons_from_blocking_rules_chart( >>> blocking_rules >>> ) Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" if blocking_rules : blocking_rules = ensure_is_list ( blocking_rules ) records = cumulative_comparisons_generated_by_blocking_rules ( self , blocking_rules , link_type , unique_id_column_name , ) return cumulative_blocking_rule_comparisons_generated ( records ) def count_num_comparisons_from_blocking_rules_for_prediction ( self , df_predict ): \"\"\"Counts the maginal number of edges created from each of the blocking rules in `blocking_rules_to_generate_predictions` This is different to `count_num_comparisons_from_blocking_rule` because it (a) analyses multiple blocking rules rather than a single rule, and (b) deduplicates any comparisons that are generated, to tell you the marginal effect of each entry in `blocking_rules_to_generate_predictions` Args: df_predict (SplinkDataFrame): SplinkDataFrame with match weights and probabilities of rows matching Examples: >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.load_settings_from_json(\"saved_settings.json\") >>> df_predict = linker.predict(threshold_match_probability=0.95) >>> count_pairwise = linker.count_num_comparisons_from_blocking_rules_for_prediction(df_predict) >>> count_pairwise.as_pandas_dataframe(limit=5) Returns: SplinkDataFrame: A SplinkDataFrame of the pairwise comparisons and estimated pairwise comparisons generated by the blocking rules. \"\"\" # noqa: E501 sql = count_num_comparisons_from_blocking_rules_for_prediction_sql ( df_predict ) match_key_analysis = self . _sql_to_splink_dataframe_checking_cache ( sql , \"__splink__match_key_analysis\" ) return match_key_analysis def match_weights_chart ( self ): \"\"\"Display a chart of the (partial) match weights of the linkage model Examples: >>> linker.match_weights_chart() >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker.match_weights_chart() >>> save_offline_chart(c.spec, \"test_chart.html\") >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame(src=\"./test_chart.html\", width=1000, height=500) Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" return self . _settings_obj . match_weights_chart () def m_u_parameters_chart ( self ): \"\"\"Display a chart of the m and u parameters of the linkage model Examples: >>> linker.m_u_parameters_chart() >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker.match_weights_chart() >>> save_offline_chart(c.spec, \"test_chart.html\") >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame(src=\"./test_chart.html\", width=1000, height=500) Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" return self . _settings_obj . m_u_parameters_chart () def cluster_studio_dashboard ( self , df_predict : SplinkDataFrame , df_clustered : SplinkDataFrame , out_path : str , sampling_method = \"random\" , sample_size : int = 10 , cluster_ids : list = None , cluster_names : list = None , overwrite : bool = False , return_html_as_string = False , ): \"\"\"Generate an interactive html visualization of the predicted cluster and save to `out_path`. Args: df_predict (SplinkDataFrame): The outputs of `linker.predict()` df_clustered (SplinkDataFrame): The outputs of `linker.cluster_pairwise_predictions_at_threshold()` out_path (str): The path (including filename) to save the html file to. sampling_method (str, optional): `random` or `by_cluster_size`. Defaults to `random`. sample_size (int, optional): Number of clusters to show in the dahboard. Defaults to 10. cluster_ids (list): The IDs of the clusters that will be displayed in the dashboard. If provided, ignore the `sampling_method` and `sample_size` arguments. Defaults to None. overwrite (bool, optional): Overwrite the html file if it already exists? Defaults to False. cluster_names (list, optional): If provided, the dashboard will display these names in the selection box. Ony works in conjunction with `cluster_ids`. Defaults to None. return_html_as_string: If True, return the html as a string Examples: >>> df_p = linker.predict() >>> df_c = linker.cluster_pairwise_predictions_at_threshold(df_p, 0.5) >>> linker.cluster_studio_dashboard( >>> df_p, df_c, [0, 4, 7], \"cluster_studio.html\" >>> ) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame(src=\"./cluster_studio.html\", width=\"100%\", height=1200) \"\"\" self . _raise_error_if_necessary_waterfall_columns_not_computed () rendered = render_splink_cluster_studio_html ( self , df_predict , df_clustered , out_path , sampling_method = sampling_method , sample_size = sample_size , cluster_ids = cluster_ids , overwrite = overwrite , cluster_names = cluster_names , ) if return_html_as_string : return rendered def save_settings_to_json ( self , out_path : str , overwrite = False ) -> dict : \"\"\"Save the configuration and parameters the linkage model to a `.json` file. The model can later be loaded back in using `linker.load_settings_from_json()` Examples: >>> linker.save_settings_to_json(\"my_settings.json\", overwrite=True) Args: out_path (str): File path for json file overwrite (bool, optional): Overwrite if already exists? Defaults to False. \"\"\" model_dict = self . _settings_obj . as_dict () if out_path : if os . path . isfile ( out_path ) and not overwrite : raise ValueError ( f \"The path { out_path } already exists. Please provide a different \" \"path or set overwrite=True\" ) with open ( out_path , \"w\" , encoding = \"utf-8\" ) as f : json . dump ( model_dict , f , indent = 4 ) def load_settings_from_json ( self , in_path : str ): \"\"\"Load settings from a `.json` file. This `.json` file would usually be the output of `linker.save_settings_to_json()` Examples: >>> linker.load_settings_from_json(\"my_settings.json\") Args: in_path (str): Path to settings json file \"\"\" with open ( in_path , \"r\" ) as f : model_dict = json . load ( f ) self . initialise_settings ( model_dict )","title":"Documentation for Linker object"},{"location":"linker.html#splink.linker.Linker.__init__","text":"Initialise the linker object, which manages the data linkage process and holds the data linkage model. Examples: >>> # Example 1: DuckDB >>> df = pd . read_csv ( \"data_to_dedupe.csv\" ) >>> linker = DuckDBLinker ( df , settings_dict ) >>> # Example 2: Spark >>> df_1 = spark . read . parquet ( \"table_1/\" ) >>> df_2 = spark . read . parquet ( \"table_2/\" ) >>> linker = SparkLinker ( >>> [ df_1 , df_2 ], >>> settings_dict , >>> input_table_aliases = [ \"customers\" , \"contact_center_callers\" ] >>> ) Parameters: Name Type Description Default input_table_or_tables Union [ str , list ] Input data into the linkage model. Either a single string (the name of a table in a database) for deduplication jobs, or a list of strings (the name of tables in a database) for link_only or link_and_dedupe. For some linkers, such as the DuckDBLinker and the SparkLinker, it's also possible to pass in dataframes (Pandas and Spark respectively) rather than strings. required settings_dict dict A Splink settings dictionary. If not provided when the object is created, can later be added using linker.initialise_settings() Defaults to None. None set_up_basic_logging bool If true, sets ups up basic logging so that Splink sends messages at INFO level to stdout. Defaults to True. True input_table_aliases Union [ str , list ] Labels assigned to input tables in Splink outputs. If the names of the tables in the input database are long or unspecific, this argument can be used to attach more easily readable/interpretable names. Defaults to None. None Source code in splink/linker.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 def __init__ ( self , input_table_or_tables : Union [ str , list ], settings_dict : dict = None , set_up_basic_logging : bool = True , input_table_aliases : Union [ str , list ] = None , ): \"\"\"Initialise the linker object, which manages the data linkage process and holds the data linkage model. Examples: >>> # Example 1: DuckDB >>> df = pd.read_csv(\"data_to_dedupe.csv\") >>> linker = DuckDBLinker(df, settings_dict) >>> # Example 2: Spark >>> df_1 = spark.read.parquet(\"table_1/\") >>> df_2 = spark.read.parquet(\"table_2/\") >>> linker = SparkLinker( >>> [df_1, df_2], >>> settings_dict, >>> input_table_aliases=[\"customers\", \"contact_center_callers\"] >>> ) Args: input_table_or_tables (Union[str, list]): Input data into the linkage model. Either a single string (the name of a table in a database) for deduplication jobs, or a list of strings (the name of tables in a database) for link_only or link_and_dedupe. For some linkers, such as the DuckDBLinker and the SparkLinker, it's also possible to pass in dataframes (Pandas and Spark respectively) rather than strings. settings_dict (dict, optional): A Splink settings dictionary. If not provided when the object is created, can later be added using `linker.initialise_settings()` Defaults to None. set_up_basic_logging (bool, optional): If true, sets ups up basic logging so that Splink sends messages at INFO level to stdout. Defaults to True. input_table_aliases (Union[str, list], optional): Labels assigned to input tables in Splink outputs. If the names of the tables in the input database are long or unspecific, this argument can be used to attach more easily readable/interpretable names. Defaults to None. \"\"\" if set_up_basic_logging : logging . basicConfig ( format = \" %(message)s \" , ) splink_logger = logging . getLogger ( \"splink\" ) splink_logger . setLevel ( logging . INFO ) self . _pipeline = SQLPipeline () self . _settings_dict = settings_dict if settings_dict is None : self . _settings_obj_ = None else : self . _settings_obj_ = Settings ( settings_dict ) self . _input_tables_dict = self . _get_input_tables_dict ( input_table_or_tables , input_table_aliases ) self . _validate_input_dfs () self . _em_training_sessions = [] self . _names_of_tables_created_by_splink : list = [] self . _find_new_matches_mode = False self . _train_u_using_random_sample_mode = False self . _compare_two_records_mode = False self . _self_link_mode = False self . _output_schema = \"\" self . debug_mode = False","title":"__init__()"},{"location":"linker.html#splink.linker.Linker.cluster_pairwise_predictions_at_threshold","text":"Clusters the pairwise match predictions that result from linker.predict() into groups of connected record using the connected components graph clustering algorithm Records with an estimated match_probability above threshold_match_probability are considered to be a match (i.e. they represent the same entity). Parameters: Name Type Description Default df_predict SplinkDataFrame The results of linker.predict() required threshold_match_probability float Filter the pairwise match predictions to include only pairwise comparisons with a match_probability above this threshold. This dataframe is then fed into the clustering algorithm. required Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame containing a list of all IDs, clustered into groups based on the desired match threshold. Source code in splink/linker.py 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 def cluster_pairwise_predictions_at_threshold ( self , df_predict : SplinkDataFrame , threshold_match_probability : float ) -> SplinkDataFrame : \"\"\"Clusters the pairwise match predictions that result from `linker.predict()` into groups of connected record using the connected components graph clustering algorithm Records with an estimated `match_probability` above `threshold_match_probability` are considered to be a match (i.e. they represent the same entity). Args: df_predict (SplinkDataFrame): The results of `linker.predict()` threshold_match_probability (float): Filter the pairwise match predictions to include only pairwise comparisons with a match_probability above this threshold. This dataframe is then fed into the clustering algorithm. Returns: SplinkDataFrame: A SplinkDataFrame containing a list of all IDs, clustered into groups based on the desired match threshold. \"\"\" self . _initialise_df_concat_with_tf ( df_predict ) edges_table = _cc_create_unique_id_cols ( self , df_predict , threshold_match_probability , ) cc = solve_connected_components ( self , edges_table ) return cc","title":"cluster_pairwise_predictions_at_threshold()"},{"location":"linker.html#splink.linker.Linker.cluster_studio_dashboard","text":"Generate an interactive html visualization of the predicted cluster and save to out_path . Parameters: Name Type Description Default df_predict SplinkDataFrame The outputs of linker.predict() required df_clustered SplinkDataFrame The outputs of linker.cluster_pairwise_predictions_at_threshold() required out_path str The path (including filename) to save the html file to. required sampling_method str random or by_cluster_size . Defaults to random . 'random' sample_size int Number of clusters to show in the dahboard. Defaults to 10. 10 cluster_ids list The IDs of the clusters that will be displayed in the dashboard. If provided, ignore the sampling_method and sample_size arguments. Defaults to None. None overwrite bool Overwrite the html file if it already exists? Defaults to False. False cluster_names list If provided, the dashboard will display these names in the selection box. Ony works in conjunction with cluster_ids . Defaults to None. None return_html_as_string If True, return the html as a string False Examples: >>> df_p = linker . predict () >>> df_c = linker . cluster_pairwise_predictions_at_threshold ( df_p , 0.5 ) >>> linker . cluster_studio_dashboard ( >>> df_p , df_c , [ 0 , 4 , 7 ], \"cluster_studio.html\" >>> ) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame ( src = \"./cluster_studio.html\" , width = \"100%\" , height = 1200 ) Source code in splink/linker.py 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 def cluster_studio_dashboard ( self , df_predict : SplinkDataFrame , df_clustered : SplinkDataFrame , out_path : str , sampling_method = \"random\" , sample_size : int = 10 , cluster_ids : list = None , cluster_names : list = None , overwrite : bool = False , return_html_as_string = False , ): \"\"\"Generate an interactive html visualization of the predicted cluster and save to `out_path`. Args: df_predict (SplinkDataFrame): The outputs of `linker.predict()` df_clustered (SplinkDataFrame): The outputs of `linker.cluster_pairwise_predictions_at_threshold()` out_path (str): The path (including filename) to save the html file to. sampling_method (str, optional): `random` or `by_cluster_size`. Defaults to `random`. sample_size (int, optional): Number of clusters to show in the dahboard. Defaults to 10. cluster_ids (list): The IDs of the clusters that will be displayed in the dashboard. If provided, ignore the `sampling_method` and `sample_size` arguments. Defaults to None. overwrite (bool, optional): Overwrite the html file if it already exists? Defaults to False. cluster_names (list, optional): If provided, the dashboard will display these names in the selection box. Ony works in conjunction with `cluster_ids`. Defaults to None. return_html_as_string: If True, return the html as a string Examples: >>> df_p = linker.predict() >>> df_c = linker.cluster_pairwise_predictions_at_threshold(df_p, 0.5) >>> linker.cluster_studio_dashboard( >>> df_p, df_c, [0, 4, 7], \"cluster_studio.html\" >>> ) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame(src=\"./cluster_studio.html\", width=\"100%\", height=1200) \"\"\" self . _raise_error_if_necessary_waterfall_columns_not_computed () rendered = render_splink_cluster_studio_html ( self , df_predict , df_clustered , out_path , sampling_method = sampling_method , sample_size = sample_size , cluster_ids = cluster_ids , overwrite = overwrite , cluster_names = cluster_names , ) if return_html_as_string : return rendered","title":"cluster_studio_dashboard()"},{"location":"linker.html#splink.linker.Linker.compare_two_records","text":"Use the linkage model to compare and score a pairwise record comparison based on the two input records provided Parameters: Name Type Description Default record_1 dict dictionary representing the first record. Columns names and data types must be the same as the columns in the settings object required record_2 dict dictionary representing the second record. Columns names and data types must be the same as the columns in the settings object required Examples: >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . compare_two_records ( record_left , record_right ) Returns: Name Type Description SplinkDataFrame Pairwise comparison with scored prediction Source code in splink/linker.py 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 def compare_two_records ( self , record_1 : dict , record_2 : dict ): \"\"\"Use the linkage model to compare and score a pairwise record comparison based on the two input records provided Args: record_1 (dict): dictionary representing the first record. Columns names and data types must be the same as the columns in the settings object record_2 (dict): dictionary representing the second record. Columns names and data types must be the same as the columns in the settings object Examples: >>> linker = DuckDBLinker(df) >>> linker.load_settings_from_json(\"saved_settings.json\") >>> linker.compare_two_records(record_left, record_right) Returns: SplinkDataFrame: Pairwise comparison with scored prediction \"\"\" original_blocking_rules = ( self . _settings_obj . _blocking_rules_to_generate_predictions ) original_link_type = self . _settings_obj . _link_type self . _compare_two_records_mode = True self . _settings_obj . _blocking_rules_to_generate_predictions = [] self . _records_to_table ([ record_1 ], \"__splink__compare_two_records_left\" ) self . _records_to_table ([ record_2 ], \"__splink__compare_two_records_right\" ) sql_join_tf = _join_tf_to_input_df_sql ( self ) sql_join_tf = sql_join_tf . replace ( \"__splink__df_concat\" , \"__splink__compare_two_records_left\" ) self . _enqueue_sql ( sql_join_tf , \"__splink__compare_two_records_left_with_tf\" ) sql_join_tf = sql_join_tf . replace ( \"__splink__compare_two_records_left\" , \"__splink__compare_two_records_right\" ) self . _enqueue_sql ( sql_join_tf , \"__splink__compare_two_records_right_with_tf\" ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) predictions = self . _execute_sql_pipeline ( use_cache = False ) self . _settings_obj . _blocking_rules_to_generate_predictions = ( original_blocking_rules ) self . _settings_obj . _link_type = original_link_type self . _compare_two_records_mode = False return predictions","title":"compare_two_records()"},{"location":"linker.html#splink.linker.Linker.comparison_viewer_dashboard","text":"Generate an interactive html visualization of the linker's predictions and save to out_path . For more information see this video Parameters: Name Type Description Default df_predict SplinkDataFrame The outputs of linker.predict() required out_path str The path (including filename) to save the html file to. required overwrite bool Overwrite the html file if it already exists? Defaults to False. False num_example_rows int Number of example rows per comparison vector. Defaults to 2. 2 return_html_as_string If True, return the html as a string False Examples: >>> df_predictions = linker . predict () >>> linker . comparison_viewer_dashboard ( df_predictions , \"scv.html\" , True , 2 ) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame ( src = \"./scv.html\" , width = \"100%\" , height = 1200 ) Source code in splink/linker.py 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 def comparison_viewer_dashboard ( self , df_predict : SplinkDataFrame , out_path : str , overwrite = False , num_example_rows = 2 , return_html_as_string = False , ): \"\"\"Generate an interactive html visualization of the linker's predictions and save to `out_path`. For more information see [this video](https://www.youtube.com/watch?v=DNvCMqjipis) Args: df_predict (SplinkDataFrame): The outputs of `linker.predict()` out_path (str): The path (including filename) to save the html file to. overwrite (bool, optional): Overwrite the html file if it already exists? Defaults to False. num_example_rows (int, optional): Number of example rows per comparison vector. Defaults to 2. return_html_as_string: If True, return the html as a string Examples: >>> df_predictions = linker.predict() >>> linker.comparison_viewer_dashboard(df_predictions, \"scv.html\", True, 2) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame(src=\"./scv.html\", width=\"100%\", height=1200) \"\"\" self . _raise_error_if_necessary_waterfall_columns_not_computed () sql = comparison_vector_distribution_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vector_distribution\" ) sqls = comparison_viewer_table_sqls ( self , num_example_rows ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) df = self . _execute_sql_pipeline ([ df_predict ]) rendered = render_splink_comparison_viewer_html ( df . as_record_dict (), self . _settings_obj . _as_completed_dict (), out_path , overwrite , ) if return_html_as_string : return rendered","title":"comparison_viewer_dashboard()"},{"location":"linker.html#splink.linker.Linker.count_num_comparisons_from_blocking_rule","text":"Compute the number of pairwise record comparisons that would be generated by a blocking rule Parameters: Name Type Description Default blocking_rule str The blocking rule to analyse required link_type str The link type. This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None unique_id_column_name str This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None Examples: >>> br = \"l.first_name = r.first_name\" >>> linker . count_num_comparisons_from_blocking_rule ( br ) 19387 >>> br = \"l.name = r.name and substr(l.dob,1,4) = substr(r.dob,1,4)\" >>> linker . count_num_comparisons_from_blocking_rule ( br ) 394 Returns: Name Type Description int int The number of comparisons generated by the blocking rule Source code in splink/linker.py 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 def count_num_comparisons_from_blocking_rule ( self , blocking_rule : str , link_type : str = None , unique_id_column_name : str = None , ) -> int : \"\"\"Compute the number of pairwise record comparisons that would be generated by a blocking rule Args: blocking_rule (str): The blocking rule to analyse link_type (str, optional): The link type. This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. unique_id_column_name (str, optional): This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. Examples: >>> br = \"l.first_name = r.first_name\" >>> linker.count_num_comparisons_from_blocking_rule(br) 19387 >>> br = \"l.name = r.name and substr(l.dob,1,4) = substr(r.dob,1,4)\" >>> linker.count_num_comparisons_from_blocking_rule(br) 394 Returns: int: The number of comparisons generated by the blocking rule \"\"\" sql = vertically_concatenate_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_concat\" ) sql = number_of_comparisons_generated_by_blocking_rule_sql ( self , blocking_rule , link_type , unique_id_column_name ) self . _enqueue_sql ( sql , \"__splink__analyse_blocking_rule\" ) res = self . _execute_sql_pipeline () . as_record_dict ()[ 0 ] return res [ \"count_of_pairwise_comparisons_generated\" ]","title":"count_num_comparisons_from_blocking_rule()"},{"location":"linker.html#splink.linker.Linker.count_num_comparisons_from_blocking_rules_for_prediction","text":"Counts the maginal number of edges created from each of the blocking rules in blocking_rules_to_generate_predictions This is different to count_num_comparisons_from_blocking_rule because it (a) analyses multiple blocking rules rather than a single rule, and (b) deduplicates any comparisons that are generated, to tell you the marginal effect of each entry in blocking_rules_to_generate_predictions Parameters: Name Type Description Default df_predict SplinkDataFrame SplinkDataFrame with match weights required Examples: >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> df_predict = linker . predict ( threshold_match_probability = 0.95 ) >>> count_pairwise = linker . count_num_comparisons_from_blocking_rules_for_prediction ( df_predict ) >>> count_pairwise . as_pandas_dataframe ( limit = 5 ) Returns: Name Type Description SplinkDataFrame A SplinkDataFrame of the pairwise comparisons and estimated pairwise comparisons generated by the blocking rules. Source code in splink/linker.py 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 def count_num_comparisons_from_blocking_rules_for_prediction ( self , df_predict ): \"\"\"Counts the maginal number of edges created from each of the blocking rules in `blocking_rules_to_generate_predictions` This is different to `count_num_comparisons_from_blocking_rule` because it (a) analyses multiple blocking rules rather than a single rule, and (b) deduplicates any comparisons that are generated, to tell you the marginal effect of each entry in `blocking_rules_to_generate_predictions` Args: df_predict (SplinkDataFrame): SplinkDataFrame with match weights and probabilities of rows matching Examples: >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.load_settings_from_json(\"saved_settings.json\") >>> df_predict = linker.predict(threshold_match_probability=0.95) >>> count_pairwise = linker.count_num_comparisons_from_blocking_rules_for_prediction(df_predict) >>> count_pairwise.as_pandas_dataframe(limit=5) Returns: SplinkDataFrame: A SplinkDataFrame of the pairwise comparisons and estimated pairwise comparisons generated by the blocking rules. \"\"\" # noqa: E501 sql = count_num_comparisons_from_blocking_rules_for_prediction_sql ( df_predict ) match_key_analysis = self . _sql_to_splink_dataframe_checking_cache ( sql , \"__splink__match_key_analysis\" ) return match_key_analysis","title":"count_num_comparisons_from_blocking_rules_for_prediction()"},{"location":"linker.html#splink.linker.Linker.compute_tf_table","text":"Compute a term frequency table for a given column and persist to the database This method is useful if you want to pre-compute term frequency tables e.g. so that real time linkage executes faster, or so that you can estimate various models without having to recompute term frequency tables each time Examples: >>> # Example 1: Real time linkage >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . compute_tf_table ( \"surname\" ) >>> linker . compare_two_records ( record_left , record_right ) >>> # Example 2: Pre-computed term frequency tables in Spark >>> linker = SparkLinker ( df ) >>> df_first_name_tf = linker . compute_tf_table ( \"first_name\" ) >>> df_first_name_tf . write . parquet ( \"folder/first_name_tf\" ) >>> >>> # On subsequent data linking job, read this table rather than recompute >>> df_first_name_tf = spark . read . parquet ( \"folder/first_name_tf\" ) >>> df_first_name_tf . createOrReplaceTempView ( \"__splink__df_tf_first_name\" ) Parameters: Name Type Description Default column_name str The column name in the input table required Returns: Name Type Description SplinkDataFrame SplinkDataFrame The resultant table as a splink data frame Source code in splink/linker.py 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 def compute_tf_table ( self , column_name : str ) -> SplinkDataFrame : \"\"\"Compute a term frequency table for a given column and persist to the database This method is useful if you want to pre-compute term frequency tables e.g. so that real time linkage executes faster, or so that you can estimate various models without having to recompute term frequency tables each time Examples: >>> # Example 1: Real time linkage >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.load_settings_from_json(\"saved_settings.json\") >>> linker.compute_tf_table(\"surname\") >>> linker.compare_two_records(record_left, record_right) >>> # Example 2: Pre-computed term frequency tables in Spark >>> linker = SparkLinker(df) >>> df_first_name_tf = linker.compute_tf_table(\"first_name\") >>> df_first_name_tf.write.parquet(\"folder/first_name_tf\") >>> >>> # On subsequent data linking job, read this table rather than recompute >>> df_first_name_tf = spark.read.parquet(\"folder/first_name_tf\") >>> df_first_name_tf.createOrReplaceTempView(\"__splink__df_tf_first_name\") Args: column_name (str): The column name in the input table Returns: SplinkDataFrame: The resultant table as a splink data frame \"\"\" sql = vertically_concatenate_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_concat\" ) input_col = InputColumn ( column_name , tf_adjustments = True ) sql = term_frequencies_for_single_column_sql ( input_col ) self . _enqueue_sql ( sql , colname_to_tf_tablename ( input_col )) return self . _execute_sql_pipeline ( materialise_as_hash = False )","title":"compute_tf_table()"},{"location":"linker.html#splink.linker.Linker.cumulative_num_comparisons_from_blocking_rules_chart","text":"Display a chart with the cumulative number of comparisons generated by a selection of blocking rules. This is equivalent to the output size of df_predict and details how many comparisons each of your individual blocking rules will contribute to the total. Parameters: Name Type Description Default blocking_rules str or list The blocking rule(s) to compute comparisons for. If null, the rules set out in your settings object will be used. None link_type str The link type. This defaults to the link type outlined in your settings object. None unique_id_column_name str This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None Examples: >>> linker_settings = DuckDBLinker ( df , settings ) >>> # Compute the cumulative number of comparisons generated by the rules >>> # in your settings object. >>> linker_settings . cumulative_num_comparisons_from_blocking_rules_chart () >>> >>> # Generate total comparisons with custom blocking rules. >>> blocking_rules = [ >>> \"l.surname = r.surname\" , >>> \"l.first_name = r.first_name >>> and substr ( l . dob , 1 , 4 ) = substr ( r . dob , 1 , 4 ) \" >>> ] >>> >>> linker . cumulative_num_comparisons_from_blocking_rules_chart ( >>> blocking_rules >>> ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. Source code in splink/linker.py 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 def cumulative_num_comparisons_from_blocking_rules_chart ( self , blocking_rules : str or list = None , link_type : str = None , unique_id_column_name : str = None , ): \"\"\"Display a chart with the cumulative number of comparisons generated by a selection of blocking rules. This is equivalent to the output size of df_predict and details how many comparisons each of your individual blocking rules will contribute to the total. Args: blocking_rules (str or list): The blocking rule(s) to compute comparisons for. If null, the rules set out in your settings object will be used. link_type (str, optional): The link type. This defaults to the link type outlined in your settings object. unique_id_column_name (str, optional): This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. Examples: >>> linker_settings = DuckDBLinker(df, settings) >>> # Compute the cumulative number of comparisons generated by the rules >>> # in your settings object. >>> linker_settings.cumulative_num_comparisons_from_blocking_rules_chart() >>> >>> # Generate total comparisons with custom blocking rules. >>> blocking_rules = [ >>> \"l.surname = r.surname\", >>> \"l.first_name = r.first_name >>> and substr(l.dob,1,4) = substr(r.dob,1,4)\" >>> ] >>> >>> linker.cumulative_num_comparisons_from_blocking_rules_chart( >>> blocking_rules >>> ) Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" if blocking_rules : blocking_rules = ensure_is_list ( blocking_rules ) records = cumulative_comparisons_generated_by_blocking_rules ( self , blocking_rules , link_type , unique_id_column_name , ) return cumulative_blocking_rule_comparisons_generated ( records )","title":"cumulative_num_comparisons_from_blocking_rules_chart()"},{"location":"linker.html#splink.linker.Linker.deterministic_link","text":"Uses the blocking rules specified by blocking_rules_to_generate_predictions in the settings dictionary to generate pairwise record comparisons. For deterministic linkage, this should be a list of blocking rules which are strict enough to generate only true links. Deterministic linkage, however, is likely to result in missed links (false negatives). Examples: >>> linker = DuckDBLinker ( df ) >>> >>> settings = { >>> \"link_type\" : \"dedupe_only\" , >>> \"blocking_rules_to_generate_predictions\" : [ >>> \"l.first_name = r.first_name\" , >>> \"l.surname = r.surname\" , >>> ], >>> \"comparisons\" : [] >>> } >>> >>> from splink.duckdb.duckdb_linker import DuckDBLinker >>> >>> linker = DuckDBLinker ( df , settings ) >>> df = linker . deterministic_link () Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. Source code in splink/linker.py 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 def deterministic_link ( self ) -> SplinkDataFrame : \"\"\"Uses the blocking rules specified by `blocking_rules_to_generate_predictions` in the settings dictionary to generate pairwise record comparisons. For deterministic linkage, this should be a list of blocking rules which are strict enough to generate only true links. Deterministic linkage, however, is likely to result in missed links (false negatives). Examples: >>> linker = DuckDBLinker(df) >>> >>> settings = { >>> \"link_type\": \"dedupe_only\", >>> \"blocking_rules_to_generate_predictions\": [ >>> \"l.first_name = r.first_name\", >>> \"l.surname = r.surname\", >>> ], >>> \"comparisons\": [] >>> } >>> >>> from splink.duckdb.duckdb_linker import DuckDBLinker >>> >>> linker = DuckDBLinker(df, settings) >>> df = linker.deterministic_link() Returns: SplinkDataFrame: A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. \"\"\" self . _initialise_df_concat_with_tf () sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) return self . _execute_sql_pipeline ()","title":"deterministic_link()"},{"location":"linker.html#splink.linker.Linker.estimate_m_from_label_column","text":"Estimate the m parameters of the linkage model from a label (ground truth) column in the input dataframe(s). The m parameters represent the proportion of record comparisons that fall into each comparison level amongst truly matching records. The ground truth column is used to generate pairwise record comparisons which are then assumed to be matches. For example, if the entity being matched is persons, and your input dataset(s) contain social security number, this could be used to estimate the m values for the model. Note that this column does not need to be fully populated. A common case is where a unique identifier such as social security number is only partially populated. Parameters: Name Type Description Default label_colname str The name of the column containing the ground truth label in the input data. required Examples: >>> linker . estimate_m_from_label_column ( \"social_security_number\" ) Returns: Type Description Updates the estimated m parameters within the linker object and returns nothing. Source code in splink/linker.py 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 def estimate_m_from_label_column ( self , label_colname : str ): \"\"\"Estimate the m parameters of the linkage model from a label (ground truth) column in the input dataframe(s). The m parameters represent the proportion of record comparisons that fall into each comparison level amongst truly matching records. The ground truth column is used to generate pairwise record comparisons which are then assumed to be matches. For example, if the entity being matched is persons, and your input dataset(s) contain social security number, this could be used to estimate the m values for the model. Note that this column does not need to be fully populated. A common case is where a unique identifier such as social security number is only partially populated. Args: label_colname (str): The name of the column containing the ground truth label in the input data. Examples: >>> linker.estimate_m_from_label_column(\"social_security_number\") Returns: Updates the estimated m parameters within the linker object and returns nothing. \"\"\" self . _initialise_df_concat_with_tf ( materialise = True ) estimate_m_values_from_label_column ( self , self . _input_tables_dict , label_colname ) self . _populate_m_u_from_trained_values () self . _settings_obj . _columns_without_estimated_parameters_message ()","title":"estimate_m_from_label_column()"},{"location":"linker.html#splink.linker.Linker.estimate_parameters_using_expectation_maximisation","text":"Estimate the parameters of the linkage model using expectation maximisation. By default, the m probabilities are estimated, but not the u probabilities, because good estiamtes for the u probabilities can be obtained from linker.estimate_u_using_random_sampling() . You can change this by setting fix_u_probabilities to False. The blocking rule provided is used to generate pairwise record comparisons. Usually, this should be a blocking rule that results in a dataframe where matches are between about 1% and 99% of the comparisons. By default, m parameters are estimated for all comparisons except those which are included in the blocking rule. For example, if the blocking rule is l.first_name = r.first_name , then parameter esimates will be made for all comparison except those which use first_name in their sql_condition By default, the probability two random records match is estimated for the blocked data, and then the m and u parameters for the columns specified in the blocking rules are used to estiamte the global probability two random records match. To control which comparisons should have their parameter estimated, and the process of 'reversing out' the global probability two random records match, the user may specify comparisons_to_deactivate and comparison_levels_to_reverse_blocking_rule . This is useful, for example if you block on the dmetaphone of a column but match on the original column. Examples: >>> # Default behaviour >>> br_training = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker . estimate_parameters_using_expectation_maximisation ( br_training ) >>> # Specify which comparisons to deactivate >>> br_training = \"l.dmeta_first_name = r.dmeta_first_name\" >>> settings_obj = linker . _settings_obj >>> comp = settings_obj . _get_comparison_by_output_column_name ( \"first_name\" ) >>> dmeta_level = comp . _get_comparison_level_by_comparison_vector_value ( 1 ) >>> linker . estimate_parameters_using_expectation_maximisation ( >>> br_training , >>> comparisons_to_deactivate = [ \"first_name\" ], >>> comparison_levels_to_reverse_blocking_rule = [ dmeta_level ], >>> ) Parameters: Name Type Description Default blocking_rule str The blocking rule used to generate pairwise record comparisons. required comparisons_to_deactivate list By default, splink will analyse the blocking rule provided and estimate the m parameters for all comaprisons except those included in the blocking rule. If comparisons_to_deactivate are provided, spink will instead estimate m parameters for all comparison except those specified in the comparisons_to_deactivate list. This list can either contain the output_column_name of the Comparison as a string, or Comparison objects. Defaults to None. None comparison_levels_to_reverse_blocking_rule list By default, splink will analyse the blocking rule provided and adjust the global probability two random records match to account for the matches specified in the blocking rule. If provided, this argument will overrule this default behaviour. The user must provide a list of ComparisonLevel objects. Defaults to None. None fix_probability_two_random_records_match bool If True, do not update the probability two random records match after each iteration. Defaults to False. False fix_m_probabilities bool If True, do not update the m probabilities after each iteration. Defaults to False. False fix_u_probabilities bool If True, do not update the u probabilities after each iteration. Defaults to True. True Examples: >>> blocking_rule = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker . estimate_parameters_using_expectation_maximisation ( blocking_rule ) Returns: Name Type Description EMTrainingSession EMTrainingSession An object containing information about the training session such as how parameters changed during the iteration history Source code in splink/linker.py 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 def estimate_parameters_using_expectation_maximisation ( self , blocking_rule : str , comparisons_to_deactivate : List [ Union [ str , Comparison ]] = None , comparison_levels_to_reverse_blocking_rule : List [ ComparisonLevel ] = None , fix_probability_two_random_records_match : bool = False , fix_m_probabilities = False , fix_u_probabilities = True , ) -> EMTrainingSession : \"\"\"Estimate the parameters of the linkage model using expectation maximisation. By default, the m probabilities are estimated, but not the u probabilities, because good estiamtes for the u probabilities can be obtained from `linker.estimate_u_using_random_sampling()`. You can change this by setting `fix_u_probabilities` to False. The blocking rule provided is used to generate pairwise record comparisons. Usually, this should be a blocking rule that results in a dataframe where matches are between about 1% and 99% of the comparisons. By default, m parameters are estimated for all comparisons except those which are included in the blocking rule. For example, if the blocking rule is `l.first_name = r.first_name`, then parameter esimates will be made for all comparison except those which use `first_name` in their sql_condition By default, the probability two random records match is estimated for the blocked data, and then the m and u parameters for the columns specified in the blocking rules are used to estiamte the global probability two random records match. To control which comparisons should have their parameter estimated, and the process of 'reversing out' the global probability two random records match, the user may specify `comparisons_to_deactivate` and `comparison_levels_to_reverse_blocking_rule`. This is useful, for example if you block on the dmetaphone of a column but match on the original column. Examples: >>> # Default behaviour >>> br_training = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker.estimate_parameters_using_expectation_maximisation(br_training) >>> # Specify which comparisons to deactivate >>> br_training = \"l.dmeta_first_name = r.dmeta_first_name\" >>> settings_obj = linker._settings_obj >>> comp = settings_obj._get_comparison_by_output_column_name(\"first_name\") >>> dmeta_level = comp._get_comparison_level_by_comparison_vector_value(1) >>> linker.estimate_parameters_using_expectation_maximisation( >>> br_training, >>> comparisons_to_deactivate=[\"first_name\"], >>> comparison_levels_to_reverse_blocking_rule=[dmeta_level], >>> ) Args: blocking_rule (str): The blocking rule used to generate pairwise record comparisons. comparisons_to_deactivate (list, optional): By default, splink will analyse the blocking rule provided and estimate the m parameters for all comaprisons except those included in the blocking rule. If comparisons_to_deactivate are provided, spink will instead estimate m parameters for all comparison except those specified in the comparisons_to_deactivate list. This list can either contain the output_column_name of the Comparison as a string, or Comparison objects. Defaults to None. comparison_levels_to_reverse_blocking_rule (list, optional): By default, splink will analyse the blocking rule provided and adjust the global probability two random records match to account for the matches specified in the blocking rule. If provided, this argument will overrule this default behaviour. The user must provide a list of ComparisonLevel objects. Defaults to None. fix_probability_two_random_records_match (bool, optional): If True, do not update the probability two random records match after each iteration. Defaults to False. fix_m_probabilities (bool, optional): If True, do not update the m probabilities after each iteration. Defaults to False. fix_u_probabilities (bool, optional): If True, do not update the u probabilities after each iteration. Defaults to True. Examples: >>> blocking_rule = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker.estimate_parameters_using_expectation_maximisation(blocking_rule) Returns: EMTrainingSession: An object containing information about the training session such as how parameters changed during the iteration history \"\"\" self . _initialise_df_concat_with_tf ( materialise = True ) if comparisons_to_deactivate : # If user provided a string, convert to Comparison object comparisons_to_deactivate = [ self . _settings_obj . _get_comparison_by_output_column_name ( n ) if isinstance ( n , str ) else n for n in comparisons_to_deactivate ] if comparison_levels_to_reverse_blocking_rule is None : logger . warning ( \" \\n WARNING: \\n \" \"You have provided comparisons_to_deactivate but not \" \"comparison_levels_to_reverse_blocking_rule. \\n \" \"If comparisons_to_deactivate is provided, then \" \"you usually need to provide corresponding \" \"comparison_levels_to_reverse_blocking_rule. \" \"because each comparison to deactivate if effectively treated \" \"as an exact match.\" ) em_training_session = EMTrainingSession ( self , blocking_rule , fix_u_probabilities = fix_u_probabilities , fix_m_probabilities = fix_m_probabilities , fix_probability_two_random_records_match = fix_probability_two_random_records_match , # noqa 501 comparisons_to_deactivate = comparisons_to_deactivate , comparison_levels_to_reverse_blocking_rule = comparison_levels_to_reverse_blocking_rule , # noqa 501 ) em_training_session . _train () self . _populate_m_u_from_trained_values () self . _populate_probability_two_random_records_match_from_trained_values () self . _settings_obj . _columns_without_estimated_parameters_message () return em_training_session","title":"estimate_parameters_using_expectation_maximisation()"},{"location":"linker.html#splink.linker.Linker.estimate_u_using_random_sampling","text":"Estimate the u parameters of the linkage model using random sampling. The u parameters represent the proportion of record comparisons that fall into each comparison level amongst truly non-matching records. This procedure takes a sample of the data and generates the cartesian product of pairwise record comparisons amongst the sampled records. The validity of the u values rests on the assumption that the resultant pairwise comparisons are non-matches (or at least, they are very unlikely to be matches). For large datasets, this is typically true. Parameters: Name Type Description Default target_rows int The target number of pairwise record comparisons from required Examples: >>> linker . estimate_u_using_random_sampling ( 1e8 ) Returns: Name Type Description None Updates the estimated u parameters within the linker object and returns nothing. Source code in splink/linker.py 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 def estimate_u_using_random_sampling ( self , target_rows : int ): \"\"\"Estimate the u parameters of the linkage model using random sampling. The u parameters represent the proportion of record comparisons that fall into each comparison level amongst truly non-matching records. This procedure takes a sample of the data and generates the cartesian product of pairwise record comparisons amongst the sampled records. The validity of the u values rests on the assumption that the resultant pairwise comparisons are non-matches (or at least, they are very unlikely to be matches). For large datasets, this is typically true. Args: target_rows (int): The target number of pairwise record comparisons from which to derive the u values. Larger will give more accurate estimates but lead to longer runtimes. In our experience at least 1e9 (one billion) gives best results but can take a long time to compute. 1e7 (ten million) is often adequate whilst testing different model specifications, before the final model is estimated. Examples: >>> linker.estimate_u_using_random_sampling(1e8) Returns: None: Updates the estimated u parameters within the linker object and returns nothing. \"\"\" self . _initialise_df_concat_with_tf ( materialise = True ) estimate_u_values ( self , target_rows ) self . _populate_m_u_from_trained_values () self . _settings_obj . _columns_without_estimated_parameters_message ()","title":"estimate_u_using_random_sampling()"},{"location":"linker.html#splink.linker.Linker.find_matches_to_new_records","text":"Given one or more records, find records in the input dataset(s) which match and return in order of the splink prediction score. This effectively provides a way of searching the input datasets for given record(s) Parameters: Name Type Description Default records_or_tablename List [ dict ] Input search record(s) as list of dict, or a table registered to the database. required blocking_rules list Blocking rules to select which records to find and score. If [], do not use a blocking rule - meaning the input records will be compared to all records provided to the linker when it was instantiated. Defaults to []. [] match_weight_threshold int Return matches with a match weight above this threshold. Defaults to -4. -4 Examples: >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> # Pre-compute tf tables for any tables with >>> # term frequency adjustments >>> linker . compute_tf_table ( \"first_name\" ) >>> record = { 'unique_id' : 1 , >>> 'first_name' : \"John\" , >>> 'surname' : \"Smith\" , >>> 'dob' : \"1971-05-24\" , >>> 'city' : \"London\" , >>> 'email' : \"john@smith.net\" >>> } >>> df = linker . find_matches_to_new_records ([ record ], blocking_rules = []) Returns: Name Type Description SplinkDataFrame SplinkDataFrame The pairwise comparisons. Source code in splink/linker.py 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 def find_matches_to_new_records ( self , records_or_tablename , blocking_rules = [], match_weight_threshold =- 4 , ) -> SplinkDataFrame : \"\"\"Given one or more records, find records in the input dataset(s) which match and return in order of the splink prediction score. This effectively provides a way of searching the input datasets for given record(s) Args: records_or_tablename (List[dict]): Input search record(s) as list of dict, or a table registered to the database. blocking_rules (list, optional): Blocking rules to select which records to find and score. If [], do not use a blocking rule - meaning the input records will be compared to all records provided to the linker when it was instantiated. Defaults to []. match_weight_threshold (int, optional): Return matches with a match weight above this threshold. Defaults to -4. Examples: >>> linker = DuckDBLinker(df) >>> linker.load_settings_from_json(\"saved_settings.json\") >>> # Pre-compute tf tables for any tables with >>> # term frequency adjustments >>> linker.compute_tf_table(\"first_name\") >>> record = {'unique_id': 1, >>> 'first_name': \"John\", >>> 'surname': \"Smith\", >>> 'dob': \"1971-05-24\", >>> 'city': \"London\", >>> 'email': \"john@smith.net\" >>> } >>> df = linker.find_matches_to_new_records([record], blocking_rules=[]) Returns: SplinkDataFrame: The pairwise comparisons. \"\"\" original_blocking_rules = ( self . _settings_obj . _blocking_rules_to_generate_predictions ) original_link_type = self . _settings_obj . _link_type if not isinstance ( records_or_tablename , str ): self . _records_to_table ( records_or_tablename , \"__splink__df_new_records\" ) new_records_tablename = \"__splink__df_new_records\" else : new_records_tablename = records_or_tablename blocking_rules = [ BlockingRule ( r ) if not isinstance ( r , BlockingRule ) else r for r in blocking_rules ] self . _settings_obj . _blocking_rules_to_generate_predictions = blocking_rules self . _settings_obj . _link_type = \"link_only_find_matches_to_new_records\" self . _find_new_matches_mode = True sql = _join_tf_to_input_df_sql ( self ) sql = sql . replace ( \"__splink__df_concat\" , new_records_tablename ) self . _enqueue_sql ( sql , \"__splink__df_new_records_with_tf\" ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) sql = f \"\"\" select * from __splink__df_predict where match_weight > { match_weight_threshold } \"\"\" self . _enqueue_sql ( sql , \"__splink_find_matches_predictions\" ) predictions = self . _execute_sql_pipeline ( use_cache = False ) self . _settings_obj . _blocking_rules_to_generate_predictions = ( original_blocking_rules ) self . _settings_obj . _link_type = original_link_type self . _find_new_matches_mode = False return predictions","title":"find_matches_to_new_records()"},{"location":"linker.html#splink.linker.Linker.initialise_settings","text":"Initialise settings for the linker. To be used if settings were not passed to the linker on creation. Examples: >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . profile_columns ([ \"first_name\" , \"surname\" ]) >>> linker . initialise_settings ( settings_dict ) Parameters: Name Type Description Default settings_dict dict A Splink settings dictionary required Source code in splink/linker.py 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 def initialise_settings ( self , settings_dict : dict ): \"\"\"Initialise settings for the linker. To be used if settings were not passed to the linker on creation. Examples: >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.profile_columns([\"first_name\", \"surname\"]) >>> linker.initialise_settings(settings_dict) Args: settings_dict (dict): A Splink settings dictionary \"\"\" self . _settings_dict = settings_dict self . _settings_obj_ = Settings ( settings_dict ) self . _validate_input_dfs ()","title":"initialise_settings()"},{"location":"linker.html#splink.linker.Linker.load_settings_from_json","text":"Load settings from a .json file. This .json file would usually be the output of linker.save_settings_to_json() Examples: >>> linker . load_settings_from_json ( \"my_settings.json\" ) Parameters: Name Type Description Default in_path str Path to settings json file required Source code in splink/linker.py 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 def load_settings_from_json ( self , in_path : str ): \"\"\"Load settings from a `.json` file. This `.json` file would usually be the output of `linker.save_settings_to_json()` Examples: >>> linker.load_settings_from_json(\"my_settings.json\") Args: in_path (str): Path to settings json file \"\"\" with open ( in_path , \"r\" ) as f : model_dict = json . load ( f ) self . initialise_settings ( model_dict )","title":"load_settings_from_json()"},{"location":"linker.html#splink.linker.Linker.m_u_parameters_chart","text":"Display a chart of the m and u parameters of the linkage model Examples: >>> linker . m_u_parameters_chart () >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . match_weights_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500 ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. Source code in splink/linker.py 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 def m_u_parameters_chart ( self ): \"\"\"Display a chart of the m and u parameters of the linkage model Examples: >>> linker.m_u_parameters_chart() >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker.match_weights_chart() >>> save_offline_chart(c.spec, \"test_chart.html\") >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame(src=\"./test_chart.html\", width=1000, height=500) Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" return self . _settings_obj . m_u_parameters_chart ()","title":"m_u_parameters_chart()"},{"location":"linker.html#splink.linker.Linker.match_weights_chart","text":"Display a chart of the (partial) match weights of the linkage model Examples: >>> linker . match_weights_chart () >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . match_weights_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500 ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. Source code in splink/linker.py 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 def match_weights_chart ( self ): \"\"\"Display a chart of the (partial) match weights of the linkage model Examples: >>> linker.match_weights_chart() >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker.match_weights_chart() >>> save_offline_chart(c.spec, \"test_chart.html\") >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame(src=\"./test_chart.html\", width=1000, height=500) Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" return self . _settings_obj . match_weights_chart ()","title":"match_weights_chart()"},{"location":"linker.html#splink.linker.Linker.missingness_chart","text":"Generate a summary chart of the missingness (prevalence of nulls) of columns in the input datasets. By default, missingness is assessed across all input datasets Parameters: Name Type Description Default input_dataset str Name of one of the input tables in the None Examples: >>> linker . missingness_chart () >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . missingness_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500 Source code in splink/linker.py 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 def missingness_chart ( self , input_dataset : str = None ): \"\"\"Generate a summary chart of the missingness (prevalence of nulls) of columns in the input datasets. By default, missingness is assessed across all input datasets Args: input_dataset (str, optional): Name of one of the input tables in the database. If provided, missingness will be computed for this table alone. Defaults to None. Examples: >>> linker.missingness_chart() >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker.missingness_chart() >>> save_offline_chart(c.spec, \"test_chart.html\") >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame(src=\"./test_chart.html\", width=1000, height=500 \"\"\" records = missingness_data ( self , input_dataset ) return missingness_chart ( records , input_dataset )","title":"missingness_chart()"},{"location":"linker.html#splink.linker.Linker.parameter_estimate_comparisons_chart","text":"Show a chart that shows how parameter estimates have differed across the different estimation methods you have used. For example, if you have run two EM estimation sessions, blocking on different variables, and both result in parameter estimates for first_name, this chart will enable easy comparison of the different estimates Parameters: Name Type Description Default include_m bool Show different estimates of m values. Defaults to True. True include_u bool Show different estimates of u values. Defaults to True. True Source code in splink/linker.py 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 def parameter_estimate_comparisons_chart ( self , include_m = True , include_u = True ): \"\"\"Show a chart that shows how parameter estimates have differed across the different estimation methods you have used. For example, if you have run two EM estimation sessions, blocking on different variables, and both result in parameter estimates for first_name, this chart will enable easy comparison of the different estimates Args: include_m (bool, optional): Show different estimates of m values. Defaults to True. include_u (bool, optional): Show different estimates of u values. Defaults to True. \"\"\" records = self . _settings_obj . _parameter_estimates_as_records to_retain = [] if include_m : to_retain . append ( \"m\" ) if include_u : to_retain . append ( \"u\" ) records = [ r for r in records if r [ \"m_or_u\" ] in to_retain ] return parameter_estimate_comparisons ( records )","title":"parameter_estimate_comparisons_chart()"},{"location":"linker.html#splink.linker.Linker.precision_recall_chart_from_labels","text":"Generate a precision-recall chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered as a table with your database: source_dataset_l unique_id_l source_dataset_r unique_id_r clerical_match_score df_1 1 df_2 2 0.99 df_1 1 df_2 3 0.2 Note that source_dataset and unique_id should correspond to the values specified in the settings dict, and the input_table_aliases passed to the linker object. For dedupe_only links, the source_dataset columns can be ommitted. Parameters: Name Type Description Default labels_tablename str Name of table containing labels in the database required threshold_actual float Where the clerical_match_score provided by the user is a probability rather than binary, this value is used as the threshold to classify clerical_match_score s as binary matches or non matches. Defaults to 0.5. required match_weight_round_to_nearest float When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. required Examples: >>> # DuckDBLinker >>> labels = pd . read_csv ( \"my_labels.csv\" ) >>> linker . _con . register ( \"labels\" , labels ) >>> linker . precision_recall_chart_from_labels ( \"labels\" ) >>> >>> # SparkLinker >>> labels = spark . read . csv ( \"my_labels.csv\" , header = True ) >>> labels . createDataFrame ( \"labels\" ) >>> linker . precision_recall_chart_from_labels ( \"labels\" ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. Source code in splink/linker.py 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 def precision_recall_chart_from_labels ( self , labels_tablename ): \"\"\"Generate a precision-recall chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered as a table with your database: |source_dataset_l|unique_id_l|source_dataset_r|unique_id_r|clerical_match_score| |----------------|-----------|----------------|-----------|--------------------| |df_1 |1 |df_2 |2 |0.99 | |df_1 |1 |df_2 |3 |0.2 | Note that `source_dataset` and `unique_id` should correspond to the values specified in the settings dict, and the `input_table_aliases` passed to the `linker` object. For `dedupe_only` links, the `source_dataset` columns can be ommitted. Args: labels_tablename (str): Name of table containing labels in the database threshold_actual (float, optional): Where the `clerical_match_score` provided by the user is a probability rather than binary, this value is used as the threshold to classify `clerical_match_score`s as binary matches or non matches. Defaults to 0.5. match_weight_round_to_nearest (float, optional): When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. Examples: >>> # DuckDBLinker >>> labels = pd.read_csv(\"my_labels.csv\") >>> linker._con.register(\"labels\", labels) >>> linker.precision_recall_chart_from_labels(\"labels\") >>> >>> # SparkLinker >>> labels = spark.read.csv(\"my_labels.csv\", header=True) >>> labels.createDataFrame(\"labels\") >>> linker.precision_recall_chart_from_labels(\"labels\") Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" df_truth_space = roc_table ( self , labels_tablename ) recs = df_truth_space . as_record_dict () return precision_recall_chart ( recs )","title":"precision_recall_chart_from_labels()"},{"location":"linker.html#splink.linker.Linker.predict","text":"Create a dataframe of scored pairwise comparisons using the parameters of the linkage model. Uses the blocking rules specified in the blocking_rules_to_generate_predictions of the settings dictionary to generate the pairwise comparisons. Parameters: Name Type Description Default threshold_match_probability float If specified, filter the results to include only pairwise comparisons with a match_probability above this threshold. Defaults to None. None threshold_match_weight float If specified, filter the results to include only pairwise comparisons with a match_weight above this threshold. Defaults to None. None Examples: >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> df = linker . predict ( threshold_match_probability = 0.95 ) >>> df . as_pandas_dataframe ( limit = 5 ) Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. Source code in splink/linker.py 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 def predict ( self , threshold_match_probability : float = None , threshold_match_weight : float = None , ) -> SplinkDataFrame : \"\"\"Create a dataframe of scored pairwise comparisons using the parameters of the linkage model. Uses the blocking rules specified in the `blocking_rules_to_generate_predictions` of the settings dictionary to generate the pairwise comparisons. Args: threshold_match_probability (float, optional): If specified, filter the results to include only pairwise comparisons with a match_probability above this threshold. Defaults to None. threshold_match_weight (float, optional): If specified, filter the results to include only pairwise comparisons with a match_weight above this threshold. Defaults to None. Examples: >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.load_settings_from_json(\"saved_settings.json\") >>> df = linker.predict(threshold_match_probability=0.95) >>> df.as_pandas_dataframe(limit=5) Returns: SplinkDataFrame: A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. \"\"\" # If the user only calls predict, it runs as a single pipeline with no # materialisation of anything self . _initialise_df_concat_with_tf ( materialise = False ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) repartition_after_blocking = getattr ( self , \"repartition_after_blocking\" , False ) # repartition after blocking only exists on the SparkLinker if repartition_after_blocking : df_blocked = self . _execute_sql_pipeline () input_dataframes = [ df_blocked ] else : input_dataframes = [] sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj , threshold_match_probability , threshold_match_weight ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) predictions = self . _execute_sql_pipeline ( input_dataframes ) self . _predict_warning () return predictions","title":"predict()"},{"location":"linker.html#splink.linker.Linker.profile_columns","text":"Source code in splink/linker.py 1248 1249 1250 1251 1252 def profile_columns ( self , column_expressions : Union [ str , List [ str ]], top_n = 10 , bottom_n = 10 ): return profile_columns ( self , column_expressions , top_n = top_n , bottom_n = bottom_n )","title":"profile_columns()"},{"location":"linker.html#splink.linker.Linker.roc_chart_from_labels","text":"Generate a ROC chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered with your database: source_dataset_l unique_id_l source_dataset_r unique_id_r clerical_match_score df_1 1 df_2 2 0.99 df_1 1 df_2 3 0.2 Note that source_dataset and unique_id should correspond to the values specified in the settings dict, and the input_table_aliases passed to the linker object. For dedupe_only links, the source_dataset columns can be ommitted. Parameters: Name Type Description Default labels_tablename str Name of table containing labels in the database required threshold_actual float Where the clerical_match_score provided by the user is a probability rather than binary, this value is used as the threshold to classify clerical_match_score s as binary matches or non matches. Defaults to 0.5. 0.5 match_weight_round_to_nearest float When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. None Examples: >>> # DuckDBLinker >>> labels = pd . read_csv ( \"my_labels.csv\" ) >>> linker . _con . register ( \"labels\" , labels ) >>> linker . roc_chart_from_labels ( \"labels\" ) >>> >>> # SparkLinker >>> labels = spark . read . csv ( \"my_labels.csv\" , header = True ) >>> labels . createDataFrame ( \"labels\" ) >>> linker . roc_chart_from_labels ( \"labels\" ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. Source code in splink/linker.py 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 def roc_chart_from_labels ( self , labels_tablename , threshold_actual = 0.5 , match_weight_round_to_nearest : float = None , ): \"\"\"Generate a ROC chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered with your database: |source_dataset_l|unique_id_l|source_dataset_r|unique_id_r|clerical_match_score| |----------------|-----------|----------------|-----------|--------------------| |df_1 |1 |df_2 |2 |0.99 | |df_1 |1 |df_2 |3 |0.2 | Note that `source_dataset` and `unique_id` should correspond to the values specified in the settings dict, and the `input_table_aliases` passed to the `linker` object. For `dedupe_only` links, the `source_dataset` columns can be ommitted. Args: labels_tablename (str): Name of table containing labels in the database threshold_actual (float, optional): Where the `clerical_match_score` provided by the user is a probability rather than binary, this value is used as the threshold to classify `clerical_match_score`s as binary matches or non matches. Defaults to 0.5. match_weight_round_to_nearest (float, optional): When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. Examples: >>> # DuckDBLinker >>> labels = pd.read_csv(\"my_labels.csv\") >>> linker._con.register(\"labels\", labels) >>> linker.roc_chart_from_labels(\"labels\") >>> >>> # SparkLinker >>> labels = spark.read.csv(\"my_labels.csv\", header=True) >>> labels.createDataFrame(\"labels\") >>> linker.roc_chart_from_labels(\"labels\") Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" df_truth_space = roc_table ( self , labels_tablename , threshold_actual = threshold_actual , match_weight_round_to_nearest = match_weight_round_to_nearest , ) recs = df_truth_space . as_record_dict () return roc_chart ( recs )","title":"roc_chart_from_labels()"},{"location":"linker.html#splink.linker.Linker.roc_table_from_labels","text":"Generate truth statistics (false positive etc.) for each threshold value of match_probability, suitable for plotting a ROC chart. The table of labels should be in the following format, and should be registered with your database: source_dataset_l unique_id_l source_dataset_r unique_id_r clerical_match_score df_1 1 df_2 2 0.99 df_1 1 df_2 3 0.2 Note that source_dataset and unique_id should correspond to the values specified in the settings dict, and the input_table_aliases passed to the linker object. For dedupe_only links, the source_dataset columns can be ommitted. Parameters: Name Type Description Default labels_tablename str Name of table containing labels in the database required threshold_actual float Where the clerical_match_score provided by the user is a probability rather than binary, this value is used as the threshold to classify clerical_match_score s as binary matches or non matches. Defaults to 0.5. 0.5 match_weight_round_to_nearest float When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. None Examples: >>> # DuckDBLinker >>> labels = pd . read_csv ( \"my_labels.csv\" ) >>> linker . _con . register ( \"labels\" , labels ) >>> linker . roc_table_from_labels ( \"labels\" ) >>> >>> # SparkLinker >>> labels = spark . read . csv ( \"my_labels.csv\" , header = True ) >>> labels . createDataFrame ( \"labels\" ) >>> linker . roc_table_from_labels ( \"labels\" ) Returns: Name Type Description SplinkDataFrame SplinkDataFrame Table of truth statistics Source code in splink/linker.py 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 def roc_table_from_labels ( self , labels_tablename , threshold_actual = 0.5 , match_weight_round_to_nearest : float = None , ) -> SplinkDataFrame : \"\"\"Generate truth statistics (false positive etc.) for each threshold value of match_probability, suitable for plotting a ROC chart. The table of labels should be in the following format, and should be registered with your database: |source_dataset_l|unique_id_l|source_dataset_r|unique_id_r|clerical_match_score| |----------------|-----------|----------------|-----------|--------------------| |df_1 |1 |df_2 |2 |0.99 | |df_1 |1 |df_2 |3 |0.2 | Note that `source_dataset` and `unique_id` should correspond to the values specified in the settings dict, and the `input_table_aliases` passed to the `linker` object. For `dedupe_only` links, the `source_dataset` columns can be ommitted. Args: labels_tablename (str): Name of table containing labels in the database threshold_actual (float, optional): Where the `clerical_match_score` provided by the user is a probability rather than binary, this value is used as the threshold to classify `clerical_match_score`s as binary matches or non matches. Defaults to 0.5. match_weight_round_to_nearest (float, optional): When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. Examples: >>> # DuckDBLinker >>> labels = pd.read_csv(\"my_labels.csv\") >>> linker._con.register(\"labels\", labels) >>> linker.roc_table_from_labels(\"labels\") >>> >>> # SparkLinker >>> labels = spark.read.csv(\"my_labels.csv\", header=True) >>> labels.createDataFrame(\"labels\") >>> linker.roc_table_from_labels(\"labels\") Returns: SplinkDataFrame: Table of truth statistics \"\"\" return roc_table ( self , labels_tablename , threshold_actual = threshold_actual , match_weight_round_to_nearest = match_weight_round_to_nearest , )","title":"roc_table_from_labels()"},{"location":"linker.html#splink.linker.Linker.save_settings_to_json","text":"Save the configuration and parameters the linkage model to a .json file. The model can later be loaded back in using linker.load_settings_from_json() Examples: >>> linker . save_settings_to_json ( \"my_settings.json\" , overwrite = True ) Parameters: Name Type Description Default out_path str File path for json file required overwrite bool Overwrite if already exists? Defaults to False. False Source code in splink/linker.py 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 def save_settings_to_json ( self , out_path : str , overwrite = False ) -> dict : \"\"\"Save the configuration and parameters the linkage model to a `.json` file. The model can later be loaded back in using `linker.load_settings_from_json()` Examples: >>> linker.save_settings_to_json(\"my_settings.json\", overwrite=True) Args: out_path (str): File path for json file overwrite (bool, optional): Overwrite if already exists? Defaults to False. \"\"\" model_dict = self . _settings_obj . as_dict () if out_path : if os . path . isfile ( out_path ) and not overwrite : raise ValueError ( f \"The path { out_path } already exists. Please provide a different \" \"path or set overwrite=True\" ) with open ( out_path , \"w\" , encoding = \"utf-8\" ) as f : json . dump ( model_dict , f , indent = 4 )","title":"save_settings_to_json()"},{"location":"linker.html#splink.linker.Linker.unlinkables_chart","text":"Generate an interactive chart displaying the proportion of records that are \"unlinkable\" for a given splink score threshold and model parameters. Unlinkable records are those that, even when compared with themselves, do not contain enough information to confirm a match. Parameters: Name Type Description Default x_col str Column to use for the x-axis. Defaults to \"match_weight\". 'match_weight' source_dataset str Name of the source dataset to use for the title of the output chart. None as_dict bool If True, return a dict version of the chart. False Examples: >>> # For the simplest code pipeline, load a pre-trained model >>> # and run this against the test data. >>> df = pd . read_csv ( \"./tests/datasets/fake_1000_from_splink_demos.csv\" ) >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . unlinkables_chart () >>> >>> # For more complex code pipelines, you can run an entire pipeline >>> # that estimates your m and u values, before `unlinkables_chart(). Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. Source code in splink/linker.py 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 def unlinkables_chart ( self , x_col = \"match_weight\" , source_dataset = None , as_dict = False , ): \"\"\"Generate an interactive chart displaying the proportion of records that are \"unlinkable\" for a given splink score threshold and model parameters. Unlinkable records are those that, even when compared with themselves, do not contain enough information to confirm a match. Args: x_col (str, optional): Column to use for the x-axis. Defaults to \"match_weight\". source_dataset (str, optional): Name of the source dataset to use for the title of the output chart. as_dict (bool, optional): If True, return a dict version of the chart. Examples: >>> # For the simplest code pipeline, load a pre-trained model >>> # and run this against the test data. >>> df = pd.read_csv(\"./tests/datasets/fake_1000_from_splink_demos.csv\") >>> linker = DuckDBLinker(df) >>> linker.load_settings_from_json(\"saved_settings.json\") >>> linker.unlinkables_chart() >>> >>> # For more complex code pipelines, you can run an entire pipeline >>> # that estimates your m and u values, before `unlinkables_chart(). Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" # Link our initial df on itself and calculate the % of unlinkable entries records = unlinkables_data ( self , x_col ) return unlinkables_chart ( records , x_col , source_dataset )","title":"unlinkables_chart()"},{"location":"linker.html#splink.linker.Linker.waterfall_chart","text":"Visualise how the final match weight is computed for the provided pairwise record comparisons. Records must be provided as a list of dictionaries. This would usually be obtained from df.as_record_dict(limit=n) where df is a SplinkDataFrame. Examples: >>> df = linker . predict ( threshold_match_weight = 2 ) >>> records = df . as_record_dict ( limit = 10 ) >>> linker . waterfall_chart ( records ) Parameters: Name Type Description Default records List [ dict ] Usually be obtained from df.as_record_dict(limit=n) where df is a SplinkDataFrame. required filter_nulls bool Whether the visualiation shows null comparisons, which have no effect on final match weight. Defaults to True. True Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. Source code in splink/linker.py 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 def waterfall_chart ( self , records : List [ dict ], filter_nulls = True ): \"\"\"Visualise how the final match weight is computed for the provided pairwise record comparisons. Records must be provided as a list of dictionaries. This would usually be obtained from `df.as_record_dict(limit=n)` where `df` is a SplinkDataFrame. Examples: >>> df = linker.predict(threshold_match_weight=2) >>> records = df.as_record_dict(limit=10) >>> linker.waterfall_chart(records) Args: records (List[dict]): Usually be obtained from `df.as_record_dict(limit=n)` where `df` is a SplinkDataFrame. filter_nulls (bool, optional): Whether the visualiation shows null comparisons, which have no effect on final match weight. Defaults to True. Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" self . _raise_error_if_necessary_waterfall_columns_not_computed () return waterfall_chart ( records , self . _settings_obj , filter_nulls )","title":"waterfall_chart()"},{"location":"linkerest.html","tags":["API"],"text":"Documentation for Linker object methods related to parameter estimation \u00b6 The Linker object manages the data linkage process and holds the data linkage model. Most of Splink's functionality can be accessed by calling methods (functions) on the linker, such as linker.predict() , linker.profile_columns() etc. The Linker class is intended for subclassing for specific backends, e.g. a DuckDBLinker . __deepcopy__ ( memo ) \u00b6 When we do EM training, we need a copy of the linker which is independent of the main linker e.g. setting parameters on the copy will not affect the main linker. This method implements ensures linker can be deepcopied. __init__ ( input_table_or_tables , settings_dict = None , set_up_basic_logging = True , input_table_aliases = None ) \u00b6 Initialise the linker object, which manages the data linkage process and holds the data linkage model. Examples: >>> # Example 1: DuckDB >>> df = pd . read_csv ( \"data_to_dedupe.csv\" ) >>> linker = DuckDBLinker ( df , settings_dict ) >>> # Example 2: Spark >>> df_1 = spark . read . parquet ( \"table_1/\" ) >>> df_2 = spark . read . parquet ( \"table_2/\" ) >>> linker = SparkLinker ( >>> [ df_1 , df_2 ], >>> settings_dict , >>> input_table_aliases = [ \"customers\" , \"contact_center_callers\" ] >>> ) Parameters: Name Type Description Default input_table_or_tables Union [ str , list ] Input data into the linkage model. Either a single string (the name of a table in a database) for deduplication jobs, or a list of strings (the name of tables in a database) for link_only or link_and_dedupe. For some linkers, such as the DuckDBLinker and the SparkLinker, it's also possible to pass in dataframes (Pandas and Spark respectively) rather than strings. required settings_dict dict A Splink settings dictionary. If not provided when the object is created, can later be added using linker.initialise_settings() Defaults to None. None set_up_basic_logging bool If true, sets ups up basic logging so that Splink sends messages at INFO level to stdout. Defaults to True. True input_table_aliases Union [ str , list ] Labels assigned to input tables in Splink outputs. If the names of the tables in the input database are long or unspecific, this argument can be used to attach more easily readable/interpretable names. Defaults to None. None cluster_pairwise_predictions_at_threshold ( df_predict , threshold_match_probability ) \u00b6 Clusters the pairwise match predictions that result from linker.predict() into groups of connected record using the connected components graph clustering algorithm Records with an estimated match_probability above threshold_match_probability are considered to be a match (i.e. they represent the same entity). Parameters: Name Type Description Default df_predict SplinkDataFrame The results of linker.predict() required threshold_match_probability float Filter the pairwise match predictions to include only pairwise comparisons with a match_probability above this threshold. This dataframe is then fed into the clustering algorithm. required Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame containing a list of all IDs, clustered into groups based on the desired match threshold. cluster_studio_dashboard ( df_predict , df_clustered , out_path , sampling_method = 'random' , sample_size = 10 , cluster_ids = None , cluster_names = None , overwrite = False , return_html_as_string = False ) \u00b6 Generate an interactive html visualization of the predicted cluster and save to out_path . Parameters: Name Type Description Default df_predict SplinkDataFrame The outputs of linker.predict() required df_clustered SplinkDataFrame The outputs of linker.cluster_pairwise_predictions_at_threshold() required out_path str The path (including filename) to save the html file to. required sampling_method str random or by_cluster_size . Defaults to random . 'random' sample_size int Number of clusters to show in the dahboard. Defaults to 10. 10 cluster_ids list The IDs of the clusters that will be displayed in the dashboard. If provided, ignore the sampling_method and sample_size arguments. Defaults to None. None overwrite bool Overwrite the html file if it already exists? Defaults to False. False cluster_names list If provided, the dashboard will display these names in the selection box. Ony works in conjunction with cluster_ids . Defaults to None. None return_html_as_string If True, return the html as a string False Examples: >>> df_p = linker . predict () >>> df_c = linker . cluster_pairwise_predictions_at_threshold ( df_p , 0.5 ) >>> linker . cluster_studio_dashboard ( >>> df_p , df_c , [ 0 , 4 , 7 ], \"cluster_studio.html\" >>> ) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame ( src = \"./cluster_studio.html\" , width = \"100%\" , height = 1200 ) compare_two_records ( record_1 , record_2 ) \u00b6 Use the linkage model to compare and score a pairwise record comparison based on the two input records provided Parameters: Name Type Description Default record_1 dict dictionary representing the first record. Columns names and data types must be the same as the columns in the settings object required record_2 dict dictionary representing the second record. Columns names and data types must be the same as the columns in the settings object required Examples: >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . compare_two_records ( record_left , record_right ) Returns: Name Type Description SplinkDataFrame Pairwise comparison with scored prediction comparison_viewer_dashboard ( df_predict , out_path , overwrite = False , num_example_rows = 2 , return_html_as_string = False ) \u00b6 Generate an interactive html visualization of the linker's predictions and save to out_path . For more information see this video Parameters: Name Type Description Default df_predict SplinkDataFrame The outputs of linker.predict() required out_path str The path (including filename) to save the html file to. required overwrite bool Overwrite the html file if it already exists? Defaults to False. False num_example_rows int Number of example rows per comparison vector. Defaults to 2. 2 return_html_as_string If True, return the html as a string False Examples: >>> df_predictions = linker . predict () >>> linker . comparison_viewer_dashboard ( df_predictions , \"scv.html\" , True , 2 ) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame ( src = \"./scv.html\" , width = \"100%\" , height = 1200 ) completeness_chart ( input_dataset = None , cols = None ) \u00b6 Generate a summary chart of the completeness (proportion of non-nulls) of columns in each of the input datasets. By default, completeness is assessed for all column in the input data. Parameters: Name Type Description Default input_dataset str Name of one of the input tables in the database. If provided, completeness will be computed for this table alone. Defaults to None. None cols List [ str ] List of column names to calculate completeness. Default to None. None Examples: >>> linker . completeness_chart () >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . completeness_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500 compute_tf_table ( column_name ) \u00b6 Compute a term frequency table for a given column and persist to the database This method is useful if you want to pre-compute term frequency tables e.g. so that real time linkage executes faster, or so that you can estimate various models without having to recompute term frequency tables each time Examples: >>> # Example 1: Real time linkage >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . compute_tf_table ( \"surname\" ) >>> linker . compare_two_records ( record_left , record_right ) >>> # Example 2: Pre-computed term frequency tables in Spark >>> linker = SparkLinker ( df ) >>> df_first_name_tf = linker . compute_tf_table ( \"first_name\" ) >>> df_first_name_tf . write . parquet ( \"folder/first_name_tf\" ) >>> >>> # On subsequent data linking job, read this table rather than recompute >>> df_first_name_tf = spark . read . parquet ( \"folder/first_name_tf\" ) >>> df_first_name_tf . createOrReplaceTempView ( \"__splink__df_tf_first_name\" ) Parameters: Name Type Description Default column_name str The column name in the input table required Returns: Name Type Description SplinkDataFrame SplinkDataFrame The resultant table as a splink data frame count_num_comparisons_from_blocking_rule ( blocking_rule , link_type = None , unique_id_column_name = None ) \u00b6 Compute the number of pairwise record comparisons that would be generated by a blocking rule Parameters: Name Type Description Default blocking_rule str The blocking rule to analyse required link_type str The link type. This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None unique_id_column_name str This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None Examples: >>> br = \"l.first_name = r.first_name\" >>> linker . count_num_comparisons_from_blocking_rule ( br ) 19387 >>> br = \"l.name = r.name and substr(l.dob,1,4) = substr(r.dob,1,4)\" >>> linker . count_num_comparisons_from_blocking_rule ( br ) 394 Returns: Name Type Description int int The number of comparisons generated by the blocking rule count_num_comparisons_from_blocking_rules_for_prediction ( df_predict ) \u00b6 Counts the maginal number of edges created from each of the blocking rules in blocking_rules_to_generate_predictions This is different to count_num_comparisons_from_blocking_rule because it (a) analyses multiple blocking rules rather than a single rule, and (b) deduplicates any comparisons that are generated, to tell you the marginal effect of each entry in blocking_rules_to_generate_predictions Parameters: Name Type Description Default df_predict SplinkDataFrame SplinkDataFrame with match weights required Examples: >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> df_predict = linker . predict ( threshold_match_probability = 0.95 ) >>> count_pairwise = linker . count_num_comparisons_from_blocking_rules_for_prediction ( df_predict ) >>> count_pairwise . as_pandas_dataframe ( limit = 5 ) Returns: Name Type Description SplinkDataFrame A SplinkDataFrame of the pairwise comparisons and estimated pairwise comparisons generated by the blocking rules. cumulative_num_comparisons_from_blocking_rules_chart ( blocking_rules = None , link_type = None , unique_id_column_name = None ) \u00b6 Display a chart with the cumulative number of comparisons generated by a selection of blocking rules. This is equivalent to the output size of df_predict and details how many comparisons each of your individual blocking rules will contribute to the total. Parameters: Name Type Description Default blocking_rules str or list The blocking rule(s) to compute comparisons for. If null, the rules set out in your settings object will be used. None link_type str The link type. This defaults to the link type outlined in your settings object. None unique_id_column_name str This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None Examples: >>> linker_settings = DuckDBLinker ( df , settings ) >>> # Compute the cumulative number of comparisons generated by the rules >>> # in your settings object. >>> linker_settings . cumulative_num_comparisons_from_blocking_rules_chart () >>> >>> # Generate total comparisons with custom blocking rules. >>> blocking_rules = [ >>> \"l.surname = r.surname\" , >>> \"l.first_name = r.first_name >>> and substr ( l . dob , 1 , 4 ) = substr ( r . dob , 1 , 4 ) \" >>> ] >>> >>> linker . cumulative_num_comparisons_from_blocking_rules_chart ( >>> blocking_rules >>> ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. deterministic_link () \u00b6 Uses the blocking rules specified by blocking_rules_to_generate_predictions in the settings dictionary to generate pairwise record comparisons. For deterministic linkage, this should be a list of blocking rules which are strict enough to generate only true links. Deterministic linkage, however, is likely to result in missed links (false negatives). Examples: >>> linker = DuckDBLinker ( df ) >>> >>> settings = { >>> \"link_type\" : \"dedupe_only\" , >>> \"blocking_rules_to_generate_predictions\" : [ >>> \"l.first_name = r.first_name\" , >>> \"l.surname = r.surname\" , >>> ], >>> \"comparisons\" : [] >>> } >>> >>> from splink.duckdb.duckdb_linker import DuckDBLinker >>> >>> linker = DuckDBLinker ( df , settings ) >>> df = linker . deterministic_link () Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. estimate_m_from_label_column ( label_colname ) \u00b6 Estimate the m parameters of the linkage model from a label (ground truth) column in the input dataframe(s). The m parameters represent the proportion of record comparisons that fall into each comparison level amongst truly matching records. The ground truth column is used to generate pairwise record comparisons which are then assumed to be matches. For example, if the entity being matched is persons, and your input dataset(s) contain social security number, this could be used to estimate the m values for the model. Note that this column does not need to be fully populated. A common case is where a unique identifier such as social security number is only partially populated. Parameters: Name Type Description Default label_colname str The name of the column containing the ground truth label in the input data. required Examples: >>> linker . estimate_m_from_label_column ( \"social_security_number\" ) Returns: Type Description Updates the estimated m parameters within the linker object and returns nothing. estimate_parameters_using_expectation_maximisation ( blocking_rule , comparisons_to_deactivate = None , comparison_levels_to_reverse_blocking_rule = None , fix_probability_two_random_records_match = False , fix_m_probabilities = False , fix_u_probabilities = True ) \u00b6 Estimate the parameters of the linkage model using expectation maximisation. By default, the m probabilities are estimated, but not the u probabilities, because good estiamtes for the u probabilities can be obtained from linker.estimate_u_using_random_sampling() . You can change this by setting fix_u_probabilities to False. The blocking rule provided is used to generate pairwise record comparisons. Usually, this should be a blocking rule that results in a dataframe where matches are between about 1% and 99% of the comparisons. By default, m parameters are estimated for all comparisons except those which are included in the blocking rule. For example, if the blocking rule is l.first_name = r.first_name , then parameter esimates will be made for all comparison except those which use first_name in their sql_condition By default, the probability two random records match is estimated for the blocked data, and then the m and u parameters for the columns specified in the blocking rules are used to estiamte the global probability two random records match. To control which comparisons should have their parameter estimated, and the process of 'reversing out' the global probability two random records match, the user may specify comparisons_to_deactivate and comparison_levels_to_reverse_blocking_rule . This is useful, for example if you block on the dmetaphone of a column but match on the original column. Examples: >>> # Default behaviour >>> br_training = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker . estimate_parameters_using_expectation_maximisation ( br_training ) >>> # Specify which comparisons to deactivate >>> br_training = \"l.dmeta_first_name = r.dmeta_first_name\" >>> settings_obj = linker . _settings_obj >>> comp = settings_obj . _get_comparison_by_output_column_name ( \"first_name\" ) >>> dmeta_level = comp . _get_comparison_level_by_comparison_vector_value ( 1 ) >>> linker . estimate_parameters_using_expectation_maximisation ( >>> br_training , >>> comparisons_to_deactivate = [ \"first_name\" ], >>> comparison_levels_to_reverse_blocking_rule = [ dmeta_level ], >>> ) Parameters: Name Type Description Default blocking_rule str The blocking rule used to generate pairwise record comparisons. required comparisons_to_deactivate list By default, splink will analyse the blocking rule provided and estimate the m parameters for all comaprisons except those included in the blocking rule. If comparisons_to_deactivate are provided, spink will instead estimate m parameters for all comparison except those specified in the comparisons_to_deactivate list. This list can either contain the output_column_name of the Comparison as a string, or Comparison objects. Defaults to None. None comparison_levels_to_reverse_blocking_rule list By default, splink will analyse the blocking rule provided and adjust the global probability two random records match to account for the matches specified in the blocking rule. If provided, this argument will overrule this default behaviour. The user must provide a list of ComparisonLevel objects. Defaults to None. None fix_probability_two_random_records_match bool If True, do not update the probability two random records match after each iteration. Defaults to False. False fix_m_probabilities bool If True, do not update the m probabilities after each iteration. Defaults to False. False fix_u_probabilities bool If True, do not update the u probabilities after each iteration. Defaults to True. True Examples: >>> blocking_rule = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker . estimate_parameters_using_expectation_maximisation ( blocking_rule ) Returns: Name Type Description EMTrainingSession EMTrainingSession An object containing information about the training session such as how parameters changed during the iteration history estimate_u_using_random_sampling ( target_rows ) \u00b6 Estimate the u parameters of the linkage model using random sampling. The u parameters represent the proportion of record comparisons that fall into each comparison level amongst truly non-matching records. This procedure takes a sample of the data and generates the cartesian product of pairwise record comparisons amongst the sampled records. The validity of the u values rests on the assumption that the resultant pairwise comparisons are non-matches (or at least, they are very unlikely to be matches). For large datasets, this is typically true. Parameters: Name Type Description Default target_rows int The target number of pairwise record comparisons from required Examples: >>> linker . estimate_u_using_random_sampling ( 1e8 ) Returns: Name Type Description None Updates the estimated u parameters within the linker object and returns nothing. find_matches_to_new_records ( records_or_tablename , blocking_rules = [], match_weight_threshold =- 4 ) \u00b6 Given one or more records, find records in the input dataset(s) which match and return in order of the splink prediction score. This effectively provides a way of searching the input datasets for given record(s) Parameters: Name Type Description Default records_or_tablename List [ dict ] Input search record(s) as list of dict, or a table registered to the database. required blocking_rules list Blocking rules to select which records to find and score. If [], do not use a blocking rule - meaning the input records will be compared to all records provided to the linker when it was instantiated. Defaults to []. [] match_weight_threshold int Return matches with a match weight above this threshold. Defaults to -4. -4 Examples: >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> # Pre-compute tf tables for any tables with >>> # term frequency adjustments >>> linker . compute_tf_table ( \"first_name\" ) >>> record = { 'unique_id' : 1 , >>> 'first_name' : \"John\" , >>> 'surname' : \"Smith\" , >>> 'dob' : \"1971-05-24\" , >>> 'city' : \"London\" , >>> 'email' : \"john@smith.net\" >>> } >>> df = linker . find_matches_to_new_records ([ record ], blocking_rules = []) Returns: Name Type Description SplinkDataFrame SplinkDataFrame The pairwise comparisons. initialise_settings ( settings_dict ) \u00b6 Initialise settings for the linker. To be used if settings were not passed to the linker on creation. Examples: >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . profile_columns ([ \"first_name\" , \"surname\" ]) >>> linker . initialise_settings ( settings_dict ) Parameters: Name Type Description Default settings_dict dict A Splink settings dictionary required load_settings_from_json ( in_path ) \u00b6 Load settings from a .json file. This .json file would usually be the output of linker.save_settings_to_json() Examples: >>> linker . load_settings_from_json ( \"my_settings.json\" ) Parameters: Name Type Description Default in_path str Path to settings json file required m_u_parameters_chart () \u00b6 Display a chart of the m and u parameters of the linkage model Examples: >>> linker . m_u_parameters_chart () >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . match_weights_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500 ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. match_weights_chart () \u00b6 Display a chart of the (partial) match weights of the linkage model Examples: >>> linker . match_weights_chart () >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . match_weights_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500 ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. match_weights_histogram ( df_predict , target_bins = 30 , width = 600 , height = 250 ) \u00b6 Generate a histogram that shows the distribution of match weights in df_predict Parameters: Name Type Description Default df_predict SplinkDataFrame Output of linker.predict() required target_bins int Target number of bins in histogram. Defaults to 30. 30 width int Width of output. Defaults to 600. 600 height int Height of output chart. Defaults to 250. 250 Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. missingness_chart ( input_dataset = None ) \u00b6 Generate a summary chart of the missingness (prevalence of nulls) of columns in the input datasets. By default, missingness is assessed across all input datasets Parameters: Name Type Description Default input_dataset str Name of one of the input tables in the None Examples: >>> linker . missingness_chart () >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . missingness_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500 parameter_estimate_comparisons_chart ( include_m = True , include_u = True ) \u00b6 Show a chart that shows how parameter estimates have differed across the different estimation methods you have used. For example, if you have run two EM estimation sessions, blocking on different variables, and both result in parameter estimates for first_name, this chart will enable easy comparison of the different estimates Parameters: Name Type Description Default include_m bool Show different estimates of m values. Defaults to True. True include_u bool Show different estimates of u values. Defaults to True. True precision_recall_chart_from_labels ( labels_tablename ) \u00b6 Generate a precision-recall chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered as a table with your database: source_dataset_l unique_id_l source_dataset_r unique_id_r clerical_match_score df_1 1 df_2 2 0.99 df_1 1 df_2 3 0.2 Note that source_dataset and unique_id should correspond to the values specified in the settings dict, and the input_table_aliases passed to the linker object. For dedupe_only links, the source_dataset columns can be ommitted. Parameters: Name Type Description Default labels_tablename str Name of table containing labels in the database required threshold_actual float Where the clerical_match_score provided by the user is a probability rather than binary, this value is used as the threshold to classify clerical_match_score s as binary matches or non matches. Defaults to 0.5. required match_weight_round_to_nearest float When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. required Examples: >>> # DuckDBLinker >>> labels = pd . read_csv ( \"my_labels.csv\" ) >>> linker . _con . register ( \"labels\" , labels ) >>> linker . precision_recall_chart_from_labels ( \"labels\" ) >>> >>> # SparkLinker >>> labels = spark . read . csv ( \"my_labels.csv\" , header = True ) >>> labels . createDataFrame ( \"labels\" ) >>> linker . precision_recall_chart_from_labels ( \"labels\" ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. predict ( threshold_match_probability = None , threshold_match_weight = None ) \u00b6 Create a dataframe of scored pairwise comparisons using the parameters of the linkage model. Uses the blocking rules specified in the blocking_rules_to_generate_predictions of the settings dictionary to generate the pairwise comparisons. Parameters: Name Type Description Default threshold_match_probability float If specified, filter the results to include only pairwise comparisons with a match_probability above this threshold. Defaults to None. None threshold_match_weight float If specified, filter the results to include only pairwise comparisons with a match_weight above this threshold. Defaults to None. None Examples: >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> df = linker . predict ( threshold_match_probability = 0.95 ) >>> df . as_pandas_dataframe ( limit = 5 ) Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. roc_chart_from_labels ( labels_tablename , threshold_actual = 0.5 , match_weight_round_to_nearest = None ) \u00b6 Generate a ROC chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered with your database: source_dataset_l unique_id_l source_dataset_r unique_id_r clerical_match_score df_1 1 df_2 2 0.99 df_1 1 df_2 3 0.2 Note that source_dataset and unique_id should correspond to the values specified in the settings dict, and the input_table_aliases passed to the linker object. For dedupe_only links, the source_dataset columns can be ommitted. Parameters: Name Type Description Default labels_tablename str Name of table containing labels in the database required threshold_actual float Where the clerical_match_score provided by the user is a probability rather than binary, this value is used as the threshold to classify clerical_match_score s as binary matches or non matches. Defaults to 0.5. 0.5 match_weight_round_to_nearest float When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. None Examples: >>> # DuckDBLinker >>> labels = pd . read_csv ( \"my_labels.csv\" ) >>> linker . _con . register ( \"labels\" , labels ) >>> linker . roc_chart_from_labels ( \"labels\" ) >>> >>> # SparkLinker >>> labels = spark . read . csv ( \"my_labels.csv\" , header = True ) >>> labels . createDataFrame ( \"labels\" ) >>> linker . roc_chart_from_labels ( \"labels\" ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. roc_table_from_labels ( labels_tablename , threshold_actual = 0.5 , match_weight_round_to_nearest = None ) \u00b6 Generate truth statistics (false positive etc.) for each threshold value of match_probability, suitable for plotting a ROC chart. The table of labels should be in the following format, and should be registered with your database: source_dataset_l unique_id_l source_dataset_r unique_id_r clerical_match_score df_1 1 df_2 2 0.99 df_1 1 df_2 3 0.2 Note that source_dataset and unique_id should correspond to the values specified in the settings dict, and the input_table_aliases passed to the linker object. For dedupe_only links, the source_dataset columns can be ommitted. Parameters: Name Type Description Default labels_tablename str Name of table containing labels in the database required threshold_actual float Where the clerical_match_score provided by the user is a probability rather than binary, this value is used as the threshold to classify clerical_match_score s as binary matches or non matches. Defaults to 0.5. 0.5 match_weight_round_to_nearest float When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. None Examples: >>> # DuckDBLinker >>> labels = pd . read_csv ( \"my_labels.csv\" ) >>> linker . _con . register ( \"labels\" , labels ) >>> linker . roc_table_from_labels ( \"labels\" ) >>> >>> # SparkLinker >>> labels = spark . read . csv ( \"my_labels.csv\" , header = True ) >>> labels . createDataFrame ( \"labels\" ) >>> linker . roc_table_from_labels ( \"labels\" ) Returns: Name Type Description SplinkDataFrame SplinkDataFrame Table of truth statistics save_settings_to_json ( out_path , overwrite = False ) \u00b6 Save the configuration and parameters the linkage model to a .json file. The model can later be loaded back in using linker.load_settings_from_json() Examples: >>> linker . save_settings_to_json ( \"my_settings.json\" , overwrite = True ) Parameters: Name Type Description Default out_path str File path for json file required overwrite bool Overwrite if already exists? Defaults to False. False unlinkables_chart ( x_col = 'match_weight' , source_dataset = None , as_dict = False ) \u00b6 Generate an interactive chart displaying the proportion of records that are \"unlinkable\" for a given splink score threshold and model parameters. Unlinkable records are those that, even when compared with themselves, do not contain enough information to confirm a match. Parameters: Name Type Description Default x_col str Column to use for the x-axis. Defaults to \"match_weight\". 'match_weight' source_dataset str Name of the source dataset to use for the title of the output chart. None as_dict bool If True, return a dict version of the chart. False Examples: >>> # For the simplest code pipeline, load a pre-trained model >>> # and run this against the test data. >>> df = pd . read_csv ( \"./tests/datasets/fake_1000_from_splink_demos.csv\" ) >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . unlinkables_chart () >>> >>> # For more complex code pipelines, you can run an entire pipeline >>> # that estimates your m and u values, before `unlinkables_chart(). Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. waterfall_chart ( records , filter_nulls = True ) \u00b6 Visualise how the final match weight is computed for the provided pairwise record comparisons. Records must be provided as a list of dictionaries. This would usually be obtained from df.as_record_dict(limit=n) where df is a SplinkDataFrame. Examples: >>> df = linker . predict ( threshold_match_weight = 2 ) >>> records = df . as_record_dict ( limit = 10 ) >>> linker . waterfall_chart ( records ) Parameters: Name Type Description Default records List [ dict ] Usually be obtained from df.as_record_dict(limit=n) where df is a SplinkDataFrame. required filter_nulls bool Whether the visualiation shows null comparisons, which have no effect on final match weight. Defaults to True. True Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. handler: python selection: members: - estimate_m_from_label_column - estimate_parameters_using_expectation_maximisation - estimate_u_using_random_sampling - save_settings_to_json - estimate_m_from_pairwise_labels rendering: show_root_heading: false show_source: true","title":"Estimating model parameters"},{"location":"linkerest.html#documentation-for-linker-object-methods-related-to-parameter-estimation","text":"The Linker object manages the data linkage process and holds the data linkage model. Most of Splink's functionality can be accessed by calling methods (functions) on the linker, such as linker.predict() , linker.profile_columns() etc. The Linker class is intended for subclassing for specific backends, e.g. a DuckDBLinker .","title":"Documentation for Linker object methods related to parameter estimation"},{"location":"linkerest.html#splink.linker.Linker.__deepcopy__","text":"When we do EM training, we need a copy of the linker which is independent of the main linker e.g. setting parameters on the copy will not affect the main linker. This method implements ensures linker can be deepcopied.","title":"__deepcopy__()"},{"location":"linkerest.html#splink.linker.Linker.__init__","text":"Initialise the linker object, which manages the data linkage process and holds the data linkage model. Examples: >>> # Example 1: DuckDB >>> df = pd . read_csv ( \"data_to_dedupe.csv\" ) >>> linker = DuckDBLinker ( df , settings_dict ) >>> # Example 2: Spark >>> df_1 = spark . read . parquet ( \"table_1/\" ) >>> df_2 = spark . read . parquet ( \"table_2/\" ) >>> linker = SparkLinker ( >>> [ df_1 , df_2 ], >>> settings_dict , >>> input_table_aliases = [ \"customers\" , \"contact_center_callers\" ] >>> ) Parameters: Name Type Description Default input_table_or_tables Union [ str , list ] Input data into the linkage model. Either a single string (the name of a table in a database) for deduplication jobs, or a list of strings (the name of tables in a database) for link_only or link_and_dedupe. For some linkers, such as the DuckDBLinker and the SparkLinker, it's also possible to pass in dataframes (Pandas and Spark respectively) rather than strings. required settings_dict dict A Splink settings dictionary. If not provided when the object is created, can later be added using linker.initialise_settings() Defaults to None. None set_up_basic_logging bool If true, sets ups up basic logging so that Splink sends messages at INFO level to stdout. Defaults to True. True input_table_aliases Union [ str , list ] Labels assigned to input tables in Splink outputs. If the names of the tables in the input database are long or unspecific, this argument can be used to attach more easily readable/interpretable names. Defaults to None. None","title":"__init__()"},{"location":"linkerest.html#splink.linker.Linker.cluster_pairwise_predictions_at_threshold","text":"Clusters the pairwise match predictions that result from linker.predict() into groups of connected record using the connected components graph clustering algorithm Records with an estimated match_probability above threshold_match_probability are considered to be a match (i.e. they represent the same entity). Parameters: Name Type Description Default df_predict SplinkDataFrame The results of linker.predict() required threshold_match_probability float Filter the pairwise match predictions to include only pairwise comparisons with a match_probability above this threshold. This dataframe is then fed into the clustering algorithm. required Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame containing a list of all IDs, clustered into groups based on the desired match threshold.","title":"cluster_pairwise_predictions_at_threshold()"},{"location":"linkerest.html#splink.linker.Linker.cluster_studio_dashboard","text":"Generate an interactive html visualization of the predicted cluster and save to out_path . Parameters: Name Type Description Default df_predict SplinkDataFrame The outputs of linker.predict() required df_clustered SplinkDataFrame The outputs of linker.cluster_pairwise_predictions_at_threshold() required out_path str The path (including filename) to save the html file to. required sampling_method str random or by_cluster_size . Defaults to random . 'random' sample_size int Number of clusters to show in the dahboard. Defaults to 10. 10 cluster_ids list The IDs of the clusters that will be displayed in the dashboard. If provided, ignore the sampling_method and sample_size arguments. Defaults to None. None overwrite bool Overwrite the html file if it already exists? Defaults to False. False cluster_names list If provided, the dashboard will display these names in the selection box. Ony works in conjunction with cluster_ids . Defaults to None. None return_html_as_string If True, return the html as a string False Examples: >>> df_p = linker . predict () >>> df_c = linker . cluster_pairwise_predictions_at_threshold ( df_p , 0.5 ) >>> linker . cluster_studio_dashboard ( >>> df_p , df_c , [ 0 , 4 , 7 ], \"cluster_studio.html\" >>> ) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame ( src = \"./cluster_studio.html\" , width = \"100%\" , height = 1200 )","title":"cluster_studio_dashboard()"},{"location":"linkerest.html#splink.linker.Linker.compare_two_records","text":"Use the linkage model to compare and score a pairwise record comparison based on the two input records provided Parameters: Name Type Description Default record_1 dict dictionary representing the first record. Columns names and data types must be the same as the columns in the settings object required record_2 dict dictionary representing the second record. Columns names and data types must be the same as the columns in the settings object required Examples: >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . compare_two_records ( record_left , record_right ) Returns: Name Type Description SplinkDataFrame Pairwise comparison with scored prediction","title":"compare_two_records()"},{"location":"linkerest.html#splink.linker.Linker.comparison_viewer_dashboard","text":"Generate an interactive html visualization of the linker's predictions and save to out_path . For more information see this video Parameters: Name Type Description Default df_predict SplinkDataFrame The outputs of linker.predict() required out_path str The path (including filename) to save the html file to. required overwrite bool Overwrite the html file if it already exists? Defaults to False. False num_example_rows int Number of example rows per comparison vector. Defaults to 2. 2 return_html_as_string If True, return the html as a string False Examples: >>> df_predictions = linker . predict () >>> linker . comparison_viewer_dashboard ( df_predictions , \"scv.html\" , True , 2 ) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame ( src = \"./scv.html\" , width = \"100%\" , height = 1200 )","title":"comparison_viewer_dashboard()"},{"location":"linkerest.html#splink.linker.Linker.completeness_chart","text":"Generate a summary chart of the completeness (proportion of non-nulls) of columns in each of the input datasets. By default, completeness is assessed for all column in the input data. Parameters: Name Type Description Default input_dataset str Name of one of the input tables in the database. If provided, completeness will be computed for this table alone. Defaults to None. None cols List [ str ] List of column names to calculate completeness. Default to None. None Examples: >>> linker . completeness_chart () >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . completeness_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500","title":"completeness_chart()"},{"location":"linkerest.html#splink.linker.Linker.compute_tf_table","text":"Compute a term frequency table for a given column and persist to the database This method is useful if you want to pre-compute term frequency tables e.g. so that real time linkage executes faster, or so that you can estimate various models without having to recompute term frequency tables each time Examples: >>> # Example 1: Real time linkage >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . compute_tf_table ( \"surname\" ) >>> linker . compare_two_records ( record_left , record_right ) >>> # Example 2: Pre-computed term frequency tables in Spark >>> linker = SparkLinker ( df ) >>> df_first_name_tf = linker . compute_tf_table ( \"first_name\" ) >>> df_first_name_tf . write . parquet ( \"folder/first_name_tf\" ) >>> >>> # On subsequent data linking job, read this table rather than recompute >>> df_first_name_tf = spark . read . parquet ( \"folder/first_name_tf\" ) >>> df_first_name_tf . createOrReplaceTempView ( \"__splink__df_tf_first_name\" ) Parameters: Name Type Description Default column_name str The column name in the input table required Returns: Name Type Description SplinkDataFrame SplinkDataFrame The resultant table as a splink data frame","title":"compute_tf_table()"},{"location":"linkerest.html#splink.linker.Linker.count_num_comparisons_from_blocking_rule","text":"Compute the number of pairwise record comparisons that would be generated by a blocking rule Parameters: Name Type Description Default blocking_rule str The blocking rule to analyse required link_type str The link type. This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None unique_id_column_name str This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None Examples: >>> br = \"l.first_name = r.first_name\" >>> linker . count_num_comparisons_from_blocking_rule ( br ) 19387 >>> br = \"l.name = r.name and substr(l.dob,1,4) = substr(r.dob,1,4)\" >>> linker . count_num_comparisons_from_blocking_rule ( br ) 394 Returns: Name Type Description int int The number of comparisons generated by the blocking rule","title":"count_num_comparisons_from_blocking_rule()"},{"location":"linkerest.html#splink.linker.Linker.count_num_comparisons_from_blocking_rules_for_prediction","text":"Counts the maginal number of edges created from each of the blocking rules in blocking_rules_to_generate_predictions This is different to count_num_comparisons_from_blocking_rule because it (a) analyses multiple blocking rules rather than a single rule, and (b) deduplicates any comparisons that are generated, to tell you the marginal effect of each entry in blocking_rules_to_generate_predictions Parameters: Name Type Description Default df_predict SplinkDataFrame SplinkDataFrame with match weights required Examples: >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> df_predict = linker . predict ( threshold_match_probability = 0.95 ) >>> count_pairwise = linker . count_num_comparisons_from_blocking_rules_for_prediction ( df_predict ) >>> count_pairwise . as_pandas_dataframe ( limit = 5 ) Returns: Name Type Description SplinkDataFrame A SplinkDataFrame of the pairwise comparisons and estimated pairwise comparisons generated by the blocking rules.","title":"count_num_comparisons_from_blocking_rules_for_prediction()"},{"location":"linkerest.html#splink.linker.Linker.cumulative_num_comparisons_from_blocking_rules_chart","text":"Display a chart with the cumulative number of comparisons generated by a selection of blocking rules. This is equivalent to the output size of df_predict and details how many comparisons each of your individual blocking rules will contribute to the total. Parameters: Name Type Description Default blocking_rules str or list The blocking rule(s) to compute comparisons for. If null, the rules set out in your settings object will be used. None link_type str The link type. This defaults to the link type outlined in your settings object. None unique_id_column_name str This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None Examples: >>> linker_settings = DuckDBLinker ( df , settings ) >>> # Compute the cumulative number of comparisons generated by the rules >>> # in your settings object. >>> linker_settings . cumulative_num_comparisons_from_blocking_rules_chart () >>> >>> # Generate total comparisons with custom blocking rules. >>> blocking_rules = [ >>> \"l.surname = r.surname\" , >>> \"l.first_name = r.first_name >>> and substr ( l . dob , 1 , 4 ) = substr ( r . dob , 1 , 4 ) \" >>> ] >>> >>> linker . cumulative_num_comparisons_from_blocking_rules_chart ( >>> blocking_rules >>> ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute.","title":"cumulative_num_comparisons_from_blocking_rules_chart()"},{"location":"linkerest.html#splink.linker.Linker.deterministic_link","text":"Uses the blocking rules specified by blocking_rules_to_generate_predictions in the settings dictionary to generate pairwise record comparisons. For deterministic linkage, this should be a list of blocking rules which are strict enough to generate only true links. Deterministic linkage, however, is likely to result in missed links (false negatives). Examples: >>> linker = DuckDBLinker ( df ) >>> >>> settings = { >>> \"link_type\" : \"dedupe_only\" , >>> \"blocking_rules_to_generate_predictions\" : [ >>> \"l.first_name = r.first_name\" , >>> \"l.surname = r.surname\" , >>> ], >>> \"comparisons\" : [] >>> } >>> >>> from splink.duckdb.duckdb_linker import DuckDBLinker >>> >>> linker = DuckDBLinker ( df , settings ) >>> df = linker . deterministic_link () Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data.","title":"deterministic_link()"},{"location":"linkerest.html#splink.linker.Linker.estimate_m_from_label_column","text":"Estimate the m parameters of the linkage model from a label (ground truth) column in the input dataframe(s). The m parameters represent the proportion of record comparisons that fall into each comparison level amongst truly matching records. The ground truth column is used to generate pairwise record comparisons which are then assumed to be matches. For example, if the entity being matched is persons, and your input dataset(s) contain social security number, this could be used to estimate the m values for the model. Note that this column does not need to be fully populated. A common case is where a unique identifier such as social security number is only partially populated. Parameters: Name Type Description Default label_colname str The name of the column containing the ground truth label in the input data. required Examples: >>> linker . estimate_m_from_label_column ( \"social_security_number\" ) Returns: Type Description Updates the estimated m parameters within the linker object and returns nothing.","title":"estimate_m_from_label_column()"},{"location":"linkerest.html#splink.linker.Linker.estimate_parameters_using_expectation_maximisation","text":"Estimate the parameters of the linkage model using expectation maximisation. By default, the m probabilities are estimated, but not the u probabilities, because good estiamtes for the u probabilities can be obtained from linker.estimate_u_using_random_sampling() . You can change this by setting fix_u_probabilities to False. The blocking rule provided is used to generate pairwise record comparisons. Usually, this should be a blocking rule that results in a dataframe where matches are between about 1% and 99% of the comparisons. By default, m parameters are estimated for all comparisons except those which are included in the blocking rule. For example, if the blocking rule is l.first_name = r.first_name , then parameter esimates will be made for all comparison except those which use first_name in their sql_condition By default, the probability two random records match is estimated for the blocked data, and then the m and u parameters for the columns specified in the blocking rules are used to estiamte the global probability two random records match. To control which comparisons should have their parameter estimated, and the process of 'reversing out' the global probability two random records match, the user may specify comparisons_to_deactivate and comparison_levels_to_reverse_blocking_rule . This is useful, for example if you block on the dmetaphone of a column but match on the original column. Examples: >>> # Default behaviour >>> br_training = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker . estimate_parameters_using_expectation_maximisation ( br_training ) >>> # Specify which comparisons to deactivate >>> br_training = \"l.dmeta_first_name = r.dmeta_first_name\" >>> settings_obj = linker . _settings_obj >>> comp = settings_obj . _get_comparison_by_output_column_name ( \"first_name\" ) >>> dmeta_level = comp . _get_comparison_level_by_comparison_vector_value ( 1 ) >>> linker . estimate_parameters_using_expectation_maximisation ( >>> br_training , >>> comparisons_to_deactivate = [ \"first_name\" ], >>> comparison_levels_to_reverse_blocking_rule = [ dmeta_level ], >>> ) Parameters: Name Type Description Default blocking_rule str The blocking rule used to generate pairwise record comparisons. required comparisons_to_deactivate list By default, splink will analyse the blocking rule provided and estimate the m parameters for all comaprisons except those included in the blocking rule. If comparisons_to_deactivate are provided, spink will instead estimate m parameters for all comparison except those specified in the comparisons_to_deactivate list. This list can either contain the output_column_name of the Comparison as a string, or Comparison objects. Defaults to None. None comparison_levels_to_reverse_blocking_rule list By default, splink will analyse the blocking rule provided and adjust the global probability two random records match to account for the matches specified in the blocking rule. If provided, this argument will overrule this default behaviour. The user must provide a list of ComparisonLevel objects. Defaults to None. None fix_probability_two_random_records_match bool If True, do not update the probability two random records match after each iteration. Defaults to False. False fix_m_probabilities bool If True, do not update the m probabilities after each iteration. Defaults to False. False fix_u_probabilities bool If True, do not update the u probabilities after each iteration. Defaults to True. True Examples: >>> blocking_rule = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker . estimate_parameters_using_expectation_maximisation ( blocking_rule ) Returns: Name Type Description EMTrainingSession EMTrainingSession An object containing information about the training session such as how parameters changed during the iteration history","title":"estimate_parameters_using_expectation_maximisation()"},{"location":"linkerest.html#splink.linker.Linker.estimate_u_using_random_sampling","text":"Estimate the u parameters of the linkage model using random sampling. The u parameters represent the proportion of record comparisons that fall into each comparison level amongst truly non-matching records. This procedure takes a sample of the data and generates the cartesian product of pairwise record comparisons amongst the sampled records. The validity of the u values rests on the assumption that the resultant pairwise comparisons are non-matches (or at least, they are very unlikely to be matches). For large datasets, this is typically true. Parameters: Name Type Description Default target_rows int The target number of pairwise record comparisons from required Examples: >>> linker . estimate_u_using_random_sampling ( 1e8 ) Returns: Name Type Description None Updates the estimated u parameters within the linker object and returns nothing.","title":"estimate_u_using_random_sampling()"},{"location":"linkerest.html#splink.linker.Linker.find_matches_to_new_records","text":"Given one or more records, find records in the input dataset(s) which match and return in order of the splink prediction score. This effectively provides a way of searching the input datasets for given record(s) Parameters: Name Type Description Default records_or_tablename List [ dict ] Input search record(s) as list of dict, or a table registered to the database. required blocking_rules list Blocking rules to select which records to find and score. If [], do not use a blocking rule - meaning the input records will be compared to all records provided to the linker when it was instantiated. Defaults to []. [] match_weight_threshold int Return matches with a match weight above this threshold. Defaults to -4. -4 Examples: >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> # Pre-compute tf tables for any tables with >>> # term frequency adjustments >>> linker . compute_tf_table ( \"first_name\" ) >>> record = { 'unique_id' : 1 , >>> 'first_name' : \"John\" , >>> 'surname' : \"Smith\" , >>> 'dob' : \"1971-05-24\" , >>> 'city' : \"London\" , >>> 'email' : \"john@smith.net\" >>> } >>> df = linker . find_matches_to_new_records ([ record ], blocking_rules = []) Returns: Name Type Description SplinkDataFrame SplinkDataFrame The pairwise comparisons.","title":"find_matches_to_new_records()"},{"location":"linkerest.html#splink.linker.Linker.initialise_settings","text":"Initialise settings for the linker. To be used if settings were not passed to the linker on creation. Examples: >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . profile_columns ([ \"first_name\" , \"surname\" ]) >>> linker . initialise_settings ( settings_dict ) Parameters: Name Type Description Default settings_dict dict A Splink settings dictionary required","title":"initialise_settings()"},{"location":"linkerest.html#splink.linker.Linker.load_settings_from_json","text":"Load settings from a .json file. This .json file would usually be the output of linker.save_settings_to_json() Examples: >>> linker . load_settings_from_json ( \"my_settings.json\" ) Parameters: Name Type Description Default in_path str Path to settings json file required","title":"load_settings_from_json()"},{"location":"linkerest.html#splink.linker.Linker.m_u_parameters_chart","text":"Display a chart of the m and u parameters of the linkage model Examples: >>> linker . m_u_parameters_chart () >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . match_weights_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500 ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute.","title":"m_u_parameters_chart()"},{"location":"linkerest.html#splink.linker.Linker.match_weights_chart","text":"Display a chart of the (partial) match weights of the linkage model Examples: >>> linker . match_weights_chart () >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . match_weights_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500 ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute.","title":"match_weights_chart()"},{"location":"linkerest.html#splink.linker.Linker.match_weights_histogram","text":"Generate a histogram that shows the distribution of match weights in df_predict Parameters: Name Type Description Default df_predict SplinkDataFrame Output of linker.predict() required target_bins int Target number of bins in histogram. Defaults to 30. 30 width int Width of output. Defaults to 600. 600 height int Height of output chart. Defaults to 250. 250 Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute.","title":"match_weights_histogram()"},{"location":"linkerest.html#splink.linker.Linker.missingness_chart","text":"Generate a summary chart of the missingness (prevalence of nulls) of columns in the input datasets. By default, missingness is assessed across all input datasets Parameters: Name Type Description Default input_dataset str Name of one of the input tables in the None Examples: >>> linker . missingness_chart () >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . missingness_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500","title":"missingness_chart()"},{"location":"linkerest.html#splink.linker.Linker.parameter_estimate_comparisons_chart","text":"Show a chart that shows how parameter estimates have differed across the different estimation methods you have used. For example, if you have run two EM estimation sessions, blocking on different variables, and both result in parameter estimates for first_name, this chart will enable easy comparison of the different estimates Parameters: Name Type Description Default include_m bool Show different estimates of m values. Defaults to True. True include_u bool Show different estimates of u values. Defaults to True. True","title":"parameter_estimate_comparisons_chart()"},{"location":"linkerest.html#splink.linker.Linker.precision_recall_chart_from_labels","text":"Generate a precision-recall chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered as a table with your database: source_dataset_l unique_id_l source_dataset_r unique_id_r clerical_match_score df_1 1 df_2 2 0.99 df_1 1 df_2 3 0.2 Note that source_dataset and unique_id should correspond to the values specified in the settings dict, and the input_table_aliases passed to the linker object. For dedupe_only links, the source_dataset columns can be ommitted. Parameters: Name Type Description Default labels_tablename str Name of table containing labels in the database required threshold_actual float Where the clerical_match_score provided by the user is a probability rather than binary, this value is used as the threshold to classify clerical_match_score s as binary matches or non matches. Defaults to 0.5. required match_weight_round_to_nearest float When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. required Examples: >>> # DuckDBLinker >>> labels = pd . read_csv ( \"my_labels.csv\" ) >>> linker . _con . register ( \"labels\" , labels ) >>> linker . precision_recall_chart_from_labels ( \"labels\" ) >>> >>> # SparkLinker >>> labels = spark . read . csv ( \"my_labels.csv\" , header = True ) >>> labels . createDataFrame ( \"labels\" ) >>> linker . precision_recall_chart_from_labels ( \"labels\" ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute.","title":"precision_recall_chart_from_labels()"},{"location":"linkerest.html#splink.linker.Linker.predict","text":"Create a dataframe of scored pairwise comparisons using the parameters of the linkage model. Uses the blocking rules specified in the blocking_rules_to_generate_predictions of the settings dictionary to generate the pairwise comparisons. Parameters: Name Type Description Default threshold_match_probability float If specified, filter the results to include only pairwise comparisons with a match_probability above this threshold. Defaults to None. None threshold_match_weight float If specified, filter the results to include only pairwise comparisons with a match_weight above this threshold. Defaults to None. None Examples: >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> df = linker . predict ( threshold_match_probability = 0.95 ) >>> df . as_pandas_dataframe ( limit = 5 ) Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data.","title":"predict()"},{"location":"linkerest.html#splink.linker.Linker.roc_chart_from_labels","text":"Generate a ROC chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered with your database: source_dataset_l unique_id_l source_dataset_r unique_id_r clerical_match_score df_1 1 df_2 2 0.99 df_1 1 df_2 3 0.2 Note that source_dataset and unique_id should correspond to the values specified in the settings dict, and the input_table_aliases passed to the linker object. For dedupe_only links, the source_dataset columns can be ommitted. Parameters: Name Type Description Default labels_tablename str Name of table containing labels in the database required threshold_actual float Where the clerical_match_score provided by the user is a probability rather than binary, this value is used as the threshold to classify clerical_match_score s as binary matches or non matches. Defaults to 0.5. 0.5 match_weight_round_to_nearest float When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. None Examples: >>> # DuckDBLinker >>> labels = pd . read_csv ( \"my_labels.csv\" ) >>> linker . _con . register ( \"labels\" , labels ) >>> linker . roc_chart_from_labels ( \"labels\" ) >>> >>> # SparkLinker >>> labels = spark . read . csv ( \"my_labels.csv\" , header = True ) >>> labels . createDataFrame ( \"labels\" ) >>> linker . roc_chart_from_labels ( \"labels\" ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute.","title":"roc_chart_from_labels()"},{"location":"linkerest.html#splink.linker.Linker.roc_table_from_labels","text":"Generate truth statistics (false positive etc.) for each threshold value of match_probability, suitable for plotting a ROC chart. The table of labels should be in the following format, and should be registered with your database: source_dataset_l unique_id_l source_dataset_r unique_id_r clerical_match_score df_1 1 df_2 2 0.99 df_1 1 df_2 3 0.2 Note that source_dataset and unique_id should correspond to the values specified in the settings dict, and the input_table_aliases passed to the linker object. For dedupe_only links, the source_dataset columns can be ommitted. Parameters: Name Type Description Default labels_tablename str Name of table containing labels in the database required threshold_actual float Where the clerical_match_score provided by the user is a probability rather than binary, this value is used as the threshold to classify clerical_match_score s as binary matches or non matches. Defaults to 0.5. 0.5 match_weight_round_to_nearest float When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. None Examples: >>> # DuckDBLinker >>> labels = pd . read_csv ( \"my_labels.csv\" ) >>> linker . _con . register ( \"labels\" , labels ) >>> linker . roc_table_from_labels ( \"labels\" ) >>> >>> # SparkLinker >>> labels = spark . read . csv ( \"my_labels.csv\" , header = True ) >>> labels . createDataFrame ( \"labels\" ) >>> linker . roc_table_from_labels ( \"labels\" ) Returns: Name Type Description SplinkDataFrame SplinkDataFrame Table of truth statistics","title":"roc_table_from_labels()"},{"location":"linkerest.html#splink.linker.Linker.save_settings_to_json","text":"Save the configuration and parameters the linkage model to a .json file. The model can later be loaded back in using linker.load_settings_from_json() Examples: >>> linker . save_settings_to_json ( \"my_settings.json\" , overwrite = True ) Parameters: Name Type Description Default out_path str File path for json file required overwrite bool Overwrite if already exists? Defaults to False. False","title":"save_settings_to_json()"},{"location":"linkerest.html#splink.linker.Linker.unlinkables_chart","text":"Generate an interactive chart displaying the proportion of records that are \"unlinkable\" for a given splink score threshold and model parameters. Unlinkable records are those that, even when compared with themselves, do not contain enough information to confirm a match. Parameters: Name Type Description Default x_col str Column to use for the x-axis. Defaults to \"match_weight\". 'match_weight' source_dataset str Name of the source dataset to use for the title of the output chart. None as_dict bool If True, return a dict version of the chart. False Examples: >>> # For the simplest code pipeline, load a pre-trained model >>> # and run this against the test data. >>> df = pd . read_csv ( \"./tests/datasets/fake_1000_from_splink_demos.csv\" ) >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . unlinkables_chart () >>> >>> # For more complex code pipelines, you can run an entire pipeline >>> # that estimates your m and u values, before `unlinkables_chart(). Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute.","title":"unlinkables_chart()"},{"location":"linkerest.html#splink.linker.Linker.waterfall_chart","text":"Visualise how the final match weight is computed for the provided pairwise record comparisons. Records must be provided as a list of dictionaries. This would usually be obtained from df.as_record_dict(limit=n) where df is a SplinkDataFrame. Examples: >>> df = linker . predict ( threshold_match_weight = 2 ) >>> records = df . as_record_dict ( limit = 10 ) >>> linker . waterfall_chart ( records ) Parameters: Name Type Description Default records List [ dict ] Usually be obtained from df.as_record_dict(limit=n) where df is a SplinkDataFrame. required filter_nulls bool Whether the visualiation shows null comparisons, which have no effect on final match weight. Defaults to True. True Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. handler: python selection: members: - estimate_m_from_label_column - estimate_parameters_using_expectation_maximisation - estimate_u_using_random_sampling - save_settings_to_json - estimate_m_from_pairwise_labels rendering: show_root_heading: false show_source: true","title":"waterfall_chart()"},{"location":"linkerexp.html","tags":["API"],"text":"Documentation for Linker object methods related to exploratory analysis \u00b6 The Linker object manages the data linkage process and holds the data linkage model. Most of Splink's functionality can be accessed by calling methods (functions) on the linker, such as linker.predict() , linker.profile_columns() etc. The Linker class is intended for subclassing for specific backends, e.g. a DuckDBLinker . count_num_comparisons_from_blocking_rule ( blocking_rule , link_type = None , unique_id_column_name = None ) \u00b6 Compute the number of pairwise record comparisons that would be generated by a blocking rule Parameters: Name Type Description Default blocking_rule str The blocking rule to analyse required link_type str The link type. This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None unique_id_column_name str This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None Examples: >>> br = \"l.first_name = r.first_name\" >>> linker . count_num_comparisons_from_blocking_rule ( br ) 19387 >>> br = \"l.name = r.name and substr(l.dob,1,4) = substr(r.dob,1,4)\" >>> linker . count_num_comparisons_from_blocking_rule ( br ) 394 Returns: Name Type Description int int The number of comparisons generated by the blocking rule cumulative_num_comparisons_from_blocking_rules_chart ( blocking_rules = None , link_type = None , unique_id_column_name = None ) \u00b6 Display a chart with the cumulative number of comparisons generated by a selection of blocking rules. This is equivalent to the output size of df_predict and details how many comparisons each of your individual blocking rules will contribute to the total. Parameters: Name Type Description Default blocking_rules str or list The blocking rule(s) to compute comparisons for. If null, the rules set out in your settings object will be used. None link_type str The link type. This defaults to the link type outlined in your settings object. None unique_id_column_name str This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None Examples: >>> linker_settings = DuckDBLinker ( df , settings ) >>> # Compute the cumulative number of comparisons generated by the rules >>> # in your settings object. >>> linker_settings . cumulative_num_comparisons_from_blocking_rules_chart () >>> >>> # Generate total comparisons with custom blocking rules. >>> blocking_rules = [ >>> \"l.surname = r.surname\" , >>> \"l.first_name = r.first_name >>> and substr ( l . dob , 1 , 4 ) = substr ( r . dob , 1 , 4 ) \" >>> ] >>> >>> linker . cumulative_num_comparisons_from_blocking_rules_chart ( >>> blocking_rules >>> ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. missingness_chart ( input_dataset = None ) \u00b6 Generate a summary chart of the missingness (prevalence of nulls) of columns in the input datasets. By default, missingness is assessed across all input datasets Parameters: Name Type Description Default input_dataset str Name of one of the input tables in the None Examples: >>> linker . missingness_chart () >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . missingness_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500 profile_columns ( column_expressions , top_n = 10 , bottom_n = 10 ) \u00b6 unlinkables_chart ( x_col = 'match_weight' , source_dataset = None , as_dict = False ) \u00b6 Generate an interactive chart displaying the proportion of records that are \"unlinkable\" for a given splink score threshold and model parameters. Unlinkable records are those that, even when compared with themselves, do not contain enough information to confirm a match. Parameters: Name Type Description Default x_col str Column to use for the x-axis. Defaults to \"match_weight\". 'match_weight' source_dataset str Name of the source dataset to use for the title of the output chart. None as_dict bool If True, return a dict version of the chart. False Examples: >>> # For the simplest code pipeline, load a pre-trained model >>> # and run this against the test data. >>> df = pd . read_csv ( \"./tests/datasets/fake_1000_from_splink_demos.csv\" ) >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . unlinkables_chart () >>> >>> # For more complex code pipelines, you can run an entire pipeline >>> # that estimates your m and u values, before `unlinkables_chart(). Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute.","title":"Exploratory analysis"},{"location":"linkerexp.html#documentation-for-linker-object-methods-related-to-exploratory-analysis","text":"The Linker object manages the data linkage process and holds the data linkage model. Most of Splink's functionality can be accessed by calling methods (functions) on the linker, such as linker.predict() , linker.profile_columns() etc. The Linker class is intended for subclassing for specific backends, e.g. a DuckDBLinker .","title":"Documentation for Linker object methods related to exploratory analysis"},{"location":"linkerexp.html#splink.linker.Linker.count_num_comparisons_from_blocking_rule","text":"Compute the number of pairwise record comparisons that would be generated by a blocking rule Parameters: Name Type Description Default blocking_rule str The blocking rule to analyse required link_type str The link type. This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None unique_id_column_name str This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None Examples: >>> br = \"l.first_name = r.first_name\" >>> linker . count_num_comparisons_from_blocking_rule ( br ) 19387 >>> br = \"l.name = r.name and substr(l.dob,1,4) = substr(r.dob,1,4)\" >>> linker . count_num_comparisons_from_blocking_rule ( br ) 394 Returns: Name Type Description int int The number of comparisons generated by the blocking rule","title":"count_num_comparisons_from_blocking_rule()"},{"location":"linkerexp.html#splink.linker.Linker.cumulative_num_comparisons_from_blocking_rules_chart","text":"Display a chart with the cumulative number of comparisons generated by a selection of blocking rules. This is equivalent to the output size of df_predict and details how many comparisons each of your individual blocking rules will contribute to the total. Parameters: Name Type Description Default blocking_rules str or list The blocking rule(s) to compute comparisons for. If null, the rules set out in your settings object will be used. None link_type str The link type. This defaults to the link type outlined in your settings object. None unique_id_column_name str This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None Examples: >>> linker_settings = DuckDBLinker ( df , settings ) >>> # Compute the cumulative number of comparisons generated by the rules >>> # in your settings object. >>> linker_settings . cumulative_num_comparisons_from_blocking_rules_chart () >>> >>> # Generate total comparisons with custom blocking rules. >>> blocking_rules = [ >>> \"l.surname = r.surname\" , >>> \"l.first_name = r.first_name >>> and substr ( l . dob , 1 , 4 ) = substr ( r . dob , 1 , 4 ) \" >>> ] >>> >>> linker . cumulative_num_comparisons_from_blocking_rules_chart ( >>> blocking_rules >>> ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute.","title":"cumulative_num_comparisons_from_blocking_rules_chart()"},{"location":"linkerexp.html#splink.linker.Linker.missingness_chart","text":"Generate a summary chart of the missingness (prevalence of nulls) of columns in the input datasets. By default, missingness is assessed across all input datasets Parameters: Name Type Description Default input_dataset str Name of one of the input tables in the None Examples: >>> linker . missingness_chart () >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . missingness_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500","title":"missingness_chart()"},{"location":"linkerexp.html#splink.linker.Linker.profile_columns","text":"","title":"profile_columns()"},{"location":"linkerexp.html#splink.linker.Linker.unlinkables_chart","text":"Generate an interactive chart displaying the proportion of records that are \"unlinkable\" for a given splink score threshold and model parameters. Unlinkable records are those that, even when compared with themselves, do not contain enough information to confirm a match. Parameters: Name Type Description Default x_col str Column to use for the x-axis. Defaults to \"match_weight\". 'match_weight' source_dataset str Name of the source dataset to use for the title of the output chart. None as_dict bool If True, return a dict version of the chart. False Examples: >>> # For the simplest code pipeline, load a pre-trained model >>> # and run this against the test data. >>> df = pd . read_csv ( \"./tests/datasets/fake_1000_from_splink_demos.csv\" ) >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . unlinkables_chart () >>> >>> # For more complex code pipelines, you can run an entire pipeline >>> # that estimates your m and u values, before `unlinkables_chart(). Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute.","title":"unlinkables_chart()"},{"location":"linkerpred.html","tags":["API"],"text":"Documentation for Linker object methods related to link prediction \u00b6 The Linker object manages the data linkage process and holds the data linkage model. Most of Splink's functionality can be accessed by calling methods (functions) on the linker, such as linker.predict() , linker.profile_columns() etc. The Linker class is intended for subclassing for specific backends, e.g. a DuckDBLinker . Source code in splink/linker.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 class Linker : \"\"\"The Linker object manages the data linkage process and holds the data linkage model. Most of Splink's functionality can be accessed by calling methods (functions) on the linker, such as `linker.predict()`, `linker.profile_columns()` etc. The Linker class is intended for subclassing for specific backends, e.g. a `DuckDBLinker`. \"\"\" def __init__ ( self , input_table_or_tables : Union [ str , list ], settings_dict : dict = None , set_up_basic_logging : bool = True , input_table_aliases : Union [ str , list ] = None , ): \"\"\"Initialise the linker object, which manages the data linkage process and holds the data linkage model. Examples: >>> # Example 1: DuckDB >>> df = pd.read_csv(\"data_to_dedupe.csv\") >>> linker = DuckDBLinker(df, settings_dict) >>> # Example 2: Spark >>> df_1 = spark.read.parquet(\"table_1/\") >>> df_2 = spark.read.parquet(\"table_2/\") >>> linker = SparkLinker( >>> [df_1, df_2], >>> settings_dict, >>> input_table_aliases=[\"customers\", \"contact_center_callers\"] >>> ) Args: input_table_or_tables (Union[str, list]): Input data into the linkage model. Either a single string (the name of a table in a database) for deduplication jobs, or a list of strings (the name of tables in a database) for link_only or link_and_dedupe. For some linkers, such as the DuckDBLinker and the SparkLinker, it's also possible to pass in dataframes (Pandas and Spark respectively) rather than strings. settings_dict (dict, optional): A Splink settings dictionary. If not provided when the object is created, can later be added using `linker.initialise_settings()` Defaults to None. set_up_basic_logging (bool, optional): If true, sets ups up basic logging so that Splink sends messages at INFO level to stdout. Defaults to True. input_table_aliases (Union[str, list], optional): Labels assigned to input tables in Splink outputs. If the names of the tables in the input database are long or unspecific, this argument can be used to attach more easily readable/interpretable names. Defaults to None. \"\"\" if set_up_basic_logging : logging . basicConfig ( format = \" %(message)s \" , ) splink_logger = logging . getLogger ( \"splink\" ) splink_logger . setLevel ( logging . INFO ) self . _pipeline = SQLPipeline () self . _settings_dict = settings_dict if settings_dict is None : self . _settings_obj_ = None else : self . _settings_obj_ = Settings ( settings_dict ) self . _input_tables_dict = self . _get_input_tables_dict ( input_table_or_tables , input_table_aliases ) self . _validate_input_dfs () self . _em_training_sessions = [] self . _names_of_tables_created_by_splink : list = [] self . _find_new_matches_mode = False self . _train_u_using_random_sample_mode = False self . _compare_two_records_mode = False self . _self_link_mode = False self . _output_schema = \"\" self . debug_mode = False @property def _settings_obj ( self ) -> Settings : if self . _settings_obj_ is None : raise ValueError ( \"You did not provide a settings dictionary when you \" \"created the linker. To continue, you need to provide a settings \" \"dictionary using the `initialise_settings()` method on your linker \" \"object. i.e. linker.initialise_settings(settings_dict)\" ) return self . _settings_obj_ @property def _input_tablename_l ( self ): if self . _find_new_matches_mode : return \"__splink__df_concat_with_tf\" if self . _self_link_mode : return \"__splink__df_concat_with_tf\" if self . _compare_two_records_mode : return \"__splink__compare_two_records_left_with_tf\" if self . _train_u_using_random_sample_mode : return \"__splink__df_concat_with_tf_sample\" if self . _two_dataset_link_only : return \"__splink_df_concat_with_tf_left\" return \"__splink__df_concat_with_tf\" @property def _input_tablename_r ( self ): if self . _find_new_matches_mode : return \"__splink__df_new_records_with_tf\" if self . _self_link_mode : return \"__splink__df_concat_with_tf\" if self . _compare_two_records_mode : return \"__splink__compare_two_records_right_with_tf\" if self . _train_u_using_random_sample_mode : return \"__splink__df_concat_with_tf_sample\" if self . _two_dataset_link_only : return \"__splink_df_concat_with_tf_right\" return \"__splink__df_concat_with_tf\" @property def _two_dataset_link_only ( self ): # Two dataset link only join is a special case where an inner join of the # two datasets is much more efficient than self-joining the vertically # concatenation of all input datasets if self . _find_new_matches_mode : return True if self . _compare_two_records_mode : return True if ( len ( self . _input_tables_dict ) == 2 and self . _settings_obj . _link_type == \"link_only\" ): return True else : return False def _prepend_schema_to_table_name ( self , table_name ): if self . _output_schema : return f \" { self . _output_schema } . { table_name } \" else : return table_name def _initialise_df_concat ( self , materialise = True ): if self . _table_exists_in_database ( \"__splink__df_concat\" ): return sql = vertically_concatenate_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_concat\" ) self . _execute_sql_pipeline ( materialise_as_hash = False ) def _initialise_df_concat_with_tf ( self , materialise = True ): if self . _table_exists_in_database ( \"__splink__df_concat_with_tf\" ): return sql = vertically_concatenate_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_concat\" ) sqls = compute_all_term_frequencies_sqls ( self ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) if self . _two_dataset_link_only : # If we do not materialise __splink_df_concat_with_tf # we'd have to run all the code up to this point twice self . _execute_sql_pipeline ( materialise_as_hash = False ) source_dataset_col = self . _settings_obj . _source_dataset_column_name # Need df_l to be the one with the lowest id to preeserve the property # that the left dataset is the one with the lowest concatenated id keys = self . _input_tables_dict . keys () keys = list ( sorted ( keys )) df_l = self . _input_tables_dict [ keys [ 0 ]] df_r = self . _input_tables_dict [ keys [ 1 ]] sql = f \"\"\" select * from __splink__df_concat_with_tf where { source_dataset_col } = ' { df_l . templated_name } ' \"\"\" self . _enqueue_sql ( sql , \"__splink_df_concat_with_tf_left\" ) self . _execute_sql_pipeline ( materialise_as_hash = False ) sql = f \"\"\" select * from __splink__df_concat_with_tf where { source_dataset_col } = ' { df_r . templated_name } ' \"\"\" self . _enqueue_sql ( sql , \"__splink_df_concat_with_tf_right\" ) self . _execute_sql_pipeline ( materialise_as_hash = False ) else : if materialise : self . _execute_sql_pipeline ( materialise_as_hash = False ) def _table_to_splink_dataframe ( self , templated_name , physical_name ) -> SplinkDataFrame : \"\"\"Create a SplinkDataframe from a table in the underlying database called `physical_name`. Associate a `templated_name` with this table, which signifies the purpose or 'meaning' of this table to splink. (e.g. `__splink__df_blocked`) Args: templated_name (str): The purpose of the table to Splink physical_name (str): The name of the table in the underlying databse \"\"\" raise NotImplementedError ( \"_table_to_splink_dataframe not implemented on this linker\" ) def _enqueue_sql ( self , sql , output_table_name ): \"\"\"Add sql to the current pipeline, but do not execute the pipeline.\"\"\" self . _pipeline . enqueue_sql ( sql , output_table_name ) def _execute_sql_pipeline ( self , input_dataframes : List [ SplinkDataFrame ] = [], materialise_as_hash = True , use_cache = True , transpile = True , ) -> SplinkDataFrame : \"\"\"Execute the SQL queued in the current pipeline as a single statement e.g. `with a as (), b as , c as (), select ... from c`, then execute the pipeline, returning the resultant table as a SplinkDataFrame Args: input_dataframes (List[SplinkDataFrame], optional): A 'starting point' of SplinkDataFrames if needed. Defaults to []. materialise_as_hash (bool, optional): If true, the output tablename will end in a unique identifer. Defaults to True. use_cache (bool, optional): If true, look at whether the SQL pipeline has been executed before, and if so, use the existing result. Defaults to True. transpile (bool, optional): Transpile the SQL using SQLGlot. Defaults to True. Returns: SplinkDataFrame: An abstraction representing the table created by the sql pipeline \"\"\" if not self . debug_mode : sql_gen = self . _pipeline . _generate_pipeline ( input_dataframes ) output_tablename_templated = self . _pipeline . queue [ - 1 ] . output_table_name dataframe = self . _sql_to_splink_dataframe_checking_cache ( sql_gen , output_tablename_templated , materialise_as_hash , use_cache , transpile , ) self . _pipeline . reset () return dataframe else : # In debug mode, we do not pipeline the sql and print the # results of each part of the pipeline for task in self . _pipeline . _generate_pipeline_parts ( input_dataframes ): output_tablename = task . output_table_name sql = task . sql print ( \"------\" ) print ( f \"--------Creating table: { output_tablename } --------\" ) dataframe = self . _sql_to_splink_dataframe_checking_cache ( sql , output_tablename , materialise_as_hash = False , use_cache = False , transpile = transpile , ) self . _pipeline . reset () return dataframe def _execute_sql_against_backend ( self , sql , templated_name , physical_name , transpile = True ): raise NotImplementedError ( f \"_execute_sql_against_backend not implemented for { type ( self ) } \" ) def _sql_to_splink_dataframe_checking_cache ( self , sql , output_tablename_templated , materialise_as_hash = True , use_cache = True , transpile = True , ) -> SplinkDataFrame : \"\"\"Execute sql, or if identical sql has been run before, return cached results. This function - is used by _execute_sql_pipeline to to execute SQL - or can be used directly if you have a single SQL statement that's not in a pipeline Return a SplinkDataFrame representing the results of the SQL \"\"\" hash = hashlib . sha256 ( sql . encode ()) . hexdigest ()[: 7 ] # Ensure hash is valid sql table name table_name_hash = f \" { output_tablename_templated } _ { hash } \" if use_cache : if self . _table_exists_in_database ( output_tablename_templated ): logger . debug ( f \"Using existing table { output_tablename_templated } \" ) return self . _table_to_splink_dataframe ( output_tablename_templated , output_tablename_templated ) if self . _table_exists_in_database ( table_name_hash ): logger . debug ( f \"Using cache for { output_tablename_templated } \" f \" with physical name { table_name_hash } \" ) return self . _table_to_splink_dataframe ( output_tablename_templated , table_name_hash ) if self . debug_mode : print ( sql ) if materialise_as_hash : splink_dataframe = self . _execute_sql_against_backend ( sql , output_tablename_templated , table_name_hash , transpile = transpile ) else : splink_dataframe = self . _execute_sql_against_backend ( sql , output_tablename_templated , output_tablename_templated , transpile = transpile , ) self . _names_of_tables_created_by_splink . append ( splink_dataframe . physical_name ) if self . debug_mode : df_pd = splink_dataframe . as_pandas_dataframe () try : from IPython.display import display display ( df_pd ) except ModuleNotFoundError : print ( df_pd ) return splink_dataframe def __deepcopy__ ( self , memo ): \"\"\"When we do EM training, we need a copy of the linker which is independent of the main linker e.g. setting parameters on the copy will not affect the main linker. This method implements ensures linker can be deepcopied. \"\"\" new_linker = copy ( self ) new_linker . _em_training_sessions = [] new_settings = deepcopy ( self . _settings_obj ) new_linker . _settings_obj_ = new_settings return new_linker def _ensure_aliases_populated_and_is_list ( self , input_table_or_tables , input_table_aliases ): if input_table_aliases is None : input_table_aliases = input_table_or_tables input_table_aliases = ensure_is_list ( input_table_aliases ) return input_table_aliases def _get_input_tables_dict ( self , input_table_or_tables , input_table_aliases ): input_table_or_tables = ensure_is_list ( input_table_or_tables ) input_table_aliases = self . _ensure_aliases_populated_and_is_list ( input_table_or_tables , input_table_aliases ) d = {} for table_name , table_alias in zip ( input_table_or_tables , input_table_aliases ): d [ table_alias ] = self . _table_to_splink_dataframe ( table_alias , table_name ) return d def _get_input_tf_dict ( self , df_dict ): d = {} for df_name , df_value in df_dict . items (): renamed = colname_to_tf_tablename ( df_name ) d [ renamed ] = self . _table_to_splink_dataframe ( renamed , df_value ) return d def _predict_warning ( self ): if not self . _settings_obj . _is_fully_trained : msg = ( \" \\n -- WARNING -- \\n \" \"You have called predict(), but there are some parameter \" \"estimates which have neither been estimated or specified in your \" \"settings dictionary. To produce predictions the following\" \" untrained trained parameters will use default values.\" ) messages = self . _settings_obj . _not_trained_messages () warn_message = \" \\n \" . join ([ msg ] + messages ) logger . warning ( warn_message ) def _table_exists_in_database ( self , table_name ): raise NotImplementedError ( f \"table_exists_in_database not implemented for { type ( self ) } \" ) def _validate_input_dfs ( self ): for df in self . _input_tables_dict . values (): df . validate () if self . _settings_obj_ is not None : if self . _settings_obj . _link_type == \"dedupe_only\" : if len ( self . _input_tables_dict ) > 1 : raise ValueError ( 'If link_type = \"dedupe only\" then input tables must contain ' \"only a single input table\" , ) def _populate_probability_two_random_records_match_from_trained_values ( self ): recip_prop_matches_estimates = [] logger . log ( 15 , ( \"---- Using training sessions to compute \" \"probability two random records match ----\" ), ) for em_training_session in self . _em_training_sessions : training_lambda = ( em_training_session . _settings_obj . _probability_two_random_records_match ) training_lambda_bf = prob_to_bayes_factor ( training_lambda ) reverse_levels = ( em_training_session . _comparison_levels_to_reverse_blocking_rule ) logger . log ( 15 , \" \\n \" f \"Probability two random records match from trained model blocking on \" f \" { em_training_session . _blocking_rule_for_training . blocking_rule } : \" f \" { training_lambda : ,.3f } \" , ) for reverse_level in reverse_levels : # Get comparison level on current settings obj cc = self . _settings_obj . _get_comparison_by_output_column_name ( reverse_level . comparison . _output_column_name ) cl = cc . _get_comparison_level_by_comparison_vector_value ( reverse_level . _comparison_vector_value ) if cl . _has_estimated_values : bf = cl . _trained_m_median / cl . _trained_u_median else : bf = cl . _bayes_factor logger . log ( 15 , f \"Reversing comparison level { cc . _output_column_name } \" f \" using bayes factor { bf : ,.3f } \" , ) training_lambda_bf = training_lambda_bf / bf as_prob = bayes_factor_to_prob ( training_lambda_bf ) logger . log ( 15 , ( \"This estimate of probability two random records match now: \" f \" { as_prob : ,.3f } \" f \"with reciprocal { ( 1 / as_prob ) : ,.3f } \" ), ) logger . log ( 15 , \" \\n ---------\" ) p = bayes_factor_to_prob ( training_lambda_bf ) recip_prop_matches_estimates . append ( 1 / p ) prop_matches_estimate = 1 / median ( recip_prop_matches_estimates ) self . _settings_obj . _probability_two_random_records_match = prop_matches_estimate logger . log ( 15 , \" \\n Median of prop of matches estimates: \" f \" { self . _settings_obj . _probability_two_random_records_match : ,.3f } \" \"reciprocal \" f \" { 1 / self . _settings_obj . _probability_two_random_records_match : ,.3f } \" , ) def _records_to_table ( records , as_table_name ): # Create table in database containing records # Probably quite difficult to implement correctly # Due to data type issues. raise NotImplementedError def _populate_m_u_from_trained_values ( self ): ccs = self . _settings_obj . comparisons for cc in ccs : for cl in cc . _comparison_levels_excluding_null : if cl . _has_estimated_u_values : cl . u_probability = cl . _trained_u_median if cl . _has_estimated_m_values : cl . m_probability = cl . _trained_m_median def _delete_tables_created_by_splink_from_db ( self , retain_term_frequency = True , retain_df_concat_with_tf = True ): tables_remaining = [] for name in self . _names_of_tables_created_by_splink : # Only delete tables explicitly marked as having been created by splink if \"__splink__\" not in name : tables_remaining . append ( name ) continue if name == \"__splink__df_concat_with_tf\" : if retain_df_concat_with_tf : tables_remaining . append ( name ) else : self . _delete_table_from_database ( name ) elif name . startswith ( \"__splink__df_tf_\" ): if retain_term_frequency : tables_remaining . append ( name ) else : self . _delete_table_from_database ( name ) else : self . _delete_table_from_database ( name ) self . _names_of_tables_created_by_splink = tables_remaining def _raise_error_if_necessary_waterfall_columns_not_computed ( self ): ricc = self . _settings_obj . _retain_intermediate_calculation_columns rmc = self . _settings_obj . _retain_matching_columns if not ( ricc and rmc ): raise ValueError ( \"retain_intermediate_calculation_columns and \" \"retain_matching_columns must both be set to True in your settings\" \" dictionary to use this function, because otherwise the necessary \" \"columns will not be available in the input records.\" f \" Their current values are { ricc } and { rmc } , respectively. \" \"Please re-run your linkage with them both set to True.\" ) def initialise_settings ( self , settings_dict : dict ): \"\"\"Initialise settings for the linker. To be used if settings were not passed to the linker on creation. Examples: >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.profile_columns([\"first_name\", \"surname\"]) >>> linker.initialise_settings(settings_dict) Args: settings_dict (dict): A Splink settings dictionary \"\"\" self . _settings_dict = settings_dict self . _settings_obj_ = Settings ( settings_dict ) self . _validate_input_dfs () def compute_tf_table ( self , column_name : str ) -> SplinkDataFrame : \"\"\"Compute a term frequency table for a given column and persist to the database This method is useful if you want to pre-compute term frequency tables e.g. so that real time linkage executes faster, or so that you can estimate various models without having to recompute term frequency tables each time Examples: >>> # Example 1: Real time linkage >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.load_settings_from_json(\"saved_settings.json\") >>> linker.compute_tf_table(\"surname\") >>> linker.compare_two_records(record_left, record_right) >>> # Example 2: Pre-computed term frequency tables in Spark >>> linker = SparkLinker(df) >>> df_first_name_tf = linker.compute_tf_table(\"first_name\") >>> df_first_name_tf.write.parquet(\"folder/first_name_tf\") >>> >>> # On subsequent data linking job, read this table rather than recompute >>> df_first_name_tf = spark.read.parquet(\"folder/first_name_tf\") >>> df_first_name_tf.createOrReplaceTempView(\"__splink__df_tf_first_name\") Args: column_name (str): The column name in the input table Returns: SplinkDataFrame: The resultant table as a splink data frame \"\"\" sql = vertically_concatenate_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_concat\" ) input_col = InputColumn ( column_name , tf_adjustments = True ) sql = term_frequencies_for_single_column_sql ( input_col ) self . _enqueue_sql ( sql , colname_to_tf_tablename ( input_col )) return self . _execute_sql_pipeline ( materialise_as_hash = False ) def deterministic_link ( self ) -> SplinkDataFrame : \"\"\"Uses the blocking rules specified by `blocking_rules_to_generate_predictions` in the settings dictionary to generate pairwise record comparisons. For deterministic linkage, this should be a list of blocking rules which are strict enough to generate only true links. Deterministic linkage, however, is likely to result in missed links (false negatives). Examples: >>> linker = DuckDBLinker(df) >>> >>> settings = { >>> \"link_type\": \"dedupe_only\", >>> \"blocking_rules_to_generate_predictions\": [ >>> \"l.first_name = r.first_name\", >>> \"l.surname = r.surname\", >>> ], >>> \"comparisons\": [] >>> } >>> >>> from splink.duckdb.duckdb_linker import DuckDBLinker >>> >>> linker = DuckDBLinker(df, settings) >>> df = linker.deterministic_link() Returns: SplinkDataFrame: A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. \"\"\" self . _initialise_df_concat_with_tf () sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) return self . _execute_sql_pipeline () def estimate_u_using_random_sampling ( self , target_rows : int ): \"\"\"Estimate the u parameters of the linkage model using random sampling. The u parameters represent the proportion of record comparisons that fall into each comparison level amongst truly non-matching records. This procedure takes a sample of the data and generates the cartesian product of pairwise record comparisons amongst the sampled records. The validity of the u values rests on the assumption that the resultant pairwise comparisons are non-matches (or at least, they are very unlikely to be matches). For large datasets, this is typically true. Args: target_rows (int): The target number of pairwise record comparisons from which to derive the u values. Larger will give more accurate estimates but lead to longer runtimes. In our experience at least 1e9 (one billion) gives best results but can take a long time to compute. 1e7 (ten million) is often adequate whilst testing different model specifications, before the final model is estimated. Examples: >>> linker.estimate_u_using_random_sampling(1e8) Returns: None: Updates the estimated u parameters within the linker object and returns nothing. \"\"\" self . _initialise_df_concat_with_tf ( materialise = True ) estimate_u_values ( self , target_rows ) self . _populate_m_u_from_trained_values () self . _settings_obj . _columns_without_estimated_parameters_message () def estimate_m_from_label_column ( self , label_colname : str ): \"\"\"Estimate the m parameters of the linkage model from a label (ground truth) column in the input dataframe(s). The m parameters represent the proportion of record comparisons that fall into each comparison level amongst truly matching records. The ground truth column is used to generate pairwise record comparisons which are then assumed to be matches. For example, if the entity being matched is persons, and your input dataset(s) contain social security number, this could be used to estimate the m values for the model. Note that this column does not need to be fully populated. A common case is where a unique identifier such as social security number is only partially populated. Args: label_colname (str): The name of the column containing the ground truth label in the input data. Examples: >>> linker.estimate_m_from_label_column(\"social_security_number\") Returns: Updates the estimated m parameters within the linker object and returns nothing. \"\"\" self . _initialise_df_concat_with_tf ( materialise = True ) estimate_m_values_from_label_column ( self , self . _input_tables_dict , label_colname ) self . _populate_m_u_from_trained_values () self . _settings_obj . _columns_without_estimated_parameters_message () def estimate_parameters_using_expectation_maximisation ( self , blocking_rule : str , comparisons_to_deactivate : List [ Union [ str , Comparison ]] = None , comparison_levels_to_reverse_blocking_rule : List [ ComparisonLevel ] = None , fix_probability_two_random_records_match : bool = False , fix_m_probabilities = False , fix_u_probabilities = True , ) -> EMTrainingSession : \"\"\"Estimate the parameters of the linkage model using expectation maximisation. By default, the m probabilities are estimated, but not the u probabilities, because good estiamtes for the u probabilities can be obtained from `linker.estimate_u_using_random_sampling()`. You can change this by setting `fix_u_probabilities` to False. The blocking rule provided is used to generate pairwise record comparisons. Usually, this should be a blocking rule that results in a dataframe where matches are between about 1% and 99% of the comparisons. By default, m parameters are estimated for all comparisons except those which are included in the blocking rule. For example, if the blocking rule is `l.first_name = r.first_name`, then parameter esimates will be made for all comparison except those which use `first_name` in their sql_condition By default, the probability two random records match is estimated for the blocked data, and then the m and u parameters for the columns specified in the blocking rules are used to estiamte the global probability two random records match. To control which comparisons should have their parameter estimated, and the process of 'reversing out' the global probability two random records match, the user may specify `comparisons_to_deactivate` and `comparison_levels_to_reverse_blocking_rule`. This is useful, for example if you block on the dmetaphone of a column but match on the original column. Examples: >>> # Default behaviour >>> br_training = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker.estimate_parameters_using_expectation_maximisation(br_training) >>> # Specify which comparisons to deactivate >>> br_training = \"l.dmeta_first_name = r.dmeta_first_name\" >>> settings_obj = linker._settings_obj >>> comp = settings_obj._get_comparison_by_output_column_name(\"first_name\") >>> dmeta_level = comp._get_comparison_level_by_comparison_vector_value(1) >>> linker.estimate_parameters_using_expectation_maximisation( >>> br_training, >>> comparisons_to_deactivate=[\"first_name\"], >>> comparison_levels_to_reverse_blocking_rule=[dmeta_level], >>> ) Args: blocking_rule (str): The blocking rule used to generate pairwise record comparisons. comparisons_to_deactivate (list, optional): By default, splink will analyse the blocking rule provided and estimate the m parameters for all comaprisons except those included in the blocking rule. If comparisons_to_deactivate are provided, spink will instead estimate m parameters for all comparison except those specified in the comparisons_to_deactivate list. This list can either contain the output_column_name of the Comparison as a string, or Comparison objects. Defaults to None. comparison_levels_to_reverse_blocking_rule (list, optional): By default, splink will analyse the blocking rule provided and adjust the global probability two random records match to account for the matches specified in the blocking rule. If provided, this argument will overrule this default behaviour. The user must provide a list of ComparisonLevel objects. Defaults to None. fix_probability_two_random_records_match (bool, optional): If True, do not update the probability two random records match after each iteration. Defaults to False. fix_m_probabilities (bool, optional): If True, do not update the m probabilities after each iteration. Defaults to False. fix_u_probabilities (bool, optional): If True, do not update the u probabilities after each iteration. Defaults to True. Examples: >>> blocking_rule = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker.estimate_parameters_using_expectation_maximisation(blocking_rule) Returns: EMTrainingSession: An object containing information about the training session such as how parameters changed during the iteration history \"\"\" self . _initialise_df_concat_with_tf ( materialise = True ) if comparisons_to_deactivate : # If user provided a string, convert to Comparison object comparisons_to_deactivate = [ self . _settings_obj . _get_comparison_by_output_column_name ( n ) if isinstance ( n , str ) else n for n in comparisons_to_deactivate ] if comparison_levels_to_reverse_blocking_rule is None : logger . warning ( \" \\n WARNING: \\n \" \"You have provided comparisons_to_deactivate but not \" \"comparison_levels_to_reverse_blocking_rule. \\n \" \"If comparisons_to_deactivate is provided, then \" \"you usually need to provide corresponding \" \"comparison_levels_to_reverse_blocking_rule. \" \"because each comparison to deactivate if effectively treated \" \"as an exact match.\" ) em_training_session = EMTrainingSession ( self , blocking_rule , fix_u_probabilities = fix_u_probabilities , fix_m_probabilities = fix_m_probabilities , fix_probability_two_random_records_match = fix_probability_two_random_records_match , # noqa 501 comparisons_to_deactivate = comparisons_to_deactivate , comparison_levels_to_reverse_blocking_rule = comparison_levels_to_reverse_blocking_rule , # noqa 501 ) em_training_session . _train () self . _populate_m_u_from_trained_values () self . _populate_probability_two_random_records_match_from_trained_values () self . _settings_obj . _columns_without_estimated_parameters_message () return em_training_session def predict ( self , threshold_match_probability : float = None , threshold_match_weight : float = None , ) -> SplinkDataFrame : \"\"\"Create a dataframe of scored pairwise comparisons using the parameters of the linkage model. Uses the blocking rules specified in the `blocking_rules_to_generate_predictions` of the settings dictionary to generate the pairwise comparisons. Args: threshold_match_probability (float, optional): If specified, filter the results to include only pairwise comparisons with a match_probability above this threshold. Defaults to None. threshold_match_weight (float, optional): If specified, filter the results to include only pairwise comparisons with a match_weight above this threshold. Defaults to None. Examples: >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.load_settings_from_json(\"saved_settings.json\") >>> df = linker.predict(threshold_match_probability=0.95) >>> df.as_pandas_dataframe(limit=5) Returns: SplinkDataFrame: A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. \"\"\" # If the user only calls predict, it runs as a single pipeline with no # materialisation of anything self . _initialise_df_concat_with_tf ( materialise = False ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) repartition_after_blocking = getattr ( self , \"repartition_after_blocking\" , False ) # repartition after blocking only exists on the SparkLinker if repartition_after_blocking : df_blocked = self . _execute_sql_pipeline () input_dataframes = [ df_blocked ] else : input_dataframes = [] sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj , threshold_match_probability , threshold_match_weight ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) predictions = self . _execute_sql_pipeline ( input_dataframes ) self . _predict_warning () return predictions def find_matches_to_new_records ( self , records_or_tablename , blocking_rules = [], match_weight_threshold =- 4 , ) -> SplinkDataFrame : \"\"\"Given one or more records, find records in the input dataset(s) which match and return in order of the splink prediction score. This effectively provides a way of searching the input datasets for given record(s) Args: records_or_tablename (List[dict]): Input search record(s) as list of dict, or a table registered to the database. blocking_rules (list, optional): Blocking rules to select which records to find and score. If [], do not use a blocking rule - meaning the input records will be compared to all records provided to the linker when it was instantiated. Defaults to []. match_weight_threshold (int, optional): Return matches with a match weight above this threshold. Defaults to -4. Examples: >>> linker = DuckDBLinker(df) >>> linker.load_settings_from_json(\"saved_settings.json\") >>> # Pre-compute tf tables for any tables with >>> # term frequency adjustments >>> linker.compute_tf_table(\"first_name\") >>> record = {'unique_id': 1, >>> 'first_name': \"John\", >>> 'surname': \"Smith\", >>> 'dob': \"1971-05-24\", >>> 'city': \"London\", >>> 'email': \"john@smith.net\" >>> } >>> df = linker.find_matches_to_new_records([record], blocking_rules=[]) Returns: SplinkDataFrame: The pairwise comparisons. \"\"\" original_blocking_rules = ( self . _settings_obj . _blocking_rules_to_generate_predictions ) original_link_type = self . _settings_obj . _link_type if not isinstance ( records_or_tablename , str ): self . _records_to_table ( records_or_tablename , \"__splink__df_new_records\" ) new_records_tablename = \"__splink__df_new_records\" else : new_records_tablename = records_or_tablename blocking_rules = [ BlockingRule ( r ) if not isinstance ( r , BlockingRule ) else r for r in blocking_rules ] self . _settings_obj . _blocking_rules_to_generate_predictions = blocking_rules self . _settings_obj . _link_type = \"link_only_find_matches_to_new_records\" self . _find_new_matches_mode = True sql = _join_tf_to_input_df_sql ( self ) sql = sql . replace ( \"__splink__df_concat\" , new_records_tablename ) self . _enqueue_sql ( sql , \"__splink__df_new_records_with_tf\" ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) sql = f \"\"\" select * from __splink__df_predict where match_weight > { match_weight_threshold } \"\"\" self . _enqueue_sql ( sql , \"__splink_find_matches_predictions\" ) predictions = self . _execute_sql_pipeline ( use_cache = False ) self . _settings_obj . _blocking_rules_to_generate_predictions = ( original_blocking_rules ) self . _settings_obj . _link_type = original_link_type self . _find_new_matches_mode = False return predictions def compare_two_records ( self , record_1 : dict , record_2 : dict ): \"\"\"Use the linkage model to compare and score a pairwise record comparison based on the two input records provided Args: record_1 (dict): dictionary representing the first record. Columns names and data types must be the same as the columns in the settings object record_2 (dict): dictionary representing the second record. Columns names and data types must be the same as the columns in the settings object Examples: >>> linker = DuckDBLinker(df) >>> linker.load_settings_from_json(\"saved_settings.json\") >>> linker.compare_two_records(record_left, record_right) Returns: SplinkDataFrame: Pairwise comparison with scored prediction \"\"\" original_blocking_rules = ( self . _settings_obj . _blocking_rules_to_generate_predictions ) original_link_type = self . _settings_obj . _link_type self . _compare_two_records_mode = True self . _settings_obj . _blocking_rules_to_generate_predictions = [] self . _records_to_table ([ record_1 ], \"__splink__compare_two_records_left\" ) self . _records_to_table ([ record_2 ], \"__splink__compare_two_records_right\" ) sql_join_tf = _join_tf_to_input_df_sql ( self ) sql_join_tf = sql_join_tf . replace ( \"__splink__df_concat\" , \"__splink__compare_two_records_left\" ) self . _enqueue_sql ( sql_join_tf , \"__splink__compare_two_records_left_with_tf\" ) sql_join_tf = sql_join_tf . replace ( \"__splink__compare_two_records_left\" , \"__splink__compare_two_records_right\" ) self . _enqueue_sql ( sql_join_tf , \"__splink__compare_two_records_right_with_tf\" ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) predictions = self . _execute_sql_pipeline ( use_cache = False ) self . _settings_obj . _blocking_rules_to_generate_predictions = ( original_blocking_rules ) self . _settings_obj . _link_type = original_link_type self . _compare_two_records_mode = False return predictions def _self_link ( self ) -> SplinkDataFrame : \"\"\"Use the linkage model to compare and score all records in our input df with themselves. Returns: SplinkDataFrame: Scored pairwise comparisons of the input records to themselves. \"\"\" original_blocking_rules = ( self . _settings_obj . _blocking_rules_to_generate_predictions ) original_link_type = self . _settings_obj . _link_type # Changes our sql to allow for a self link. # This is used in `_sql_gen_where_condition` in blocking.py # to remove any 'where' clauses when blocking (normally when blocking # we want to *remove* self links!) self . _self_link_mode = True # Block on uid i.e. create pairwise record comparisons where the uid matches uid_cols = self . _settings_obj . _unique_id_input_columns uid_l = _composite_unique_id_from_edges_sql ( uid_cols , None , \"l\" ) uid_r = _composite_unique_id_from_edges_sql ( uid_cols , None , \"r\" ) self . _settings_obj . _blocking_rules_to_generate_predictions = [ BlockingRule ( f \" { uid_l } = { uid_r } \" ) ] self . _initialise_df_concat_with_tf () sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) predictions = self . _execute_sql_pipeline ( use_cache = False ) self . _settings_obj . _blocking_rules_to_generate_predictions = ( original_blocking_rules ) self . _settings_obj . _link_type = original_link_type self . _self_link_mode = False return predictions def cluster_pairwise_predictions_at_threshold ( self , df_predict : SplinkDataFrame , threshold_match_probability : float ) -> SplinkDataFrame : \"\"\"Clusters the pairwise match predictions that result from `linker.predict()` into groups of connected record using the connected components graph clustering algorithm Records with an estimated `match_probability` above `threshold_match_probability` are considered to be a match (i.e. they represent the same entity). Args: df_predict (SplinkDataFrame): The results of `linker.predict()` threshold_match_probability (float): Filter the pairwise match predictions to include only pairwise comparisons with a match_probability above this threshold. This dataframe is then fed into the clustering algorithm. Returns: SplinkDataFrame: A SplinkDataFrame containing a list of all IDs, clustered into groups based on the desired match threshold. \"\"\" self . _initialise_df_concat_with_tf ( df_predict ) edges_table = _cc_create_unique_id_cols ( self , df_predict , threshold_match_probability , ) cc = solve_connected_components ( self , edges_table ) return cc def profile_columns ( self , column_expressions : Union [ str , List [ str ]], top_n = 10 , bottom_n = 10 ): return profile_columns ( self , column_expressions , top_n = top_n , bottom_n = bottom_n ) def estimate_m_from_pairwise_labels ( self , table_name ): self . _initialise_df_concat_with_tf ( materialise = True ) estimate_m_from_pairwise_labels ( self , table_name ) def roc_chart_from_labels ( self , labels_tablename , threshold_actual = 0.5 , match_weight_round_to_nearest : float = None , ): \"\"\"Generate a ROC chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered with your database: |source_dataset_l|unique_id_l|source_dataset_r|unique_id_r|clerical_match_score| |----------------|-----------|----------------|-----------|--------------------| |df_1 |1 |df_2 |2 |0.99 | |df_1 |1 |df_2 |3 |0.2 | Note that `source_dataset` and `unique_id` should correspond to the values specified in the settings dict, and the `input_table_aliases` passed to the `linker` object. For `dedupe_only` links, the `source_dataset` columns can be ommitted. Args: labels_tablename (str): Name of table containing labels in the database threshold_actual (float, optional): Where the `clerical_match_score` provided by the user is a probability rather than binary, this value is used as the threshold to classify `clerical_match_score`s as binary matches or non matches. Defaults to 0.5. match_weight_round_to_nearest (float, optional): When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. Examples: >>> # DuckDBLinker >>> labels = pd.read_csv(\"my_labels.csv\") >>> linker._con.register(\"labels\", labels) >>> linker.roc_chart_from_labels(\"labels\") >>> >>> # SparkLinker >>> labels = spark.read.csv(\"my_labels.csv\", header=True) >>> labels.createDataFrame(\"labels\") >>> linker.roc_chart_from_labels(\"labels\") Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" df_truth_space = roc_table ( self , labels_tablename , threshold_actual = threshold_actual , match_weight_round_to_nearest = match_weight_round_to_nearest , ) recs = df_truth_space . as_record_dict () return roc_chart ( recs ) def precision_recall_chart_from_labels ( self , labels_tablename ): \"\"\"Generate a precision-recall chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered as a table with your database: |source_dataset_l|unique_id_l|source_dataset_r|unique_id_r|clerical_match_score| |----------------|-----------|----------------|-----------|--------------------| |df_1 |1 |df_2 |2 |0.99 | |df_1 |1 |df_2 |3 |0.2 | Note that `source_dataset` and `unique_id` should correspond to the values specified in the settings dict, and the `input_table_aliases` passed to the `linker` object. For `dedupe_only` links, the `source_dataset` columns can be ommitted. Args: labels_tablename (str): Name of table containing labels in the database threshold_actual (float, optional): Where the `clerical_match_score` provided by the user is a probability rather than binary, this value is used as the threshold to classify `clerical_match_score`s as binary matches or non matches. Defaults to 0.5. match_weight_round_to_nearest (float, optional): When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. Examples: >>> # DuckDBLinker >>> labels = pd.read_csv(\"my_labels.csv\") >>> linker._con.register(\"labels\", labels) >>> linker.precision_recall_chart_from_labels(\"labels\") >>> >>> # SparkLinker >>> labels = spark.read.csv(\"my_labels.csv\", header=True) >>> labels.createDataFrame(\"labels\") >>> linker.precision_recall_chart_from_labels(\"labels\") Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" df_truth_space = roc_table ( self , labels_tablename ) recs = df_truth_space . as_record_dict () return precision_recall_chart ( recs ) def roc_table_from_labels ( self , labels_tablename , threshold_actual = 0.5 , match_weight_round_to_nearest : float = None , ) -> SplinkDataFrame : \"\"\"Generate truth statistics (false positive etc.) for each threshold value of match_probability, suitable for plotting a ROC chart. The table of labels should be in the following format, and should be registered with your database: |source_dataset_l|unique_id_l|source_dataset_r|unique_id_r|clerical_match_score| |----------------|-----------|----------------|-----------|--------------------| |df_1 |1 |df_2 |2 |0.99 | |df_1 |1 |df_2 |3 |0.2 | Note that `source_dataset` and `unique_id` should correspond to the values specified in the settings dict, and the `input_table_aliases` passed to the `linker` object. For `dedupe_only` links, the `source_dataset` columns can be ommitted. Args: labels_tablename (str): Name of table containing labels in the database threshold_actual (float, optional): Where the `clerical_match_score` provided by the user is a probability rather than binary, this value is used as the threshold to classify `clerical_match_score`s as binary matches or non matches. Defaults to 0.5. match_weight_round_to_nearest (float, optional): When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. Examples: >>> # DuckDBLinker >>> labels = pd.read_csv(\"my_labels.csv\") >>> linker._con.register(\"labels\", labels) >>> linker.roc_table_from_labels(\"labels\") >>> >>> # SparkLinker >>> labels = spark.read.csv(\"my_labels.csv\", header=True) >>> labels.createDataFrame(\"labels\") >>> linker.roc_table_from_labels(\"labels\") Returns: SplinkDataFrame: Table of truth statistics \"\"\" return roc_table ( self , labels_tablename , threshold_actual = threshold_actual , match_weight_round_to_nearest = match_weight_round_to_nearest , ) def match_weights_histogram ( self , df_predict : SplinkDataFrame , target_bins : int = 30 , width = 600 , height = 250 ): \"\"\"Generate a histogram that shows the distribution of match weights in `df_predict` Args: df_predict (SplinkDataFrame): Output of `linker.predict()` target_bins (int, optional): Target number of bins in histogram. Defaults to 30. width (int, optional): Width of output. Defaults to 600. height (int, optional): Height of output chart. Defaults to 250. Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" df = histogram_data ( self , df_predict , target_bins ) recs = df . as_record_dict () return match_weights_histogram ( recs , width = width , height = height ) def waterfall_chart ( self , records : List [ dict ], filter_nulls = True ): \"\"\"Visualise how the final match weight is computed for the provided pairwise record comparisons. Records must be provided as a list of dictionaries. This would usually be obtained from `df.as_record_dict(limit=n)` where `df` is a SplinkDataFrame. Examples: >>> df = linker.predict(threshold_match_weight=2) >>> records = df.as_record_dict(limit=10) >>> linker.waterfall_chart(records) Args: records (List[dict]): Usually be obtained from `df.as_record_dict(limit=n)` where `df` is a SplinkDataFrame. filter_nulls (bool, optional): Whether the visualiation shows null comparisons, which have no effect on final match weight. Defaults to True. Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" self . _raise_error_if_necessary_waterfall_columns_not_computed () return waterfall_chart ( records , self . _settings_obj , filter_nulls ) def unlinkables_chart ( self , x_col = \"match_weight\" , source_dataset = None , as_dict = False , ): \"\"\"Generate an interactive chart displaying the proportion of records that are \"unlinkable\" for a given splink score threshold and model parameters. Unlinkable records are those that, even when compared with themselves, do not contain enough information to confirm a match. Args: x_col (str, optional): Column to use for the x-axis. Defaults to \"match_weight\". source_dataset (str, optional): Name of the source dataset to use for the title of the output chart. as_dict (bool, optional): If True, return a dict version of the chart. Examples: >>> # For the simplest code pipeline, load a pre-trained model >>> # and run this against the test data. >>> df = pd.read_csv(\"./tests/datasets/fake_1000_from_splink_demos.csv\") >>> linker = DuckDBLinker(df) >>> linker.load_settings_from_json(\"saved_settings.json\") >>> linker.unlinkables_chart() >>> >>> # For more complex code pipelines, you can run an entire pipeline >>> # that estimates your m and u values, before `unlinkables_chart(). Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" # Link our initial df on itself and calculate the % of unlinkable entries records = unlinkables_data ( self , x_col ) return unlinkables_chart ( records , x_col , source_dataset ) def comparison_viewer_dashboard ( self , df_predict : SplinkDataFrame , out_path : str , overwrite = False , num_example_rows = 2 , return_html_as_string = False , ): \"\"\"Generate an interactive html visualization of the linker's predictions and save to `out_path`. For more information see [this video](https://www.youtube.com/watch?v=DNvCMqjipis) Args: df_predict (SplinkDataFrame): The outputs of `linker.predict()` out_path (str): The path (including filename) to save the html file to. overwrite (bool, optional): Overwrite the html file if it already exists? Defaults to False. num_example_rows (int, optional): Number of example rows per comparison vector. Defaults to 2. return_html_as_string: If True, return the html as a string Examples: >>> df_predictions = linker.predict() >>> linker.comparison_viewer_dashboard(df_predictions, \"scv.html\", True, 2) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame(src=\"./scv.html\", width=\"100%\", height=1200) \"\"\" self . _raise_error_if_necessary_waterfall_columns_not_computed () sql = comparison_vector_distribution_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vector_distribution\" ) sqls = comparison_viewer_table_sqls ( self , num_example_rows ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) df = self . _execute_sql_pipeline ([ df_predict ]) rendered = render_splink_comparison_viewer_html ( df . as_record_dict (), self . _settings_obj . _as_completed_dict (), out_path , overwrite , ) if return_html_as_string : return rendered def parameter_estimate_comparisons_chart ( self , include_m = True , include_u = True ): \"\"\"Show a chart that shows how parameter estimates have differed across the different estimation methods you have used. For example, if you have run two EM estimation sessions, blocking on different variables, and both result in parameter estimates for first_name, this chart will enable easy comparison of the different estimates Args: include_m (bool, optional): Show different estimates of m values. Defaults to True. include_u (bool, optional): Show different estimates of u values. Defaults to True. \"\"\" records = self . _settings_obj . _parameter_estimates_as_records to_retain = [] if include_m : to_retain . append ( \"m\" ) if include_u : to_retain . append ( \"u\" ) records = [ r for r in records if r [ \"m_or_u\" ] in to_retain ] return parameter_estimate_comparisons ( records ) def missingness_chart ( self , input_dataset : str = None ): \"\"\"Generate a summary chart of the missingness (prevalence of nulls) of columns in the input datasets. By default, missingness is assessed across all input datasets Args: input_dataset (str, optional): Name of one of the input tables in the database. If provided, missingness will be computed for this table alone. Defaults to None. Examples: >>> linker.missingness_chart() >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker.missingness_chart() >>> save_offline_chart(c.spec, \"test_chart.html\") >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame(src=\"./test_chart.html\", width=1000, height=500 \"\"\" records = missingness_data ( self , input_dataset ) return missingness_chart ( records , input_dataset ) def completeness_chart ( self , input_dataset : str = None , cols : List [ str ] = None ): \"\"\"Generate a summary chart of the completeness (proportion of non-nulls) of columns in each of the input datasets. By default, completeness is assessed for all column in the input data. Args: input_dataset (str, optional): Name of one of the input tables in the database. If provided, completeness will be computed for this table alone. Defaults to None. cols (List[str], optional): List of column names to calculate completeness. Default to None. Examples: >>> linker.completeness_chart() >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker.completeness_chart() >>> save_offline_chart(c.spec, \"test_chart.html\") >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame(src=\"./test_chart.html\", width=1000, height=500 \"\"\" records = completeness_data ( self , input_dataset , cols ) return completeness_chart ( records , input_dataset ) def count_num_comparisons_from_blocking_rule ( self , blocking_rule : str , link_type : str = None , unique_id_column_name : str = None , ) -> int : \"\"\"Compute the number of pairwise record comparisons that would be generated by a blocking rule Args: blocking_rule (str): The blocking rule to analyse link_type (str, optional): The link type. This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. unique_id_column_name (str, optional): This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. Examples: >>> br = \"l.first_name = r.first_name\" >>> linker.count_num_comparisons_from_blocking_rule(br) 19387 >>> br = \"l.name = r.name and substr(l.dob,1,4) = substr(r.dob,1,4)\" >>> linker.count_num_comparisons_from_blocking_rule(br) 394 Returns: int: The number of comparisons generated by the blocking rule \"\"\" sql = vertically_concatenate_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_concat\" ) sql = number_of_comparisons_generated_by_blocking_rule_sql ( self , blocking_rule , link_type , unique_id_column_name ) self . _enqueue_sql ( sql , \"__splink__analyse_blocking_rule\" ) res = self . _execute_sql_pipeline () . as_record_dict ()[ 0 ] return res [ \"count_of_pairwise_comparisons_generated\" ] def cumulative_num_comparisons_from_blocking_rules_chart ( self , blocking_rules : str or list = None , link_type : str = None , unique_id_column_name : str = None , ): \"\"\"Display a chart with the cumulative number of comparisons generated by a selection of blocking rules. This is equivalent to the output size of df_predict and details how many comparisons each of your individual blocking rules will contribute to the total. Args: blocking_rules (str or list): The blocking rule(s) to compute comparisons for. If null, the rules set out in your settings object will be used. link_type (str, optional): The link type. This defaults to the link type outlined in your settings object. unique_id_column_name (str, optional): This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. Examples: >>> linker_settings = DuckDBLinker(df, settings) >>> # Compute the cumulative number of comparisons generated by the rules >>> # in your settings object. >>> linker_settings.cumulative_num_comparisons_from_blocking_rules_chart() >>> >>> # Generate total comparisons with custom blocking rules. >>> blocking_rules = [ >>> \"l.surname = r.surname\", >>> \"l.first_name = r.first_name >>> and substr(l.dob,1,4) = substr(r.dob,1,4)\" >>> ] >>> >>> linker.cumulative_num_comparisons_from_blocking_rules_chart( >>> blocking_rules >>> ) Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" if blocking_rules : blocking_rules = ensure_is_list ( blocking_rules ) records = cumulative_comparisons_generated_by_blocking_rules ( self , blocking_rules , link_type , unique_id_column_name , ) return cumulative_blocking_rule_comparisons_generated ( records ) def count_num_comparisons_from_blocking_rules_for_prediction ( self , df_predict ): \"\"\"Counts the maginal number of edges created from each of the blocking rules in `blocking_rules_to_generate_predictions` This is different to `count_num_comparisons_from_blocking_rule` because it (a) analyses multiple blocking rules rather than a single rule, and (b) deduplicates any comparisons that are generated, to tell you the marginal effect of each entry in `blocking_rules_to_generate_predictions` Args: df_predict (SplinkDataFrame): SplinkDataFrame with match weights and probabilities of rows matching Examples: >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.load_settings_from_json(\"saved_settings.json\") >>> df_predict = linker.predict(threshold_match_probability=0.95) >>> count_pairwise = linker.count_num_comparisons_from_blocking_rules_for_prediction(df_predict) >>> count_pairwise.as_pandas_dataframe(limit=5) Returns: SplinkDataFrame: A SplinkDataFrame of the pairwise comparisons and estimated pairwise comparisons generated by the blocking rules. \"\"\" # noqa: E501 sql = count_num_comparisons_from_blocking_rules_for_prediction_sql ( df_predict ) match_key_analysis = self . _sql_to_splink_dataframe_checking_cache ( sql , \"__splink__match_key_analysis\" ) return match_key_analysis def match_weights_chart ( self ): \"\"\"Display a chart of the (partial) match weights of the linkage model Examples: >>> linker.match_weights_chart() >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker.match_weights_chart() >>> save_offline_chart(c.spec, \"test_chart.html\") >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame(src=\"./test_chart.html\", width=1000, height=500) Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" return self . _settings_obj . match_weights_chart () def m_u_parameters_chart ( self ): \"\"\"Display a chart of the m and u parameters of the linkage model Examples: >>> linker.m_u_parameters_chart() >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker.match_weights_chart() >>> save_offline_chart(c.spec, \"test_chart.html\") >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame(src=\"./test_chart.html\", width=1000, height=500) Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" return self . _settings_obj . m_u_parameters_chart () def cluster_studio_dashboard ( self , df_predict : SplinkDataFrame , df_clustered : SplinkDataFrame , out_path : str , sampling_method = \"random\" , sample_size : int = 10 , cluster_ids : list = None , cluster_names : list = None , overwrite : bool = False , return_html_as_string = False , ): \"\"\"Generate an interactive html visualization of the predicted cluster and save to `out_path`. Args: df_predict (SplinkDataFrame): The outputs of `linker.predict()` df_clustered (SplinkDataFrame): The outputs of `linker.cluster_pairwise_predictions_at_threshold()` out_path (str): The path (including filename) to save the html file to. sampling_method (str, optional): `random` or `by_cluster_size`. Defaults to `random`. sample_size (int, optional): Number of clusters to show in the dahboard. Defaults to 10. cluster_ids (list): The IDs of the clusters that will be displayed in the dashboard. If provided, ignore the `sampling_method` and `sample_size` arguments. Defaults to None. overwrite (bool, optional): Overwrite the html file if it already exists? Defaults to False. cluster_names (list, optional): If provided, the dashboard will display these names in the selection box. Ony works in conjunction with `cluster_ids`. Defaults to None. return_html_as_string: If True, return the html as a string Examples: >>> df_p = linker.predict() >>> df_c = linker.cluster_pairwise_predictions_at_threshold(df_p, 0.5) >>> linker.cluster_studio_dashboard( >>> df_p, df_c, [0, 4, 7], \"cluster_studio.html\" >>> ) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame(src=\"./cluster_studio.html\", width=\"100%\", height=1200) \"\"\" self . _raise_error_if_necessary_waterfall_columns_not_computed () rendered = render_splink_cluster_studio_html ( self , df_predict , df_clustered , out_path , sampling_method = sampling_method , sample_size = sample_size , cluster_ids = cluster_ids , overwrite = overwrite , cluster_names = cluster_names , ) if return_html_as_string : return rendered def save_settings_to_json ( self , out_path : str , overwrite = False ) -> dict : \"\"\"Save the configuration and parameters the linkage model to a `.json` file. The model can later be loaded back in using `linker.load_settings_from_json()` Examples: >>> linker.save_settings_to_json(\"my_settings.json\", overwrite=True) Args: out_path (str): File path for json file overwrite (bool, optional): Overwrite if already exists? Defaults to False. \"\"\" model_dict = self . _settings_obj . as_dict () if out_path : if os . path . isfile ( out_path ) and not overwrite : raise ValueError ( f \"The path { out_path } already exists. Please provide a different \" \"path or set overwrite=True\" ) with open ( out_path , \"w\" , encoding = \"utf-8\" ) as f : json . dump ( model_dict , f , indent = 4 ) def load_settings_from_json ( self , in_path : str ): \"\"\"Load settings from a `.json` file. This `.json` file would usually be the output of `linker.save_settings_to_json()` Examples: >>> linker.load_settings_from_json(\"my_settings.json\") Args: in_path (str): Path to settings json file \"\"\" with open ( in_path , \"r\" ) as f : model_dict = json . load ( f ) self . initialise_settings ( model_dict ) cluster_pairwise_predictions_at_threshold ( df_predict , threshold_match_probability ) \u00b6 Clusters the pairwise match predictions that result from linker.predict() into groups of connected record using the connected components graph clustering algorithm Records with an estimated match_probability above threshold_match_probability are considered to be a match (i.e. they represent the same entity). Parameters: Name Type Description Default df_predict SplinkDataFrame The results of linker.predict() required threshold_match_probability float Filter the pairwise match predictions to include only pairwise comparisons with a match_probability above this threshold. This dataframe is then fed into the clustering algorithm. required Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame containing a list of all IDs, clustered into groups based on the desired match threshold. Source code in splink/linker.py 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 def cluster_pairwise_predictions_at_threshold ( self , df_predict : SplinkDataFrame , threshold_match_probability : float ) -> SplinkDataFrame : \"\"\"Clusters the pairwise match predictions that result from `linker.predict()` into groups of connected record using the connected components graph clustering algorithm Records with an estimated `match_probability` above `threshold_match_probability` are considered to be a match (i.e. they represent the same entity). Args: df_predict (SplinkDataFrame): The results of `linker.predict()` threshold_match_probability (float): Filter the pairwise match predictions to include only pairwise comparisons with a match_probability above this threshold. This dataframe is then fed into the clustering algorithm. Returns: SplinkDataFrame: A SplinkDataFrame containing a list of all IDs, clustered into groups based on the desired match threshold. \"\"\" self . _initialise_df_concat_with_tf ( df_predict ) edges_table = _cc_create_unique_id_cols ( self , df_predict , threshold_match_probability , ) cc = solve_connected_components ( self , edges_table ) return cc compare_two_records ( record_1 , record_2 ) \u00b6 Use the linkage model to compare and score a pairwise record comparison based on the two input records provided Parameters: Name Type Description Default record_1 dict dictionary representing the first record. Columns names and data types must be the same as the columns in the settings object required record_2 dict dictionary representing the second record. Columns names and data types must be the same as the columns in the settings object required Examples: >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . compare_two_records ( record_left , record_right ) Returns: Name Type Description SplinkDataFrame Pairwise comparison with scored prediction Source code in splink/linker.py 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 def compare_two_records ( self , record_1 : dict , record_2 : dict ): \"\"\"Use the linkage model to compare and score a pairwise record comparison based on the two input records provided Args: record_1 (dict): dictionary representing the first record. Columns names and data types must be the same as the columns in the settings object record_2 (dict): dictionary representing the second record. Columns names and data types must be the same as the columns in the settings object Examples: >>> linker = DuckDBLinker(df) >>> linker.load_settings_from_json(\"saved_settings.json\") >>> linker.compare_two_records(record_left, record_right) Returns: SplinkDataFrame: Pairwise comparison with scored prediction \"\"\" original_blocking_rules = ( self . _settings_obj . _blocking_rules_to_generate_predictions ) original_link_type = self . _settings_obj . _link_type self . _compare_two_records_mode = True self . _settings_obj . _blocking_rules_to_generate_predictions = [] self . _records_to_table ([ record_1 ], \"__splink__compare_two_records_left\" ) self . _records_to_table ([ record_2 ], \"__splink__compare_two_records_right\" ) sql_join_tf = _join_tf_to_input_df_sql ( self ) sql_join_tf = sql_join_tf . replace ( \"__splink__df_concat\" , \"__splink__compare_two_records_left\" ) self . _enqueue_sql ( sql_join_tf , \"__splink__compare_two_records_left_with_tf\" ) sql_join_tf = sql_join_tf . replace ( \"__splink__compare_two_records_left\" , \"__splink__compare_two_records_right\" ) self . _enqueue_sql ( sql_join_tf , \"__splink__compare_two_records_right_with_tf\" ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) predictions = self . _execute_sql_pipeline ( use_cache = False ) self . _settings_obj . _blocking_rules_to_generate_predictions = ( original_blocking_rules ) self . _settings_obj . _link_type = original_link_type self . _compare_two_records_mode = False return predictions compute_tf_table ( column_name ) \u00b6 Compute a term frequency table for a given column and persist to the database This method is useful if you want to pre-compute term frequency tables e.g. so that real time linkage executes faster, or so that you can estimate various models without having to recompute term frequency tables each time Examples: >>> # Example 1: Real time linkage >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . compute_tf_table ( \"surname\" ) >>> linker . compare_two_records ( record_left , record_right ) >>> # Example 2: Pre-computed term frequency tables in Spark >>> linker = SparkLinker ( df ) >>> df_first_name_tf = linker . compute_tf_table ( \"first_name\" ) >>> df_first_name_tf . write . parquet ( \"folder/first_name_tf\" ) >>> >>> # On subsequent data linking job, read this table rather than recompute >>> df_first_name_tf = spark . read . parquet ( \"folder/first_name_tf\" ) >>> df_first_name_tf . createOrReplaceTempView ( \"__splink__df_tf_first_name\" ) Parameters: Name Type Description Default column_name str The column name in the input table required Returns: Name Type Description SplinkDataFrame SplinkDataFrame The resultant table as a splink data frame Source code in splink/linker.py 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 def compute_tf_table ( self , column_name : str ) -> SplinkDataFrame : \"\"\"Compute a term frequency table for a given column and persist to the database This method is useful if you want to pre-compute term frequency tables e.g. so that real time linkage executes faster, or so that you can estimate various models without having to recompute term frequency tables each time Examples: >>> # Example 1: Real time linkage >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.load_settings_from_json(\"saved_settings.json\") >>> linker.compute_tf_table(\"surname\") >>> linker.compare_two_records(record_left, record_right) >>> # Example 2: Pre-computed term frequency tables in Spark >>> linker = SparkLinker(df) >>> df_first_name_tf = linker.compute_tf_table(\"first_name\") >>> df_first_name_tf.write.parquet(\"folder/first_name_tf\") >>> >>> # On subsequent data linking job, read this table rather than recompute >>> df_first_name_tf = spark.read.parquet(\"folder/first_name_tf\") >>> df_first_name_tf.createOrReplaceTempView(\"__splink__df_tf_first_name\") Args: column_name (str): The column name in the input table Returns: SplinkDataFrame: The resultant table as a splink data frame \"\"\" sql = vertically_concatenate_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_concat\" ) input_col = InputColumn ( column_name , tf_adjustments = True ) sql = term_frequencies_for_single_column_sql ( input_col ) self . _enqueue_sql ( sql , colname_to_tf_tablename ( input_col )) return self . _execute_sql_pipeline ( materialise_as_hash = False ) deterministic_link () \u00b6 Uses the blocking rules specified by blocking_rules_to_generate_predictions in the settings dictionary to generate pairwise record comparisons. For deterministic linkage, this should be a list of blocking rules which are strict enough to generate only true links. Deterministic linkage, however, is likely to result in missed links (false negatives). Examples: >>> linker = DuckDBLinker ( df ) >>> >>> settings = { >>> \"link_type\" : \"dedupe_only\" , >>> \"blocking_rules_to_generate_predictions\" : [ >>> \"l.first_name = r.first_name\" , >>> \"l.surname = r.surname\" , >>> ], >>> \"comparisons\" : [] >>> } >>> >>> from splink.duckdb.duckdb_linker import DuckDBLinker >>> >>> linker = DuckDBLinker ( df , settings ) >>> df = linker . deterministic_link () Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. Source code in splink/linker.py 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 def deterministic_link ( self ) -> SplinkDataFrame : \"\"\"Uses the blocking rules specified by `blocking_rules_to_generate_predictions` in the settings dictionary to generate pairwise record comparisons. For deterministic linkage, this should be a list of blocking rules which are strict enough to generate only true links. Deterministic linkage, however, is likely to result in missed links (false negatives). Examples: >>> linker = DuckDBLinker(df) >>> >>> settings = { >>> \"link_type\": \"dedupe_only\", >>> \"blocking_rules_to_generate_predictions\": [ >>> \"l.first_name = r.first_name\", >>> \"l.surname = r.surname\", >>> ], >>> \"comparisons\": [] >>> } >>> >>> from splink.duckdb.duckdb_linker import DuckDBLinker >>> >>> linker = DuckDBLinker(df, settings) >>> df = linker.deterministic_link() Returns: SplinkDataFrame: A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. \"\"\" self . _initialise_df_concat_with_tf () sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) return self . _execute_sql_pipeline () find_matches_to_new_records ( records_or_tablename , blocking_rules = [], match_weight_threshold =- 4 ) \u00b6 Given one or more records, find records in the input dataset(s) which match and return in order of the splink prediction score. This effectively provides a way of searching the input datasets for given record(s) Parameters: Name Type Description Default records_or_tablename List [ dict ] Input search record(s) as list of dict, or a table registered to the database. required blocking_rules list Blocking rules to select which records to find and score. If [], do not use a blocking rule - meaning the input records will be compared to all records provided to the linker when it was instantiated. Defaults to []. [] match_weight_threshold int Return matches with a match weight above this threshold. Defaults to -4. -4 Examples: >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> # Pre-compute tf tables for any tables with >>> # term frequency adjustments >>> linker . compute_tf_table ( \"first_name\" ) >>> record = { 'unique_id' : 1 , >>> 'first_name' : \"John\" , >>> 'surname' : \"Smith\" , >>> 'dob' : \"1971-05-24\" , >>> 'city' : \"London\" , >>> 'email' : \"john@smith.net\" >>> } >>> df = linker . find_matches_to_new_records ([ record ], blocking_rules = []) Returns: Name Type Description SplinkDataFrame SplinkDataFrame The pairwise comparisons. Source code in splink/linker.py 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 def find_matches_to_new_records ( self , records_or_tablename , blocking_rules = [], match_weight_threshold =- 4 , ) -> SplinkDataFrame : \"\"\"Given one or more records, find records in the input dataset(s) which match and return in order of the splink prediction score. This effectively provides a way of searching the input datasets for given record(s) Args: records_or_tablename (List[dict]): Input search record(s) as list of dict, or a table registered to the database. blocking_rules (list, optional): Blocking rules to select which records to find and score. If [], do not use a blocking rule - meaning the input records will be compared to all records provided to the linker when it was instantiated. Defaults to []. match_weight_threshold (int, optional): Return matches with a match weight above this threshold. Defaults to -4. Examples: >>> linker = DuckDBLinker(df) >>> linker.load_settings_from_json(\"saved_settings.json\") >>> # Pre-compute tf tables for any tables with >>> # term frequency adjustments >>> linker.compute_tf_table(\"first_name\") >>> record = {'unique_id': 1, >>> 'first_name': \"John\", >>> 'surname': \"Smith\", >>> 'dob': \"1971-05-24\", >>> 'city': \"London\", >>> 'email': \"john@smith.net\" >>> } >>> df = linker.find_matches_to_new_records([record], blocking_rules=[]) Returns: SplinkDataFrame: The pairwise comparisons. \"\"\" original_blocking_rules = ( self . _settings_obj . _blocking_rules_to_generate_predictions ) original_link_type = self . _settings_obj . _link_type if not isinstance ( records_or_tablename , str ): self . _records_to_table ( records_or_tablename , \"__splink__df_new_records\" ) new_records_tablename = \"__splink__df_new_records\" else : new_records_tablename = records_or_tablename blocking_rules = [ BlockingRule ( r ) if not isinstance ( r , BlockingRule ) else r for r in blocking_rules ] self . _settings_obj . _blocking_rules_to_generate_predictions = blocking_rules self . _settings_obj . _link_type = \"link_only_find_matches_to_new_records\" self . _find_new_matches_mode = True sql = _join_tf_to_input_df_sql ( self ) sql = sql . replace ( \"__splink__df_concat\" , new_records_tablename ) self . _enqueue_sql ( sql , \"__splink__df_new_records_with_tf\" ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) sql = f \"\"\" select * from __splink__df_predict where match_weight > { match_weight_threshold } \"\"\" self . _enqueue_sql ( sql , \"__splink_find_matches_predictions\" ) predictions = self . _execute_sql_pipeline ( use_cache = False ) self . _settings_obj . _blocking_rules_to_generate_predictions = ( original_blocking_rules ) self . _settings_obj . _link_type = original_link_type self . _find_new_matches_mode = False return predictions load_settings_from_json ( in_path ) \u00b6 Load settings from a .json file. This .json file would usually be the output of linker.save_settings_to_json() Examples: >>> linker . load_settings_from_json ( \"my_settings.json\" ) Parameters: Name Type Description Default in_path str Path to settings json file required Source code in splink/linker.py 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 def load_settings_from_json ( self , in_path : str ): \"\"\"Load settings from a `.json` file. This `.json` file would usually be the output of `linker.save_settings_to_json()` Examples: >>> linker.load_settings_from_json(\"my_settings.json\") Args: in_path (str): Path to settings json file \"\"\" with open ( in_path , \"r\" ) as f : model_dict = json . load ( f ) self . initialise_settings ( model_dict ) predict ( threshold_match_probability = None , threshold_match_weight = None ) \u00b6 Create a dataframe of scored pairwise comparisons using the parameters of the linkage model. Uses the blocking rules specified in the blocking_rules_to_generate_predictions of the settings dictionary to generate the pairwise comparisons. Parameters: Name Type Description Default threshold_match_probability float If specified, filter the results to include only pairwise comparisons with a match_probability above this threshold. Defaults to None. None threshold_match_weight float If specified, filter the results to include only pairwise comparisons with a match_weight above this threshold. Defaults to None. None Examples: >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> df = linker . predict ( threshold_match_probability = 0.95 ) >>> df . as_pandas_dataframe ( limit = 5 ) Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. Source code in splink/linker.py 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 def predict ( self , threshold_match_probability : float = None , threshold_match_weight : float = None , ) -> SplinkDataFrame : \"\"\"Create a dataframe of scored pairwise comparisons using the parameters of the linkage model. Uses the blocking rules specified in the `blocking_rules_to_generate_predictions` of the settings dictionary to generate the pairwise comparisons. Args: threshold_match_probability (float, optional): If specified, filter the results to include only pairwise comparisons with a match_probability above this threshold. Defaults to None. threshold_match_weight (float, optional): If specified, filter the results to include only pairwise comparisons with a match_weight above this threshold. Defaults to None. Examples: >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.load_settings_from_json(\"saved_settings.json\") >>> df = linker.predict(threshold_match_probability=0.95) >>> df.as_pandas_dataframe(limit=5) Returns: SplinkDataFrame: A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. \"\"\" # If the user only calls predict, it runs as a single pipeline with no # materialisation of anything self . _initialise_df_concat_with_tf ( materialise = False ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) repartition_after_blocking = getattr ( self , \"repartition_after_blocking\" , False ) # repartition after blocking only exists on the SparkLinker if repartition_after_blocking : df_blocked = self . _execute_sql_pipeline () input_dataframes = [ df_blocked ] else : input_dataframes = [] sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj , threshold_match_probability , threshold_match_weight ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) predictions = self . _execute_sql_pipeline ( input_dataframes ) self . _predict_warning () return predictions","title":"Predicting results"},{"location":"linkerpred.html#documentation-for-linker-object-methods-related-to-link-prediction","text":"The Linker object manages the data linkage process and holds the data linkage model. Most of Splink's functionality can be accessed by calling methods (functions) on the linker, such as linker.predict() , linker.profile_columns() etc. The Linker class is intended for subclassing for specific backends, e.g. a DuckDBLinker . Source code in splink/linker.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 class Linker : \"\"\"The Linker object manages the data linkage process and holds the data linkage model. Most of Splink's functionality can be accessed by calling methods (functions) on the linker, such as `linker.predict()`, `linker.profile_columns()` etc. The Linker class is intended for subclassing for specific backends, e.g. a `DuckDBLinker`. \"\"\" def __init__ ( self , input_table_or_tables : Union [ str , list ], settings_dict : dict = None , set_up_basic_logging : bool = True , input_table_aliases : Union [ str , list ] = None , ): \"\"\"Initialise the linker object, which manages the data linkage process and holds the data linkage model. Examples: >>> # Example 1: DuckDB >>> df = pd.read_csv(\"data_to_dedupe.csv\") >>> linker = DuckDBLinker(df, settings_dict) >>> # Example 2: Spark >>> df_1 = spark.read.parquet(\"table_1/\") >>> df_2 = spark.read.parquet(\"table_2/\") >>> linker = SparkLinker( >>> [df_1, df_2], >>> settings_dict, >>> input_table_aliases=[\"customers\", \"contact_center_callers\"] >>> ) Args: input_table_or_tables (Union[str, list]): Input data into the linkage model. Either a single string (the name of a table in a database) for deduplication jobs, or a list of strings (the name of tables in a database) for link_only or link_and_dedupe. For some linkers, such as the DuckDBLinker and the SparkLinker, it's also possible to pass in dataframes (Pandas and Spark respectively) rather than strings. settings_dict (dict, optional): A Splink settings dictionary. If not provided when the object is created, can later be added using `linker.initialise_settings()` Defaults to None. set_up_basic_logging (bool, optional): If true, sets ups up basic logging so that Splink sends messages at INFO level to stdout. Defaults to True. input_table_aliases (Union[str, list], optional): Labels assigned to input tables in Splink outputs. If the names of the tables in the input database are long or unspecific, this argument can be used to attach more easily readable/interpretable names. Defaults to None. \"\"\" if set_up_basic_logging : logging . basicConfig ( format = \" %(message)s \" , ) splink_logger = logging . getLogger ( \"splink\" ) splink_logger . setLevel ( logging . INFO ) self . _pipeline = SQLPipeline () self . _settings_dict = settings_dict if settings_dict is None : self . _settings_obj_ = None else : self . _settings_obj_ = Settings ( settings_dict ) self . _input_tables_dict = self . _get_input_tables_dict ( input_table_or_tables , input_table_aliases ) self . _validate_input_dfs () self . _em_training_sessions = [] self . _names_of_tables_created_by_splink : list = [] self . _find_new_matches_mode = False self . _train_u_using_random_sample_mode = False self . _compare_two_records_mode = False self . _self_link_mode = False self . _output_schema = \"\" self . debug_mode = False @property def _settings_obj ( self ) -> Settings : if self . _settings_obj_ is None : raise ValueError ( \"You did not provide a settings dictionary when you \" \"created the linker. To continue, you need to provide a settings \" \"dictionary using the `initialise_settings()` method on your linker \" \"object. i.e. linker.initialise_settings(settings_dict)\" ) return self . _settings_obj_ @property def _input_tablename_l ( self ): if self . _find_new_matches_mode : return \"__splink__df_concat_with_tf\" if self . _self_link_mode : return \"__splink__df_concat_with_tf\" if self . _compare_two_records_mode : return \"__splink__compare_two_records_left_with_tf\" if self . _train_u_using_random_sample_mode : return \"__splink__df_concat_with_tf_sample\" if self . _two_dataset_link_only : return \"__splink_df_concat_with_tf_left\" return \"__splink__df_concat_with_tf\" @property def _input_tablename_r ( self ): if self . _find_new_matches_mode : return \"__splink__df_new_records_with_tf\" if self . _self_link_mode : return \"__splink__df_concat_with_tf\" if self . _compare_two_records_mode : return \"__splink__compare_two_records_right_with_tf\" if self . _train_u_using_random_sample_mode : return \"__splink__df_concat_with_tf_sample\" if self . _two_dataset_link_only : return \"__splink_df_concat_with_tf_right\" return \"__splink__df_concat_with_tf\" @property def _two_dataset_link_only ( self ): # Two dataset link only join is a special case where an inner join of the # two datasets is much more efficient than self-joining the vertically # concatenation of all input datasets if self . _find_new_matches_mode : return True if self . _compare_two_records_mode : return True if ( len ( self . _input_tables_dict ) == 2 and self . _settings_obj . _link_type == \"link_only\" ): return True else : return False def _prepend_schema_to_table_name ( self , table_name ): if self . _output_schema : return f \" { self . _output_schema } . { table_name } \" else : return table_name def _initialise_df_concat ( self , materialise = True ): if self . _table_exists_in_database ( \"__splink__df_concat\" ): return sql = vertically_concatenate_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_concat\" ) self . _execute_sql_pipeline ( materialise_as_hash = False ) def _initialise_df_concat_with_tf ( self , materialise = True ): if self . _table_exists_in_database ( \"__splink__df_concat_with_tf\" ): return sql = vertically_concatenate_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_concat\" ) sqls = compute_all_term_frequencies_sqls ( self ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) if self . _two_dataset_link_only : # If we do not materialise __splink_df_concat_with_tf # we'd have to run all the code up to this point twice self . _execute_sql_pipeline ( materialise_as_hash = False ) source_dataset_col = self . _settings_obj . _source_dataset_column_name # Need df_l to be the one with the lowest id to preeserve the property # that the left dataset is the one with the lowest concatenated id keys = self . _input_tables_dict . keys () keys = list ( sorted ( keys )) df_l = self . _input_tables_dict [ keys [ 0 ]] df_r = self . _input_tables_dict [ keys [ 1 ]] sql = f \"\"\" select * from __splink__df_concat_with_tf where { source_dataset_col } = ' { df_l . templated_name } ' \"\"\" self . _enqueue_sql ( sql , \"__splink_df_concat_with_tf_left\" ) self . _execute_sql_pipeline ( materialise_as_hash = False ) sql = f \"\"\" select * from __splink__df_concat_with_tf where { source_dataset_col } = ' { df_r . templated_name } ' \"\"\" self . _enqueue_sql ( sql , \"__splink_df_concat_with_tf_right\" ) self . _execute_sql_pipeline ( materialise_as_hash = False ) else : if materialise : self . _execute_sql_pipeline ( materialise_as_hash = False ) def _table_to_splink_dataframe ( self , templated_name , physical_name ) -> SplinkDataFrame : \"\"\"Create a SplinkDataframe from a table in the underlying database called `physical_name`. Associate a `templated_name` with this table, which signifies the purpose or 'meaning' of this table to splink. (e.g. `__splink__df_blocked`) Args: templated_name (str): The purpose of the table to Splink physical_name (str): The name of the table in the underlying databse \"\"\" raise NotImplementedError ( \"_table_to_splink_dataframe not implemented on this linker\" ) def _enqueue_sql ( self , sql , output_table_name ): \"\"\"Add sql to the current pipeline, but do not execute the pipeline.\"\"\" self . _pipeline . enqueue_sql ( sql , output_table_name ) def _execute_sql_pipeline ( self , input_dataframes : List [ SplinkDataFrame ] = [], materialise_as_hash = True , use_cache = True , transpile = True , ) -> SplinkDataFrame : \"\"\"Execute the SQL queued in the current pipeline as a single statement e.g. `with a as (), b as , c as (), select ... from c`, then execute the pipeline, returning the resultant table as a SplinkDataFrame Args: input_dataframes (List[SplinkDataFrame], optional): A 'starting point' of SplinkDataFrames if needed. Defaults to []. materialise_as_hash (bool, optional): If true, the output tablename will end in a unique identifer. Defaults to True. use_cache (bool, optional): If true, look at whether the SQL pipeline has been executed before, and if so, use the existing result. Defaults to True. transpile (bool, optional): Transpile the SQL using SQLGlot. Defaults to True. Returns: SplinkDataFrame: An abstraction representing the table created by the sql pipeline \"\"\" if not self . debug_mode : sql_gen = self . _pipeline . _generate_pipeline ( input_dataframes ) output_tablename_templated = self . _pipeline . queue [ - 1 ] . output_table_name dataframe = self . _sql_to_splink_dataframe_checking_cache ( sql_gen , output_tablename_templated , materialise_as_hash , use_cache , transpile , ) self . _pipeline . reset () return dataframe else : # In debug mode, we do not pipeline the sql and print the # results of each part of the pipeline for task in self . _pipeline . _generate_pipeline_parts ( input_dataframes ): output_tablename = task . output_table_name sql = task . sql print ( \"------\" ) print ( f \"--------Creating table: { output_tablename } --------\" ) dataframe = self . _sql_to_splink_dataframe_checking_cache ( sql , output_tablename , materialise_as_hash = False , use_cache = False , transpile = transpile , ) self . _pipeline . reset () return dataframe def _execute_sql_against_backend ( self , sql , templated_name , physical_name , transpile = True ): raise NotImplementedError ( f \"_execute_sql_against_backend not implemented for { type ( self ) } \" ) def _sql_to_splink_dataframe_checking_cache ( self , sql , output_tablename_templated , materialise_as_hash = True , use_cache = True , transpile = True , ) -> SplinkDataFrame : \"\"\"Execute sql, or if identical sql has been run before, return cached results. This function - is used by _execute_sql_pipeline to to execute SQL - or can be used directly if you have a single SQL statement that's not in a pipeline Return a SplinkDataFrame representing the results of the SQL \"\"\" hash = hashlib . sha256 ( sql . encode ()) . hexdigest ()[: 7 ] # Ensure hash is valid sql table name table_name_hash = f \" { output_tablename_templated } _ { hash } \" if use_cache : if self . _table_exists_in_database ( output_tablename_templated ): logger . debug ( f \"Using existing table { output_tablename_templated } \" ) return self . _table_to_splink_dataframe ( output_tablename_templated , output_tablename_templated ) if self . _table_exists_in_database ( table_name_hash ): logger . debug ( f \"Using cache for { output_tablename_templated } \" f \" with physical name { table_name_hash } \" ) return self . _table_to_splink_dataframe ( output_tablename_templated , table_name_hash ) if self . debug_mode : print ( sql ) if materialise_as_hash : splink_dataframe = self . _execute_sql_against_backend ( sql , output_tablename_templated , table_name_hash , transpile = transpile ) else : splink_dataframe = self . _execute_sql_against_backend ( sql , output_tablename_templated , output_tablename_templated , transpile = transpile , ) self . _names_of_tables_created_by_splink . append ( splink_dataframe . physical_name ) if self . debug_mode : df_pd = splink_dataframe . as_pandas_dataframe () try : from IPython.display import display display ( df_pd ) except ModuleNotFoundError : print ( df_pd ) return splink_dataframe def __deepcopy__ ( self , memo ): \"\"\"When we do EM training, we need a copy of the linker which is independent of the main linker e.g. setting parameters on the copy will not affect the main linker. This method implements ensures linker can be deepcopied. \"\"\" new_linker = copy ( self ) new_linker . _em_training_sessions = [] new_settings = deepcopy ( self . _settings_obj ) new_linker . _settings_obj_ = new_settings return new_linker def _ensure_aliases_populated_and_is_list ( self , input_table_or_tables , input_table_aliases ): if input_table_aliases is None : input_table_aliases = input_table_or_tables input_table_aliases = ensure_is_list ( input_table_aliases ) return input_table_aliases def _get_input_tables_dict ( self , input_table_or_tables , input_table_aliases ): input_table_or_tables = ensure_is_list ( input_table_or_tables ) input_table_aliases = self . _ensure_aliases_populated_and_is_list ( input_table_or_tables , input_table_aliases ) d = {} for table_name , table_alias in zip ( input_table_or_tables , input_table_aliases ): d [ table_alias ] = self . _table_to_splink_dataframe ( table_alias , table_name ) return d def _get_input_tf_dict ( self , df_dict ): d = {} for df_name , df_value in df_dict . items (): renamed = colname_to_tf_tablename ( df_name ) d [ renamed ] = self . _table_to_splink_dataframe ( renamed , df_value ) return d def _predict_warning ( self ): if not self . _settings_obj . _is_fully_trained : msg = ( \" \\n -- WARNING -- \\n \" \"You have called predict(), but there are some parameter \" \"estimates which have neither been estimated or specified in your \" \"settings dictionary. To produce predictions the following\" \" untrained trained parameters will use default values.\" ) messages = self . _settings_obj . _not_trained_messages () warn_message = \" \\n \" . join ([ msg ] + messages ) logger . warning ( warn_message ) def _table_exists_in_database ( self , table_name ): raise NotImplementedError ( f \"table_exists_in_database not implemented for { type ( self ) } \" ) def _validate_input_dfs ( self ): for df in self . _input_tables_dict . values (): df . validate () if self . _settings_obj_ is not None : if self . _settings_obj . _link_type == \"dedupe_only\" : if len ( self . _input_tables_dict ) > 1 : raise ValueError ( 'If link_type = \"dedupe only\" then input tables must contain ' \"only a single input table\" , ) def _populate_probability_two_random_records_match_from_trained_values ( self ): recip_prop_matches_estimates = [] logger . log ( 15 , ( \"---- Using training sessions to compute \" \"probability two random records match ----\" ), ) for em_training_session in self . _em_training_sessions : training_lambda = ( em_training_session . _settings_obj . _probability_two_random_records_match ) training_lambda_bf = prob_to_bayes_factor ( training_lambda ) reverse_levels = ( em_training_session . _comparison_levels_to_reverse_blocking_rule ) logger . log ( 15 , \" \\n \" f \"Probability two random records match from trained model blocking on \" f \" { em_training_session . _blocking_rule_for_training . blocking_rule } : \" f \" { training_lambda : ,.3f } \" , ) for reverse_level in reverse_levels : # Get comparison level on current settings obj cc = self . _settings_obj . _get_comparison_by_output_column_name ( reverse_level . comparison . _output_column_name ) cl = cc . _get_comparison_level_by_comparison_vector_value ( reverse_level . _comparison_vector_value ) if cl . _has_estimated_values : bf = cl . _trained_m_median / cl . _trained_u_median else : bf = cl . _bayes_factor logger . log ( 15 , f \"Reversing comparison level { cc . _output_column_name } \" f \" using bayes factor { bf : ,.3f } \" , ) training_lambda_bf = training_lambda_bf / bf as_prob = bayes_factor_to_prob ( training_lambda_bf ) logger . log ( 15 , ( \"This estimate of probability two random records match now: \" f \" { as_prob : ,.3f } \" f \"with reciprocal { ( 1 / as_prob ) : ,.3f } \" ), ) logger . log ( 15 , \" \\n ---------\" ) p = bayes_factor_to_prob ( training_lambda_bf ) recip_prop_matches_estimates . append ( 1 / p ) prop_matches_estimate = 1 / median ( recip_prop_matches_estimates ) self . _settings_obj . _probability_two_random_records_match = prop_matches_estimate logger . log ( 15 , \" \\n Median of prop of matches estimates: \" f \" { self . _settings_obj . _probability_two_random_records_match : ,.3f } \" \"reciprocal \" f \" { 1 / self . _settings_obj . _probability_two_random_records_match : ,.3f } \" , ) def _records_to_table ( records , as_table_name ): # Create table in database containing records # Probably quite difficult to implement correctly # Due to data type issues. raise NotImplementedError def _populate_m_u_from_trained_values ( self ): ccs = self . _settings_obj . comparisons for cc in ccs : for cl in cc . _comparison_levels_excluding_null : if cl . _has_estimated_u_values : cl . u_probability = cl . _trained_u_median if cl . _has_estimated_m_values : cl . m_probability = cl . _trained_m_median def _delete_tables_created_by_splink_from_db ( self , retain_term_frequency = True , retain_df_concat_with_tf = True ): tables_remaining = [] for name in self . _names_of_tables_created_by_splink : # Only delete tables explicitly marked as having been created by splink if \"__splink__\" not in name : tables_remaining . append ( name ) continue if name == \"__splink__df_concat_with_tf\" : if retain_df_concat_with_tf : tables_remaining . append ( name ) else : self . _delete_table_from_database ( name ) elif name . startswith ( \"__splink__df_tf_\" ): if retain_term_frequency : tables_remaining . append ( name ) else : self . _delete_table_from_database ( name ) else : self . _delete_table_from_database ( name ) self . _names_of_tables_created_by_splink = tables_remaining def _raise_error_if_necessary_waterfall_columns_not_computed ( self ): ricc = self . _settings_obj . _retain_intermediate_calculation_columns rmc = self . _settings_obj . _retain_matching_columns if not ( ricc and rmc ): raise ValueError ( \"retain_intermediate_calculation_columns and \" \"retain_matching_columns must both be set to True in your settings\" \" dictionary to use this function, because otherwise the necessary \" \"columns will not be available in the input records.\" f \" Their current values are { ricc } and { rmc } , respectively. \" \"Please re-run your linkage with them both set to True.\" ) def initialise_settings ( self , settings_dict : dict ): \"\"\"Initialise settings for the linker. To be used if settings were not passed to the linker on creation. Examples: >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.profile_columns([\"first_name\", \"surname\"]) >>> linker.initialise_settings(settings_dict) Args: settings_dict (dict): A Splink settings dictionary \"\"\" self . _settings_dict = settings_dict self . _settings_obj_ = Settings ( settings_dict ) self . _validate_input_dfs () def compute_tf_table ( self , column_name : str ) -> SplinkDataFrame : \"\"\"Compute a term frequency table for a given column and persist to the database This method is useful if you want to pre-compute term frequency tables e.g. so that real time linkage executes faster, or so that you can estimate various models without having to recompute term frequency tables each time Examples: >>> # Example 1: Real time linkage >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.load_settings_from_json(\"saved_settings.json\") >>> linker.compute_tf_table(\"surname\") >>> linker.compare_two_records(record_left, record_right) >>> # Example 2: Pre-computed term frequency tables in Spark >>> linker = SparkLinker(df) >>> df_first_name_tf = linker.compute_tf_table(\"first_name\") >>> df_first_name_tf.write.parquet(\"folder/first_name_tf\") >>> >>> # On subsequent data linking job, read this table rather than recompute >>> df_first_name_tf = spark.read.parquet(\"folder/first_name_tf\") >>> df_first_name_tf.createOrReplaceTempView(\"__splink__df_tf_first_name\") Args: column_name (str): The column name in the input table Returns: SplinkDataFrame: The resultant table as a splink data frame \"\"\" sql = vertically_concatenate_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_concat\" ) input_col = InputColumn ( column_name , tf_adjustments = True ) sql = term_frequencies_for_single_column_sql ( input_col ) self . _enqueue_sql ( sql , colname_to_tf_tablename ( input_col )) return self . _execute_sql_pipeline ( materialise_as_hash = False ) def deterministic_link ( self ) -> SplinkDataFrame : \"\"\"Uses the blocking rules specified by `blocking_rules_to_generate_predictions` in the settings dictionary to generate pairwise record comparisons. For deterministic linkage, this should be a list of blocking rules which are strict enough to generate only true links. Deterministic linkage, however, is likely to result in missed links (false negatives). Examples: >>> linker = DuckDBLinker(df) >>> >>> settings = { >>> \"link_type\": \"dedupe_only\", >>> \"blocking_rules_to_generate_predictions\": [ >>> \"l.first_name = r.first_name\", >>> \"l.surname = r.surname\", >>> ], >>> \"comparisons\": [] >>> } >>> >>> from splink.duckdb.duckdb_linker import DuckDBLinker >>> >>> linker = DuckDBLinker(df, settings) >>> df = linker.deterministic_link() Returns: SplinkDataFrame: A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. \"\"\" self . _initialise_df_concat_with_tf () sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) return self . _execute_sql_pipeline () def estimate_u_using_random_sampling ( self , target_rows : int ): \"\"\"Estimate the u parameters of the linkage model using random sampling. The u parameters represent the proportion of record comparisons that fall into each comparison level amongst truly non-matching records. This procedure takes a sample of the data and generates the cartesian product of pairwise record comparisons amongst the sampled records. The validity of the u values rests on the assumption that the resultant pairwise comparisons are non-matches (or at least, they are very unlikely to be matches). For large datasets, this is typically true. Args: target_rows (int): The target number of pairwise record comparisons from which to derive the u values. Larger will give more accurate estimates but lead to longer runtimes. In our experience at least 1e9 (one billion) gives best results but can take a long time to compute. 1e7 (ten million) is often adequate whilst testing different model specifications, before the final model is estimated. Examples: >>> linker.estimate_u_using_random_sampling(1e8) Returns: None: Updates the estimated u parameters within the linker object and returns nothing. \"\"\" self . _initialise_df_concat_with_tf ( materialise = True ) estimate_u_values ( self , target_rows ) self . _populate_m_u_from_trained_values () self . _settings_obj . _columns_without_estimated_parameters_message () def estimate_m_from_label_column ( self , label_colname : str ): \"\"\"Estimate the m parameters of the linkage model from a label (ground truth) column in the input dataframe(s). The m parameters represent the proportion of record comparisons that fall into each comparison level amongst truly matching records. The ground truth column is used to generate pairwise record comparisons which are then assumed to be matches. For example, if the entity being matched is persons, and your input dataset(s) contain social security number, this could be used to estimate the m values for the model. Note that this column does not need to be fully populated. A common case is where a unique identifier such as social security number is only partially populated. Args: label_colname (str): The name of the column containing the ground truth label in the input data. Examples: >>> linker.estimate_m_from_label_column(\"social_security_number\") Returns: Updates the estimated m parameters within the linker object and returns nothing. \"\"\" self . _initialise_df_concat_with_tf ( materialise = True ) estimate_m_values_from_label_column ( self , self . _input_tables_dict , label_colname ) self . _populate_m_u_from_trained_values () self . _settings_obj . _columns_without_estimated_parameters_message () def estimate_parameters_using_expectation_maximisation ( self , blocking_rule : str , comparisons_to_deactivate : List [ Union [ str , Comparison ]] = None , comparison_levels_to_reverse_blocking_rule : List [ ComparisonLevel ] = None , fix_probability_two_random_records_match : bool = False , fix_m_probabilities = False , fix_u_probabilities = True , ) -> EMTrainingSession : \"\"\"Estimate the parameters of the linkage model using expectation maximisation. By default, the m probabilities are estimated, but not the u probabilities, because good estiamtes for the u probabilities can be obtained from `linker.estimate_u_using_random_sampling()`. You can change this by setting `fix_u_probabilities` to False. The blocking rule provided is used to generate pairwise record comparisons. Usually, this should be a blocking rule that results in a dataframe where matches are between about 1% and 99% of the comparisons. By default, m parameters are estimated for all comparisons except those which are included in the blocking rule. For example, if the blocking rule is `l.first_name = r.first_name`, then parameter esimates will be made for all comparison except those which use `first_name` in their sql_condition By default, the probability two random records match is estimated for the blocked data, and then the m and u parameters for the columns specified in the blocking rules are used to estiamte the global probability two random records match. To control which comparisons should have their parameter estimated, and the process of 'reversing out' the global probability two random records match, the user may specify `comparisons_to_deactivate` and `comparison_levels_to_reverse_blocking_rule`. This is useful, for example if you block on the dmetaphone of a column but match on the original column. Examples: >>> # Default behaviour >>> br_training = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker.estimate_parameters_using_expectation_maximisation(br_training) >>> # Specify which comparisons to deactivate >>> br_training = \"l.dmeta_first_name = r.dmeta_first_name\" >>> settings_obj = linker._settings_obj >>> comp = settings_obj._get_comparison_by_output_column_name(\"first_name\") >>> dmeta_level = comp._get_comparison_level_by_comparison_vector_value(1) >>> linker.estimate_parameters_using_expectation_maximisation( >>> br_training, >>> comparisons_to_deactivate=[\"first_name\"], >>> comparison_levels_to_reverse_blocking_rule=[dmeta_level], >>> ) Args: blocking_rule (str): The blocking rule used to generate pairwise record comparisons. comparisons_to_deactivate (list, optional): By default, splink will analyse the blocking rule provided and estimate the m parameters for all comaprisons except those included in the blocking rule. If comparisons_to_deactivate are provided, spink will instead estimate m parameters for all comparison except those specified in the comparisons_to_deactivate list. This list can either contain the output_column_name of the Comparison as a string, or Comparison objects. Defaults to None. comparison_levels_to_reverse_blocking_rule (list, optional): By default, splink will analyse the blocking rule provided and adjust the global probability two random records match to account for the matches specified in the blocking rule. If provided, this argument will overrule this default behaviour. The user must provide a list of ComparisonLevel objects. Defaults to None. fix_probability_two_random_records_match (bool, optional): If True, do not update the probability two random records match after each iteration. Defaults to False. fix_m_probabilities (bool, optional): If True, do not update the m probabilities after each iteration. Defaults to False. fix_u_probabilities (bool, optional): If True, do not update the u probabilities after each iteration. Defaults to True. Examples: >>> blocking_rule = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker.estimate_parameters_using_expectation_maximisation(blocking_rule) Returns: EMTrainingSession: An object containing information about the training session such as how parameters changed during the iteration history \"\"\" self . _initialise_df_concat_with_tf ( materialise = True ) if comparisons_to_deactivate : # If user provided a string, convert to Comparison object comparisons_to_deactivate = [ self . _settings_obj . _get_comparison_by_output_column_name ( n ) if isinstance ( n , str ) else n for n in comparisons_to_deactivate ] if comparison_levels_to_reverse_blocking_rule is None : logger . warning ( \" \\n WARNING: \\n \" \"You have provided comparisons_to_deactivate but not \" \"comparison_levels_to_reverse_blocking_rule. \\n \" \"If comparisons_to_deactivate is provided, then \" \"you usually need to provide corresponding \" \"comparison_levels_to_reverse_blocking_rule. \" \"because each comparison to deactivate if effectively treated \" \"as an exact match.\" ) em_training_session = EMTrainingSession ( self , blocking_rule , fix_u_probabilities = fix_u_probabilities , fix_m_probabilities = fix_m_probabilities , fix_probability_two_random_records_match = fix_probability_two_random_records_match , # noqa 501 comparisons_to_deactivate = comparisons_to_deactivate , comparison_levels_to_reverse_blocking_rule = comparison_levels_to_reverse_blocking_rule , # noqa 501 ) em_training_session . _train () self . _populate_m_u_from_trained_values () self . _populate_probability_two_random_records_match_from_trained_values () self . _settings_obj . _columns_without_estimated_parameters_message () return em_training_session def predict ( self , threshold_match_probability : float = None , threshold_match_weight : float = None , ) -> SplinkDataFrame : \"\"\"Create a dataframe of scored pairwise comparisons using the parameters of the linkage model. Uses the blocking rules specified in the `blocking_rules_to_generate_predictions` of the settings dictionary to generate the pairwise comparisons. Args: threshold_match_probability (float, optional): If specified, filter the results to include only pairwise comparisons with a match_probability above this threshold. Defaults to None. threshold_match_weight (float, optional): If specified, filter the results to include only pairwise comparisons with a match_weight above this threshold. Defaults to None. Examples: >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.load_settings_from_json(\"saved_settings.json\") >>> df = linker.predict(threshold_match_probability=0.95) >>> df.as_pandas_dataframe(limit=5) Returns: SplinkDataFrame: A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. \"\"\" # If the user only calls predict, it runs as a single pipeline with no # materialisation of anything self . _initialise_df_concat_with_tf ( materialise = False ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) repartition_after_blocking = getattr ( self , \"repartition_after_blocking\" , False ) # repartition after blocking only exists on the SparkLinker if repartition_after_blocking : df_blocked = self . _execute_sql_pipeline () input_dataframes = [ df_blocked ] else : input_dataframes = [] sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj , threshold_match_probability , threshold_match_weight ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) predictions = self . _execute_sql_pipeline ( input_dataframes ) self . _predict_warning () return predictions def find_matches_to_new_records ( self , records_or_tablename , blocking_rules = [], match_weight_threshold =- 4 , ) -> SplinkDataFrame : \"\"\"Given one or more records, find records in the input dataset(s) which match and return in order of the splink prediction score. This effectively provides a way of searching the input datasets for given record(s) Args: records_or_tablename (List[dict]): Input search record(s) as list of dict, or a table registered to the database. blocking_rules (list, optional): Blocking rules to select which records to find and score. If [], do not use a blocking rule - meaning the input records will be compared to all records provided to the linker when it was instantiated. Defaults to []. match_weight_threshold (int, optional): Return matches with a match weight above this threshold. Defaults to -4. Examples: >>> linker = DuckDBLinker(df) >>> linker.load_settings_from_json(\"saved_settings.json\") >>> # Pre-compute tf tables for any tables with >>> # term frequency adjustments >>> linker.compute_tf_table(\"first_name\") >>> record = {'unique_id': 1, >>> 'first_name': \"John\", >>> 'surname': \"Smith\", >>> 'dob': \"1971-05-24\", >>> 'city': \"London\", >>> 'email': \"john@smith.net\" >>> } >>> df = linker.find_matches_to_new_records([record], blocking_rules=[]) Returns: SplinkDataFrame: The pairwise comparisons. \"\"\" original_blocking_rules = ( self . _settings_obj . _blocking_rules_to_generate_predictions ) original_link_type = self . _settings_obj . _link_type if not isinstance ( records_or_tablename , str ): self . _records_to_table ( records_or_tablename , \"__splink__df_new_records\" ) new_records_tablename = \"__splink__df_new_records\" else : new_records_tablename = records_or_tablename blocking_rules = [ BlockingRule ( r ) if not isinstance ( r , BlockingRule ) else r for r in blocking_rules ] self . _settings_obj . _blocking_rules_to_generate_predictions = blocking_rules self . _settings_obj . _link_type = \"link_only_find_matches_to_new_records\" self . _find_new_matches_mode = True sql = _join_tf_to_input_df_sql ( self ) sql = sql . replace ( \"__splink__df_concat\" , new_records_tablename ) self . _enqueue_sql ( sql , \"__splink__df_new_records_with_tf\" ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) sql = f \"\"\" select * from __splink__df_predict where match_weight > { match_weight_threshold } \"\"\" self . _enqueue_sql ( sql , \"__splink_find_matches_predictions\" ) predictions = self . _execute_sql_pipeline ( use_cache = False ) self . _settings_obj . _blocking_rules_to_generate_predictions = ( original_blocking_rules ) self . _settings_obj . _link_type = original_link_type self . _find_new_matches_mode = False return predictions def compare_two_records ( self , record_1 : dict , record_2 : dict ): \"\"\"Use the linkage model to compare and score a pairwise record comparison based on the two input records provided Args: record_1 (dict): dictionary representing the first record. Columns names and data types must be the same as the columns in the settings object record_2 (dict): dictionary representing the second record. Columns names and data types must be the same as the columns in the settings object Examples: >>> linker = DuckDBLinker(df) >>> linker.load_settings_from_json(\"saved_settings.json\") >>> linker.compare_two_records(record_left, record_right) Returns: SplinkDataFrame: Pairwise comparison with scored prediction \"\"\" original_blocking_rules = ( self . _settings_obj . _blocking_rules_to_generate_predictions ) original_link_type = self . _settings_obj . _link_type self . _compare_two_records_mode = True self . _settings_obj . _blocking_rules_to_generate_predictions = [] self . _records_to_table ([ record_1 ], \"__splink__compare_two_records_left\" ) self . _records_to_table ([ record_2 ], \"__splink__compare_two_records_right\" ) sql_join_tf = _join_tf_to_input_df_sql ( self ) sql_join_tf = sql_join_tf . replace ( \"__splink__df_concat\" , \"__splink__compare_two_records_left\" ) self . _enqueue_sql ( sql_join_tf , \"__splink__compare_two_records_left_with_tf\" ) sql_join_tf = sql_join_tf . replace ( \"__splink__compare_two_records_left\" , \"__splink__compare_two_records_right\" ) self . _enqueue_sql ( sql_join_tf , \"__splink__compare_two_records_right_with_tf\" ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) predictions = self . _execute_sql_pipeline ( use_cache = False ) self . _settings_obj . _blocking_rules_to_generate_predictions = ( original_blocking_rules ) self . _settings_obj . _link_type = original_link_type self . _compare_two_records_mode = False return predictions def _self_link ( self ) -> SplinkDataFrame : \"\"\"Use the linkage model to compare and score all records in our input df with themselves. Returns: SplinkDataFrame: Scored pairwise comparisons of the input records to themselves. \"\"\" original_blocking_rules = ( self . _settings_obj . _blocking_rules_to_generate_predictions ) original_link_type = self . _settings_obj . _link_type # Changes our sql to allow for a self link. # This is used in `_sql_gen_where_condition` in blocking.py # to remove any 'where' clauses when blocking (normally when blocking # we want to *remove* self links!) self . _self_link_mode = True # Block on uid i.e. create pairwise record comparisons where the uid matches uid_cols = self . _settings_obj . _unique_id_input_columns uid_l = _composite_unique_id_from_edges_sql ( uid_cols , None , \"l\" ) uid_r = _composite_unique_id_from_edges_sql ( uid_cols , None , \"r\" ) self . _settings_obj . _blocking_rules_to_generate_predictions = [ BlockingRule ( f \" { uid_l } = { uid_r } \" ) ] self . _initialise_df_concat_with_tf () sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) predictions = self . _execute_sql_pipeline ( use_cache = False ) self . _settings_obj . _blocking_rules_to_generate_predictions = ( original_blocking_rules ) self . _settings_obj . _link_type = original_link_type self . _self_link_mode = False return predictions def cluster_pairwise_predictions_at_threshold ( self , df_predict : SplinkDataFrame , threshold_match_probability : float ) -> SplinkDataFrame : \"\"\"Clusters the pairwise match predictions that result from `linker.predict()` into groups of connected record using the connected components graph clustering algorithm Records with an estimated `match_probability` above `threshold_match_probability` are considered to be a match (i.e. they represent the same entity). Args: df_predict (SplinkDataFrame): The results of `linker.predict()` threshold_match_probability (float): Filter the pairwise match predictions to include only pairwise comparisons with a match_probability above this threshold. This dataframe is then fed into the clustering algorithm. Returns: SplinkDataFrame: A SplinkDataFrame containing a list of all IDs, clustered into groups based on the desired match threshold. \"\"\" self . _initialise_df_concat_with_tf ( df_predict ) edges_table = _cc_create_unique_id_cols ( self , df_predict , threshold_match_probability , ) cc = solve_connected_components ( self , edges_table ) return cc def profile_columns ( self , column_expressions : Union [ str , List [ str ]], top_n = 10 , bottom_n = 10 ): return profile_columns ( self , column_expressions , top_n = top_n , bottom_n = bottom_n ) def estimate_m_from_pairwise_labels ( self , table_name ): self . _initialise_df_concat_with_tf ( materialise = True ) estimate_m_from_pairwise_labels ( self , table_name ) def roc_chart_from_labels ( self , labels_tablename , threshold_actual = 0.5 , match_weight_round_to_nearest : float = None , ): \"\"\"Generate a ROC chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered with your database: |source_dataset_l|unique_id_l|source_dataset_r|unique_id_r|clerical_match_score| |----------------|-----------|----------------|-----------|--------------------| |df_1 |1 |df_2 |2 |0.99 | |df_1 |1 |df_2 |3 |0.2 | Note that `source_dataset` and `unique_id` should correspond to the values specified in the settings dict, and the `input_table_aliases` passed to the `linker` object. For `dedupe_only` links, the `source_dataset` columns can be ommitted. Args: labels_tablename (str): Name of table containing labels in the database threshold_actual (float, optional): Where the `clerical_match_score` provided by the user is a probability rather than binary, this value is used as the threshold to classify `clerical_match_score`s as binary matches or non matches. Defaults to 0.5. match_weight_round_to_nearest (float, optional): When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. Examples: >>> # DuckDBLinker >>> labels = pd.read_csv(\"my_labels.csv\") >>> linker._con.register(\"labels\", labels) >>> linker.roc_chart_from_labels(\"labels\") >>> >>> # SparkLinker >>> labels = spark.read.csv(\"my_labels.csv\", header=True) >>> labels.createDataFrame(\"labels\") >>> linker.roc_chart_from_labels(\"labels\") Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" df_truth_space = roc_table ( self , labels_tablename , threshold_actual = threshold_actual , match_weight_round_to_nearest = match_weight_round_to_nearest , ) recs = df_truth_space . as_record_dict () return roc_chart ( recs ) def precision_recall_chart_from_labels ( self , labels_tablename ): \"\"\"Generate a precision-recall chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered as a table with your database: |source_dataset_l|unique_id_l|source_dataset_r|unique_id_r|clerical_match_score| |----------------|-----------|----------------|-----------|--------------------| |df_1 |1 |df_2 |2 |0.99 | |df_1 |1 |df_2 |3 |0.2 | Note that `source_dataset` and `unique_id` should correspond to the values specified in the settings dict, and the `input_table_aliases` passed to the `linker` object. For `dedupe_only` links, the `source_dataset` columns can be ommitted. Args: labels_tablename (str): Name of table containing labels in the database threshold_actual (float, optional): Where the `clerical_match_score` provided by the user is a probability rather than binary, this value is used as the threshold to classify `clerical_match_score`s as binary matches or non matches. Defaults to 0.5. match_weight_round_to_nearest (float, optional): When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. Examples: >>> # DuckDBLinker >>> labels = pd.read_csv(\"my_labels.csv\") >>> linker._con.register(\"labels\", labels) >>> linker.precision_recall_chart_from_labels(\"labels\") >>> >>> # SparkLinker >>> labels = spark.read.csv(\"my_labels.csv\", header=True) >>> labels.createDataFrame(\"labels\") >>> linker.precision_recall_chart_from_labels(\"labels\") Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" df_truth_space = roc_table ( self , labels_tablename ) recs = df_truth_space . as_record_dict () return precision_recall_chart ( recs ) def roc_table_from_labels ( self , labels_tablename , threshold_actual = 0.5 , match_weight_round_to_nearest : float = None , ) -> SplinkDataFrame : \"\"\"Generate truth statistics (false positive etc.) for each threshold value of match_probability, suitable for plotting a ROC chart. The table of labels should be in the following format, and should be registered with your database: |source_dataset_l|unique_id_l|source_dataset_r|unique_id_r|clerical_match_score| |----------------|-----------|----------------|-----------|--------------------| |df_1 |1 |df_2 |2 |0.99 | |df_1 |1 |df_2 |3 |0.2 | Note that `source_dataset` and `unique_id` should correspond to the values specified in the settings dict, and the `input_table_aliases` passed to the `linker` object. For `dedupe_only` links, the `source_dataset` columns can be ommitted. Args: labels_tablename (str): Name of table containing labels in the database threshold_actual (float, optional): Where the `clerical_match_score` provided by the user is a probability rather than binary, this value is used as the threshold to classify `clerical_match_score`s as binary matches or non matches. Defaults to 0.5. match_weight_round_to_nearest (float, optional): When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. Examples: >>> # DuckDBLinker >>> labels = pd.read_csv(\"my_labels.csv\") >>> linker._con.register(\"labels\", labels) >>> linker.roc_table_from_labels(\"labels\") >>> >>> # SparkLinker >>> labels = spark.read.csv(\"my_labels.csv\", header=True) >>> labels.createDataFrame(\"labels\") >>> linker.roc_table_from_labels(\"labels\") Returns: SplinkDataFrame: Table of truth statistics \"\"\" return roc_table ( self , labels_tablename , threshold_actual = threshold_actual , match_weight_round_to_nearest = match_weight_round_to_nearest , ) def match_weights_histogram ( self , df_predict : SplinkDataFrame , target_bins : int = 30 , width = 600 , height = 250 ): \"\"\"Generate a histogram that shows the distribution of match weights in `df_predict` Args: df_predict (SplinkDataFrame): Output of `linker.predict()` target_bins (int, optional): Target number of bins in histogram. Defaults to 30. width (int, optional): Width of output. Defaults to 600. height (int, optional): Height of output chart. Defaults to 250. Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" df = histogram_data ( self , df_predict , target_bins ) recs = df . as_record_dict () return match_weights_histogram ( recs , width = width , height = height ) def waterfall_chart ( self , records : List [ dict ], filter_nulls = True ): \"\"\"Visualise how the final match weight is computed for the provided pairwise record comparisons. Records must be provided as a list of dictionaries. This would usually be obtained from `df.as_record_dict(limit=n)` where `df` is a SplinkDataFrame. Examples: >>> df = linker.predict(threshold_match_weight=2) >>> records = df.as_record_dict(limit=10) >>> linker.waterfall_chart(records) Args: records (List[dict]): Usually be obtained from `df.as_record_dict(limit=n)` where `df` is a SplinkDataFrame. filter_nulls (bool, optional): Whether the visualiation shows null comparisons, which have no effect on final match weight. Defaults to True. Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" self . _raise_error_if_necessary_waterfall_columns_not_computed () return waterfall_chart ( records , self . _settings_obj , filter_nulls ) def unlinkables_chart ( self , x_col = \"match_weight\" , source_dataset = None , as_dict = False , ): \"\"\"Generate an interactive chart displaying the proportion of records that are \"unlinkable\" for a given splink score threshold and model parameters. Unlinkable records are those that, even when compared with themselves, do not contain enough information to confirm a match. Args: x_col (str, optional): Column to use for the x-axis. Defaults to \"match_weight\". source_dataset (str, optional): Name of the source dataset to use for the title of the output chart. as_dict (bool, optional): If True, return a dict version of the chart. Examples: >>> # For the simplest code pipeline, load a pre-trained model >>> # and run this against the test data. >>> df = pd.read_csv(\"./tests/datasets/fake_1000_from_splink_demos.csv\") >>> linker = DuckDBLinker(df) >>> linker.load_settings_from_json(\"saved_settings.json\") >>> linker.unlinkables_chart() >>> >>> # For more complex code pipelines, you can run an entire pipeline >>> # that estimates your m and u values, before `unlinkables_chart(). Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" # Link our initial df on itself and calculate the % of unlinkable entries records = unlinkables_data ( self , x_col ) return unlinkables_chart ( records , x_col , source_dataset ) def comparison_viewer_dashboard ( self , df_predict : SplinkDataFrame , out_path : str , overwrite = False , num_example_rows = 2 , return_html_as_string = False , ): \"\"\"Generate an interactive html visualization of the linker's predictions and save to `out_path`. For more information see [this video](https://www.youtube.com/watch?v=DNvCMqjipis) Args: df_predict (SplinkDataFrame): The outputs of `linker.predict()` out_path (str): The path (including filename) to save the html file to. overwrite (bool, optional): Overwrite the html file if it already exists? Defaults to False. num_example_rows (int, optional): Number of example rows per comparison vector. Defaults to 2. return_html_as_string: If True, return the html as a string Examples: >>> df_predictions = linker.predict() >>> linker.comparison_viewer_dashboard(df_predictions, \"scv.html\", True, 2) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame(src=\"./scv.html\", width=\"100%\", height=1200) \"\"\" self . _raise_error_if_necessary_waterfall_columns_not_computed () sql = comparison_vector_distribution_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vector_distribution\" ) sqls = comparison_viewer_table_sqls ( self , num_example_rows ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) df = self . _execute_sql_pipeline ([ df_predict ]) rendered = render_splink_comparison_viewer_html ( df . as_record_dict (), self . _settings_obj . _as_completed_dict (), out_path , overwrite , ) if return_html_as_string : return rendered def parameter_estimate_comparisons_chart ( self , include_m = True , include_u = True ): \"\"\"Show a chart that shows how parameter estimates have differed across the different estimation methods you have used. For example, if you have run two EM estimation sessions, blocking on different variables, and both result in parameter estimates for first_name, this chart will enable easy comparison of the different estimates Args: include_m (bool, optional): Show different estimates of m values. Defaults to True. include_u (bool, optional): Show different estimates of u values. Defaults to True. \"\"\" records = self . _settings_obj . _parameter_estimates_as_records to_retain = [] if include_m : to_retain . append ( \"m\" ) if include_u : to_retain . append ( \"u\" ) records = [ r for r in records if r [ \"m_or_u\" ] in to_retain ] return parameter_estimate_comparisons ( records ) def missingness_chart ( self , input_dataset : str = None ): \"\"\"Generate a summary chart of the missingness (prevalence of nulls) of columns in the input datasets. By default, missingness is assessed across all input datasets Args: input_dataset (str, optional): Name of one of the input tables in the database. If provided, missingness will be computed for this table alone. Defaults to None. Examples: >>> linker.missingness_chart() >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker.missingness_chart() >>> save_offline_chart(c.spec, \"test_chart.html\") >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame(src=\"./test_chart.html\", width=1000, height=500 \"\"\" records = missingness_data ( self , input_dataset ) return missingness_chart ( records , input_dataset ) def completeness_chart ( self , input_dataset : str = None , cols : List [ str ] = None ): \"\"\"Generate a summary chart of the completeness (proportion of non-nulls) of columns in each of the input datasets. By default, completeness is assessed for all column in the input data. Args: input_dataset (str, optional): Name of one of the input tables in the database. If provided, completeness will be computed for this table alone. Defaults to None. cols (List[str], optional): List of column names to calculate completeness. Default to None. Examples: >>> linker.completeness_chart() >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker.completeness_chart() >>> save_offline_chart(c.spec, \"test_chart.html\") >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame(src=\"./test_chart.html\", width=1000, height=500 \"\"\" records = completeness_data ( self , input_dataset , cols ) return completeness_chart ( records , input_dataset ) def count_num_comparisons_from_blocking_rule ( self , blocking_rule : str , link_type : str = None , unique_id_column_name : str = None , ) -> int : \"\"\"Compute the number of pairwise record comparisons that would be generated by a blocking rule Args: blocking_rule (str): The blocking rule to analyse link_type (str, optional): The link type. This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. unique_id_column_name (str, optional): This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. Examples: >>> br = \"l.first_name = r.first_name\" >>> linker.count_num_comparisons_from_blocking_rule(br) 19387 >>> br = \"l.name = r.name and substr(l.dob,1,4) = substr(r.dob,1,4)\" >>> linker.count_num_comparisons_from_blocking_rule(br) 394 Returns: int: The number of comparisons generated by the blocking rule \"\"\" sql = vertically_concatenate_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_concat\" ) sql = number_of_comparisons_generated_by_blocking_rule_sql ( self , blocking_rule , link_type , unique_id_column_name ) self . _enqueue_sql ( sql , \"__splink__analyse_blocking_rule\" ) res = self . _execute_sql_pipeline () . as_record_dict ()[ 0 ] return res [ \"count_of_pairwise_comparisons_generated\" ] def cumulative_num_comparisons_from_blocking_rules_chart ( self , blocking_rules : str or list = None , link_type : str = None , unique_id_column_name : str = None , ): \"\"\"Display a chart with the cumulative number of comparisons generated by a selection of blocking rules. This is equivalent to the output size of df_predict and details how many comparisons each of your individual blocking rules will contribute to the total. Args: blocking_rules (str or list): The blocking rule(s) to compute comparisons for. If null, the rules set out in your settings object will be used. link_type (str, optional): The link type. This defaults to the link type outlined in your settings object. unique_id_column_name (str, optional): This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. Examples: >>> linker_settings = DuckDBLinker(df, settings) >>> # Compute the cumulative number of comparisons generated by the rules >>> # in your settings object. >>> linker_settings.cumulative_num_comparisons_from_blocking_rules_chart() >>> >>> # Generate total comparisons with custom blocking rules. >>> blocking_rules = [ >>> \"l.surname = r.surname\", >>> \"l.first_name = r.first_name >>> and substr(l.dob,1,4) = substr(r.dob,1,4)\" >>> ] >>> >>> linker.cumulative_num_comparisons_from_blocking_rules_chart( >>> blocking_rules >>> ) Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" if blocking_rules : blocking_rules = ensure_is_list ( blocking_rules ) records = cumulative_comparisons_generated_by_blocking_rules ( self , blocking_rules , link_type , unique_id_column_name , ) return cumulative_blocking_rule_comparisons_generated ( records ) def count_num_comparisons_from_blocking_rules_for_prediction ( self , df_predict ): \"\"\"Counts the maginal number of edges created from each of the blocking rules in `blocking_rules_to_generate_predictions` This is different to `count_num_comparisons_from_blocking_rule` because it (a) analyses multiple blocking rules rather than a single rule, and (b) deduplicates any comparisons that are generated, to tell you the marginal effect of each entry in `blocking_rules_to_generate_predictions` Args: df_predict (SplinkDataFrame): SplinkDataFrame with match weights and probabilities of rows matching Examples: >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.load_settings_from_json(\"saved_settings.json\") >>> df_predict = linker.predict(threshold_match_probability=0.95) >>> count_pairwise = linker.count_num_comparisons_from_blocking_rules_for_prediction(df_predict) >>> count_pairwise.as_pandas_dataframe(limit=5) Returns: SplinkDataFrame: A SplinkDataFrame of the pairwise comparisons and estimated pairwise comparisons generated by the blocking rules. \"\"\" # noqa: E501 sql = count_num_comparisons_from_blocking_rules_for_prediction_sql ( df_predict ) match_key_analysis = self . _sql_to_splink_dataframe_checking_cache ( sql , \"__splink__match_key_analysis\" ) return match_key_analysis def match_weights_chart ( self ): \"\"\"Display a chart of the (partial) match weights of the linkage model Examples: >>> linker.match_weights_chart() >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker.match_weights_chart() >>> save_offline_chart(c.spec, \"test_chart.html\") >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame(src=\"./test_chart.html\", width=1000, height=500) Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" return self . _settings_obj . match_weights_chart () def m_u_parameters_chart ( self ): \"\"\"Display a chart of the m and u parameters of the linkage model Examples: >>> linker.m_u_parameters_chart() >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker.match_weights_chart() >>> save_offline_chart(c.spec, \"test_chart.html\") >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame(src=\"./test_chart.html\", width=1000, height=500) Returns: VegaLite: A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the `spec` attribute. \"\"\" return self . _settings_obj . m_u_parameters_chart () def cluster_studio_dashboard ( self , df_predict : SplinkDataFrame , df_clustered : SplinkDataFrame , out_path : str , sampling_method = \"random\" , sample_size : int = 10 , cluster_ids : list = None , cluster_names : list = None , overwrite : bool = False , return_html_as_string = False , ): \"\"\"Generate an interactive html visualization of the predicted cluster and save to `out_path`. Args: df_predict (SplinkDataFrame): The outputs of `linker.predict()` df_clustered (SplinkDataFrame): The outputs of `linker.cluster_pairwise_predictions_at_threshold()` out_path (str): The path (including filename) to save the html file to. sampling_method (str, optional): `random` or `by_cluster_size`. Defaults to `random`. sample_size (int, optional): Number of clusters to show in the dahboard. Defaults to 10. cluster_ids (list): The IDs of the clusters that will be displayed in the dashboard. If provided, ignore the `sampling_method` and `sample_size` arguments. Defaults to None. overwrite (bool, optional): Overwrite the html file if it already exists? Defaults to False. cluster_names (list, optional): If provided, the dashboard will display these names in the selection box. Ony works in conjunction with `cluster_ids`. Defaults to None. return_html_as_string: If True, return the html as a string Examples: >>> df_p = linker.predict() >>> df_c = linker.cluster_pairwise_predictions_at_threshold(df_p, 0.5) >>> linker.cluster_studio_dashboard( >>> df_p, df_c, [0, 4, 7], \"cluster_studio.html\" >>> ) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame(src=\"./cluster_studio.html\", width=\"100%\", height=1200) \"\"\" self . _raise_error_if_necessary_waterfall_columns_not_computed () rendered = render_splink_cluster_studio_html ( self , df_predict , df_clustered , out_path , sampling_method = sampling_method , sample_size = sample_size , cluster_ids = cluster_ids , overwrite = overwrite , cluster_names = cluster_names , ) if return_html_as_string : return rendered def save_settings_to_json ( self , out_path : str , overwrite = False ) -> dict : \"\"\"Save the configuration and parameters the linkage model to a `.json` file. The model can later be loaded back in using `linker.load_settings_from_json()` Examples: >>> linker.save_settings_to_json(\"my_settings.json\", overwrite=True) Args: out_path (str): File path for json file overwrite (bool, optional): Overwrite if already exists? Defaults to False. \"\"\" model_dict = self . _settings_obj . as_dict () if out_path : if os . path . isfile ( out_path ) and not overwrite : raise ValueError ( f \"The path { out_path } already exists. Please provide a different \" \"path or set overwrite=True\" ) with open ( out_path , \"w\" , encoding = \"utf-8\" ) as f : json . dump ( model_dict , f , indent = 4 ) def load_settings_from_json ( self , in_path : str ): \"\"\"Load settings from a `.json` file. This `.json` file would usually be the output of `linker.save_settings_to_json()` Examples: >>> linker.load_settings_from_json(\"my_settings.json\") Args: in_path (str): Path to settings json file \"\"\" with open ( in_path , \"r\" ) as f : model_dict = json . load ( f ) self . initialise_settings ( model_dict )","title":"Documentation for Linker object methods related to link prediction"},{"location":"linkerpred.html#splink.linker.Linker.cluster_pairwise_predictions_at_threshold","text":"Clusters the pairwise match predictions that result from linker.predict() into groups of connected record using the connected components graph clustering algorithm Records with an estimated match_probability above threshold_match_probability are considered to be a match (i.e. they represent the same entity). Parameters: Name Type Description Default df_predict SplinkDataFrame The results of linker.predict() required threshold_match_probability float Filter the pairwise match predictions to include only pairwise comparisons with a match_probability above this threshold. This dataframe is then fed into the clustering algorithm. required Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame containing a list of all IDs, clustered into groups based on the desired match threshold. Source code in splink/linker.py 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 def cluster_pairwise_predictions_at_threshold ( self , df_predict : SplinkDataFrame , threshold_match_probability : float ) -> SplinkDataFrame : \"\"\"Clusters the pairwise match predictions that result from `linker.predict()` into groups of connected record using the connected components graph clustering algorithm Records with an estimated `match_probability` above `threshold_match_probability` are considered to be a match (i.e. they represent the same entity). Args: df_predict (SplinkDataFrame): The results of `linker.predict()` threshold_match_probability (float): Filter the pairwise match predictions to include only pairwise comparisons with a match_probability above this threshold. This dataframe is then fed into the clustering algorithm. Returns: SplinkDataFrame: A SplinkDataFrame containing a list of all IDs, clustered into groups based on the desired match threshold. \"\"\" self . _initialise_df_concat_with_tf ( df_predict ) edges_table = _cc_create_unique_id_cols ( self , df_predict , threshold_match_probability , ) cc = solve_connected_components ( self , edges_table ) return cc","title":"cluster_pairwise_predictions_at_threshold()"},{"location":"linkerpred.html#splink.linker.Linker.compare_two_records","text":"Use the linkage model to compare and score a pairwise record comparison based on the two input records provided Parameters: Name Type Description Default record_1 dict dictionary representing the first record. Columns names and data types must be the same as the columns in the settings object required record_2 dict dictionary representing the second record. Columns names and data types must be the same as the columns in the settings object required Examples: >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . compare_two_records ( record_left , record_right ) Returns: Name Type Description SplinkDataFrame Pairwise comparison with scored prediction Source code in splink/linker.py 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 def compare_two_records ( self , record_1 : dict , record_2 : dict ): \"\"\"Use the linkage model to compare and score a pairwise record comparison based on the two input records provided Args: record_1 (dict): dictionary representing the first record. Columns names and data types must be the same as the columns in the settings object record_2 (dict): dictionary representing the second record. Columns names and data types must be the same as the columns in the settings object Examples: >>> linker = DuckDBLinker(df) >>> linker.load_settings_from_json(\"saved_settings.json\") >>> linker.compare_two_records(record_left, record_right) Returns: SplinkDataFrame: Pairwise comparison with scored prediction \"\"\" original_blocking_rules = ( self . _settings_obj . _blocking_rules_to_generate_predictions ) original_link_type = self . _settings_obj . _link_type self . _compare_two_records_mode = True self . _settings_obj . _blocking_rules_to_generate_predictions = [] self . _records_to_table ([ record_1 ], \"__splink__compare_two_records_left\" ) self . _records_to_table ([ record_2 ], \"__splink__compare_two_records_right\" ) sql_join_tf = _join_tf_to_input_df_sql ( self ) sql_join_tf = sql_join_tf . replace ( \"__splink__df_concat\" , \"__splink__compare_two_records_left\" ) self . _enqueue_sql ( sql_join_tf , \"__splink__compare_two_records_left_with_tf\" ) sql_join_tf = sql_join_tf . replace ( \"__splink__compare_two_records_left\" , \"__splink__compare_two_records_right\" ) self . _enqueue_sql ( sql_join_tf , \"__splink__compare_two_records_right_with_tf\" ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) predictions = self . _execute_sql_pipeline ( use_cache = False ) self . _settings_obj . _blocking_rules_to_generate_predictions = ( original_blocking_rules ) self . _settings_obj . _link_type = original_link_type self . _compare_two_records_mode = False return predictions","title":"compare_two_records()"},{"location":"linkerpred.html#splink.linker.Linker.compute_tf_table","text":"Compute a term frequency table for a given column and persist to the database This method is useful if you want to pre-compute term frequency tables e.g. so that real time linkage executes faster, or so that you can estimate various models without having to recompute term frequency tables each time Examples: >>> # Example 1: Real time linkage >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . compute_tf_table ( \"surname\" ) >>> linker . compare_two_records ( record_left , record_right ) >>> # Example 2: Pre-computed term frequency tables in Spark >>> linker = SparkLinker ( df ) >>> df_first_name_tf = linker . compute_tf_table ( \"first_name\" ) >>> df_first_name_tf . write . parquet ( \"folder/first_name_tf\" ) >>> >>> # On subsequent data linking job, read this table rather than recompute >>> df_first_name_tf = spark . read . parquet ( \"folder/first_name_tf\" ) >>> df_first_name_tf . createOrReplaceTempView ( \"__splink__df_tf_first_name\" ) Parameters: Name Type Description Default column_name str The column name in the input table required Returns: Name Type Description SplinkDataFrame SplinkDataFrame The resultant table as a splink data frame Source code in splink/linker.py 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 def compute_tf_table ( self , column_name : str ) -> SplinkDataFrame : \"\"\"Compute a term frequency table for a given column and persist to the database This method is useful if you want to pre-compute term frequency tables e.g. so that real time linkage executes faster, or so that you can estimate various models without having to recompute term frequency tables each time Examples: >>> # Example 1: Real time linkage >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.load_settings_from_json(\"saved_settings.json\") >>> linker.compute_tf_table(\"surname\") >>> linker.compare_two_records(record_left, record_right) >>> # Example 2: Pre-computed term frequency tables in Spark >>> linker = SparkLinker(df) >>> df_first_name_tf = linker.compute_tf_table(\"first_name\") >>> df_first_name_tf.write.parquet(\"folder/first_name_tf\") >>> >>> # On subsequent data linking job, read this table rather than recompute >>> df_first_name_tf = spark.read.parquet(\"folder/first_name_tf\") >>> df_first_name_tf.createOrReplaceTempView(\"__splink__df_tf_first_name\") Args: column_name (str): The column name in the input table Returns: SplinkDataFrame: The resultant table as a splink data frame \"\"\" sql = vertically_concatenate_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_concat\" ) input_col = InputColumn ( column_name , tf_adjustments = True ) sql = term_frequencies_for_single_column_sql ( input_col ) self . _enqueue_sql ( sql , colname_to_tf_tablename ( input_col )) return self . _execute_sql_pipeline ( materialise_as_hash = False )","title":"compute_tf_table()"},{"location":"linkerpred.html#splink.linker.Linker.deterministic_link","text":"Uses the blocking rules specified by blocking_rules_to_generate_predictions in the settings dictionary to generate pairwise record comparisons. For deterministic linkage, this should be a list of blocking rules which are strict enough to generate only true links. Deterministic linkage, however, is likely to result in missed links (false negatives). Examples: >>> linker = DuckDBLinker ( df ) >>> >>> settings = { >>> \"link_type\" : \"dedupe_only\" , >>> \"blocking_rules_to_generate_predictions\" : [ >>> \"l.first_name = r.first_name\" , >>> \"l.surname = r.surname\" , >>> ], >>> \"comparisons\" : [] >>> } >>> >>> from splink.duckdb.duckdb_linker import DuckDBLinker >>> >>> linker = DuckDBLinker ( df , settings ) >>> df = linker . deterministic_link () Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. Source code in splink/linker.py 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 def deterministic_link ( self ) -> SplinkDataFrame : \"\"\"Uses the blocking rules specified by `blocking_rules_to_generate_predictions` in the settings dictionary to generate pairwise record comparisons. For deterministic linkage, this should be a list of blocking rules which are strict enough to generate only true links. Deterministic linkage, however, is likely to result in missed links (false negatives). Examples: >>> linker = DuckDBLinker(df) >>> >>> settings = { >>> \"link_type\": \"dedupe_only\", >>> \"blocking_rules_to_generate_predictions\": [ >>> \"l.first_name = r.first_name\", >>> \"l.surname = r.surname\", >>> ], >>> \"comparisons\": [] >>> } >>> >>> from splink.duckdb.duckdb_linker import DuckDBLinker >>> >>> linker = DuckDBLinker(df, settings) >>> df = linker.deterministic_link() Returns: SplinkDataFrame: A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. \"\"\" self . _initialise_df_concat_with_tf () sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) return self . _execute_sql_pipeline ()","title":"deterministic_link()"},{"location":"linkerpred.html#splink.linker.Linker.find_matches_to_new_records","text":"Given one or more records, find records in the input dataset(s) which match and return in order of the splink prediction score. This effectively provides a way of searching the input datasets for given record(s) Parameters: Name Type Description Default records_or_tablename List [ dict ] Input search record(s) as list of dict, or a table registered to the database. required blocking_rules list Blocking rules to select which records to find and score. If [], do not use a blocking rule - meaning the input records will be compared to all records provided to the linker when it was instantiated. Defaults to []. [] match_weight_threshold int Return matches with a match weight above this threshold. Defaults to -4. -4 Examples: >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> # Pre-compute tf tables for any tables with >>> # term frequency adjustments >>> linker . compute_tf_table ( \"first_name\" ) >>> record = { 'unique_id' : 1 , >>> 'first_name' : \"John\" , >>> 'surname' : \"Smith\" , >>> 'dob' : \"1971-05-24\" , >>> 'city' : \"London\" , >>> 'email' : \"john@smith.net\" >>> } >>> df = linker . find_matches_to_new_records ([ record ], blocking_rules = []) Returns: Name Type Description SplinkDataFrame SplinkDataFrame The pairwise comparisons. Source code in splink/linker.py 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 def find_matches_to_new_records ( self , records_or_tablename , blocking_rules = [], match_weight_threshold =- 4 , ) -> SplinkDataFrame : \"\"\"Given one or more records, find records in the input dataset(s) which match and return in order of the splink prediction score. This effectively provides a way of searching the input datasets for given record(s) Args: records_or_tablename (List[dict]): Input search record(s) as list of dict, or a table registered to the database. blocking_rules (list, optional): Blocking rules to select which records to find and score. If [], do not use a blocking rule - meaning the input records will be compared to all records provided to the linker when it was instantiated. Defaults to []. match_weight_threshold (int, optional): Return matches with a match weight above this threshold. Defaults to -4. Examples: >>> linker = DuckDBLinker(df) >>> linker.load_settings_from_json(\"saved_settings.json\") >>> # Pre-compute tf tables for any tables with >>> # term frequency adjustments >>> linker.compute_tf_table(\"first_name\") >>> record = {'unique_id': 1, >>> 'first_name': \"John\", >>> 'surname': \"Smith\", >>> 'dob': \"1971-05-24\", >>> 'city': \"London\", >>> 'email': \"john@smith.net\" >>> } >>> df = linker.find_matches_to_new_records([record], blocking_rules=[]) Returns: SplinkDataFrame: The pairwise comparisons. \"\"\" original_blocking_rules = ( self . _settings_obj . _blocking_rules_to_generate_predictions ) original_link_type = self . _settings_obj . _link_type if not isinstance ( records_or_tablename , str ): self . _records_to_table ( records_or_tablename , \"__splink__df_new_records\" ) new_records_tablename = \"__splink__df_new_records\" else : new_records_tablename = records_or_tablename blocking_rules = [ BlockingRule ( r ) if not isinstance ( r , BlockingRule ) else r for r in blocking_rules ] self . _settings_obj . _blocking_rules_to_generate_predictions = blocking_rules self . _settings_obj . _link_type = \"link_only_find_matches_to_new_records\" self . _find_new_matches_mode = True sql = _join_tf_to_input_df_sql ( self ) sql = sql . replace ( \"__splink__df_concat\" , new_records_tablename ) self . _enqueue_sql ( sql , \"__splink__df_new_records_with_tf\" ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) sql = f \"\"\" select * from __splink__df_predict where match_weight > { match_weight_threshold } \"\"\" self . _enqueue_sql ( sql , \"__splink_find_matches_predictions\" ) predictions = self . _execute_sql_pipeline ( use_cache = False ) self . _settings_obj . _blocking_rules_to_generate_predictions = ( original_blocking_rules ) self . _settings_obj . _link_type = original_link_type self . _find_new_matches_mode = False return predictions","title":"find_matches_to_new_records()"},{"location":"linkerpred.html#splink.linker.Linker.load_settings_from_json","text":"Load settings from a .json file. This .json file would usually be the output of linker.save_settings_to_json() Examples: >>> linker . load_settings_from_json ( \"my_settings.json\" ) Parameters: Name Type Description Default in_path str Path to settings json file required Source code in splink/linker.py 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 def load_settings_from_json ( self , in_path : str ): \"\"\"Load settings from a `.json` file. This `.json` file would usually be the output of `linker.save_settings_to_json()` Examples: >>> linker.load_settings_from_json(\"my_settings.json\") Args: in_path (str): Path to settings json file \"\"\" with open ( in_path , \"r\" ) as f : model_dict = json . load ( f ) self . initialise_settings ( model_dict )","title":"load_settings_from_json()"},{"location":"linkerpred.html#splink.linker.Linker.predict","text":"Create a dataframe of scored pairwise comparisons using the parameters of the linkage model. Uses the blocking rules specified in the blocking_rules_to_generate_predictions of the settings dictionary to generate the pairwise comparisons. Parameters: Name Type Description Default threshold_match_probability float If specified, filter the results to include only pairwise comparisons with a match_probability above this threshold. Defaults to None. None threshold_match_weight float If specified, filter the results to include only pairwise comparisons with a match_weight above this threshold. Defaults to None. None Examples: >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> df = linker . predict ( threshold_match_probability = 0.95 ) >>> df . as_pandas_dataframe ( limit = 5 ) Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. Source code in splink/linker.py 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 def predict ( self , threshold_match_probability : float = None , threshold_match_weight : float = None , ) -> SplinkDataFrame : \"\"\"Create a dataframe of scored pairwise comparisons using the parameters of the linkage model. Uses the blocking rules specified in the `blocking_rules_to_generate_predictions` of the settings dictionary to generate the pairwise comparisons. Args: threshold_match_probability (float, optional): If specified, filter the results to include only pairwise comparisons with a match_probability above this threshold. Defaults to None. threshold_match_weight (float, optional): If specified, filter the results to include only pairwise comparisons with a match_weight above this threshold. Defaults to None. Examples: >>> linker = DuckDBLinker(df, connection=\":memory:\") >>> linker.load_settings_from_json(\"saved_settings.json\") >>> df = linker.predict(threshold_match_probability=0.95) >>> df.as_pandas_dataframe(limit=5) Returns: SplinkDataFrame: A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. \"\"\" # If the user only calls predict, it runs as a single pipeline with no # materialisation of anything self . _initialise_df_concat_with_tf ( materialise = False ) sql = block_using_rules_sql ( self ) self . _enqueue_sql ( sql , \"__splink__df_blocked\" ) repartition_after_blocking = getattr ( self , \"repartition_after_blocking\" , False ) # repartition after blocking only exists on the SparkLinker if repartition_after_blocking : df_blocked = self . _execute_sql_pipeline () input_dataframes = [ df_blocked ] else : input_dataframes = [] sql = compute_comparison_vector_values_sql ( self . _settings_obj ) self . _enqueue_sql ( sql , \"__splink__df_comparison_vectors\" ) sqls = predict_from_comparison_vectors_sqls ( self . _settings_obj , threshold_match_probability , threshold_match_weight ) for sql in sqls : self . _enqueue_sql ( sql [ \"sql\" ], sql [ \"output_table_name\" ]) predictions = self . _execute_sql_pipeline ( input_dataframes ) self . _predict_warning () return predictions","title":"predict()"},{"location":"linkerqa.html","tags":["API"],"text":"Documentation for Linker object methods related to QA \u00b6 The Linker object manages the data linkage process and holds the data linkage model. Most of Splink's functionality can be accessed by calling methods (functions) on the linker, such as linker.predict() , linker.profile_columns() etc. The Linker class is intended for subclassing for specific backends, e.g. a DuckDBLinker . __deepcopy__ ( memo ) \u00b6 When we do EM training, we need a copy of the linker which is independent of the main linker e.g. setting parameters on the copy will not affect the main linker. This method implements ensures linker can be deepcopied. __init__ ( input_table_or_tables , settings_dict = None , set_up_basic_logging = True , input_table_aliases = None ) \u00b6 Initialise the linker object, which manages the data linkage process and holds the data linkage model. Examples: >>> # Example 1: DuckDB >>> df = pd . read_csv ( \"data_to_dedupe.csv\" ) >>> linker = DuckDBLinker ( df , settings_dict ) >>> # Example 2: Spark >>> df_1 = spark . read . parquet ( \"table_1/\" ) >>> df_2 = spark . read . parquet ( \"table_2/\" ) >>> linker = SparkLinker ( >>> [ df_1 , df_2 ], >>> settings_dict , >>> input_table_aliases = [ \"customers\" , \"contact_center_callers\" ] >>> ) Parameters: Name Type Description Default input_table_or_tables Union [ str , list ] Input data into the linkage model. Either a single string (the name of a table in a database) for deduplication jobs, or a list of strings (the name of tables in a database) for link_only or link_and_dedupe. For some linkers, such as the DuckDBLinker and the SparkLinker, it's also possible to pass in dataframes (Pandas and Spark respectively) rather than strings. required settings_dict dict A Splink settings dictionary. If not provided when the object is created, can later be added using linker.initialise_settings() Defaults to None. None set_up_basic_logging bool If true, sets ups up basic logging so that Splink sends messages at INFO level to stdout. Defaults to True. True input_table_aliases Union [ str , list ] Labels assigned to input tables in Splink outputs. If the names of the tables in the input database are long or unspecific, this argument can be used to attach more easily readable/interpretable names. Defaults to None. None cluster_pairwise_predictions_at_threshold ( df_predict , threshold_match_probability ) \u00b6 Clusters the pairwise match predictions that result from linker.predict() into groups of connected record using the connected components graph clustering algorithm Records with an estimated match_probability above threshold_match_probability are considered to be a match (i.e. they represent the same entity). Parameters: Name Type Description Default df_predict SplinkDataFrame The results of linker.predict() required threshold_match_probability float Filter the pairwise match predictions to include only pairwise comparisons with a match_probability above this threshold. This dataframe is then fed into the clustering algorithm. required Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame containing a list of all IDs, clustered into groups based on the desired match threshold. cluster_studio_dashboard ( df_predict , df_clustered , out_path , sampling_method = 'random' , sample_size = 10 , cluster_ids = None , cluster_names = None , overwrite = False , return_html_as_string = False ) \u00b6 Generate an interactive html visualization of the predicted cluster and save to out_path . Parameters: Name Type Description Default df_predict SplinkDataFrame The outputs of linker.predict() required df_clustered SplinkDataFrame The outputs of linker.cluster_pairwise_predictions_at_threshold() required out_path str The path (including filename) to save the html file to. required sampling_method str random or by_cluster_size . Defaults to random . 'random' sample_size int Number of clusters to show in the dahboard. Defaults to 10. 10 cluster_ids list The IDs of the clusters that will be displayed in the dashboard. If provided, ignore the sampling_method and sample_size arguments. Defaults to None. None overwrite bool Overwrite the html file if it already exists? Defaults to False. False cluster_names list If provided, the dashboard will display these names in the selection box. Ony works in conjunction with cluster_ids . Defaults to None. None return_html_as_string If True, return the html as a string False Examples: >>> df_p = linker . predict () >>> df_c = linker . cluster_pairwise_predictions_at_threshold ( df_p , 0.5 ) >>> linker . cluster_studio_dashboard ( >>> df_p , df_c , [ 0 , 4 , 7 ], \"cluster_studio.html\" >>> ) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame ( src = \"./cluster_studio.html\" , width = \"100%\" , height = 1200 ) compare_two_records ( record_1 , record_2 ) \u00b6 Use the linkage model to compare and score a pairwise record comparison based on the two input records provided Parameters: Name Type Description Default record_1 dict dictionary representing the first record. Columns names and data types must be the same as the columns in the settings object required record_2 dict dictionary representing the second record. Columns names and data types must be the same as the columns in the settings object required Examples: >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . compare_two_records ( record_left , record_right ) Returns: Name Type Description SplinkDataFrame Pairwise comparison with scored prediction comparison_viewer_dashboard ( df_predict , out_path , overwrite = False , num_example_rows = 2 , return_html_as_string = False ) \u00b6 Generate an interactive html visualization of the linker's predictions and save to out_path . For more information see this video Parameters: Name Type Description Default df_predict SplinkDataFrame The outputs of linker.predict() required out_path str The path (including filename) to save the html file to. required overwrite bool Overwrite the html file if it already exists? Defaults to False. False num_example_rows int Number of example rows per comparison vector. Defaults to 2. 2 return_html_as_string If True, return the html as a string False Examples: >>> df_predictions = linker . predict () >>> linker . comparison_viewer_dashboard ( df_predictions , \"scv.html\" , True , 2 ) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame ( src = \"./scv.html\" , width = \"100%\" , height = 1200 ) completeness_chart ( input_dataset = None , cols = None ) \u00b6 Generate a summary chart of the completeness (proportion of non-nulls) of columns in each of the input datasets. By default, completeness is assessed for all column in the input data. Parameters: Name Type Description Default input_dataset str Name of one of the input tables in the database. If provided, completeness will be computed for this table alone. Defaults to None. None cols List [ str ] List of column names to calculate completeness. Default to None. None Examples: >>> linker . completeness_chart () >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . completeness_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500 compute_tf_table ( column_name ) \u00b6 Compute a term frequency table for a given column and persist to the database This method is useful if you want to pre-compute term frequency tables e.g. so that real time linkage executes faster, or so that you can estimate various models without having to recompute term frequency tables each time Examples: >>> # Example 1: Real time linkage >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . compute_tf_table ( \"surname\" ) >>> linker . compare_two_records ( record_left , record_right ) >>> # Example 2: Pre-computed term frequency tables in Spark >>> linker = SparkLinker ( df ) >>> df_first_name_tf = linker . compute_tf_table ( \"first_name\" ) >>> df_first_name_tf . write . parquet ( \"folder/first_name_tf\" ) >>> >>> # On subsequent data linking job, read this table rather than recompute >>> df_first_name_tf = spark . read . parquet ( \"folder/first_name_tf\" ) >>> df_first_name_tf . createOrReplaceTempView ( \"__splink__df_tf_first_name\" ) Parameters: Name Type Description Default column_name str The column name in the input table required Returns: Name Type Description SplinkDataFrame SplinkDataFrame The resultant table as a splink data frame count_num_comparisons_from_blocking_rule ( blocking_rule , link_type = None , unique_id_column_name = None ) \u00b6 Compute the number of pairwise record comparisons that would be generated by a blocking rule Parameters: Name Type Description Default blocking_rule str The blocking rule to analyse required link_type str The link type. This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None unique_id_column_name str This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None Examples: >>> br = \"l.first_name = r.first_name\" >>> linker . count_num_comparisons_from_blocking_rule ( br ) 19387 >>> br = \"l.name = r.name and substr(l.dob,1,4) = substr(r.dob,1,4)\" >>> linker . count_num_comparisons_from_blocking_rule ( br ) 394 Returns: Name Type Description int int The number of comparisons generated by the blocking rule count_num_comparisons_from_blocking_rules_for_prediction ( df_predict ) \u00b6 Counts the maginal number of edges created from each of the blocking rules in blocking_rules_to_generate_predictions This is different to count_num_comparisons_from_blocking_rule because it (a) analyses multiple blocking rules rather than a single rule, and (b) deduplicates any comparisons that are generated, to tell you the marginal effect of each entry in blocking_rules_to_generate_predictions Parameters: Name Type Description Default df_predict SplinkDataFrame SplinkDataFrame with match weights required Examples: >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> df_predict = linker . predict ( threshold_match_probability = 0.95 ) >>> count_pairwise = linker . count_num_comparisons_from_blocking_rules_for_prediction ( df_predict ) >>> count_pairwise . as_pandas_dataframe ( limit = 5 ) Returns: Name Type Description SplinkDataFrame A SplinkDataFrame of the pairwise comparisons and estimated pairwise comparisons generated by the blocking rules. cumulative_num_comparisons_from_blocking_rules_chart ( blocking_rules = None , link_type = None , unique_id_column_name = None ) \u00b6 Display a chart with the cumulative number of comparisons generated by a selection of blocking rules. This is equivalent to the output size of df_predict and details how many comparisons each of your individual blocking rules will contribute to the total. Parameters: Name Type Description Default blocking_rules str or list The blocking rule(s) to compute comparisons for. If null, the rules set out in your settings object will be used. None link_type str The link type. This defaults to the link type outlined in your settings object. None unique_id_column_name str This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None Examples: >>> linker_settings = DuckDBLinker ( df , settings ) >>> # Compute the cumulative number of comparisons generated by the rules >>> # in your settings object. >>> linker_settings . cumulative_num_comparisons_from_blocking_rules_chart () >>> >>> # Generate total comparisons with custom blocking rules. >>> blocking_rules = [ >>> \"l.surname = r.surname\" , >>> \"l.first_name = r.first_name >>> and substr ( l . dob , 1 , 4 ) = substr ( r . dob , 1 , 4 ) \" >>> ] >>> >>> linker . cumulative_num_comparisons_from_blocking_rules_chart ( >>> blocking_rules >>> ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. deterministic_link () \u00b6 Uses the blocking rules specified by blocking_rules_to_generate_predictions in the settings dictionary to generate pairwise record comparisons. For deterministic linkage, this should be a list of blocking rules which are strict enough to generate only true links. Deterministic linkage, however, is likely to result in missed links (false negatives). Examples: >>> linker = DuckDBLinker ( df ) >>> >>> settings = { >>> \"link_type\" : \"dedupe_only\" , >>> \"blocking_rules_to_generate_predictions\" : [ >>> \"l.first_name = r.first_name\" , >>> \"l.surname = r.surname\" , >>> ], >>> \"comparisons\" : [] >>> } >>> >>> from splink.duckdb.duckdb_linker import DuckDBLinker >>> >>> linker = DuckDBLinker ( df , settings ) >>> df = linker . deterministic_link () Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. estimate_m_from_label_column ( label_colname ) \u00b6 Estimate the m parameters of the linkage model from a label (ground truth) column in the input dataframe(s). The m parameters represent the proportion of record comparisons that fall into each comparison level amongst truly matching records. The ground truth column is used to generate pairwise record comparisons which are then assumed to be matches. For example, if the entity being matched is persons, and your input dataset(s) contain social security number, this could be used to estimate the m values for the model. Note that this column does not need to be fully populated. A common case is where a unique identifier such as social security number is only partially populated. Parameters: Name Type Description Default label_colname str The name of the column containing the ground truth label in the input data. required Examples: >>> linker . estimate_m_from_label_column ( \"social_security_number\" ) Returns: Type Description Updates the estimated m parameters within the linker object and returns nothing. estimate_parameters_using_expectation_maximisation ( blocking_rule , comparisons_to_deactivate = None , comparison_levels_to_reverse_blocking_rule = None , fix_probability_two_random_records_match = False , fix_m_probabilities = False , fix_u_probabilities = True ) \u00b6 Estimate the parameters of the linkage model using expectation maximisation. By default, the m probabilities are estimated, but not the u probabilities, because good estiamtes for the u probabilities can be obtained from linker.estimate_u_using_random_sampling() . You can change this by setting fix_u_probabilities to False. The blocking rule provided is used to generate pairwise record comparisons. Usually, this should be a blocking rule that results in a dataframe where matches are between about 1% and 99% of the comparisons. By default, m parameters are estimated for all comparisons except those which are included in the blocking rule. For example, if the blocking rule is l.first_name = r.first_name , then parameter esimates will be made for all comparison except those which use first_name in their sql_condition By default, the probability two random records match is estimated for the blocked data, and then the m and u parameters for the columns specified in the blocking rules are used to estiamte the global probability two random records match. To control which comparisons should have their parameter estimated, and the process of 'reversing out' the global probability two random records match, the user may specify comparisons_to_deactivate and comparison_levels_to_reverse_blocking_rule . This is useful, for example if you block on the dmetaphone of a column but match on the original column. Examples: >>> # Default behaviour >>> br_training = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker . estimate_parameters_using_expectation_maximisation ( br_training ) >>> # Specify which comparisons to deactivate >>> br_training = \"l.dmeta_first_name = r.dmeta_first_name\" >>> settings_obj = linker . _settings_obj >>> comp = settings_obj . _get_comparison_by_output_column_name ( \"first_name\" ) >>> dmeta_level = comp . _get_comparison_level_by_comparison_vector_value ( 1 ) >>> linker . estimate_parameters_using_expectation_maximisation ( >>> br_training , >>> comparisons_to_deactivate = [ \"first_name\" ], >>> comparison_levels_to_reverse_blocking_rule = [ dmeta_level ], >>> ) Parameters: Name Type Description Default blocking_rule str The blocking rule used to generate pairwise record comparisons. required comparisons_to_deactivate list By default, splink will analyse the blocking rule provided and estimate the m parameters for all comaprisons except those included in the blocking rule. If comparisons_to_deactivate are provided, spink will instead estimate m parameters for all comparison except those specified in the comparisons_to_deactivate list. This list can either contain the output_column_name of the Comparison as a string, or Comparison objects. Defaults to None. None comparison_levels_to_reverse_blocking_rule list By default, splink will analyse the blocking rule provided and adjust the global probability two random records match to account for the matches specified in the blocking rule. If provided, this argument will overrule this default behaviour. The user must provide a list of ComparisonLevel objects. Defaults to None. None fix_probability_two_random_records_match bool If True, do not update the probability two random records match after each iteration. Defaults to False. False fix_m_probabilities bool If True, do not update the m probabilities after each iteration. Defaults to False. False fix_u_probabilities bool If True, do not update the u probabilities after each iteration. Defaults to True. True Examples: >>> blocking_rule = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker . estimate_parameters_using_expectation_maximisation ( blocking_rule ) Returns: Name Type Description EMTrainingSession EMTrainingSession An object containing information about the training session such as how parameters changed during the iteration history estimate_u_using_random_sampling ( target_rows ) \u00b6 Estimate the u parameters of the linkage model using random sampling. The u parameters represent the proportion of record comparisons that fall into each comparison level amongst truly non-matching records. This procedure takes a sample of the data and generates the cartesian product of pairwise record comparisons amongst the sampled records. The validity of the u values rests on the assumption that the resultant pairwise comparisons are non-matches (or at least, they are very unlikely to be matches). For large datasets, this is typically true. Parameters: Name Type Description Default target_rows int The target number of pairwise record comparisons from required Examples: >>> linker . estimate_u_using_random_sampling ( 1e8 ) Returns: Name Type Description None Updates the estimated u parameters within the linker object and returns nothing. find_matches_to_new_records ( records_or_tablename , blocking_rules = [], match_weight_threshold =- 4 ) \u00b6 Given one or more records, find records in the input dataset(s) which match and return in order of the splink prediction score. This effectively provides a way of searching the input datasets for given record(s) Parameters: Name Type Description Default records_or_tablename List [ dict ] Input search record(s) as list of dict, or a table registered to the database. required blocking_rules list Blocking rules to select which records to find and score. If [], do not use a blocking rule - meaning the input records will be compared to all records provided to the linker when it was instantiated. Defaults to []. [] match_weight_threshold int Return matches with a match weight above this threshold. Defaults to -4. -4 Examples: >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> # Pre-compute tf tables for any tables with >>> # term frequency adjustments >>> linker . compute_tf_table ( \"first_name\" ) >>> record = { 'unique_id' : 1 , >>> 'first_name' : \"John\" , >>> 'surname' : \"Smith\" , >>> 'dob' : \"1971-05-24\" , >>> 'city' : \"London\" , >>> 'email' : \"john@smith.net\" >>> } >>> df = linker . find_matches_to_new_records ([ record ], blocking_rules = []) Returns: Name Type Description SplinkDataFrame SplinkDataFrame The pairwise comparisons. initialise_settings ( settings_dict ) \u00b6 Initialise settings for the linker. To be used if settings were not passed to the linker on creation. Examples: >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . profile_columns ([ \"first_name\" , \"surname\" ]) >>> linker . initialise_settings ( settings_dict ) Parameters: Name Type Description Default settings_dict dict A Splink settings dictionary required load_settings_from_json ( in_path ) \u00b6 Load settings from a .json file. This .json file would usually be the output of linker.save_settings_to_json() Examples: >>> linker . load_settings_from_json ( \"my_settings.json\" ) Parameters: Name Type Description Default in_path str Path to settings json file required m_u_parameters_chart () \u00b6 Display a chart of the m and u parameters of the linkage model Examples: >>> linker . m_u_parameters_chart () >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . match_weights_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500 ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. match_weights_chart () \u00b6 Display a chart of the (partial) match weights of the linkage model Examples: >>> linker . match_weights_chart () >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . match_weights_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500 ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. match_weights_histogram ( df_predict , target_bins = 30 , width = 600 , height = 250 ) \u00b6 Generate a histogram that shows the distribution of match weights in df_predict Parameters: Name Type Description Default df_predict SplinkDataFrame Output of linker.predict() required target_bins int Target number of bins in histogram. Defaults to 30. 30 width int Width of output. Defaults to 600. 600 height int Height of output chart. Defaults to 250. 250 Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. missingness_chart ( input_dataset = None ) \u00b6 Generate a summary chart of the missingness (prevalence of nulls) of columns in the input datasets. By default, missingness is assessed across all input datasets Parameters: Name Type Description Default input_dataset str Name of one of the input tables in the None Examples: >>> linker . missingness_chart () >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . missingness_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500 parameter_estimate_comparisons_chart ( include_m = True , include_u = True ) \u00b6 Show a chart that shows how parameter estimates have differed across the different estimation methods you have used. For example, if you have run two EM estimation sessions, blocking on different variables, and both result in parameter estimates for first_name, this chart will enable easy comparison of the different estimates Parameters: Name Type Description Default include_m bool Show different estimates of m values. Defaults to True. True include_u bool Show different estimates of u values. Defaults to True. True precision_recall_chart_from_labels ( labels_tablename ) \u00b6 Generate a precision-recall chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered as a table with your database: source_dataset_l unique_id_l source_dataset_r unique_id_r clerical_match_score df_1 1 df_2 2 0.99 df_1 1 df_2 3 0.2 Note that source_dataset and unique_id should correspond to the values specified in the settings dict, and the input_table_aliases passed to the linker object. For dedupe_only links, the source_dataset columns can be ommitted. Parameters: Name Type Description Default labels_tablename str Name of table containing labels in the database required threshold_actual float Where the clerical_match_score provided by the user is a probability rather than binary, this value is used as the threshold to classify clerical_match_score s as binary matches or non matches. Defaults to 0.5. required match_weight_round_to_nearest float When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. required Examples: >>> # DuckDBLinker >>> labels = pd . read_csv ( \"my_labels.csv\" ) >>> linker . _con . register ( \"labels\" , labels ) >>> linker . precision_recall_chart_from_labels ( \"labels\" ) >>> >>> # SparkLinker >>> labels = spark . read . csv ( \"my_labels.csv\" , header = True ) >>> labels . createDataFrame ( \"labels\" ) >>> linker . precision_recall_chart_from_labels ( \"labels\" ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. predict ( threshold_match_probability = None , threshold_match_weight = None ) \u00b6 Create a dataframe of scored pairwise comparisons using the parameters of the linkage model. Uses the blocking rules specified in the blocking_rules_to_generate_predictions of the settings dictionary to generate the pairwise comparisons. Parameters: Name Type Description Default threshold_match_probability float If specified, filter the results to include only pairwise comparisons with a match_probability above this threshold. Defaults to None. None threshold_match_weight float If specified, filter the results to include only pairwise comparisons with a match_weight above this threshold. Defaults to None. None Examples: >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> df = linker . predict ( threshold_match_probability = 0.95 ) >>> df . as_pandas_dataframe ( limit = 5 ) Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data. roc_chart_from_labels ( labels_tablename , threshold_actual = 0.5 , match_weight_round_to_nearest = None ) \u00b6 Generate a ROC chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered with your database: source_dataset_l unique_id_l source_dataset_r unique_id_r clerical_match_score df_1 1 df_2 2 0.99 df_1 1 df_2 3 0.2 Note that source_dataset and unique_id should correspond to the values specified in the settings dict, and the input_table_aliases passed to the linker object. For dedupe_only links, the source_dataset columns can be ommitted. Parameters: Name Type Description Default labels_tablename str Name of table containing labels in the database required threshold_actual float Where the clerical_match_score provided by the user is a probability rather than binary, this value is used as the threshold to classify clerical_match_score s as binary matches or non matches. Defaults to 0.5. 0.5 match_weight_round_to_nearest float When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. None Examples: >>> # DuckDBLinker >>> labels = pd . read_csv ( \"my_labels.csv\" ) >>> linker . _con . register ( \"labels\" , labels ) >>> linker . roc_chart_from_labels ( \"labels\" ) >>> >>> # SparkLinker >>> labels = spark . read . csv ( \"my_labels.csv\" , header = True ) >>> labels . createDataFrame ( \"labels\" ) >>> linker . roc_chart_from_labels ( \"labels\" ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. roc_table_from_labels ( labels_tablename , threshold_actual = 0.5 , match_weight_round_to_nearest = None ) \u00b6 Generate truth statistics (false positive etc.) for each threshold value of match_probability, suitable for plotting a ROC chart. The table of labels should be in the following format, and should be registered with your database: source_dataset_l unique_id_l source_dataset_r unique_id_r clerical_match_score df_1 1 df_2 2 0.99 df_1 1 df_2 3 0.2 Note that source_dataset and unique_id should correspond to the values specified in the settings dict, and the input_table_aliases passed to the linker object. For dedupe_only links, the source_dataset columns can be ommitted. Parameters: Name Type Description Default labels_tablename str Name of table containing labels in the database required threshold_actual float Where the clerical_match_score provided by the user is a probability rather than binary, this value is used as the threshold to classify clerical_match_score s as binary matches or non matches. Defaults to 0.5. 0.5 match_weight_round_to_nearest float When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. None Examples: >>> # DuckDBLinker >>> labels = pd . read_csv ( \"my_labels.csv\" ) >>> linker . _con . register ( \"labels\" , labels ) >>> linker . roc_table_from_labels ( \"labels\" ) >>> >>> # SparkLinker >>> labels = spark . read . csv ( \"my_labels.csv\" , header = True ) >>> labels . createDataFrame ( \"labels\" ) >>> linker . roc_table_from_labels ( \"labels\" ) Returns: Name Type Description SplinkDataFrame SplinkDataFrame Table of truth statistics save_settings_to_json ( out_path , overwrite = False ) \u00b6 Save the configuration and parameters the linkage model to a .json file. The model can later be loaded back in using linker.load_settings_from_json() Examples: >>> linker . save_settings_to_json ( \"my_settings.json\" , overwrite = True ) Parameters: Name Type Description Default out_path str File path for json file required overwrite bool Overwrite if already exists? Defaults to False. False unlinkables_chart ( x_col = 'match_weight' , source_dataset = None , as_dict = False ) \u00b6 Generate an interactive chart displaying the proportion of records that are \"unlinkable\" for a given splink score threshold and model parameters. Unlinkable records are those that, even when compared with themselves, do not contain enough information to confirm a match. Parameters: Name Type Description Default x_col str Column to use for the x-axis. Defaults to \"match_weight\". 'match_weight' source_dataset str Name of the source dataset to use for the title of the output chart. None as_dict bool If True, return a dict version of the chart. False Examples: >>> # For the simplest code pipeline, load a pre-trained model >>> # and run this against the test data. >>> df = pd . read_csv ( \"./tests/datasets/fake_1000_from_splink_demos.csv\" ) >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . unlinkables_chart () >>> >>> # For more complex code pipelines, you can run an entire pipeline >>> # that estimates your m and u values, before `unlinkables_chart(). Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. waterfall_chart ( records , filter_nulls = True ) \u00b6 Visualise how the final match weight is computed for the provided pairwise record comparisons. Records must be provided as a list of dictionaries. This would usually be obtained from df.as_record_dict(limit=n) where df is a SplinkDataFrame. Examples: >>> df = linker . predict ( threshold_match_weight = 2 ) >>> records = df . as_record_dict ( limit = 10 ) >>> linker . waterfall_chart ( records ) Parameters: Name Type Description Default records List [ dict ] Usually be obtained from df.as_record_dict(limit=n) where df is a SplinkDataFrame. required filter_nulls bool Whether the visualiation shows null comparisons, which have no effect on final match weight. Defaults to True. True Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. handler: python selection: members: - cluster_studio_dashboard - comparison_viewer_dashboard - m_u_parameters_chart - match_weights_histogram - match_weights_chart - parameter_estimate_comparisons_chart - precision_recall_chart_from_labels - roc_chart_from_labels - roc_table_from_labels - unlinkables_chart - waterfall_chart rendering: show_root_heading: false show_source: true","title":"Visualisation and quality assurance"},{"location":"linkerqa.html#documentation-for-linker-object-methods-related-to-qa","text":"The Linker object manages the data linkage process and holds the data linkage model. Most of Splink's functionality can be accessed by calling methods (functions) on the linker, such as linker.predict() , linker.profile_columns() etc. The Linker class is intended for subclassing for specific backends, e.g. a DuckDBLinker .","title":"Documentation for Linker object methods related to QA"},{"location":"linkerqa.html#splink.linker.Linker.__deepcopy__","text":"When we do EM training, we need a copy of the linker which is independent of the main linker e.g. setting parameters on the copy will not affect the main linker. This method implements ensures linker can be deepcopied.","title":"__deepcopy__()"},{"location":"linkerqa.html#splink.linker.Linker.__init__","text":"Initialise the linker object, which manages the data linkage process and holds the data linkage model. Examples: >>> # Example 1: DuckDB >>> df = pd . read_csv ( \"data_to_dedupe.csv\" ) >>> linker = DuckDBLinker ( df , settings_dict ) >>> # Example 2: Spark >>> df_1 = spark . read . parquet ( \"table_1/\" ) >>> df_2 = spark . read . parquet ( \"table_2/\" ) >>> linker = SparkLinker ( >>> [ df_1 , df_2 ], >>> settings_dict , >>> input_table_aliases = [ \"customers\" , \"contact_center_callers\" ] >>> ) Parameters: Name Type Description Default input_table_or_tables Union [ str , list ] Input data into the linkage model. Either a single string (the name of a table in a database) for deduplication jobs, or a list of strings (the name of tables in a database) for link_only or link_and_dedupe. For some linkers, such as the DuckDBLinker and the SparkLinker, it's also possible to pass in dataframes (Pandas and Spark respectively) rather than strings. required settings_dict dict A Splink settings dictionary. If not provided when the object is created, can later be added using linker.initialise_settings() Defaults to None. None set_up_basic_logging bool If true, sets ups up basic logging so that Splink sends messages at INFO level to stdout. Defaults to True. True input_table_aliases Union [ str , list ] Labels assigned to input tables in Splink outputs. If the names of the tables in the input database are long or unspecific, this argument can be used to attach more easily readable/interpretable names. Defaults to None. None","title":"__init__()"},{"location":"linkerqa.html#splink.linker.Linker.cluster_pairwise_predictions_at_threshold","text":"Clusters the pairwise match predictions that result from linker.predict() into groups of connected record using the connected components graph clustering algorithm Records with an estimated match_probability above threshold_match_probability are considered to be a match (i.e. they represent the same entity). Parameters: Name Type Description Default df_predict SplinkDataFrame The results of linker.predict() required threshold_match_probability float Filter the pairwise match predictions to include only pairwise comparisons with a match_probability above this threshold. This dataframe is then fed into the clustering algorithm. required Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame containing a list of all IDs, clustered into groups based on the desired match threshold.","title":"cluster_pairwise_predictions_at_threshold()"},{"location":"linkerqa.html#splink.linker.Linker.cluster_studio_dashboard","text":"Generate an interactive html visualization of the predicted cluster and save to out_path . Parameters: Name Type Description Default df_predict SplinkDataFrame The outputs of linker.predict() required df_clustered SplinkDataFrame The outputs of linker.cluster_pairwise_predictions_at_threshold() required out_path str The path (including filename) to save the html file to. required sampling_method str random or by_cluster_size . Defaults to random . 'random' sample_size int Number of clusters to show in the dahboard. Defaults to 10. 10 cluster_ids list The IDs of the clusters that will be displayed in the dashboard. If provided, ignore the sampling_method and sample_size arguments. Defaults to None. None overwrite bool Overwrite the html file if it already exists? Defaults to False. False cluster_names list If provided, the dashboard will display these names in the selection box. Ony works in conjunction with cluster_ids . Defaults to None. None return_html_as_string If True, return the html as a string False Examples: >>> df_p = linker . predict () >>> df_c = linker . cluster_pairwise_predictions_at_threshold ( df_p , 0.5 ) >>> linker . cluster_studio_dashboard ( >>> df_p , df_c , [ 0 , 4 , 7 ], \"cluster_studio.html\" >>> ) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame ( src = \"./cluster_studio.html\" , width = \"100%\" , height = 1200 )","title":"cluster_studio_dashboard()"},{"location":"linkerqa.html#splink.linker.Linker.compare_two_records","text":"Use the linkage model to compare and score a pairwise record comparison based on the two input records provided Parameters: Name Type Description Default record_1 dict dictionary representing the first record. Columns names and data types must be the same as the columns in the settings object required record_2 dict dictionary representing the second record. Columns names and data types must be the same as the columns in the settings object required Examples: >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . compare_two_records ( record_left , record_right ) Returns: Name Type Description SplinkDataFrame Pairwise comparison with scored prediction","title":"compare_two_records()"},{"location":"linkerqa.html#splink.linker.Linker.comparison_viewer_dashboard","text":"Generate an interactive html visualization of the linker's predictions and save to out_path . For more information see this video Parameters: Name Type Description Default df_predict SplinkDataFrame The outputs of linker.predict() required out_path str The path (including filename) to save the html file to. required overwrite bool Overwrite the html file if it already exists? Defaults to False. False num_example_rows int Number of example rows per comparison vector. Defaults to 2. 2 return_html_as_string If True, return the html as a string False Examples: >>> df_predictions = linker . predict () >>> linker . comparison_viewer_dashboard ( df_predictions , \"scv.html\" , True , 2 ) >>> >>> # Optionally, in Jupyter, you can display the results inline >>> # Otherwise you can just load the html file in your browser >>> from IPython.display import IFrame >>> IFrame ( src = \"./scv.html\" , width = \"100%\" , height = 1200 )","title":"comparison_viewer_dashboard()"},{"location":"linkerqa.html#splink.linker.Linker.completeness_chart","text":"Generate a summary chart of the completeness (proportion of non-nulls) of columns in each of the input datasets. By default, completeness is assessed for all column in the input data. Parameters: Name Type Description Default input_dataset str Name of one of the input tables in the database. If provided, completeness will be computed for this table alone. Defaults to None. None cols List [ str ] List of column names to calculate completeness. Default to None. None Examples: >>> linker . completeness_chart () >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . completeness_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500","title":"completeness_chart()"},{"location":"linkerqa.html#splink.linker.Linker.compute_tf_table","text":"Compute a term frequency table for a given column and persist to the database This method is useful if you want to pre-compute term frequency tables e.g. so that real time linkage executes faster, or so that you can estimate various models without having to recompute term frequency tables each time Examples: >>> # Example 1: Real time linkage >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . compute_tf_table ( \"surname\" ) >>> linker . compare_two_records ( record_left , record_right ) >>> # Example 2: Pre-computed term frequency tables in Spark >>> linker = SparkLinker ( df ) >>> df_first_name_tf = linker . compute_tf_table ( \"first_name\" ) >>> df_first_name_tf . write . parquet ( \"folder/first_name_tf\" ) >>> >>> # On subsequent data linking job, read this table rather than recompute >>> df_first_name_tf = spark . read . parquet ( \"folder/first_name_tf\" ) >>> df_first_name_tf . createOrReplaceTempView ( \"__splink__df_tf_first_name\" ) Parameters: Name Type Description Default column_name str The column name in the input table required Returns: Name Type Description SplinkDataFrame SplinkDataFrame The resultant table as a splink data frame","title":"compute_tf_table()"},{"location":"linkerqa.html#splink.linker.Linker.count_num_comparisons_from_blocking_rule","text":"Compute the number of pairwise record comparisons that would be generated by a blocking rule Parameters: Name Type Description Default blocking_rule str The blocking rule to analyse required link_type str The link type. This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None unique_id_column_name str This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None Examples: >>> br = \"l.first_name = r.first_name\" >>> linker . count_num_comparisons_from_blocking_rule ( br ) 19387 >>> br = \"l.name = r.name and substr(l.dob,1,4) = substr(r.dob,1,4)\" >>> linker . count_num_comparisons_from_blocking_rule ( br ) 394 Returns: Name Type Description int int The number of comparisons generated by the blocking rule","title":"count_num_comparisons_from_blocking_rule()"},{"location":"linkerqa.html#splink.linker.Linker.count_num_comparisons_from_blocking_rules_for_prediction","text":"Counts the maginal number of edges created from each of the blocking rules in blocking_rules_to_generate_predictions This is different to count_num_comparisons_from_blocking_rule because it (a) analyses multiple blocking rules rather than a single rule, and (b) deduplicates any comparisons that are generated, to tell you the marginal effect of each entry in blocking_rules_to_generate_predictions Parameters: Name Type Description Default df_predict SplinkDataFrame SplinkDataFrame with match weights required Examples: >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> df_predict = linker . predict ( threshold_match_probability = 0.95 ) >>> count_pairwise = linker . count_num_comparisons_from_blocking_rules_for_prediction ( df_predict ) >>> count_pairwise . as_pandas_dataframe ( limit = 5 ) Returns: Name Type Description SplinkDataFrame A SplinkDataFrame of the pairwise comparisons and estimated pairwise comparisons generated by the blocking rules.","title":"count_num_comparisons_from_blocking_rules_for_prediction()"},{"location":"linkerqa.html#splink.linker.Linker.cumulative_num_comparisons_from_blocking_rules_chart","text":"Display a chart with the cumulative number of comparisons generated by a selection of blocking rules. This is equivalent to the output size of df_predict and details how many comparisons each of your individual blocking rules will contribute to the total. Parameters: Name Type Description Default blocking_rules str or list The blocking rule(s) to compute comparisons for. If null, the rules set out in your settings object will be used. None link_type str The link type. This defaults to the link type outlined in your settings object. None unique_id_column_name str This is needed only if the linker has not yet been provided with a settings dictionary. Defaults to None. None Examples: >>> linker_settings = DuckDBLinker ( df , settings ) >>> # Compute the cumulative number of comparisons generated by the rules >>> # in your settings object. >>> linker_settings . cumulative_num_comparisons_from_blocking_rules_chart () >>> >>> # Generate total comparisons with custom blocking rules. >>> blocking_rules = [ >>> \"l.surname = r.surname\" , >>> \"l.first_name = r.first_name >>> and substr ( l . dob , 1 , 4 ) = substr ( r . dob , 1 , 4 ) \" >>> ] >>> >>> linker . cumulative_num_comparisons_from_blocking_rules_chart ( >>> blocking_rules >>> ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute.","title":"cumulative_num_comparisons_from_blocking_rules_chart()"},{"location":"linkerqa.html#splink.linker.Linker.deterministic_link","text":"Uses the blocking rules specified by blocking_rules_to_generate_predictions in the settings dictionary to generate pairwise record comparisons. For deterministic linkage, this should be a list of blocking rules which are strict enough to generate only true links. Deterministic linkage, however, is likely to result in missed links (false negatives). Examples: >>> linker = DuckDBLinker ( df ) >>> >>> settings = { >>> \"link_type\" : \"dedupe_only\" , >>> \"blocking_rules_to_generate_predictions\" : [ >>> \"l.first_name = r.first_name\" , >>> \"l.surname = r.surname\" , >>> ], >>> \"comparisons\" : [] >>> } >>> >>> from splink.duckdb.duckdb_linker import DuckDBLinker >>> >>> linker = DuckDBLinker ( df , settings ) >>> df = linker . deterministic_link () Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data.","title":"deterministic_link()"},{"location":"linkerqa.html#splink.linker.Linker.estimate_m_from_label_column","text":"Estimate the m parameters of the linkage model from a label (ground truth) column in the input dataframe(s). The m parameters represent the proportion of record comparisons that fall into each comparison level amongst truly matching records. The ground truth column is used to generate pairwise record comparisons which are then assumed to be matches. For example, if the entity being matched is persons, and your input dataset(s) contain social security number, this could be used to estimate the m values for the model. Note that this column does not need to be fully populated. A common case is where a unique identifier such as social security number is only partially populated. Parameters: Name Type Description Default label_colname str The name of the column containing the ground truth label in the input data. required Examples: >>> linker . estimate_m_from_label_column ( \"social_security_number\" ) Returns: Type Description Updates the estimated m parameters within the linker object and returns nothing.","title":"estimate_m_from_label_column()"},{"location":"linkerqa.html#splink.linker.Linker.estimate_parameters_using_expectation_maximisation","text":"Estimate the parameters of the linkage model using expectation maximisation. By default, the m probabilities are estimated, but not the u probabilities, because good estiamtes for the u probabilities can be obtained from linker.estimate_u_using_random_sampling() . You can change this by setting fix_u_probabilities to False. The blocking rule provided is used to generate pairwise record comparisons. Usually, this should be a blocking rule that results in a dataframe where matches are between about 1% and 99% of the comparisons. By default, m parameters are estimated for all comparisons except those which are included in the blocking rule. For example, if the blocking rule is l.first_name = r.first_name , then parameter esimates will be made for all comparison except those which use first_name in their sql_condition By default, the probability two random records match is estimated for the blocked data, and then the m and u parameters for the columns specified in the blocking rules are used to estiamte the global probability two random records match. To control which comparisons should have their parameter estimated, and the process of 'reversing out' the global probability two random records match, the user may specify comparisons_to_deactivate and comparison_levels_to_reverse_blocking_rule . This is useful, for example if you block on the dmetaphone of a column but match on the original column. Examples: >>> # Default behaviour >>> br_training = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker . estimate_parameters_using_expectation_maximisation ( br_training ) >>> # Specify which comparisons to deactivate >>> br_training = \"l.dmeta_first_name = r.dmeta_first_name\" >>> settings_obj = linker . _settings_obj >>> comp = settings_obj . _get_comparison_by_output_column_name ( \"first_name\" ) >>> dmeta_level = comp . _get_comparison_level_by_comparison_vector_value ( 1 ) >>> linker . estimate_parameters_using_expectation_maximisation ( >>> br_training , >>> comparisons_to_deactivate = [ \"first_name\" ], >>> comparison_levels_to_reverse_blocking_rule = [ dmeta_level ], >>> ) Parameters: Name Type Description Default blocking_rule str The blocking rule used to generate pairwise record comparisons. required comparisons_to_deactivate list By default, splink will analyse the blocking rule provided and estimate the m parameters for all comaprisons except those included in the blocking rule. If comparisons_to_deactivate are provided, spink will instead estimate m parameters for all comparison except those specified in the comparisons_to_deactivate list. This list can either contain the output_column_name of the Comparison as a string, or Comparison objects. Defaults to None. None comparison_levels_to_reverse_blocking_rule list By default, splink will analyse the blocking rule provided and adjust the global probability two random records match to account for the matches specified in the blocking rule. If provided, this argument will overrule this default behaviour. The user must provide a list of ComparisonLevel objects. Defaults to None. None fix_probability_two_random_records_match bool If True, do not update the probability two random records match after each iteration. Defaults to False. False fix_m_probabilities bool If True, do not update the m probabilities after each iteration. Defaults to False. False fix_u_probabilities bool If True, do not update the u probabilities after each iteration. Defaults to True. True Examples: >>> blocking_rule = \"l.first_name = r.first_name and l.dob = r.dob\" >>> linker . estimate_parameters_using_expectation_maximisation ( blocking_rule ) Returns: Name Type Description EMTrainingSession EMTrainingSession An object containing information about the training session such as how parameters changed during the iteration history","title":"estimate_parameters_using_expectation_maximisation()"},{"location":"linkerqa.html#splink.linker.Linker.estimate_u_using_random_sampling","text":"Estimate the u parameters of the linkage model using random sampling. The u parameters represent the proportion of record comparisons that fall into each comparison level amongst truly non-matching records. This procedure takes a sample of the data and generates the cartesian product of pairwise record comparisons amongst the sampled records. The validity of the u values rests on the assumption that the resultant pairwise comparisons are non-matches (or at least, they are very unlikely to be matches). For large datasets, this is typically true. Parameters: Name Type Description Default target_rows int The target number of pairwise record comparisons from required Examples: >>> linker . estimate_u_using_random_sampling ( 1e8 ) Returns: Name Type Description None Updates the estimated u parameters within the linker object and returns nothing.","title":"estimate_u_using_random_sampling()"},{"location":"linkerqa.html#splink.linker.Linker.find_matches_to_new_records","text":"Given one or more records, find records in the input dataset(s) which match and return in order of the splink prediction score. This effectively provides a way of searching the input datasets for given record(s) Parameters: Name Type Description Default records_or_tablename List [ dict ] Input search record(s) as list of dict, or a table registered to the database. required blocking_rules list Blocking rules to select which records to find and score. If [], do not use a blocking rule - meaning the input records will be compared to all records provided to the linker when it was instantiated. Defaults to []. [] match_weight_threshold int Return matches with a match weight above this threshold. Defaults to -4. -4 Examples: >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> # Pre-compute tf tables for any tables with >>> # term frequency adjustments >>> linker . compute_tf_table ( \"first_name\" ) >>> record = { 'unique_id' : 1 , >>> 'first_name' : \"John\" , >>> 'surname' : \"Smith\" , >>> 'dob' : \"1971-05-24\" , >>> 'city' : \"London\" , >>> 'email' : \"john@smith.net\" >>> } >>> df = linker . find_matches_to_new_records ([ record ], blocking_rules = []) Returns: Name Type Description SplinkDataFrame SplinkDataFrame The pairwise comparisons.","title":"find_matches_to_new_records()"},{"location":"linkerqa.html#splink.linker.Linker.initialise_settings","text":"Initialise settings for the linker. To be used if settings were not passed to the linker on creation. Examples: >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . profile_columns ([ \"first_name\" , \"surname\" ]) >>> linker . initialise_settings ( settings_dict ) Parameters: Name Type Description Default settings_dict dict A Splink settings dictionary required","title":"initialise_settings()"},{"location":"linkerqa.html#splink.linker.Linker.load_settings_from_json","text":"Load settings from a .json file. This .json file would usually be the output of linker.save_settings_to_json() Examples: >>> linker . load_settings_from_json ( \"my_settings.json\" ) Parameters: Name Type Description Default in_path str Path to settings json file required","title":"load_settings_from_json()"},{"location":"linkerqa.html#splink.linker.Linker.m_u_parameters_chart","text":"Display a chart of the m and u parameters of the linkage model Examples: >>> linker . m_u_parameters_chart () >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . match_weights_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500 ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute.","title":"m_u_parameters_chart()"},{"location":"linkerqa.html#splink.linker.Linker.match_weights_chart","text":"Display a chart of the (partial) match weights of the linkage model Examples: >>> linker . match_weights_chart () >>> >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . match_weights_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500 ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute.","title":"match_weights_chart()"},{"location":"linkerqa.html#splink.linker.Linker.match_weights_histogram","text":"Generate a histogram that shows the distribution of match weights in df_predict Parameters: Name Type Description Default df_predict SplinkDataFrame Output of linker.predict() required target_bins int Target number of bins in histogram. Defaults to 30. 30 width int Width of output. Defaults to 600. 600 height int Height of output chart. Defaults to 250. 250 Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute.","title":"match_weights_histogram()"},{"location":"linkerqa.html#splink.linker.Linker.missingness_chart","text":"Generate a summary chart of the missingness (prevalence of nulls) of columns in the input datasets. By default, missingness is assessed across all input datasets Parameters: Name Type Description Default input_dataset str Name of one of the input tables in the None Examples: >>> linker . missingness_chart () >>> # To view offline (if you don't have an internet connection): >>> >>> from splink.charts import save_offline_chart >>> c = linker . missingness_chart () >>> save_offline_chart ( c . spec , \"test_chart.html\" ) >>> >>> # View resultant html file in Jupyter (or just load it in your browser) >>> from IPython.display import IFrame >>> IFrame ( src = \"./test_chart.html\" , width = 1000 , height = 500","title":"missingness_chart()"},{"location":"linkerqa.html#splink.linker.Linker.parameter_estimate_comparisons_chart","text":"Show a chart that shows how parameter estimates have differed across the different estimation methods you have used. For example, if you have run two EM estimation sessions, blocking on different variables, and both result in parameter estimates for first_name, this chart will enable easy comparison of the different estimates Parameters: Name Type Description Default include_m bool Show different estimates of m values. Defaults to True. True include_u bool Show different estimates of u values. Defaults to True. True","title":"parameter_estimate_comparisons_chart()"},{"location":"linkerqa.html#splink.linker.Linker.precision_recall_chart_from_labels","text":"Generate a precision-recall chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered as a table with your database: source_dataset_l unique_id_l source_dataset_r unique_id_r clerical_match_score df_1 1 df_2 2 0.99 df_1 1 df_2 3 0.2 Note that source_dataset and unique_id should correspond to the values specified in the settings dict, and the input_table_aliases passed to the linker object. For dedupe_only links, the source_dataset columns can be ommitted. Parameters: Name Type Description Default labels_tablename str Name of table containing labels in the database required threshold_actual float Where the clerical_match_score provided by the user is a probability rather than binary, this value is used as the threshold to classify clerical_match_score s as binary matches or non matches. Defaults to 0.5. required match_weight_round_to_nearest float When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. required Examples: >>> # DuckDBLinker >>> labels = pd . read_csv ( \"my_labels.csv\" ) >>> linker . _con . register ( \"labels\" , labels ) >>> linker . precision_recall_chart_from_labels ( \"labels\" ) >>> >>> # SparkLinker >>> labels = spark . read . csv ( \"my_labels.csv\" , header = True ) >>> labels . createDataFrame ( \"labels\" ) >>> linker . precision_recall_chart_from_labels ( \"labels\" ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute.","title":"precision_recall_chart_from_labels()"},{"location":"linkerqa.html#splink.linker.Linker.predict","text":"Create a dataframe of scored pairwise comparisons using the parameters of the linkage model. Uses the blocking rules specified in the blocking_rules_to_generate_predictions of the settings dictionary to generate the pairwise comparisons. Parameters: Name Type Description Default threshold_match_probability float If specified, filter the results to include only pairwise comparisons with a match_probability above this threshold. Defaults to None. None threshold_match_weight float If specified, filter the results to include only pairwise comparisons with a match_weight above this threshold. Defaults to None. None Examples: >>> linker = DuckDBLinker ( df , connection = \":memory:\" ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> df = linker . predict ( threshold_match_probability = 0.95 ) >>> df . as_pandas_dataframe ( limit = 5 ) Returns: Name Type Description SplinkDataFrame SplinkDataFrame A SplinkDataFrame of the pairwise comparisons. This represents a table materialised in the database. Methods on the SplinkDataFrame allow you to access the underlying data.","title":"predict()"},{"location":"linkerqa.html#splink.linker.Linker.roc_chart_from_labels","text":"Generate a ROC chart from labelled (ground truth) data. The table of labels should be in the following format, and should be registered with your database: source_dataset_l unique_id_l source_dataset_r unique_id_r clerical_match_score df_1 1 df_2 2 0.99 df_1 1 df_2 3 0.2 Note that source_dataset and unique_id should correspond to the values specified in the settings dict, and the input_table_aliases passed to the linker object. For dedupe_only links, the source_dataset columns can be ommitted. Parameters: Name Type Description Default labels_tablename str Name of table containing labels in the database required threshold_actual float Where the clerical_match_score provided by the user is a probability rather than binary, this value is used as the threshold to classify clerical_match_score s as binary matches or non matches. Defaults to 0.5. 0.5 match_weight_round_to_nearest float When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. None Examples: >>> # DuckDBLinker >>> labels = pd . read_csv ( \"my_labels.csv\" ) >>> linker . _con . register ( \"labels\" , labels ) >>> linker . roc_chart_from_labels ( \"labels\" ) >>> >>> # SparkLinker >>> labels = spark . read . csv ( \"my_labels.csv\" , header = True ) >>> labels . createDataFrame ( \"labels\" ) >>> linker . roc_chart_from_labels ( \"labels\" ) Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute.","title":"roc_chart_from_labels()"},{"location":"linkerqa.html#splink.linker.Linker.roc_table_from_labels","text":"Generate truth statistics (false positive etc.) for each threshold value of match_probability, suitable for plotting a ROC chart. The table of labels should be in the following format, and should be registered with your database: source_dataset_l unique_id_l source_dataset_r unique_id_r clerical_match_score df_1 1 df_2 2 0.99 df_1 1 df_2 3 0.2 Note that source_dataset and unique_id should correspond to the values specified in the settings dict, and the input_table_aliases passed to the linker object. For dedupe_only links, the source_dataset columns can be ommitted. Parameters: Name Type Description Default labels_tablename str Name of table containing labels in the database required threshold_actual float Where the clerical_match_score provided by the user is a probability rather than binary, this value is used as the threshold to classify clerical_match_score s as binary matches or non matches. Defaults to 0.5. 0.5 match_weight_round_to_nearest float When provided, thresholds are rounded. When large numbers of labels are provided, this is sometimes necessary to reduce the size of the ROC table, and therefore the number of points plotted on the ROC chart. Defaults to None. None Examples: >>> # DuckDBLinker >>> labels = pd . read_csv ( \"my_labels.csv\" ) >>> linker . _con . register ( \"labels\" , labels ) >>> linker . roc_table_from_labels ( \"labels\" ) >>> >>> # SparkLinker >>> labels = spark . read . csv ( \"my_labels.csv\" , header = True ) >>> labels . createDataFrame ( \"labels\" ) >>> linker . roc_table_from_labels ( \"labels\" ) Returns: Name Type Description SplinkDataFrame SplinkDataFrame Table of truth statistics","title":"roc_table_from_labels()"},{"location":"linkerqa.html#splink.linker.Linker.save_settings_to_json","text":"Save the configuration and parameters the linkage model to a .json file. The model can later be loaded back in using linker.load_settings_from_json() Examples: >>> linker . save_settings_to_json ( \"my_settings.json\" , overwrite = True ) Parameters: Name Type Description Default out_path str File path for json file required overwrite bool Overwrite if already exists? Defaults to False. False","title":"save_settings_to_json()"},{"location":"linkerqa.html#splink.linker.Linker.unlinkables_chart","text":"Generate an interactive chart displaying the proportion of records that are \"unlinkable\" for a given splink score threshold and model parameters. Unlinkable records are those that, even when compared with themselves, do not contain enough information to confirm a match. Parameters: Name Type Description Default x_col str Column to use for the x-axis. Defaults to \"match_weight\". 'match_weight' source_dataset str Name of the source dataset to use for the title of the output chart. None as_dict bool If True, return a dict version of the chart. False Examples: >>> # For the simplest code pipeline, load a pre-trained model >>> # and run this against the test data. >>> df = pd . read_csv ( \"./tests/datasets/fake_1000_from_splink_demos.csv\" ) >>> linker = DuckDBLinker ( df ) >>> linker . load_settings_from_json ( \"saved_settings.json\" ) >>> linker . unlinkables_chart () >>> >>> # For more complex code pipelines, you can run an entire pipeline >>> # that estimates your m and u values, before `unlinkables_chart(). Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute.","title":"unlinkables_chart()"},{"location":"linkerqa.html#splink.linker.Linker.waterfall_chart","text":"Visualise how the final match weight is computed for the provided pairwise record comparisons. Records must be provided as a list of dictionaries. This would usually be obtained from df.as_record_dict(limit=n) where df is a SplinkDataFrame. Examples: >>> df = linker . predict ( threshold_match_weight = 2 ) >>> records = df . as_record_dict ( limit = 10 ) >>> linker . waterfall_chart ( records ) Parameters: Name Type Description Default records List [ dict ] Usually be obtained from df.as_record_dict(limit=n) where df is a SplinkDataFrame. required filter_nulls bool Whether the visualiation shows null comparisons, which have no effect on final match weight. Defaults to True. True Returns: Name Type Description VegaLite A VegaLite chart object. See altair.vegalite.v4.display.VegaLite. The vegalite spec is available as a dictionary using the spec attribute. handler: python selection: members: - cluster_studio_dashboard - comparison_viewer_dashboard - m_u_parameters_chart - match_weights_histogram - match_weights_chart - parameter_estimate_comparisons_chart - precision_recall_chart_from_labels - roc_chart_from_labels - roc_table_from_labels - unlinkables_chart - waterfall_chart rendering: show_root_heading: false show_source: true","title":"waterfall_chart()"},{"location":"settings_dict_guide.html","text":"Guide to Splink settings \u00b6 This document enumerates all the settings and configuration options available when developing your data linkage model. You can find an interative settings editor here . Settings keys in the base setting dictionary \u00b6 link_type \u00b6 The type of data linking task. Required. When dedupe_only , splink find duplicates. User expected to provide a single input dataset. When link_and_dedupe , splink finds links within and between input datasets. User is expected to provide two or more input datasets. When link_only , splink finds links between datasets, but does not attempt to deduplicate the datasets (it does not try and find links within each input dataset.) User is expected to provide two or more input datasets. Examples : ['dedupe_only', 'link_only', 'link_and_dedupe'] probability_two_random_records_match \u00b6 The probability that two records chosen at random (with no blocking) are a match. For example, if there are a million input records and each has on average one match, then this value should be 1/1,000,000. If you estimate parameters using expectation maximisation (EM), this provides an initial value (prior) from which the EM algorithm will start iterating. EM will then estimate the true value of this parameter. Default value : 0.0001 Examples : [1e-05, 0.006] em_convergence \u00b6 Convergence tolerance for the Expectation Maximisation algorithm The algorithm will stop converging when the maximum of the change in model parameters between iterations is below this value Default value : 0.0001 Examples : [0.0001, 1e-05, 1e-06] max_iterations \u00b6 The maximum number of Expectation Maximisation iterations to run (even if convergence has not been reached) Default value : 25 Examples : [20, 150] unique_id_column_name \u00b6 Splink requires that the input dataset has a column that uniquely identifies each reecord. unique_id_column_name is the name of the column in the input dataset representing this unique id For linking tasks, ids must be unique within each dataset being linked, and do not need to be globally unique across input datasets Default value : unique_id Examples : ['unique_id', 'id', 'pk'] source_dataset_column_name \u00b6 The name of the column in the input dataset representing the source dataset Where we are linking datasets, we can't guarantee that the unique id column is globally unique across datasets, so we combine it with a source_dataset column. Usually, this is created by Splink for the user Default value : source_dataset Examples : ['source_dataset', 'dataset_name'] retain_matching_columns \u00b6 If set to true, each column used by the comparisons sql expressions will be retained in output datasets This is helpful so that the user can inspect matches, but once the comparison vector (gamma) columns are computed, this information is not actually needed by the algorithm. The algorithm will run faster and use less resources if this is set to false. Default value : True Examples : [False, True] retain_intermediate_calculation_columns \u00b6 Retain intermediate calculation columns, such as the bayes factors associated with each column in comparisons The algorithm will run faster and use less resources if this is set to false. Default value : False Examples : [False, True] comparisons \u00b6 A list specifying how records should be compared for probabalistic matching. Each element is a dictionary blocking_rules_to_generate_predictions \u00b6 A list of one or more blocking rules to apply. A cartesian join is applied if blocking_rules_to_generate_predictions is empty or not supplied. Each rule is a SQL expression representing the blocking rule, which will be used to create a join. The left table is aliased with l and the right table is aliased with r . For example, if you want to block on a first_name column, the blocking rule would be l.first_name = r.first_name . To block on first name and the first letter of surname, it would be l.first_name = r.first_name and substr(l.surname,1,1) = substr(r.surname,1,1) . Note that splink deduplicates the comparisons generated by the blocking rules. If empty or not supplied, all comparisons between the input dataset(s) will be generated and blocking will not be used. For large input datasets, this will generally be computationally intractable because it will generate comparisons equal to the number of rows squared. Default value : [] Examples : [['l.first_name = r.first_name AND l.surname = r.surname', 'l.dob = r.dob']] additional_columns_to_retain \u00b6 A list of columns not being used in the probabalistic matching comparisons that you want to include in your results. By default, splink drops columns which are not used by any comparisons. This gives you the option to retain columns which are not used by the model. A common example is if the user has labelled data (training data) and wishes to retain the labels in the outputs Default value : [] Examples : [['cluster', 'col_2'], ['other_information']] bayes_factor_column_prefix \u00b6 The prefix to use for the columns that will be created to store the bayes factors Default value : bf_ Examples : ['bf_', '__bf__'] term_frequency_adjustment_column_prefix \u00b6 The prefix to use for the columns that will be created to store the term frequency adjustments Default value : tf_ Examples : ['tf_', '__tf__'] comparison_vector_value_column_prefix \u00b6 The prefix to use for the columns that will be created to store the comparison vector values Default value : gamma_ Examples : ['gamma_', '__gamma__'] sql_dialect \u00b6 The SQL dialect in which sql_conditions are written. Must be a valid sqlglot dialect Default value : None Examples : ['spark', 'duckdb', 'presto', 'sqlite'] Settings keys nested within each member of comparisons \u00b6 output_column_name \u00b6 The name used to refer to this comparison in the output dataset. By default, Splink will set this to the name(s) of any input columns used in the comparison. This key is most useful to give a clearer description to comparisons that use multiple input columns. e.g. a location column that uses postcode and town may be named location For a comparison column that uses a single input column, e.g. first_name, this will be set first_name. For comparison columns that use multiple columns, if left blank, this will be set to the concatenation of columns used. Examples : ['first_name', 'surname'] comparison_description \u00b6 An optional label to describe this comparison, to be used in charting outputs. Examples : ['First name exact match', 'Surname with middle levenshtein level'] comparison_levels \u00b6 Comparison levels specify how input values should be compared. Each level corresponds to an assessment of similarity, such as exact match, jaro winkler match, one side of the match being null, etc Each comparison level represents a branch of a SQL case expression. They are specified in order of evaluation, each with a sql_condition that represents the branch of a case expression Examples : [{'sql_condition': 'first_name_l IS NULL OR first_name_r IS NULL', 'label': 'null', 'null_level': True}, {'sql_condition': 'first_name_l = first_name_r', 'label': 'exact_match', 'tf_adjustment_column': 'first_name'}, {'sql_condition': 'ELSE', 'label': 'else'}] Settings keys nested within each member of comparison_levels \u00b6 sql_condition \u00b6 A branch of a SQL case expression without WHEN and THEN e.g. 'jaro_winkler_sim(surname_l, surname_r) > 0.88' Examples : ['forename_l = forename_r', 'jaro_winkler_sim(surname_l, surname_r) > 0.88'] label_for_charts \u00b6 A label for this comparson level, which will appear on charts as a reminder of what the level represts Examples : ['exact', 'postcode exact'] u_probability \u00b6 the u probability for this comparison level - i.e. the proportion of records that match this level amongst truly non-matching records Examples : [0.9] m_probability \u00b6 the m probability for this comparison level - i.e. the proportion of records that match this level amongst truly matching records Examples : [0.1] is_null_level \u00b6 If true, m and u values will not be estimated and instead the match weight will be zero for this column. See treatment of nulls here on page 356, quote '. Under this MAR assumption, we can simply ignore missing data.': https://imai.fas.harvard.edu/research/files/linkage.pdf Default value : False tf_adjustment_column \u00b6 Make term frequency adjustments for this comparison level using this input column Default value : None Examples : ['first_name', 'postcode'] tf_adjustment_weight \u00b6 Make term frequency adjustments using this weight. A weight of 1.0 is a full adjustment. A weight of 0.0 is no adjustment. A weight of 0.5 is a half adjustment Default value : 1.0 Examples : ['first_name', 'postcode'] tf_minimum_u_value \u00b6 Where the term frequency adjustment implies a u value below this value, use this minimum value instead This prevents excessive weight being assigned to very unusual terms, such as a collision on a typo Default value : 0.0 Examples : [0.001, 1e-09]","title":"Settings dictionary reference"},{"location":"settings_dict_guide.html#guide-to-splink-settings","text":"This document enumerates all the settings and configuration options available when developing your data linkage model. You can find an interative settings editor here .","title":"Guide to Splink settings"},{"location":"settings_dict_guide.html#settings-keys-in-the-base-setting-dictionary","text":"","title":"Settings keys in the base setting dictionary"},{"location":"settings_dict_guide.html#link_type","text":"The type of data linking task. Required. When dedupe_only , splink find duplicates. User expected to provide a single input dataset. When link_and_dedupe , splink finds links within and between input datasets. User is expected to provide two or more input datasets. When link_only , splink finds links between datasets, but does not attempt to deduplicate the datasets (it does not try and find links within each input dataset.) User is expected to provide two or more input datasets. Examples : ['dedupe_only', 'link_only', 'link_and_dedupe']","title":"link_type"},{"location":"settings_dict_guide.html#probability_two_random_records_match","text":"The probability that two records chosen at random (with no blocking) are a match. For example, if there are a million input records and each has on average one match, then this value should be 1/1,000,000. If you estimate parameters using expectation maximisation (EM), this provides an initial value (prior) from which the EM algorithm will start iterating. EM will then estimate the true value of this parameter. Default value : 0.0001 Examples : [1e-05, 0.006]","title":"probability_two_random_records_match"},{"location":"settings_dict_guide.html#em_convergence","text":"Convergence tolerance for the Expectation Maximisation algorithm The algorithm will stop converging when the maximum of the change in model parameters between iterations is below this value Default value : 0.0001 Examples : [0.0001, 1e-05, 1e-06]","title":"em_convergence"},{"location":"settings_dict_guide.html#max_iterations","text":"The maximum number of Expectation Maximisation iterations to run (even if convergence has not been reached) Default value : 25 Examples : [20, 150]","title":"max_iterations"},{"location":"settings_dict_guide.html#unique_id_column_name","text":"Splink requires that the input dataset has a column that uniquely identifies each reecord. unique_id_column_name is the name of the column in the input dataset representing this unique id For linking tasks, ids must be unique within each dataset being linked, and do not need to be globally unique across input datasets Default value : unique_id Examples : ['unique_id', 'id', 'pk']","title":"unique_id_column_name"},{"location":"settings_dict_guide.html#source_dataset_column_name","text":"The name of the column in the input dataset representing the source dataset Where we are linking datasets, we can't guarantee that the unique id column is globally unique across datasets, so we combine it with a source_dataset column. Usually, this is created by Splink for the user Default value : source_dataset Examples : ['source_dataset', 'dataset_name']","title":"source_dataset_column_name"},{"location":"settings_dict_guide.html#retain_matching_columns","text":"If set to true, each column used by the comparisons sql expressions will be retained in output datasets This is helpful so that the user can inspect matches, but once the comparison vector (gamma) columns are computed, this information is not actually needed by the algorithm. The algorithm will run faster and use less resources if this is set to false. Default value : True Examples : [False, True]","title":"retain_matching_columns"},{"location":"settings_dict_guide.html#retain_intermediate_calculation_columns","text":"Retain intermediate calculation columns, such as the bayes factors associated with each column in comparisons The algorithm will run faster and use less resources if this is set to false. Default value : False Examples : [False, True]","title":"retain_intermediate_calculation_columns"},{"location":"settings_dict_guide.html#comparisons","text":"A list specifying how records should be compared for probabalistic matching. Each element is a dictionary","title":"comparisons"},{"location":"settings_dict_guide.html#blocking_rules_to_generate_predictions","text":"A list of one or more blocking rules to apply. A cartesian join is applied if blocking_rules_to_generate_predictions is empty or not supplied. Each rule is a SQL expression representing the blocking rule, which will be used to create a join. The left table is aliased with l and the right table is aliased with r . For example, if you want to block on a first_name column, the blocking rule would be l.first_name = r.first_name . To block on first name and the first letter of surname, it would be l.first_name = r.first_name and substr(l.surname,1,1) = substr(r.surname,1,1) . Note that splink deduplicates the comparisons generated by the blocking rules. If empty or not supplied, all comparisons between the input dataset(s) will be generated and blocking will not be used. For large input datasets, this will generally be computationally intractable because it will generate comparisons equal to the number of rows squared. Default value : [] Examples : [['l.first_name = r.first_name AND l.surname = r.surname', 'l.dob = r.dob']]","title":"blocking_rules_to_generate_predictions"},{"location":"settings_dict_guide.html#additional_columns_to_retain","text":"A list of columns not being used in the probabalistic matching comparisons that you want to include in your results. By default, splink drops columns which are not used by any comparisons. This gives you the option to retain columns which are not used by the model. A common example is if the user has labelled data (training data) and wishes to retain the labels in the outputs Default value : [] Examples : [['cluster', 'col_2'], ['other_information']]","title":"additional_columns_to_retain"},{"location":"settings_dict_guide.html#bayes_factor_column_prefix","text":"The prefix to use for the columns that will be created to store the bayes factors Default value : bf_ Examples : ['bf_', '__bf__']","title":"bayes_factor_column_prefix"},{"location":"settings_dict_guide.html#term_frequency_adjustment_column_prefix","text":"The prefix to use for the columns that will be created to store the term frequency adjustments Default value : tf_ Examples : ['tf_', '__tf__']","title":"term_frequency_adjustment_column_prefix"},{"location":"settings_dict_guide.html#comparison_vector_value_column_prefix","text":"The prefix to use for the columns that will be created to store the comparison vector values Default value : gamma_ Examples : ['gamma_', '__gamma__']","title":"comparison_vector_value_column_prefix"},{"location":"settings_dict_guide.html#sql_dialect","text":"The SQL dialect in which sql_conditions are written. Must be a valid sqlglot dialect Default value : None Examples : ['spark', 'duckdb', 'presto', 'sqlite']","title":"sql_dialect"},{"location":"settings_dict_guide.html#settings-keys-nested-within-each-member-of-comparisons","text":"","title":"Settings keys nested within each member of comparisons"},{"location":"settings_dict_guide.html#output_column_name","text":"The name used to refer to this comparison in the output dataset. By default, Splink will set this to the name(s) of any input columns used in the comparison. This key is most useful to give a clearer description to comparisons that use multiple input columns. e.g. a location column that uses postcode and town may be named location For a comparison column that uses a single input column, e.g. first_name, this will be set first_name. For comparison columns that use multiple columns, if left blank, this will be set to the concatenation of columns used. Examples : ['first_name', 'surname']","title":"output_column_name"},{"location":"settings_dict_guide.html#comparison_description","text":"An optional label to describe this comparison, to be used in charting outputs. Examples : ['First name exact match', 'Surname with middle levenshtein level']","title":"comparison_description"},{"location":"settings_dict_guide.html#comparison_levels","text":"Comparison levels specify how input values should be compared. Each level corresponds to an assessment of similarity, such as exact match, jaro winkler match, one side of the match being null, etc Each comparison level represents a branch of a SQL case expression. They are specified in order of evaluation, each with a sql_condition that represents the branch of a case expression Examples : [{'sql_condition': 'first_name_l IS NULL OR first_name_r IS NULL', 'label': 'null', 'null_level': True}, {'sql_condition': 'first_name_l = first_name_r', 'label': 'exact_match', 'tf_adjustment_column': 'first_name'}, {'sql_condition': 'ELSE', 'label': 'else'}]","title":"comparison_levels"},{"location":"settings_dict_guide.html#settings-keys-nested-within-each-member-of-comparison_levels","text":"","title":"Settings keys nested within each member of comparison_levels"},{"location":"settings_dict_guide.html#sql_condition","text":"A branch of a SQL case expression without WHEN and THEN e.g. 'jaro_winkler_sim(surname_l, surname_r) > 0.88' Examples : ['forename_l = forename_r', 'jaro_winkler_sim(surname_l, surname_r) > 0.88']","title":"sql_condition"},{"location":"settings_dict_guide.html#label_for_charts","text":"A label for this comparson level, which will appear on charts as a reminder of what the level represts Examples : ['exact', 'postcode exact']","title":"label_for_charts"},{"location":"settings_dict_guide.html#u_probability","text":"the u probability for this comparison level - i.e. the proportion of records that match this level amongst truly non-matching records Examples : [0.9]","title":"u_probability"},{"location":"settings_dict_guide.html#m_probability","text":"the m probability for this comparison level - i.e. the proportion of records that match this level amongst truly matching records Examples : [0.1]","title":"m_probability"},{"location":"settings_dict_guide.html#is_null_level","text":"If true, m and u values will not be estimated and instead the match weight will be zero for this column. See treatment of nulls here on page 356, quote '. Under this MAR assumption, we can simply ignore missing data.': https://imai.fas.harvard.edu/research/files/linkage.pdf Default value : False","title":"is_null_level"},{"location":"settings_dict_guide.html#tf_adjustment_column","text":"Make term frequency adjustments for this comparison level using this input column Default value : None Examples : ['first_name', 'postcode']","title":"tf_adjustment_column"},{"location":"settings_dict_guide.html#tf_adjustment_weight","text":"Make term frequency adjustments using this weight. A weight of 1.0 is a full adjustment. A weight of 0.0 is no adjustment. A weight of 0.5 is a half adjustment Default value : 1.0 Examples : ['first_name', 'postcode']","title":"tf_adjustment_weight"},{"location":"settings_dict_guide.html#tf_minimum_u_value","text":"Where the term frequency adjustment implies a u value below this value, use this minimum value instead This prevents excessive weight being assigned to very unusual terms, such as a collision on a typo Default value : 0.0 Examples : [0.001, 1e-09]","title":"tf_minimum_u_value"},{"location":"demos/index.html","text":"splink_demos \u00b6 This repo contains interactive notebooks containing demonstration and tutorial for version 3 of the Splink record linking library, the homepage for which is here . Running these notebooks interactively \u00b6 You can run these notebooks in an interactive Jupyter notebook by clicking the button below: Running these notebooks locally in VSCode \u00b6 If you don't already have it, you'll need to install java on your system in order to run pyspark , which splink currently depends on. Download java for your specific OS from here . You can check the installation went correctly by using: java -version within a terminal instance. It should return details of your java installation. If you have multiple java installations, you may need to change the version of java you're currently using. To download the example notebooks, simply clone this repository: git clone git@github.com:moj-analytical-services/splink_demos.git Create a virtual environment using: python3 -m venv venv source venv/bin/activate Install the package list (which includes pyspark ) with: pip3 install -r requirements.txt and, if you want to use jupyter, add a kernel corresopnding to your venv: python -m ipykernel install --user --name=splink_demos jupyter lab","title":"splink_demos"},{"location":"demos/index.html#splink_demos","text":"This repo contains interactive notebooks containing demonstration and tutorial for version 3 of the Splink record linking library, the homepage for which is here .","title":"splink_demos"},{"location":"demos/index.html#running-these-notebooks-interactively","text":"You can run these notebooks in an interactive Jupyter notebook by clicking the button below:","title":"Running these notebooks interactively"},{"location":"demos/index.html#running-these-notebooks-locally-in-vscode","text":"If you don't already have it, you'll need to install java on your system in order to run pyspark , which splink currently depends on. Download java for your specific OS from here . You can check the installation went correctly by using: java -version within a terminal instance. It should return details of your java installation. If you have multiple java installations, you may need to change the version of java you're currently using. To download the example notebooks, simply clone this repository: git clone git@github.com:moj-analytical-services/splink_demos.git Create a virtual environment using: python3 -m venv venv source venv/bin/activate Install the package list (which includes pyspark ) with: pip3 install -r requirements.txt and, if you want to use jupyter, add a kernel corresopnding to your venv: python -m ipykernel install --user --name=splink_demos jupyter lab","title":"Running these notebooks locally in VSCode"},{"location":"demos/00_Tutorial_Introduction.html","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Introductory tutorial \u00b6 This is the introduction to a five part tutorial which demonstrates how to de-duplicate a small dataset using simple settings. The aim of the tutorial is to demonstarate core Splink functionality succinctly, rather that comprehensively document all configuration options. The five parts are: 1. Exploratory analysis 2. Estimating model parameters 3. Predicting results 4. Visualising predictions 5. Quality assurance Throughout the tutorial, we use the duckdb backend, which is the recommended option for smaller datasets of up to around 1 million records on a normal laptop. You can find these tutorial notebooks in the splink_demos repo, and you can run them live in your web browser by clicking the following link:","title":"0. Tutorial introduction"},{"location":"demos/00_Tutorial_Introduction.html#introductory-tutorial","text":"This is the introduction to a five part tutorial which demonstrates how to de-duplicate a small dataset using simple settings. The aim of the tutorial is to demonstarate core Splink functionality succinctly, rather that comprehensively document all configuration options. The five parts are: 1. Exploratory analysis 2. Estimating model parameters 3. Predicting results 4. Visualising predictions 5. Quality assurance Throughout the tutorial, we use the duckdb backend, which is the recommended option for smaller datasets of up to around 1 million records on a normal laptop. You can find these tutorial notebooks in the splink_demos repo, and you can run them live in your web browser by clicking the following link:","title":"Introductory tutorial"},{"location":"demos/01_Exploratory_analysis.html","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Exploratory analysis \u00b6 The purpose of exploratory analysis to understand your data and any idiosyncacies which may be relevant to the task of data linking. Splink includes functionality to visualise and summarise your data, to identify charactersics most salient to data linking. In this notebook we perform some basic exploratory analysis, and interpret the results. Read in the data \u00b6 For the purpose of this tutorial we will use a 1,000 row synthetic dataset that contains duplicates. The first five rows of this dataset are printed below. Note that the cluster column represents the 'ground truth' - a column which tells us with which rows refer to the same person. In most real linkage scenarios, we wouldn't have this column (this is what Splink is trying to estimate.) import pandas as pd import altair as alt alt . renderers . enable ( 'mimetype' ) df = pd . read_csv ( \"./data/fake_1000.csv\" ) df . head ( 5 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } unique_id first_name surname dob city email cluster 0 0 Robert Alan 1971-06-24 NaN robert255@smith.net 0 1 1 Robert Allen 1971-05-24 NaN roberta25@smith.net 0 2 2 Rob Allen 1971-06-24 London roberta25@smith.net 0 3 3 Robert Alen 1971-06-24 Lonon NaN 0 4 4 Grace NaN 1997-04-26 Hull grace.kelly52@jones.com 1 Instantiate the linker \u00b6 Most of Splink's core functionality can be accessed as methods on a linker object. For example, to make predictions, you would call linker.predict() . We therefore begin by instantiating the linker, passing in the data we wish to deduplicate. # Initialise the linker, passing in the input dataset(s) from splink.duckdb.duckdb_linker import DuckDBLinker linker = DuckDBLinker ( df ) Analyse missingness \u00b6 It's important to understand the level of missingness in your data, because columns with higher levels of missingness are less useful for data linking. linker . missingness_chart () The above summary chart shows that in this dataset, the email , city , surname and forename columns contain nulls, but the level of missingness is relatively low (less than 22%). Analyse the distribution of values in your data \u00b6 The distribution of values in your data is important for two main reasons: Columns with higher cardinality (number of distinct values) are usually more useful for data linking. For instance, date of birth is a much stronger linkage variable than gender. The skew of values is important. If you have a city column that has 1,000 distinct values, but 75% of them are London , this is much less useful for linkage than if the 1,000 values were equally distributed The linker.profile_columns() method creates summary charts to help you understand these aspects of your data. You may input column names (e.g. first_name ), or arbitrary sql expressions like concat(first_name, surname) linker . profile_columns ([ \"first_name\" , \"city\" , \"surname\" , \"email\" , \"substr(dob, 1,4)\" ], top_n = 10 , bottom_n = 5 ) This chart is very information-dense, but here are some key takehomes relevant to our linkage: There is strong skew in the city field with around 20% of the values being London . We therefore will probably want to use term_frequency_adjustments in our linkage model, so that it can weight a match on London differently to a match on, say, Norwich . Looking at the \"Bottom 5 values by value count\", we can see typos in the data in most fields. This tells us this information was possibly entered by hand, or using Optical Character Recognition, giving us an insight into the type of data entry errors we may see Email is a much more uniquely-identifying field that any others, with a maximum value count of 6. It's likely to be a strong linking variable. Next steps \u00b6 At this point, we have begin to develop a strong understanding of our data. It's time to move on to estimating a linkage model Further reading \u00b6 You can find the documentation for the exploratory analysis tools in Splink here","title":"1. Exploratory analysis"},{"location":"demos/01_Exploratory_analysis.html#exploratory-analysis","text":"The purpose of exploratory analysis to understand your data and any idiosyncacies which may be relevant to the task of data linking. Splink includes functionality to visualise and summarise your data, to identify charactersics most salient to data linking. In this notebook we perform some basic exploratory analysis, and interpret the results.","title":"Exploratory analysis"},{"location":"demos/01_Exploratory_analysis.html#read-in-the-data","text":"For the purpose of this tutorial we will use a 1,000 row synthetic dataset that contains duplicates. The first five rows of this dataset are printed below. Note that the cluster column represents the 'ground truth' - a column which tells us with which rows refer to the same person. In most real linkage scenarios, we wouldn't have this column (this is what Splink is trying to estimate.) import pandas as pd import altair as alt alt . renderers . enable ( 'mimetype' ) df = pd . read_csv ( \"./data/fake_1000.csv\" ) df . head ( 5 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } unique_id first_name surname dob city email cluster 0 0 Robert Alan 1971-06-24 NaN robert255@smith.net 0 1 1 Robert Allen 1971-05-24 NaN roberta25@smith.net 0 2 2 Rob Allen 1971-06-24 London roberta25@smith.net 0 3 3 Robert Alen 1971-06-24 Lonon NaN 0 4 4 Grace NaN 1997-04-26 Hull grace.kelly52@jones.com 1","title":"Read in the data"},{"location":"demos/01_Exploratory_analysis.html#instantiate-the-linker","text":"Most of Splink's core functionality can be accessed as methods on a linker object. For example, to make predictions, you would call linker.predict() . We therefore begin by instantiating the linker, passing in the data we wish to deduplicate. # Initialise the linker, passing in the input dataset(s) from splink.duckdb.duckdb_linker import DuckDBLinker linker = DuckDBLinker ( df )","title":"Instantiate the linker"},{"location":"demos/01_Exploratory_analysis.html#analyse-missingness","text":"It's important to understand the level of missingness in your data, because columns with higher levels of missingness are less useful for data linking. linker . missingness_chart () The above summary chart shows that in this dataset, the email , city , surname and forename columns contain nulls, but the level of missingness is relatively low (less than 22%).","title":"Analyse missingness"},{"location":"demos/01_Exploratory_analysis.html#analyse-the-distribution-of-values-in-your-data","text":"The distribution of values in your data is important for two main reasons: Columns with higher cardinality (number of distinct values) are usually more useful for data linking. For instance, date of birth is a much stronger linkage variable than gender. The skew of values is important. If you have a city column that has 1,000 distinct values, but 75% of them are London , this is much less useful for linkage than if the 1,000 values were equally distributed The linker.profile_columns() method creates summary charts to help you understand these aspects of your data. You may input column names (e.g. first_name ), or arbitrary sql expressions like concat(first_name, surname) linker . profile_columns ([ \"first_name\" , \"city\" , \"surname\" , \"email\" , \"substr(dob, 1,4)\" ], top_n = 10 , bottom_n = 5 ) This chart is very information-dense, but here are some key takehomes relevant to our linkage: There is strong skew in the city field with around 20% of the values being London . We therefore will probably want to use term_frequency_adjustments in our linkage model, so that it can weight a match on London differently to a match on, say, Norwich . Looking at the \"Bottom 5 values by value count\", we can see typos in the data in most fields. This tells us this information was possibly entered by hand, or using Optical Character Recognition, giving us an insight into the type of data entry errors we may see Email is a much more uniquely-identifying field that any others, with a maximum value count of 6. It's likely to be a strong linking variable.","title":"Analyse the distribution of values in your data"},{"location":"demos/01_Exploratory_analysis.html#next-steps","text":"At this point, we have begin to develop a strong understanding of our data. It's time to move on to estimating a linkage model","title":"Next steps"},{"location":"demos/01_Exploratory_analysis.html#further-reading","text":"You can find the documentation for the exploratory analysis tools in Splink here","title":"Further reading"},{"location":"demos/02_Estimating_model_parameters.html","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Specifying and estimating a linkage model \u00b6 We've just seen how to use Splink's exploratory analysis tools to understand our data. Now it's time to build a linkage model. This model will make pairwise comparisons of input records and output a match score, which is a prediction of whether the two records represent the same entity (e.g. are the same person). You can read more about the theory behind probabilistic linkage models here . # Begin by reading in the tutorial data again from splink.duckdb.duckdb_linker import DuckDBLinker import pandas as pd import altair as alt alt . renderers . enable ( \"mimetype\" ) df = pd . read_csv ( \"./data/fake_1000.csv\" ) Specifying a linkage model \u00b6 To produce a match score, splink needs to know how to compare the information in pairs records from the input dataset. To be concrete, here is an example pairwise record comparison from our input dataset: unique_id first_name surname dob city email 1 Robert Allen 1971-05-24 nan roberta25@smith.net 2 Rob Allen 1971-06-24 London roberta25@smith.net What functions should we use to assess the similarity of Rob vs. Robert in the the first_name field? Should similarity in the dob field be computed in the same way, or a different way? Your job as the developer of a linkage model is to decide what comparisons are most appropriate for the types of data you have. Comparisons \u00b6 The concept of a Comparison has a specific definition within Splink: it defines how data from one or more input columns is compared, using SQL expressions assess similarity. For example, one Comparison may represent how similarity is assessed for a person's date of birth. Another Comparison may represent the comparison of a person's name or location. A model will thereby be composed of many Comparison s, which between them assess the similarity of all of the columns being used for data linking. Each Comparison contains two or more ComparisonLevels which define n discrete gradations of similarity between the input columns within the Comparison. For example, for the date of birth Comparison there may be a ComparisonLevel for an exact match, another for a one-character difference, and another for all other comparisons. To summarise: Data Linking Model \u251c\u2500-- Comparison: Date of birth \u2502 \u251c\u2500-- ComparisonLevel: Exact match \u2502 \u251c\u2500-- ComparisonLevel: One character difference \u2502 \u251c\u2500-- ComparisonLevel: All other \u251c\u2500-- Comparison: City \u2502 \u251c\u2500-- ComparisonLevel: Exact match on city \u2502 \u251c\u2500-- ComparisonLevel: All other \u2502 etc. More information about comparisons can be found here . We will now use these concepts to build a data linking model Specifying the model using comparisons \u00b6 Splink provides utility functions to help formulate some of the most common comparison types, which we'll make use of in this introductory example. Let's start by looking at a single comparison: import splink.duckdb.duckdb_comparison_library as cl first_name_comparison = cl . levenshtein_at_thresholds ( \"first_name\" , 2 ) print ( first_name_comparison . human_readable_description ) Comparison 'Exact match vs. levenshtein at threshold 2 vs. anything else' of first_name. Similarity is assessed using the following ComparisonLevels: - 'Null' with SQL rule: first_name_l IS NULL OR first_name_r IS NULL - 'Exact match' with SQL rule: first_name_l = first_name_r - 'levenshtein <= 2' with SQL rule: levenshtein(first_name_l, first_name_r) <= 2 - 'All other comparisons' with SQL rule: ELSE Specifying the full settings dictionary \u00b6 Comparisons are specified as part of the Splink settings , a Python dictionary which controls all of the configuration of a Splink model. Let's take a look at a full settings dictionary: settings = { \"probability_two_random_records_match\" : 4 / 1000 , \"link_type\" : \"dedupe_only\" , \"comparisons\" : [ cl . levenshtein_at_thresholds ( \"first_name\" , 2 ), cl . levenshtein_at_thresholds ( \"surname\" ), cl . levenshtein_at_thresholds ( \"dob\" ), cl . exact_match ( \"city\" , term_frequency_adjustments = True ), cl . levenshtein_at_thresholds ( \"email\" ), ], \"blocking_rules_to_generate_predictions\" : [ \"l.first_name = r.first_name\" , \"l.surname = r.surname\" , ], \"retain_matching_columns\" : True , \"retain_intermediate_calculation_columns\" : True , \"additional_columns_to_retain\" : [ \"cluster\" ], } In words, this setting dictionary says: We have set a starting value for probability_two_random_records_match to 4/1000. This is a starting value - we will later estimate this parameter We are performing a dedupe_only (the other options are link_only , or link_and_dedupe , which may be used if there are multiple input datasets) When comparing records, we will use information from the first_name , surname , dob , city and email columns to compute a match score. The blocking_rules_to_generate_predictions states that we will only check for duplicates amongst records where either the first_name or surname is identical. We have enabled term frequency adjustments for the 'city' column, because some values (e.g. London ) appear much more frequently than others We will retain the cluster column in the results even though this is not used as part of comparisons. Later we'll be able to use this to compare Splink scores to the ground truth. We have set retain_intermediate_calculation_columns and additional_columns_to_retain to True so that Splink outputs additional information that helps the user understand the calculations. If they were False , the computations would run faster. Estimate the parameters of the model \u00b6 Now that we have specified our linkage model, we want to estimate its m and u parameters. The m values are the proportion of records falling into each ComparisonLevel amongst truly matching records The u values are the proportion of records falling into each ComparisonLevel amongst truly non-matching records You can read more about the theory of what these mean here . We begin by using estimate_u_using_random_sampling method to compute the u values of the model. This is a simple direct estimation algorithm. The larger the random sample, the more accurate the predictions. You control this using the target_rows parameter. For large datasets, we recommend using at least 10 million - but the higher the better and 1 billion is often appropriate for larger datasets. linker = DuckDBLinker ( df , settings ) linker . estimate_u_using_random_sampling ( target_rows = 1e6 ) ----- Estimating u probabilities using random sampling ----- Estimated u probabilities using random sampling Your model is not yet fully trained. Missing estimates for: - first_name (no m values are trained). - surname (no m values are trained). - dob (no m values are trained). - city (no m values are trained). - email (no m values are trained). We then use the expectation maximisation algorithm to train the m values. This algorithm estimates the m values by generating pairwise record comparisons, and using them to maximise a likelihood function. Each estimation pass requires the user to configure an estimation blocking rule to reduce the number of record comparisons generated to a managable level. In our first estimation pass, we block on first_name and surname , meaning we will generate all record comparisons that have first_name and surname exactly equal. Recall we are trying to estimate the m values of the model, i.e. proportion of records falling into each ComparisonLevel amongst truly matching records. This means that, in this training session, we cannot estimate parameter estimates for the first_name or surname columns, since we have forced them to be equal 100% of the time. We can, however, estimate parameter estimates for all of the other columns. The output messages produced by Splink confirm this. training_blocking_rule = \"l.first_name = r.first_name and l.surname = r.surname\" training_session_fname_sname = linker . estimate_parameters_using_expectation_maximisation ( training_blocking_rule ) ----- Starting EM training session ----- Estimating the m probabilities of the model by blocking on: l.first_name = r.first_name and l.surname = r.surname Parameter estimates will be made for the following comparison(s): - dob - city - email Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: - first_name - surname Iteration 1: Largest change in params was -0.531 in the m_probability of dob, level `Exact match` Iteration 2: Largest change in params was 0.0331 in probability_two_random_records_match Iteration 3: Largest change in params was 0.0128 in probability_two_random_records_match Iteration 4: Largest change in params was 0.00635 in probability_two_random_records_match Iteration 5: Largest change in params was 0.00363 in probability_two_random_records_match Iteration 6: Largest change in params was 0.00225 in probability_two_random_records_match Iteration 7: Largest change in params was 0.00146 in probability_two_random_records_match Iteration 8: Largest change in params was 0.000987 in probability_two_random_records_match Iteration 9: Largest change in params was 0.000681 in probability_two_random_records_match Iteration 10: Largest change in params was 0.000478 in probability_two_random_records_match Iteration 11: Largest change in params was 0.000339 in probability_two_random_records_match Iteration 12: Largest change in params was 0.000242 in probability_two_random_records_match Iteration 13: Largest change in params was 0.000174 in probability_two_random_records_match Iteration 14: Largest change in params was 0.000126 in probability_two_random_records_match Iteration 15: Largest change in params was 9.12e-05 in probability_two_random_records_match EM converged after 15 iterations Your model is not yet fully trained. Missing estimates for: - first_name (no m values are trained). - surname (no m values are trained). In a second estimation pass, we block on dob. This allows us to estimate parameters for the first_name and surname comparisons. Between the two estimation passes, we now have parameter estimates for all comparisons. training_blocking_rule = \"l.dob = r.dob\" training_session_dob = linker . estimate_parameters_using_expectation_maximisation ( training_blocking_rule ) ----- Starting EM training session ----- Estimating the m probabilities of the model by blocking on: l.dob = r.dob Parameter estimates will be made for the following comparison(s): - first_name - surname - city - email Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: - dob Iteration 1: Largest change in params was 0.48 in probability_two_random_records_match Iteration 2: Largest change in params was 0.151 in probability_two_random_records_match Iteration 3: Largest change in params was 0.0477 in probability_two_random_records_match Iteration 4: Largest change in params was 0.0177 in probability_two_random_records_match Iteration 5: Largest change in params was 0.00797 in probability_two_random_records_match Iteration 6: Largest change in params was 0.004 in probability_two_random_records_match Iteration 7: Largest change in params was 0.00213 in probability_two_random_records_match Iteration 8: Largest change in params was 0.00117 in probability_two_random_records_match Iteration 9: Largest change in params was 0.00065 in probability_two_random_records_match Iteration 10: Largest change in params was 0.000366 in probability_two_random_records_match Iteration 11: Largest change in params was 0.000207 in probability_two_random_records_match Iteration 12: Largest change in params was 0.000117 in probability_two_random_records_match Iteration 13: Largest change in params was 6.67e-05 in probability_two_random_records_match EM converged after 13 iterations Your model is fully trained. All comparisons have at least one estimate for their m and u values Note that Splink includes other algorithms for estimating m and u values, which are documented here . Visualising model parameters \u00b6 Splink can generate a number of charts to help you understand your model. For an introduction to these charts and how to interpret them, please see this video. The final estimated match weights can be viewed in the match weights chart: linker . match_weights_chart () linker . m_u_parameters_chart () Saving the model \u00b6 Finally we can save the model, including our estimated parameters, to a .json file, so we can use it in the next tutorial. linker . save_settings_to_json ( \"./demo_settings/saved_model_from_demo.json\" , overwrite = True ) Next steps \u00b6 Now we have trained a model, we can move on to using it predict matching records Further reading \u00b6 Full documentation for all of the ways of estimating model parameters can be found here .","title":"2. Estimating model parameters"},{"location":"demos/02_Estimating_model_parameters.html#specifying-and-estimating-a-linkage-model","text":"We've just seen how to use Splink's exploratory analysis tools to understand our data. Now it's time to build a linkage model. This model will make pairwise comparisons of input records and output a match score, which is a prediction of whether the two records represent the same entity (e.g. are the same person). You can read more about the theory behind probabilistic linkage models here . # Begin by reading in the tutorial data again from splink.duckdb.duckdb_linker import DuckDBLinker import pandas as pd import altair as alt alt . renderers . enable ( \"mimetype\" ) df = pd . read_csv ( \"./data/fake_1000.csv\" )","title":"Specifying and estimating a linkage model"},{"location":"demos/02_Estimating_model_parameters.html#specifying-a-linkage-model","text":"To produce a match score, splink needs to know how to compare the information in pairs records from the input dataset. To be concrete, here is an example pairwise record comparison from our input dataset: unique_id first_name surname dob city email 1 Robert Allen 1971-05-24 nan roberta25@smith.net 2 Rob Allen 1971-06-24 London roberta25@smith.net What functions should we use to assess the similarity of Rob vs. Robert in the the first_name field? Should similarity in the dob field be computed in the same way, or a different way? Your job as the developer of a linkage model is to decide what comparisons are most appropriate for the types of data you have.","title":"Specifying a linkage model"},{"location":"demos/02_Estimating_model_parameters.html#comparisons","text":"The concept of a Comparison has a specific definition within Splink: it defines how data from one or more input columns is compared, using SQL expressions assess similarity. For example, one Comparison may represent how similarity is assessed for a person's date of birth. Another Comparison may represent the comparison of a person's name or location. A model will thereby be composed of many Comparison s, which between them assess the similarity of all of the columns being used for data linking. Each Comparison contains two or more ComparisonLevels which define n discrete gradations of similarity between the input columns within the Comparison. For example, for the date of birth Comparison there may be a ComparisonLevel for an exact match, another for a one-character difference, and another for all other comparisons. To summarise: Data Linking Model \u251c\u2500-- Comparison: Date of birth \u2502 \u251c\u2500-- ComparisonLevel: Exact match \u2502 \u251c\u2500-- ComparisonLevel: One character difference \u2502 \u251c\u2500-- ComparisonLevel: All other \u251c\u2500-- Comparison: City \u2502 \u251c\u2500-- ComparisonLevel: Exact match on city \u2502 \u251c\u2500-- ComparisonLevel: All other \u2502 etc. More information about comparisons can be found here . We will now use these concepts to build a data linking model","title":"Comparisons"},{"location":"demos/02_Estimating_model_parameters.html#specifying-the-model-using-comparisons","text":"Splink provides utility functions to help formulate some of the most common comparison types, which we'll make use of in this introductory example. Let's start by looking at a single comparison: import splink.duckdb.duckdb_comparison_library as cl first_name_comparison = cl . levenshtein_at_thresholds ( \"first_name\" , 2 ) print ( first_name_comparison . human_readable_description ) Comparison 'Exact match vs. levenshtein at threshold 2 vs. anything else' of first_name. Similarity is assessed using the following ComparisonLevels: - 'Null' with SQL rule: first_name_l IS NULL OR first_name_r IS NULL - 'Exact match' with SQL rule: first_name_l = first_name_r - 'levenshtein <= 2' with SQL rule: levenshtein(first_name_l, first_name_r) <= 2 - 'All other comparisons' with SQL rule: ELSE","title":"Specifying the model using comparisons"},{"location":"demos/02_Estimating_model_parameters.html#specifying-the-full-settings-dictionary","text":"Comparisons are specified as part of the Splink settings , a Python dictionary which controls all of the configuration of a Splink model. Let's take a look at a full settings dictionary: settings = { \"probability_two_random_records_match\" : 4 / 1000 , \"link_type\" : \"dedupe_only\" , \"comparisons\" : [ cl . levenshtein_at_thresholds ( \"first_name\" , 2 ), cl . levenshtein_at_thresholds ( \"surname\" ), cl . levenshtein_at_thresholds ( \"dob\" ), cl . exact_match ( \"city\" , term_frequency_adjustments = True ), cl . levenshtein_at_thresholds ( \"email\" ), ], \"blocking_rules_to_generate_predictions\" : [ \"l.first_name = r.first_name\" , \"l.surname = r.surname\" , ], \"retain_matching_columns\" : True , \"retain_intermediate_calculation_columns\" : True , \"additional_columns_to_retain\" : [ \"cluster\" ], } In words, this setting dictionary says: We have set a starting value for probability_two_random_records_match to 4/1000. This is a starting value - we will later estimate this parameter We are performing a dedupe_only (the other options are link_only , or link_and_dedupe , which may be used if there are multiple input datasets) When comparing records, we will use information from the first_name , surname , dob , city and email columns to compute a match score. The blocking_rules_to_generate_predictions states that we will only check for duplicates amongst records where either the first_name or surname is identical. We have enabled term frequency adjustments for the 'city' column, because some values (e.g. London ) appear much more frequently than others We will retain the cluster column in the results even though this is not used as part of comparisons. Later we'll be able to use this to compare Splink scores to the ground truth. We have set retain_intermediate_calculation_columns and additional_columns_to_retain to True so that Splink outputs additional information that helps the user understand the calculations. If they were False , the computations would run faster.","title":"Specifying the full settings dictionary"},{"location":"demos/02_Estimating_model_parameters.html#estimate-the-parameters-of-the-model","text":"Now that we have specified our linkage model, we want to estimate its m and u parameters. The m values are the proportion of records falling into each ComparisonLevel amongst truly matching records The u values are the proportion of records falling into each ComparisonLevel amongst truly non-matching records You can read more about the theory of what these mean here . We begin by using estimate_u_using_random_sampling method to compute the u values of the model. This is a simple direct estimation algorithm. The larger the random sample, the more accurate the predictions. You control this using the target_rows parameter. For large datasets, we recommend using at least 10 million - but the higher the better and 1 billion is often appropriate for larger datasets. linker = DuckDBLinker ( df , settings ) linker . estimate_u_using_random_sampling ( target_rows = 1e6 ) ----- Estimating u probabilities using random sampling ----- Estimated u probabilities using random sampling Your model is not yet fully trained. Missing estimates for: - first_name (no m values are trained). - surname (no m values are trained). - dob (no m values are trained). - city (no m values are trained). - email (no m values are trained). We then use the expectation maximisation algorithm to train the m values. This algorithm estimates the m values by generating pairwise record comparisons, and using them to maximise a likelihood function. Each estimation pass requires the user to configure an estimation blocking rule to reduce the number of record comparisons generated to a managable level. In our first estimation pass, we block on first_name and surname , meaning we will generate all record comparisons that have first_name and surname exactly equal. Recall we are trying to estimate the m values of the model, i.e. proportion of records falling into each ComparisonLevel amongst truly matching records. This means that, in this training session, we cannot estimate parameter estimates for the first_name or surname columns, since we have forced them to be equal 100% of the time. We can, however, estimate parameter estimates for all of the other columns. The output messages produced by Splink confirm this. training_blocking_rule = \"l.first_name = r.first_name and l.surname = r.surname\" training_session_fname_sname = linker . estimate_parameters_using_expectation_maximisation ( training_blocking_rule ) ----- Starting EM training session ----- Estimating the m probabilities of the model by blocking on: l.first_name = r.first_name and l.surname = r.surname Parameter estimates will be made for the following comparison(s): - dob - city - email Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: - first_name - surname Iteration 1: Largest change in params was -0.531 in the m_probability of dob, level `Exact match` Iteration 2: Largest change in params was 0.0331 in probability_two_random_records_match Iteration 3: Largest change in params was 0.0128 in probability_two_random_records_match Iteration 4: Largest change in params was 0.00635 in probability_two_random_records_match Iteration 5: Largest change in params was 0.00363 in probability_two_random_records_match Iteration 6: Largest change in params was 0.00225 in probability_two_random_records_match Iteration 7: Largest change in params was 0.00146 in probability_two_random_records_match Iteration 8: Largest change in params was 0.000987 in probability_two_random_records_match Iteration 9: Largest change in params was 0.000681 in probability_two_random_records_match Iteration 10: Largest change in params was 0.000478 in probability_two_random_records_match Iteration 11: Largest change in params was 0.000339 in probability_two_random_records_match Iteration 12: Largest change in params was 0.000242 in probability_two_random_records_match Iteration 13: Largest change in params was 0.000174 in probability_two_random_records_match Iteration 14: Largest change in params was 0.000126 in probability_two_random_records_match Iteration 15: Largest change in params was 9.12e-05 in probability_two_random_records_match EM converged after 15 iterations Your model is not yet fully trained. Missing estimates for: - first_name (no m values are trained). - surname (no m values are trained). In a second estimation pass, we block on dob. This allows us to estimate parameters for the first_name and surname comparisons. Between the two estimation passes, we now have parameter estimates for all comparisons. training_blocking_rule = \"l.dob = r.dob\" training_session_dob = linker . estimate_parameters_using_expectation_maximisation ( training_blocking_rule ) ----- Starting EM training session ----- Estimating the m probabilities of the model by blocking on: l.dob = r.dob Parameter estimates will be made for the following comparison(s): - first_name - surname - city - email Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: - dob Iteration 1: Largest change in params was 0.48 in probability_two_random_records_match Iteration 2: Largest change in params was 0.151 in probability_two_random_records_match Iteration 3: Largest change in params was 0.0477 in probability_two_random_records_match Iteration 4: Largest change in params was 0.0177 in probability_two_random_records_match Iteration 5: Largest change in params was 0.00797 in probability_two_random_records_match Iteration 6: Largest change in params was 0.004 in probability_two_random_records_match Iteration 7: Largest change in params was 0.00213 in probability_two_random_records_match Iteration 8: Largest change in params was 0.00117 in probability_two_random_records_match Iteration 9: Largest change in params was 0.00065 in probability_two_random_records_match Iteration 10: Largest change in params was 0.000366 in probability_two_random_records_match Iteration 11: Largest change in params was 0.000207 in probability_two_random_records_match Iteration 12: Largest change in params was 0.000117 in probability_two_random_records_match Iteration 13: Largest change in params was 6.67e-05 in probability_two_random_records_match EM converged after 13 iterations Your model is fully trained. All comparisons have at least one estimate for their m and u values Note that Splink includes other algorithms for estimating m and u values, which are documented here .","title":"Estimate the parameters of the model"},{"location":"demos/02_Estimating_model_parameters.html#visualising-model-parameters","text":"Splink can generate a number of charts to help you understand your model. For an introduction to these charts and how to interpret them, please see this video. The final estimated match weights can be viewed in the match weights chart: linker . match_weights_chart () linker . m_u_parameters_chart ()","title":"Visualising model parameters"},{"location":"demos/02_Estimating_model_parameters.html#saving-the-model","text":"Finally we can save the model, including our estimated parameters, to a .json file, so we can use it in the next tutorial. linker . save_settings_to_json ( \"./demo_settings/saved_model_from_demo.json\" , overwrite = True )","title":"Saving the model"},{"location":"demos/02_Estimating_model_parameters.html#next-steps","text":"Now we have trained a model, we can move on to using it predict matching records","title":"Next steps"},{"location":"demos/02_Estimating_model_parameters.html#further-reading","text":"Full documentation for all of the ways of estimating model parameters can be found here .","title":"Further reading"},{"location":"demos/03_Predicting_results.html","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Predicting which records match \u00b6 In the previous tutorial, we built and estimated a linkage model. In this tutorial, we will load the estimated model and use it to make predictions of which pairwise record comparisons match. from splink.duckdb.duckdb_linker import DuckDBLinker import pandas as pd pd . options . display . max_columns = 1000 df = pd . read_csv ( \"./data/fake_1000.csv\" ) Load estimated model from previous tutorial \u00b6 linker = DuckDBLinker ( df ) linker . load_settings_from_json ( \"./demo_settings/saved_model_from_demo.json\" ) Predicting match weights using the trained model \u00b6 We use linker.predict() to run the model. Under the hood this will: Generate all pairwise record comparisons that match at least one of the blocking_rules_to_generate_predictions Use the rules specified in the Comparisons to evaluate the similarity of the input data Use the estimated match weights, applying term frequency adjustments where requested to produce the final match_weight and match_probability scores Optionally, a threshold_match_probability or threshold_match_weight can be provided, which will drop any row where the predicted score is below the threshold. df_predictions = linker . predict ( threshold_match_probability = 0.2 ) df_predictions . as_pandas_dataframe ( limit = 5 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } match_weight match_probability unique_id_l unique_id_r first_name_l first_name_r gamma_first_name bf_first_name surname_l surname_r gamma_surname bf_surname dob_l dob_r gamma_dob bf_dob city_l city_r gamma_city bf_city bf_tf_adj_city tf_city_l tf_city_r email_l email_r gamma_email bf_email cluster_l cluster_r match_key 0 14.295585 0.999950 4 5 Grace Grace 2 85.549242 NaN Kelly -1 1.000000 1997-04-26 1991-04-26 2 93.584788 Hull NaN -1 1.000000 1.000000 0.001230 NaN grace.kelly52@jones.com grace.kelly52@jones.com 3 255.419933 1 1 0 1 12.793439 0.999859 26 29 Thomas Thomas 2 85.549242 Gabriel Gabriel 3 90.170377 1976-09-15 1976-08-15 2 93.584788 Loodon NaN -1 1.000000 1.000000 0.001230 NaN gabriel.t54@nnichls.info NaN -1 1.000000 11 11 0 2 12.793439 0.999859 28 29 Thomas Thomas 2 85.549242 Gabriel Gabriel 3 90.170377 1976-09-15 1976-08-15 2 93.584788 London NaN -1 1.000000 1.000000 0.212792 NaN gabriel.t54@nichols.info NaN -1 1.000000 11 11 0 3 -0.626931 0.393039 37 860 Theodore Theodore 2 85.549242 Morris Marshall 0 0.261908 1978-08-19 1972-07-25 0 0.255612 Birmingham Birmingham 1 10.257653 1.120874 0.049200 0.0492 t.m39@brooks-sawyer.com NaN -1 1.000000 13 214 0 4 -0.626931 0.393039 39 860 Theodore Theodore 2 85.549242 Morris Marshall 0 0.261908 1978-08-19 1972-07-25 0 0.255612 Birmingham Birmingham 1 10.257653 1.120874 0.049200 0.0492 t.m39@brooks-sawyer.com NaN -1 1.000000 13 214 0 Clustering \u00b6 The result of linker.predict() is a list of pairwise record comparisons and their associated scores. For instance, if we have input records A, B, C and D, it could be represented conceptually as: A -> B with score 0.9 B -> C with score 0.95 C -> D with score 0.1 D -> E with score 0.99 Often, an alternative representation of this result is more useful, where each row is an input record, and where records link, they are assigned to the same cluster. With a score threshold of 0.5, the above data could be represented conceptually as: ID, Cluster ID A, 1 B, 1 C, 1 D, 2 E, 2 The algorithm that converts between the pairwise results and the clusters is called connected components, and it is included in Splink. You can use it as follows: clusters = linker . cluster_pairwise_predictions_at_threshold ( df_predictions , threshold_match_probability = 0.5 ) clusters . as_pandas_dataframe ( limit = 10 ) Completed iteration 1, root rows count 14 Completed iteration 2, root rows count 0 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } cluster_id unique_id first_name surname dob city email cluster tf_city 0 0 0 Robert Alan 1971-06-24 NaN robert255@smith.net 0 NaN 1 0 1 Robert Allen 1971-05-24 NaN roberta25@smith.net 0 NaN 2 0 2 Rob Allen 1971-06-24 London roberta25@smith.net 0 0.212792 3 0 3 Robert Alen 1971-06-24 Lonon NaN 0 0.007380 4 4 4 Grace NaN 1997-04-26 Hull grace.kelly52@jones.com 1 0.001230 5 4 5 Grace Kelly 1991-04-26 NaN grace.kelly52@jones.com 1 NaN 6 6 6 Logan pMurphy 1973-08-01 NaN NaN 2 NaN 7 7 7 NaN NaN 2015-03-03 Portsmouth evied56@harris-bailey.net 3 0.017220 8 8 8 NaN Dean 2015-03-03 NaN NaN 3 NaN 9 8 9 Evie Dean 2015-03-03 Pootsmruth evihd56@earris-bailey.net 3 0.001230","title":"3. Predicting results"},{"location":"demos/03_Predicting_results.html#predicting-which-records-match","text":"In the previous tutorial, we built and estimated a linkage model. In this tutorial, we will load the estimated model and use it to make predictions of which pairwise record comparisons match. from splink.duckdb.duckdb_linker import DuckDBLinker import pandas as pd pd . options . display . max_columns = 1000 df = pd . read_csv ( \"./data/fake_1000.csv\" )","title":"Predicting which records match"},{"location":"demos/03_Predicting_results.html#load-estimated-model-from-previous-tutorial","text":"linker = DuckDBLinker ( df ) linker . load_settings_from_json ( \"./demo_settings/saved_model_from_demo.json\" )","title":"Load estimated model from previous tutorial"},{"location":"demos/03_Predicting_results.html#predicting-match-weights-using-the-trained-model","text":"We use linker.predict() to run the model. Under the hood this will: Generate all pairwise record comparisons that match at least one of the blocking_rules_to_generate_predictions Use the rules specified in the Comparisons to evaluate the similarity of the input data Use the estimated match weights, applying term frequency adjustments where requested to produce the final match_weight and match_probability scores Optionally, a threshold_match_probability or threshold_match_weight can be provided, which will drop any row where the predicted score is below the threshold. df_predictions = linker . predict ( threshold_match_probability = 0.2 ) df_predictions . as_pandas_dataframe ( limit = 5 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } match_weight match_probability unique_id_l unique_id_r first_name_l first_name_r gamma_first_name bf_first_name surname_l surname_r gamma_surname bf_surname dob_l dob_r gamma_dob bf_dob city_l city_r gamma_city bf_city bf_tf_adj_city tf_city_l tf_city_r email_l email_r gamma_email bf_email cluster_l cluster_r match_key 0 14.295585 0.999950 4 5 Grace Grace 2 85.549242 NaN Kelly -1 1.000000 1997-04-26 1991-04-26 2 93.584788 Hull NaN -1 1.000000 1.000000 0.001230 NaN grace.kelly52@jones.com grace.kelly52@jones.com 3 255.419933 1 1 0 1 12.793439 0.999859 26 29 Thomas Thomas 2 85.549242 Gabriel Gabriel 3 90.170377 1976-09-15 1976-08-15 2 93.584788 Loodon NaN -1 1.000000 1.000000 0.001230 NaN gabriel.t54@nnichls.info NaN -1 1.000000 11 11 0 2 12.793439 0.999859 28 29 Thomas Thomas 2 85.549242 Gabriel Gabriel 3 90.170377 1976-09-15 1976-08-15 2 93.584788 London NaN -1 1.000000 1.000000 0.212792 NaN gabriel.t54@nichols.info NaN -1 1.000000 11 11 0 3 -0.626931 0.393039 37 860 Theodore Theodore 2 85.549242 Morris Marshall 0 0.261908 1978-08-19 1972-07-25 0 0.255612 Birmingham Birmingham 1 10.257653 1.120874 0.049200 0.0492 t.m39@brooks-sawyer.com NaN -1 1.000000 13 214 0 4 -0.626931 0.393039 39 860 Theodore Theodore 2 85.549242 Morris Marshall 0 0.261908 1978-08-19 1972-07-25 0 0.255612 Birmingham Birmingham 1 10.257653 1.120874 0.049200 0.0492 t.m39@brooks-sawyer.com NaN -1 1.000000 13 214 0","title":"Predicting match weights using the trained model"},{"location":"demos/03_Predicting_results.html#clustering","text":"The result of linker.predict() is a list of pairwise record comparisons and their associated scores. For instance, if we have input records A, B, C and D, it could be represented conceptually as: A -> B with score 0.9 B -> C with score 0.95 C -> D with score 0.1 D -> E with score 0.99 Often, an alternative representation of this result is more useful, where each row is an input record, and where records link, they are assigned to the same cluster. With a score threshold of 0.5, the above data could be represented conceptually as: ID, Cluster ID A, 1 B, 1 C, 1 D, 2 E, 2 The algorithm that converts between the pairwise results and the clusters is called connected components, and it is included in Splink. You can use it as follows: clusters = linker . cluster_pairwise_predictions_at_threshold ( df_predictions , threshold_match_probability = 0.5 ) clusters . as_pandas_dataframe ( limit = 10 ) Completed iteration 1, root rows count 14 Completed iteration 2, root rows count 0 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } cluster_id unique_id first_name surname dob city email cluster tf_city 0 0 0 Robert Alan 1971-06-24 NaN robert255@smith.net 0 NaN 1 0 1 Robert Allen 1971-05-24 NaN roberta25@smith.net 0 NaN 2 0 2 Rob Allen 1971-06-24 London roberta25@smith.net 0 0.212792 3 0 3 Robert Alen 1971-06-24 Lonon NaN 0 0.007380 4 4 4 Grace NaN 1997-04-26 Hull grace.kelly52@jones.com 1 0.001230 5 4 5 Grace Kelly 1991-04-26 NaN grace.kelly52@jones.com 1 NaN 6 6 6 Logan pMurphy 1973-08-01 NaN NaN 2 NaN 7 7 7 NaN NaN 2015-03-03 Portsmouth evied56@harris-bailey.net 3 0.017220 8 8 8 NaN Dean 2015-03-03 NaN NaN 3 NaN 9 8 9 Evie Dean 2015-03-03 Pootsmruth evihd56@earris-bailey.net 3 0.001230","title":"Clustering"},{"location":"demos/04_Visualising_predictions.html","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Visualising predictions \u00b6 Splink contains a variety of tools to help you visualise your predictions. The idea is that, by developing an understanding of how your model works, you can gain confidence that the predictions it makes are sensible, or alternatively find examples of where your model isn't working, which may help you improve the model specification and fix these problems. # Rerun our predictions to we're ready to view the charts from splink.duckdb.duckdb_linker import DuckDBLinker import pandas as pd import altair as alt alt . renderers . enable ( 'mimetype' ) df = pd . read_csv ( \"./data/fake_1000.csv\" ) linker = DuckDBLinker ( df ) linker . load_settings_from_json ( \"./demo_settings/saved_model_from_demo.json\" ) df_predictions = linker . predict ( threshold_match_probability = 0.2 ) Waterfall chart \u00b6 The waterfall chart provides a means of visualising individual predictions to understand how Splink computed the final matchweight for a particular pairwise record comparison. To plot a waterfall chart, the user chooses one or more records from the results of linker.predict() , and provides these records to the linker.waterfall_chart() function. For an introduction to waterfall charts and how to interpret them, please see this video. records_to_view = df_predictions . as_record_dict ( limit = 5 ) linker . waterfall_chart ( records_to_view , filter_nulls = False ) Comparison viewer dashboard \u00b6 The comparison viewer dashboard takes this one step further by producing an interactive dashboard the contains examples predictions from across the spectrum of match scores. An in-depth video describing how to interpret the dashboard can be found here . linker . comparison_viewer_dashboard ( df_predictions , \"scv.html\" , overwrite = True ) # You can view the scv.html file in your browser, or inline in a notbook as follows from IPython.display import IFrame IFrame ( src = \"./scv.html\" , width = \"100%\" , height = 1200 ) Cluster studio dashboard \u00b6 Cluster studio is an interactive dashboards that visualises the results of clustering your predictions. It provides examples of clusters of different sizes. The shape and size of clusters can be indicative of problems with record linkage, so it provides a tool to help you find potential false positive and negative links. df_clusters = linker . cluster_pairwise_predictions_at_threshold ( df_predictions , threshold_match_probability = 0.5 ) linker . cluster_studio_dashboard ( df_predictions , df_clusters , \"cluster_studio.html\" , sampling_method = \"by_cluster_size\" , overwrite = True ) # You can view the scv.html file in your browser, or inline in a notbook as follows from IPython.display import IFrame IFrame ( src = \"./cluster_studio.html\" , width = \"100%\" , height = 1200 ) Completed iteration 1, root rows count 14 Completed iteration 2, root rows count 0","title":"4. Visualising predictions"},{"location":"demos/04_Visualising_predictions.html#visualising-predictions","text":"Splink contains a variety of tools to help you visualise your predictions. The idea is that, by developing an understanding of how your model works, you can gain confidence that the predictions it makes are sensible, or alternatively find examples of where your model isn't working, which may help you improve the model specification and fix these problems. # Rerun our predictions to we're ready to view the charts from splink.duckdb.duckdb_linker import DuckDBLinker import pandas as pd import altair as alt alt . renderers . enable ( 'mimetype' ) df = pd . read_csv ( \"./data/fake_1000.csv\" ) linker = DuckDBLinker ( df ) linker . load_settings_from_json ( \"./demo_settings/saved_model_from_demo.json\" ) df_predictions = linker . predict ( threshold_match_probability = 0.2 )","title":"Visualising predictions"},{"location":"demos/04_Visualising_predictions.html#waterfall-chart","text":"The waterfall chart provides a means of visualising individual predictions to understand how Splink computed the final matchweight for a particular pairwise record comparison. To plot a waterfall chart, the user chooses one or more records from the results of linker.predict() , and provides these records to the linker.waterfall_chart() function. For an introduction to waterfall charts and how to interpret them, please see this video. records_to_view = df_predictions . as_record_dict ( limit = 5 ) linker . waterfall_chart ( records_to_view , filter_nulls = False )","title":"Waterfall chart"},{"location":"demos/04_Visualising_predictions.html#comparison-viewer-dashboard","text":"The comparison viewer dashboard takes this one step further by producing an interactive dashboard the contains examples predictions from across the spectrum of match scores. An in-depth video describing how to interpret the dashboard can be found here . linker . comparison_viewer_dashboard ( df_predictions , \"scv.html\" , overwrite = True ) # You can view the scv.html file in your browser, or inline in a notbook as follows from IPython.display import IFrame IFrame ( src = \"./scv.html\" , width = \"100%\" , height = 1200 )","title":"Comparison viewer dashboard"},{"location":"demos/04_Visualising_predictions.html#cluster-studio-dashboard","text":"Cluster studio is an interactive dashboards that visualises the results of clustering your predictions. It provides examples of clusters of different sizes. The shape and size of clusters can be indicative of problems with record linkage, so it provides a tool to help you find potential false positive and negative links. df_clusters = linker . cluster_pairwise_predictions_at_threshold ( df_predictions , threshold_match_probability = 0.5 ) linker . cluster_studio_dashboard ( df_predictions , df_clusters , \"cluster_studio.html\" , sampling_method = \"by_cluster_size\" , overwrite = True ) # You can view the scv.html file in your browser, or inline in a notbook as follows from IPython.display import IFrame IFrame ( src = \"./cluster_studio.html\" , width = \"100%\" , height = 1200 ) Completed iteration 1, root rows count 14 Completed iteration 2, root rows count 0","title":"Cluster studio dashboard"},{"location":"demos/05_Quality_assurance.html","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Quality assurance of prediction results \u00b6 In the previous tutorial, we looked at various ways to visualise the results of our model. These are useful for quality assurance purposes because they allow us to understand how our model works and verify that it is doing something sensible. They can also be useful to identify examples where the model is not performing as expected. In addition to these spot checks, Splink also has functions to perform more formal accuracy analysis. These functions allow you to understand the likely prevalence of false positives and false negatives in your linkage models. They rely on the existence of a sample of labelled (ground truth) matches, which may have been produced (for example) by human beings. For the accuracy analysis to be unbiased, the sample should be representative of the overall dataset. # Rerun our predictions to we're ready to view the charts from splink.duckdb.duckdb_linker import DuckDBLinker import pandas as pd import altair as alt alt . renderers . enable ( 'mimetype' ) df = pd . read_csv ( \"./data/fake_1000.csv\" ) linker = DuckDBLinker ( df ) linker . load_settings_from_json ( \"./demo_settings/saved_model_from_demo.json\" ) df_predictions = linker . predict ( threshold_match_probability = 0.2 ) Load in labels \u00b6 The labels file contains a list of pairwise comparisons which represent matches and non-matches. The required format of the labels file is described here . df_labels = pd . read_csv ( \"./data/fake_1000_labels.csv\" ) df_labels . head ( 5 ) linker . _con . register ( \"labels\" , df_labels ) linker . _initialise_df_concat_with_tf () Receiver operating characteristic curve \u00b6 A ROC chart shows how the number of false positives and false negatives varies depending on the match threshold chosen. The match threshold is the match weight chosen as a cutoff for which pairwise comparisons to accept as matches. linker . roc_chart_from_labels ( \"labels\" ) Precision-recall chart \u00b6 An alternative representation of truth space is called a precision recall curve . This can be plotted as follows: linker . precision_recall_chart_from_labels ( \"labels\" ) Truth table \u00b6 Fnally, Splink can also report the underlying table used to construct the ROC and precision recall curves. linker . _initialise_df_concat_with_tf () roc_table = linker . roc_table_from_labels ( \"labels\" ) roc_table . as_pandas_dataframe ( limit = 5 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } truth_threshold row_count P N TP TN FP FN P_rate N_rate TP_rate TN_rate FP_rate FN_rate precision recall 0 -16.609950 1225.0 80.0 1145.0 80.0 0.0 1145.0 0.0 0.0 0.934694 1.0 0.000000 1.000000 0.0 0.065306 1.0 1 -15.488604 1225.0 80.0 1145.0 80.0 98.0 1047.0 0.0 0.0 0.934694 1.0 0.085590 0.914410 0.0 0.070985 1.0 2 -14.677083 1225.0 80.0 1145.0 80.0 268.0 877.0 0.0 0.0 0.934694 1.0 0.234061 0.765939 0.0 0.083595 1.0 3 -14.535475 1225.0 80.0 1145.0 80.0 310.0 835.0 0.0 0.0 0.934694 1.0 0.270742 0.729258 0.0 0.087432 1.0 4 -14.078051 1225.0 80.0 1145.0 80.0 396.0 749.0 0.0 0.0 0.934694 1.0 0.345852 0.654148 0.0 0.096502 1.0","title":"5. Quality assurance"},{"location":"demos/05_Quality_assurance.html#quality-assurance-of-prediction-results","text":"In the previous tutorial, we looked at various ways to visualise the results of our model. These are useful for quality assurance purposes because they allow us to understand how our model works and verify that it is doing something sensible. They can also be useful to identify examples where the model is not performing as expected. In addition to these spot checks, Splink also has functions to perform more formal accuracy analysis. These functions allow you to understand the likely prevalence of false positives and false negatives in your linkage models. They rely on the existence of a sample of labelled (ground truth) matches, which may have been produced (for example) by human beings. For the accuracy analysis to be unbiased, the sample should be representative of the overall dataset. # Rerun our predictions to we're ready to view the charts from splink.duckdb.duckdb_linker import DuckDBLinker import pandas as pd import altair as alt alt . renderers . enable ( 'mimetype' ) df = pd . read_csv ( \"./data/fake_1000.csv\" ) linker = DuckDBLinker ( df ) linker . load_settings_from_json ( \"./demo_settings/saved_model_from_demo.json\" ) df_predictions = linker . predict ( threshold_match_probability = 0.2 )","title":"Quality assurance of prediction results"},{"location":"demos/05_Quality_assurance.html#load-in-labels","text":"The labels file contains a list of pairwise comparisons which represent matches and non-matches. The required format of the labels file is described here . df_labels = pd . read_csv ( \"./data/fake_1000_labels.csv\" ) df_labels . head ( 5 ) linker . _con . register ( \"labels\" , df_labels ) linker . _initialise_df_concat_with_tf ()","title":"Load in labels"},{"location":"demos/05_Quality_assurance.html#receiver-operating-characteristic-curve","text":"A ROC chart shows how the number of false positives and false negatives varies depending on the match threshold chosen. The match threshold is the match weight chosen as a cutoff for which pairwise comparisons to accept as matches. linker . roc_chart_from_labels ( \"labels\" )","title":"Receiver operating characteristic curve"},{"location":"demos/05_Quality_assurance.html#precision-recall-chart","text":"An alternative representation of truth space is called a precision recall curve . This can be plotted as follows: linker . precision_recall_chart_from_labels ( \"labels\" )","title":"Precision-recall chart"},{"location":"demos/05_Quality_assurance.html#truth-table","text":"Fnally, Splink can also report the underlying table used to construct the ROC and precision recall curves. linker . _initialise_df_concat_with_tf () roc_table = linker . roc_table_from_labels ( \"labels\" ) roc_table . as_pandas_dataframe ( limit = 5 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } truth_threshold row_count P N TP TN FP FN P_rate N_rate TP_rate TN_rate FP_rate FN_rate precision recall 0 -16.609950 1225.0 80.0 1145.0 80.0 0.0 1145.0 0.0 0.0 0.934694 1.0 0.000000 1.000000 0.0 0.065306 1.0 1 -15.488604 1225.0 80.0 1145.0 80.0 98.0 1047.0 0.0 0.0 0.934694 1.0 0.085590 0.914410 0.0 0.070985 1.0 2 -14.677083 1225.0 80.0 1145.0 80.0 268.0 877.0 0.0 0.0 0.934694 1.0 0.234061 0.765939 0.0 0.083595 1.0 3 -14.535475 1225.0 80.0 1145.0 80.0 310.0 835.0 0.0 0.0 0.934694 1.0 0.270742 0.729258 0.0 0.087432 1.0 4 -14.078051 1225.0 80.0 1145.0 80.0 396.0 749.0 0.0 0.0 0.934694 1.0 0.345852 0.654148 0.0 0.096502 1.0","title":"Truth table"},{"location":"demos/deduplicate_50k_synthetic.html","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); from splink.duckdb.duckdb_linker import DuckDBLinker import altair as alt alt . renderers . enable ( 'mimetype' ) RendererRegistry.enable('mimetype') import pandas as pd pd . options . display . max_rows = 1000 df = pd . read_parquet ( \"./data/historical_figures_with_errors_50k.parquet\" ) df . head ( 5 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } uncorrupted_record cluster full_name dob birth_place postcode_fake lat lng gender occupation unique_id 0 True Q2296770 thomas clifford, 1st baron clifford of chudleigh 1630-08-01 Devon TQ13 8DF 50.692449 -3.813964 male politician Q2296770-1 1 False Q2296770 thomas of chudleigh 1630-08-01 Devon TQ13 8DF 50.692449 -3.813964 male politician Q2296770-2 2 False Q2296770 tom 1st baron clifford of chudleigh 1630-08-01 Devon TQ13 8DF 50.692449 -3.813964 male politician Q2296770-3 3 False Q2296770 thomas 1st chudleigh 1630-08-01 Devon TQ13 8HU 50.687638 -3.895877 None politician Q2296770-4 4 False Q2296770 thomas clifford, 1st baron chudleigh 1630-08-01 Devon TQ13 8DF 50.692449 -3.813964 None politician Q2296770-5 import numpy as np import pandas as pd def clean_df ( df ): cols = [ \"unique_id\" , \"cluster\" , \"full_name\" , \"dob\" , \"birth_place\" , \"postcode_fake\" , \"gender\" , \"occupation\" , ] df = df [ cols ] . copy () df [ \"name_split\" ] = df [ \"full_name\" ] . str . strip () . str . split ( \" \" ) df [ \"name_split_length\" ] = df [ \"name_split\" ] . str . len () df [ \"first_name\" ] = df [ \"name_split\" ] . str [ 0 ] df [ \"surname\" ] = df [ \"name_split\" ] . str [ - 1 ] df [ \"surname\" ] = np . where ( df [ \"name_split_length\" ] > 1 , df [ \"surname\" ], \"\" ) # df[\"middle_names\"] = df[\"name_split\"].str[1:-1] df [ \"first_and_surname\" ] = df [ \"first_name\" ] + \" \" + df [ \"surname\" ] for col in [ \"full_name\" , \"first_and_surname\" , \"first_name\" , \"surname\" , \"dob\" , \"birth_place\" , \"postcode_fake\" , \"gender\" , \"occupation\" , ]: df [ col ] = df [ col ] . str . lower () . str . strip () df [ col ] = df [ col ] . replace ({ \"\" : None }) cols = [ \"unique_id\" , \"cluster\" , \"full_name\" , \"first_and_surname\" , \"first_name\" , \"surname\" , \"dob\" , \"birth_place\" , \"postcode_fake\" , \"gender\" , \"occupation\" , ] return df [ cols ] df_clean = clean_df ( df ) df_clean . head ( 2 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } unique_id cluster full_name first_and_surname first_name surname dob birth_place postcode_fake gender occupation 0 Q2296770-1 Q2296770 thomas clifford, 1st baron clifford of chudleigh thomas chudleigh thomas chudleigh 1630-08-01 devon tq13 8df male politician 1 Q2296770-2 Q2296770 thomas of chudleigh thomas chudleigh thomas chudleigh 1630-08-01 devon tq13 8df male politician # Initialise the linker, passing in the input dataset(s) linker = DuckDBLinker ( df_clean , connection = \":temporary:\" ) import altair as alt alt . renderers . enable ( 'mimetype' ) linker . profile_columns ([ \"first_name\" , \"postcode_fake\" , \"substr(dob, 1,4)\" ], top_n = 10 , bottom_n = 5 ) linker . count_num_comparisons_from_blocking_rule ( \"l.first_name = r.first_name\" , unique_id_column_name = \"unique_id\" ) 16372982 linker . count_num_comparisons_from_blocking_rule ( \"l.first_name = r.first_name and l.surname = r.surname\" , unique_id_column_name = \"unique_id\" ) 243656 linker . count_num_comparisons_from_blocking_rule ( \"l.dob = r.dob\" , unique_id_column_name = \"unique_id\" ) 1549081 import splink.duckdb.duckdb_comparison_library as cl settings = { \"probability_two_random_records_match\" : 9 / 50_000 , \"link_type\" : \"dedupe_only\" , \"blocking_rules_to_generate_predictions\" : [ \"l.first_name = r.first_name and l.surname = r.surname\" , \"l.surname = r.surname and l.dob = r.dob\" , \"l.first_name = r.first_name and l.dob = r.dob\" , \"l.postcode_fake = r.postcode_fake and l.first_name = r.first_name\" , ], \"comparisons\" : [ cl . jaccard_at_thresholds ( \"first_name\" , [ 0.9 , 0.5 ], term_frequency_adjustments = False ), cl . jaccard_at_thresholds ( \"surname\" , [ 0.9 , 0.5 ], term_frequency_adjustments = False ), cl . levenshtein_at_thresholds ( \"dob\" , [ 1 , 2 ], term_frequency_adjustments = False ), cl . levenshtein_at_thresholds ( \"postcode_fake\" , 2 ), cl . exact_match ( \"birth_place\" , term_frequency_adjustments = False ), cl . exact_match ( \"occupation\" , term_frequency_adjustments = False ), ], \"retain_matching_columns\" : True , \"retain_intermediate_calculation_columns\" : True , \"max_iterations\" : 10 , \"em_convergence\" : 0.01 } linker . initialise_settings ( settings ) linker . estimate_u_using_random_sampling ( target_rows = 5e6 ) ----- Estimating u probabilities using random sampling ----- Estimated u probabilities using random sampling Your model is not yet fully trained. Missing estimates for: - first_name (no m values are trained). - surname (no m values are trained). - dob (no m values are trained). - postcode_fake (no m values are trained). - birth_place (no m values are trained). - occupation (no m values are trained). blocking_rule = \"l.first_name = r.first_name and l.surname = r.surname\" training_session_names = linker . estimate_parameters_using_expectation_maximisation ( blocking_rule ) training_session_names . match_weights_interactive_history_chart () ----- Starting EM training session ----- Estimating the m probabilities of the model by blocking on: l.first_name = r.first_name and l.surname = r.surname Parameter estimates will be made for the following comparison(s): - dob - postcode_fake - birth_place - occupation Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: - first_name - surname Iteration 1: Largest change in params was -0.529 in probability_two_random_records_match Iteration 2: Largest change in params was -0.0364 in probability_two_random_records_match Iteration 3: Largest change in params was 0.0156 in the m_probability of birth_place, level `Exact match` Iteration 4: Largest change in params was -0.00724 in the m_probability of dob, level `All other comparisons` EM converged after 4 iterations Your model is not yet fully trained. Missing estimates for: - first_name (no m values are trained). - surname (no m values are trained). blocking_rule = \"l.dob = r.dob\" training_session_dob = linker . estimate_parameters_using_expectation_maximisation ( blocking_rule ) training_session_dob . match_weights_interactive_history_chart () ----- Starting EM training session ----- Estimating the m probabilities of the model by blocking on: l.dob = r.dob Parameter estimates will be made for the following comparison(s): - first_name - surname - postcode_fake - birth_place - occupation Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: - dob Iteration 1: Largest change in params was -0.314 in the m_probability of first_name, level `Exact match` Iteration 2: Largest change in params was -0.0693 in the m_probability of first_name, level `Exact match` Iteration 3: Largest change in params was -0.0111 in the m_probability of surname, level `Exact match` Iteration 4: Largest change in params was -0.00275 in the m_probability of surname, level `Exact match` EM converged after 4 iterations Your model is fully trained. All comparisons have at least one estimate for their m and u values The final match weights can be viewed in the match weights chart: linker . match_weights_chart () df_predict = linker . predict () df_e = df_predict . as_pandas_dataframe ( limit = 5 ) df_e .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } match_weight match_probability unique_id_l unique_id_r first_name_l first_name_r gamma_first_name bf_first_name surname_l surname_r ... bf_postcode_fake birth_place_l birth_place_r gamma_birth_place bf_birth_place occupation_l occupation_r gamma_occupation bf_occupation match_key 0 16.708163 0.999991 Q2296770-1 Q2296770-14 thomas thomas 3 39.431526 chudleigh chudleigh ... 272.364133 devon NaN -1 1.00000 politician politician 1 22.584392 0 1 2.063113 0.806908 Q2296770-10 Q2296770-14 thomas thomas 3 39.431526 chudleigh chudleigh ... 0.170964 devon NaN -1 1.00000 politician politician 1 22.584392 0 2 22.327751 1.000000 Q1443188-1 Q1443188-3 frank frank 3 39.431526 brightman brightman ... 4343.786456 bristol bristol, city of 0 0.16064 liturgist liturgist 1 22.584392 0 3 22.327751 1.000000 Q1443188-2 Q1443188-3 frank frank 3 39.431526 brightman brightman ... 4343.786456 bristol bristol, city of 0 0.16064 liturgist liturgist 1 22.584392 0 4 6.070536 0.985339 Q1443188-4 Q1443188-5 francis francis 3 39.431526 brightman brightman ... 0.170964 NaN bristol, city of -1 1.00000 liturgist liturgist 1 22.584392 0 5 rows \u00d7 29 columns You can also view rows in this dataset as a waterfall chart as follows: from splink.charts import waterfall_chart records_to_plot = df_e . to_dict ( orient = \"records\" ) linker . waterfall_chart ( records_to_plot , filter_nulls = False ) clusters = linker . cluster_pairwise_predictions_at_threshold ( df_predict , threshold_match_probability = 0.95 ) Completed iteration 1, root rows count 668 Completed iteration 2, root rows count 149 Completed iteration 3, root rows count 43 Completed iteration 4, root rows count 11 Completed iteration 5, root rows count 1 Completed iteration 6, root rows count 0 linker . cluster_studio_dashboard ( df_predict , clusters , \"50k_cluster.html\" , sampling_method = 'by_cluster_size' , overwrite = True ) from IPython.display import IFrame IFrame ( src = \"./50k_cluster.html\" , width = \"100%\" , height = 1200 )","title":"deduplicate 50k rows of synthetic data"},{"location":"demos/real_time_record_linkage.html","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Exploring linkage models using real time linkage \u00b6 In this notebook, we demonstrate splink's incremental and real time linkage capabilities - specifically: - the linker.compare_two_records function, that allows you to interactively explore the results of a linkage model; and - the linker.find_matches_to_new_records that allows you to incrementally find matches to a small number of new records Step 1: Load a pre-trained linkage model \u00b6 import sys sys . path . insert ( 0 , '/Users/robinlinacre/Documents/data_linking/splink/' ) import pandas as pd import json from splink.duckdb.duckdb_linker import DuckDBLinker with open ( \"demo_settings/real_time_settings.json\" ) as f : trained_settings = json . load ( f ) df = pd . read_csv ( \"./data/fake_1000.csv\" ) linker = DuckDBLinker ( df , trained_settings ) linker . _initialise_df_concat_with_tf () linker . compute_tf_table ( \"first_name\" ) linker . compute_tf_table ( \"surname\" ) linker . compute_tf_table ( \"dob\" ) linker . compute_tf_table ( \"city\" ) t = linker . compute_tf_table ( \"email\" ) linker . waterfall_chart ( linker . predict () . as_record_dict ( limit = 2 )) var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG; (function(spec, embedOpt){ let outputDiv = document.currentScript.previousElementSibling; if (outputDiv.id !== \"altair-viz-80d1108ba74643f4864bb0710ebb7335\") { outputDiv = document.getElementById(\"altair-viz-80d1108ba74643f4864bb0710ebb7335\"); } const paths = { \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\", \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\", \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\", \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\", }; function maybeLoadScript(lib, version) { var key = `${lib.replace(\"-\", \"\")}_version`; return (VEGA_DEBUG[key] == version) ? Promise.resolve(paths[lib]) : new Promise(function(resolve, reject) { var s = document.createElement('script'); document.getElementsByTagName(\"head\")[0].appendChild(s); s.async = true; s.onload = () => { VEGA_DEBUG[key] = version; return resolve(paths[lib]); }; s.onerror = () => reject(`Error loading script: ${paths[lib]}`); s.src = paths[lib]; }); } function showError(err) { outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`; throw err; } function displayChart(vegaEmbed) { vegaEmbed(outputDiv, spec, embedOpt) .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`)); } if(typeof define === \"function\" && define.amd) { requirejs.config({paths}); require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`)); } else { maybeLoadScript(\"vega\", \"5\") .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\")) .then(() => maybeLoadScript(\"vega-embed\", \"6\")) .catch(showError) .then(() => displayChart(vegaEmbed)); } })({\"$schema\": \"https://vega.github.io/schema/vega-lite/v5.2.0.json\", \"height\": 450, \"resolve\": {\"axis\": {\"y\": \"independent\"}}, \"width\": {\"step\": 75}, \"data\": {\"values\": [{\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -5.391889789559854, \"bayes_factor\": 0.023816582302252427, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 0}, {\"column_name\": \"first_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.1925340745596764, \"bayes_factor\": 0.21876683164040506, \"comparison_vector_value\": 0, \"m_probability\": 0.21528549148688833, \"u_probability\": 0.9840865266118626, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 4.57 times less likely to be a match\", \"value_l\": \"Oliver\", \"value_r\": \"Alfie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 0}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.21528549148688833, \"u_probability\": 0.9840865266118626, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 4.57 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 0}, {\"column_name\": \"surname\", \"label_for_charts\": \"exact_match\", \"sql_condition\": \"surname_l = surname_r\", \"log2_bayes_factor\": 6.529599913880287, \"bayes_factor\": 92.38584465067325, \"comparison_vector_value\": 2, \"m_probability\": 0.4517645215191846, \"u_probability\": 0.004889975550122249, \"bayes_factor_description\": \"If comparison level is `exact_match` then comparison is 92.39 times more likely to be a match\", \"value_l\": \"Griffiths\", \"value_r\": \"Griffiths\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 0}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"surname_l = surname_r\", \"log2_bayes_factor\": 0.4168001079781037, \"bayes_factor\": 1.3349633251833741, \"comparison_vector_value\": 2, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.33 times more likely to be a match\", \"value_l\": \"Griffiths\", \"value_r\": \"Griffiths\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 0}, {\"column_name\": \"dob\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.114723717091652, \"bayes_factor\": 0.23088978993311773, \"comparison_vector_value\": 0, \"m_probability\": 0.22653362300553073, \"u_probability\": 0.9811331331331331, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 4.33 times less likely to be a match\", \"value_l\": \"1991-10-26\", \"value_r\": \"2008-05-07\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 0}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.22653362300553073, \"u_probability\": 0.9811331331331331, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 4.33 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 0}, {\"column_name\": \"city\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -1.1635794871398053, \"bayes_factor\": 0.4464035832880252, \"comparison_vector_value\": 0, \"m_probability\": 0.4217855099035769, \"u_probability\": 0.9448524288198547, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 2.24 times less likely to be a match\", \"value_l\": \"Lunton\", \"value_r\": \"Plymouth\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 0}, {\"column_name\": \"tf_city\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.4217855099035769, \"u_probability\": 0.9448524288198547, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 2.24 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 0}, {\"column_name\": \"email\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -1.239777184635766, \"bayes_factor\": 0.4234380485302649, \"comparison_vector_value\": 0, \"m_probability\": 0.42250907994219916, \"u_probability\": 0.9978061286856716, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 2.36 times less likely to be a match\", \"value_l\": \"o.griffiths90@reyes-coleman.com\", \"value_r\": \"a.griffiths@garner-bridges.com\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 0}, {\"column_name\": \"tf_email\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.42250907994219916, \"u_probability\": 0.9978061286856716, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 2.36 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 0}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -5.156104231128363, \"bayes_factor\": 0.028045162816898225, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 0}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -5.391889789559854, \"bayes_factor\": 0.023816582302252427, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 1}, {\"column_name\": \"first_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.1925340745596764, \"bayes_factor\": 0.21876683164040506, \"comparison_vector_value\": 0, \"m_probability\": 0.21528549148688833, \"u_probability\": 0.9840865266118626, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 4.57 times less likely to be a match\", \"value_l\": \"Rowe\", \"value_r\": \"Scott\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 1}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.21528549148688833, \"u_probability\": 0.9840865266118626, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 4.57 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 1}, {\"column_name\": \"surname\", \"label_for_charts\": \"exact_match\", \"sql_condition\": \"surname_l = surname_r\", \"log2_bayes_factor\": 6.529599913880287, \"bayes_factor\": 92.38584465067325, \"comparison_vector_value\": 2, \"m_probability\": 0.4517645215191846, \"u_probability\": 0.004889975550122249, \"bayes_factor_description\": \"If comparison level is `exact_match` then comparison is 92.39 times more likely to be a match\", \"value_l\": \"Caleb\", \"value_r\": \"Caleb\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 1}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"surname_l = surname_r\", \"log2_bayes_factor\": 0.4168001079781037, \"bayes_factor\": 1.3349633251833741, \"comparison_vector_value\": 2, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.33 times more likely to be a match\", \"value_l\": \"Caleb\", \"value_r\": \"Caleb\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 1}, {\"column_name\": \"dob\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.114723717091652, \"bayes_factor\": 0.23088978993311773, \"comparison_vector_value\": 0, \"m_probability\": 0.22653362300553073, \"u_probability\": 0.9811331331331331, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 4.33 times less likely to be a match\", \"value_l\": \"1992-12-20\", \"value_r\": \"1990-12-11\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 1}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.22653362300553073, \"u_probability\": 0.9811331331331331, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 4.33 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 1}, {\"column_name\": \"city\", \"label_for_charts\": \"Null\", \"sql_condition\": \"city_l IS NULL OR city_r IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"Lvpreool\", \"value_r\": \"nan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 1}, {\"column_name\": \"tf_city\", \"label_for_charts\": \"Null\", \"sql_condition\": \"city_l IS NULL OR city_r IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 1}, {\"column_name\": \"email\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -1.239777184635766, \"bayes_factor\": 0.4234380485302649, \"comparison_vector_value\": 0, \"m_probability\": 0.42250907994219916, \"u_probability\": 0.9978061286856716, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 2.36 times less likely to be a match\", \"value_l\": \"calebr@thompson.org\", \"value_r\": \"c.scott@brooks.com\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 1}, {\"column_name\": \"tf_email\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.42250907994219916, \"u_probability\": 0.9978061286856716, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 2.36 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 1}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -3.9925247439885574, \"bayes_factor\": 0.06282468122305176, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 1}]}, \"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"params\": [{\"name\": \"record_number\", \"value\": 0, \"bind\": {\"input\": \"range\", \"min\": 0, \"max\": 1, \"step\": 1}, \"description\": \"Filter by the interation number\"}], \"title\": {\"text\": \"Match weights waterfall chart\", \"subtitle\": \"How each comparison contributes to the final match score\"}, \"transform\": [{\"filter\": \"(datum.record_number == record_number)\"}, {\"filter\": \"(datum.bayes_factor !== 1.0)\"}, {\"window\": [{\"op\": \"sum\", \"field\": \"log2_bayes_factor\", \"as\": \"sum\"}, {\"op\": \"lead\", \"field\": \"column_name\", \"as\": \"lead\"}], \"frame\": [null, 0]}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" ? datum.sum - datum.log2_bayes_factor : datum.sum\", \"as\": \"sum\"}, {\"calculate\": \"datum.lead === null ? datum.column_name : datum.lead\", \"as\": \"lead\"}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" || datum.column_name === \\\"Prior match weight\\\" ? 0 : datum.sum - datum.log2_bayes_factor\", \"as\": \"previous_sum\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"top_label\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"bottom_label\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_top\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_bottom\"}, {\"calculate\": \"(datum.sum + datum.previous_sum) / 2\", \"as\": \"center\"}, {\"calculate\": \"(datum.log2_bayes_factor > 0 ? \\\"+\\\" : \\\"\\\") + datum.log2_bayes_factor\", \"as\": \"text_log2_bayes_factor\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? 4 : -4\", \"as\": \"dy\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? \\\"top\\\" : \\\"bottom\\\"\", \"as\": \"baseline\"}, {\"calculate\": \"1. / (1 + pow(2, -1.*datum.sum))\", \"as\": \"prob\"}, {\"calculate\": \"0*datum.sum\", \"as\": \"zero\"}], \"layer\": [{\"layer\": [{\"mark\": \"rule\", \"encoding\": {\"y\": {\"field\": \"zero\", \"type\": \"quantitative\"}, \"size\": {\"value\": 0.5}, \"color\": {\"value\": \"black\"}}}, {\"mark\": {\"type\": \"bar\", \"width\": 60}, \"encoding\": {\"color\": {\"condition\": {\"value\": \"red\", \"test\": \"(datum.log2_bayes_factor < 0)\"}, \"value\": \"green\"}, \"opacity\": {\"condition\": {\"value\": 1, \"test\": \"datum.column_name == 'Prior match weight' || datum.column_name == 'Final score'\"}, \"value\": 0.5}, \"tooltip\": [{\"type\": \"nominal\", \"field\": \"column_name\", \"title\": \"Comparison column\"}, {\"type\": \"nominal\", \"field\": \"value_l\", \"title\": \"Value (L)\"}, {\"type\": \"nominal\", \"field\": \"value_r\", \"title\": \"Value (R)\"}, {\"type\": \"ordinal\", \"field\": \"label_for_charts\", \"title\": \"Label\"}, {\"type\": \"nominal\", \"field\": \"sql_condition\", \"title\": \"SQL condition\"}, {\"type\": \"nominal\", \"field\": \"comparison_vector_value\", \"title\": \"Comparison vector value\"}, {\"type\": \"quantitative\", \"field\": \"bayes_factor\", \"title\": \"Bayes factor = m/u\", \"format\": \",.4f\"}, {\"type\": \"quantitative\", \"field\": \"log2_bayes_factor\", \"title\": \"Match weight = log2(m/u)\", \"format\": \",.4f\"}, {\"type\": \"quantitative\", \"field\": \"prob\", \"format\": \".4f\", \"title\": \"Adjusted match score\"}, {\"type\": \"nominal\", \"field\": \"bayes_factor_description\", \"title\": \"Match weight description\"}], \"x\": {\"type\": \"nominal\", \"axis\": {\"labelExpr\": \"datum.value == 'Prior' || datum.value == 'Final score' ? '' : datum.value\", \"labelAngle\": -20, \"labelAlign\": \"center\", \"labelPadding\": 10, \"title\": \"Column\", \"grid\": true, \"tickBand\": \"extent\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}}, \"y\": {\"type\": \"quantitative\", \"axis\": {\"grid\": false, \"orient\": \"left\", \"title\": \"log2(Bayes factor)\"}, \"field\": \"previous_sum\"}, \"y2\": {\"field\": \"sum\"}}}, {\"mark\": {\"type\": \"text\", \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"white\"}, \"text\": {\"condition\": {\"type\": \"nominal\", \"field\": \"log2_bayes_factor\", \"format\": \".2f\", \"test\": \"abs(datum.log2_bayes_factor) > 1\"}, \"value\": \"\"}, \"x\": {\"type\": \"nominal\", \"axis\": {\"labelAngle\": 0, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}}, \"y\": {\"type\": \"quantitative\", \"axis\": {\"orient\": \"left\"}, \"field\": \"center\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -25, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"type\": \"nominal\", \"field\": \"column_name\"}, \"x\": {\"type\": \"nominal\", \"axis\": {\"labelAngle\": 0, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}}, \"y\": {\"type\": \"quantitative\", \"field\": \"sum_top\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"fontSize\": 8, \"dy\": -13}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"type\": \"nominal\", \"field\": \"value_l\"}, \"x\": {\"type\": \"nominal\", \"axis\": {\"labelAngle\": 0, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}}, \"y\": {\"type\": \"quantitative\", \"field\": \"sum_top\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"fontSize\": 8, \"dy\": -5}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"type\": \"nominal\", \"field\": \"value_r\"}, \"x\": {\"type\": \"nominal\", \"axis\": {\"labelAngle\": 0, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}}, \"y\": {\"type\": \"quantitative\", \"field\": \"sum_top\"}}}]}, {\"mark\": {\"type\": \"rule\", \"color\": \"black\", \"strokeWidth\": 2, \"x2Offset\": 30, \"xOffset\": -30}, \"encoding\": {\"x\": {\"type\": \"nominal\", \"axis\": {\"labelAngle\": 0, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}}, \"x2\": {\"field\": \"lead\"}, \"y\": {\"type\": \"quantitative\", \"axis\": {\"labelExpr\": \"format(1 / (1 + pow(2, -1*datum.value)), '.2r')\", \"orient\": \"right\", \"title\": \"Probability\"}, \"field\": \"sum\", \"scale\": {\"zero\": false}}}}]}, {\"mode\": \"vega-lite\"}); Step Comparing two records \u00b6 It's now possible to compute a match weight for any two records using linker.compare_two_records() record_1 = { 'unique_id' : 1 , 'first_name' : \"Lucas\" , 'surname' : \"Smith\" , 'dob' : \"1984-01-02\" , 'city' : \"London\" , 'email' : \"lucas.smith@hotmail.com\" } record_2 = { 'unique_id' : 2 , 'first_name' : \"Lucas\" , 'surname' : \"Smith\" , 'dob' : \"1983-02-12\" , 'city' : \"Machester\" , 'email' : \"lucas.smith@hotmail.com\" } linker . _settings_obj_ . _retain_intermediate_calculation_columns = True linker . _settings_obj_ . _retain_matching_columns = True df_two = linker . compare_two_records ( record_1 , record_2 ) df_two . as_pandas_dataframe () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } match_weight match_probability unique_id_l unique_id_r first_name_l first_name_r gamma_first_name bf_first_name bf_tf_adj_first_name tf_first_name_l ... bf_tf_adj_city tf_city_l tf_city_r email_l email_r gamma_email bf_email bf_tf_adj_email tf_email_l tf_email_r 0 13.161672 0.999891 1 2 Lucas Lucas 2 87.571229 4.814458 0.001203 ... 1.0 0.212792 NaN lucas.smith@hotmail.com lucas.smith@hotmail.com 1 263.229168 1.0 NaN NaN 1 rows \u00d7 39 columns Step 3: Interactive comparisons \u00b6 One interesting applicatin of compare_two_records is to create a simple interface that allows the user to input two records interactively, and get real time feedback. In the following cell we use ipywidets for this purpose. \u2728\u2728 Change the values in the text boxes to see the waterfall chart update in real time. \u2728\u2728 import ipywidgets as widgets fields = [ \"unique_id\" , \"first_name\" , \"surname\" , \"dob\" , \"email\" , \"city\" ] left_text_boxes = [] right_text_boxes = [] inputs_to_interactive_output = {} for f in fields : wl = widgets . Text ( description = f , value = str ( record_1 [ f ])) left_text_boxes . append ( wl ) inputs_to_interactive_output [ f \" { f } _l\" ] = wl wr = widgets . Text ( description = f , value = str ( record_2 [ f ])) right_text_boxes . append ( wr ) inputs_to_interactive_output [ f \" { f } _r\" ] = wr b1 = widgets . VBox ( left_text_boxes ) b2 = widgets . VBox ( right_text_boxes ) ui = widgets . HBox ([ b1 , b2 ]) def myfn ( ** kwargs ): my_args = dict ( kwargs ) record_left = {} record_right = {} for key , value in my_args . items (): if value == '' : value = None if key . endswith ( \"_l\" ): record_left [ key [: - 2 ]] = value if key . endswith ( \"_r\" ): record_right [ key [: - 2 ]] = value linker . _settings_obj_ . _retain_intermediate_calculation_columns = True linker . _settings_obj_ . _retain_matching_columns = True df_two = linker . compare_two_records ( record_left , record_right ) recs = df_two . as_pandas_dataframe () . to_dict ( orient = \"records\" ) from splink.charts import waterfall_chart display ( linker . waterfall_chart ( recs , filter_nulls = False )) out = widgets . interactive_output ( myfn , inputs_to_interactive_output ) display ( ui , out ) HBox(children=(VBox(children=(Text(value='1', description='unique_id'), Text(value='Lucas', description='first\u2026 Output() Finding matching records interactively \u00b6 It is also possible to search the records in the input dataset rapidly using the linker.find_matches_to_new_records() function record = { 'unique_id' : 123987 , 'first_name' : \"Robert\" , 'surname' : \"Alan\" , 'dob' : \"1971-05-24\" , 'city' : \"London\" , 'email' : \"robert255@smith.net\" } df_inc = linker . find_matches_to_new_records ([ record ], blocking_rules = []) . as_pandas_dataframe () df_inc . sort_values ( \"match_weight\" , ascending = False ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } match_weight match_probability unique_id_l unique_id_r first_name_l first_name_r gamma_first_name bf_first_name bf_tf_adj_first_name tf_first_name_l ... bf_tf_adj_city tf_city_l tf_city_r email_l email_r gamma_email bf_email bf_tf_adj_email tf_email_l tf_email_r 1 23.531793 1.000000 0 123987 Robert Robert 2 87.571229 1.604819 0.003610 ... 1.000000 NaN 0.212792 robert255@smith.net robert255@smith.net 1 263.229168 1.730964 0.001267 0.001267 2 14.550320 0.999958 1 123987 Robert Robert 2 87.571229 1.604819 0.003610 ... 1.000000 NaN 0.212792 roberta25@smith.net robert255@smith.net 0 0.423438 1.000000 0.002535 0.001267 4 10.388623 0.999255 3 123987 Robert Robert 2 87.571229 1.604819 0.003610 ... 1.000000 0.007380 0.212792 NaN robert255@smith.net -1 1.000000 1.000000 NaN 0.001267 0 2.427256 0.843228 2 123987 Rob Robert 0 0.218767 1.000000 0.001203 ... 0.259162 0.212792 0.212792 roberta25@smith.net robert255@smith.net 0 0.423438 1.000000 0.002535 0.001267 6 -2.123090 0.186697 8 123987 NaN Robert -1 1.000000 1.000000 NaN ... 1.000000 NaN 0.212792 NaN robert255@smith.net -1 1.000000 1.000000 NaN 0.001267 5 -2.205894 0.178139 754 123987 NaN Robert -1 1.000000 1.000000 NaN ... 1.000000 NaN 0.212792 j.c@whige.wort robert255@smith.net 0 0.423438 1.000000 0.001267 0.001267 3 -2.802309 0.125383 750 123987 NaN Robert -1 1.000000 1.000000 NaN ... 0.259162 0.212792 0.212792 j.c@white.org robert255@smith.net 0 0.423438 1.000000 0.002535 0.001267 7 rows \u00d7 39 columns Interactive interface for finding records \u00b6 Again, we can use ipywidgets to build an interactive interface for the linker.find_matches_to_new_records function from splink.charts import waterfall_chart @widgets . interact ( first_name = 'Robert' , surname = \"Alan\" , dob = \"1971-05-24\" , city = \"London\" , email = \"robert255@smith.net\" ) def interactive_link ( first_name , surname , dob , city , email ): record = { 'unique_id' : 123987 , 'first_name' : first_name , 'surname' : surname , 'dob' : dob , 'city' : city , 'email' : email , 'group' : 0 } for key in record . keys (): if type ( record [ key ]) == str : if record [ key ] . strip () == \"\" : record [ key ] = None df_inc = linker . find_matches_to_new_records ([ record ], blocking_rules = [ f \"(true)\" ]) . as_pandas_dataframe () df_inc = df_inc . sort_values ( \"match_weight\" , ascending = False ) recs = df_inc . to_dict ( orient = \"records\" ) display ( linker . waterfall_chart ( recs , filter_nulls = False )) interactive(children=(Text(value='Robert', description='first_name'), Text(value='Alan', description='surname'\u2026 linker . match_weights_chart () var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG; (function(spec, embedOpt){ let outputDiv = document.currentScript.previousElementSibling; if (outputDiv.id !== \"altair-viz-4663e99319364be8854b4bc5d4c58cbf\") { outputDiv = document.getElementById(\"altair-viz-4663e99319364be8854b4bc5d4c58cbf\"); } const paths = { \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\", \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\", \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\", \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\", }; function maybeLoadScript(lib, version) { var key = `${lib.replace(\"-\", \"\")}_version`; return (VEGA_DEBUG[key] == version) ? Promise.resolve(paths[lib]) : new Promise(function(resolve, reject) { var s = document.createElement('script'); document.getElementsByTagName(\"head\")[0].appendChild(s); s.async = true; s.onload = () => { VEGA_DEBUG[key] = version; return resolve(paths[lib]); }; s.onerror = () => reject(`Error loading script: ${paths[lib]}`); s.src = paths[lib]; }); } function showError(err) { outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`; throw err; } function displayChart(vegaEmbed) { vegaEmbed(outputDiv, spec, embedOpt) .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`)); } if(typeof define === \"function\" && define.amd) { requirejs.config({paths}); require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`)); } else { maybeLoadScript(\"vega\", \"5\") .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\")) .then(() => maybeLoadScript(\"vega-embed\", \"6\")) .catch(showError) .then(() => displayChart(vegaEmbed)); } })({\"config\": {\"view\": {\"width\": 400, \"height\": 60}, \"mark\": {\"tooltip\": null}, \"title\": {\"anchor\": \"middle\"}, \"header\": {\"title\": null}}, \"data\": {\"values\": [{\"comparison_name\": \"probability_two_random_records_match\", \"sql_condition\": null, \"label_for_charts\": \"\", \"m_probability\": null, \"u_probability\": null, \"m_probability_description\": null, \"u_probability_description\": null, \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": null, \"is_null_level\": false, \"bayes_factor\": 0.023816582302252427, \"log2_bayes_factor\": -5.391889789559854, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 0, \"bayes_factor_description\": \"The probability that two random records drawn at random match is 0.023 or one in 43.0 records.This is equivalent to a starting match weight of -5.392.\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": -1}, {\"comparison_name\": \"first_name\", \"sql_condition\": \"first_name_l = first_name_r\", \"label_for_charts\": \"exact_match\", \"m_probability\": 0.5073501669215337, \"u_probability\": 0.0057935713975033705, \"m_probability_description\": \"Amongst matching record comparisons, 50.74% of records are in the exact_match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.58% of records are in the exact_match comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"first_name\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 87.57122888658395, \"log2_bayes_factor\": 6.452385051922501, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `exact_match` then comparison is 87.57 times more likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 0}, {\"comparison_name\": \"first_name\", \"sql_condition\": \"levenshtein(first_name_l, first_name_r) <= 2\", \"label_for_charts\": \"Levenstein <= 2\", \"m_probability\": 0.27736434159157797, \"u_probability\": 0.010119901990634016, \"m_probability_description\": \"Amongst matching record comparisons, 27.74% of records are in the levenstein <= 2 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 1.01% of records are in the levenstein <= 2 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 27.407809072486973, \"log2_bayes_factor\": 4.776515101395072, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `levenstein <= 2` then comparison is 27.41 times more likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 0}, {\"comparison_name\": \"first_name\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.21528549148688833, \"u_probability\": 0.9840865266118626, \"m_probability_description\": \"Amongst matching record comparisons, 21.53% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 98.41% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.21876683164040506, \"log2_bayes_factor\": -2.1925340745596764, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 4.57 times less likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 0}, {\"comparison_name\": \"surname\", \"sql_condition\": \"surname_l = surname_r\", \"label_for_charts\": \"exact_match\", \"m_probability\": 0.4517645215191846, \"u_probability\": 0.004889975550122249, \"m_probability_description\": \"Amongst matching record comparisons, 45.18% of records are in the exact_match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.49% of records are in the exact_match comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"surname\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 92.38584465067325, \"log2_bayes_factor\": 6.529599913880287, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `exact_match` then comparison is 92.39 times more likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"levenshtein(surname_l, surname_r) <= 2\", \"label_for_charts\": \"Levenstein <= 2\", \"m_probability\": 0.3078165102205689, \"u_probability\": 0.007373772654946249, \"m_probability_description\": \"Amongst matching record comparisons, 30.78% of records are in the levenstein <= 2 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.74% of records are in the levenstein <= 2 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 41.74477904659683, \"log2_bayes_factor\": 5.383523868172574, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `levenstein <= 2` then comparison is 41.74 times more likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.24041896826024636, \"u_probability\": 0.9877362517949315, \"m_probability_description\": \"Amongst matching record comparisons, 24.04% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 98.77% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.24340401379756268, \"log2_bayes_factor\": -2.03857513621085, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 4.11 times less likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 1}, {\"comparison_name\": \"dob\", \"sql_condition\": \"dob_l = dob_r\", \"label_for_charts\": \"exact_match\", \"m_probability\": 0.405530771330678, \"u_probability\": 0.0017477477477477479, \"m_probability_description\": \"Amongst matching record comparisons, 40.55% of records are in the exact_match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.17% of records are in the exact_match comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"dob\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 232.03049287476935, \"log2_bayes_factor\": 7.858170603008739, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `exact_match` then comparison is 232.03 times more likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 2}, {\"comparison_name\": \"dob\", \"sql_condition\": \"levenshtein(dob_l, dob_r) <= 2\", \"label_for_charts\": \"Levenstein <= 2\", \"m_probability\": 0.3679356056637918, \"u_probability\": 0.01711911911911912, \"m_probability_description\": \"Amongst matching record comparisons, 36.79% of records are in the levenstein <= 2 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 1.71% of records are in the levenstein <= 2 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 21.492671620753597, \"log2_bayes_factor\": 4.425772921275592, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `levenstein <= 2` then comparison is 21.49 times more likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 2}, {\"comparison_name\": \"dob\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22653362300553073, \"u_probability\": 0.9811331331331331, \"m_probability_description\": \"Amongst matching record comparisons, 22.65% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 98.11% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.23088978993311773, \"log2_bayes_factor\": -2.114723717091652, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 4.33 times less likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 2}, {\"comparison_name\": \"city\", \"sql_condition\": \"city_l = city_r\", \"label_for_charts\": \"exact_match\", \"m_probability\": 0.5782144900964232, \"u_probability\": 0.0551475711801453, \"m_probability_description\": \"Amongst matching record comparisons, 57.82% of records are in the exact_match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 5.51% of records are in the exact_match comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"city\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 10.484858675056154, \"log2_bayes_factor\": 3.3902355104306197, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact_match` then comparison is 10.48 times more likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 3}, {\"comparison_name\": \"city\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.4217855099035769, \"u_probability\": 0.9448524288198547, \"m_probability_description\": \"Amongst matching record comparisons, 42.18% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 94.49% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.4464035832880252, \"log2_bayes_factor\": -1.1635794871398053, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 2.24 times less likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 3}, {\"comparison_name\": \"email\", \"sql_condition\": \"email_l = email_r\", \"label_for_charts\": \"exact_match\", \"m_probability\": 0.5774909200578013, \"u_probability\": 0.0021938713143283602, \"m_probability_description\": \"Amongst matching record comparisons, 57.75% of records are in the exact_match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.22% of records are in the exact_match comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"email\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 263.2291676754963, \"log2_bayes_factor\": 8.04017554864013, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact_match` then comparison is 263.23 times more likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 4}, {\"comparison_name\": \"email\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.42250907994219916, \"u_probability\": 0.9978061286856716, \"m_probability_description\": \"Amongst matching record comparisons, 42.25% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 99.78% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.4234380485302649, \"log2_bayes_factor\": -1.239777184635766, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 2.36 times less likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 4}]}, \"vconcat\": [{\"height\": 30, \"mark\": {\"type\": \"bar\", \"clip\": true, \"height\": 20}, \"selection\": {\"zoom_selector\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\"]}}, \"transform\": [{\"filter\": \"(datum.comparison_name == 'probability_two_random_records_match')\"}], \"encoding\": {\"color\": {\"type\": \"quantitative\", \"field\": \"log2_bayes_factor\", \"title\": \"Match weight\", \"scale\": {\"range\": [\"red\", \"orange\", \"green\"], \"domain\": [-10, 0, 10]}}, \"tooltip\": [{\"type\": \"nominal\", \"field\": \"comparison_name\", \"title\": \"Comparison name\"}, {\"type\": \"nominal\", \"field\": \"probability_two_random_records_match\", \"format\": \".4f\", \"title\": \"Probability two random records match\"}, {\"type\": \"quantitative\", \"field\": \"log2_bayes_factor\", \"title\": \"Equivalent match weight\", \"format\": \",.4f\"}, {\"type\": \"nominal\", \"field\": \"bayes_factor_description\", \"title\": \"Match weight description\"}], \"x\": {\"type\": \"quantitative\", \"axis\": {\"labels\": false, \"domain\": false, \"title\": \"\", \"ticks\": false}, \"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 10]}}, \"y\": {\"type\": \"nominal\", \"field\": \"label_for_charts\", \"axis\": {\"title\": \"Prior (starting) match weight\", \"titleAngle\": 0, \"titleAlign\": \"right\", \"titleFontWeight\": \"normal\"}, \"sort\": {\"field\": \"comparison_vector_value\", \"order\": \"descending\"}}}}, {\"mark\": {\"type\": \"bar\", \"clip\": true}, \"selection\": {\"zoom_selector\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\"]}}, \"transform\": [{\"filter\": \"(datum.comparison_name != 'probability_two_random_records_match')\"}], \"encoding\": {\"color\": {\"type\": \"quantitative\", \"field\": \"log2_bayes_factor\", \"title\": \"Match weight\", \"scale\": {\"range\": [\"red\", \"orange\", \"green\"], \"domain\": [-10, 0, 10]}}, \"row\": {\"type\": \"nominal\", \"field\": \"comparison_name\", \"sort\": {\"field\": \"comparison_sort_order\"}, \"header\": {\"labelAngle\": 0, \"labelAnchor\": \"middle\", \"labelAlign\": \"left\"}}, \"tooltip\": [{\"type\": \"nominal\", \"field\": \"comparison_name\", \"title\": \"Comparison name\"}, {\"type\": \"ordinal\", \"field\": \"label_for_charts\", \"title\": \"Label\"}, {\"type\": \"nominal\", \"field\": \"sql_condition\", \"title\": \"SQL condition\"}, {\"type\": \"quantitative\", \"field\": \"m_probability\", \"format\": \".4f\", \"title\": \"M probability\"}, {\"type\": \"quantitative\", \"field\": \"u_probability\", \"format\": \".4f\", \"title\": \"U probability\"}, {\"type\": \"quantitative\", \"field\": \"bayes_factor\", \"title\": \"Bayes factor = m/u\", \"format\": \",.4f\"}, {\"type\": \"quantitative\", \"field\": \"log2_bayes_factor\", \"title\": \"Match weight = log2(m/u)\", \"format\": \",.4f\"}, {\"type\": \"nominal\", \"field\": \"bayes_factor_description\", \"title\": \"Match weight description\"}], \"x\": {\"type\": \"quantitative\", \"axis\": {\"title\": \"Comparison level match weight = log2(m/u)\"}, \"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 10]}}, \"y\": {\"type\": \"nominal\", \"field\": \"label_for_charts\", \"axis\": {\"title\": null}, \"sort\": {\"field\": \"comparison_vector_value\", \"order\": \"descending\"}}}, \"resolve\": {\"axis\": {\"y\": \"independent\"}, \"scale\": {\"y\": \"independent\"}}}], \"selection\": {\"zoom_selector\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\"]}}, \"resolve\": {\"axis\": {\"y\": \"independent\"}, \"scale\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Model parameters (components of final match weight)\", \"subtitle\": \"Use mousewheel to zoom\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.2.json\"}, {\"mode\": \"vega-lite\"});","title":"real time record linkage"},{"location":"demos/real_time_record_linkage.html#exploring-linkage-models-using-real-time-linkage","text":"In this notebook, we demonstrate splink's incremental and real time linkage capabilities - specifically: - the linker.compare_two_records function, that allows you to interactively explore the results of a linkage model; and - the linker.find_matches_to_new_records that allows you to incrementally find matches to a small number of new records","title":"Exploring linkage models using real time linkage"},{"location":"demos/real_time_record_linkage.html#step-1-load-a-pre-trained-linkage-model","text":"import sys sys . path . insert ( 0 , '/Users/robinlinacre/Documents/data_linking/splink/' ) import pandas as pd import json from splink.duckdb.duckdb_linker import DuckDBLinker with open ( \"demo_settings/real_time_settings.json\" ) as f : trained_settings = json . load ( f ) df = pd . read_csv ( \"./data/fake_1000.csv\" ) linker = DuckDBLinker ( df , trained_settings ) linker . _initialise_df_concat_with_tf () linker . compute_tf_table ( \"first_name\" ) linker . compute_tf_table ( \"surname\" ) linker . compute_tf_table ( \"dob\" ) linker . compute_tf_table ( \"city\" ) t = linker . compute_tf_table ( \"email\" ) linker . waterfall_chart ( linker . predict () . as_record_dict ( limit = 2 )) var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG; (function(spec, embedOpt){ let outputDiv = document.currentScript.previousElementSibling; if (outputDiv.id !== \"altair-viz-80d1108ba74643f4864bb0710ebb7335\") { outputDiv = document.getElementById(\"altair-viz-80d1108ba74643f4864bb0710ebb7335\"); } const paths = { \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\", \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\", \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\", \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\", }; function maybeLoadScript(lib, version) { var key = `${lib.replace(\"-\", \"\")}_version`; return (VEGA_DEBUG[key] == version) ? Promise.resolve(paths[lib]) : new Promise(function(resolve, reject) { var s = document.createElement('script'); document.getElementsByTagName(\"head\")[0].appendChild(s); s.async = true; s.onload = () => { VEGA_DEBUG[key] = version; return resolve(paths[lib]); }; s.onerror = () => reject(`Error loading script: ${paths[lib]}`); s.src = paths[lib]; }); } function showError(err) { outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`; throw err; } function displayChart(vegaEmbed) { vegaEmbed(outputDiv, spec, embedOpt) .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`)); } if(typeof define === \"function\" && define.amd) { requirejs.config({paths}); require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`)); } else { maybeLoadScript(\"vega\", \"5\") .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\")) .then(() => maybeLoadScript(\"vega-embed\", \"6\")) .catch(showError) .then(() => displayChart(vegaEmbed)); } })({\"$schema\": \"https://vega.github.io/schema/vega-lite/v5.2.0.json\", \"height\": 450, \"resolve\": {\"axis\": {\"y\": \"independent\"}}, \"width\": {\"step\": 75}, \"data\": {\"values\": [{\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -5.391889789559854, \"bayes_factor\": 0.023816582302252427, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 0}, {\"column_name\": \"first_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.1925340745596764, \"bayes_factor\": 0.21876683164040506, \"comparison_vector_value\": 0, \"m_probability\": 0.21528549148688833, \"u_probability\": 0.9840865266118626, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 4.57 times less likely to be a match\", \"value_l\": \"Oliver\", \"value_r\": \"Alfie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 0}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.21528549148688833, \"u_probability\": 0.9840865266118626, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 4.57 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 0}, {\"column_name\": \"surname\", \"label_for_charts\": \"exact_match\", \"sql_condition\": \"surname_l = surname_r\", \"log2_bayes_factor\": 6.529599913880287, \"bayes_factor\": 92.38584465067325, \"comparison_vector_value\": 2, \"m_probability\": 0.4517645215191846, \"u_probability\": 0.004889975550122249, \"bayes_factor_description\": \"If comparison level is `exact_match` then comparison is 92.39 times more likely to be a match\", \"value_l\": \"Griffiths\", \"value_r\": \"Griffiths\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 0}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"surname_l = surname_r\", \"log2_bayes_factor\": 0.4168001079781037, \"bayes_factor\": 1.3349633251833741, \"comparison_vector_value\": 2, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.33 times more likely to be a match\", \"value_l\": \"Griffiths\", \"value_r\": \"Griffiths\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 0}, {\"column_name\": \"dob\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.114723717091652, \"bayes_factor\": 0.23088978993311773, \"comparison_vector_value\": 0, \"m_probability\": 0.22653362300553073, \"u_probability\": 0.9811331331331331, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 4.33 times less likely to be a match\", \"value_l\": \"1991-10-26\", \"value_r\": \"2008-05-07\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 0}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.22653362300553073, \"u_probability\": 0.9811331331331331, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 4.33 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 0}, {\"column_name\": \"city\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -1.1635794871398053, \"bayes_factor\": 0.4464035832880252, \"comparison_vector_value\": 0, \"m_probability\": 0.4217855099035769, \"u_probability\": 0.9448524288198547, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 2.24 times less likely to be a match\", \"value_l\": \"Lunton\", \"value_r\": \"Plymouth\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 0}, {\"column_name\": \"tf_city\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.4217855099035769, \"u_probability\": 0.9448524288198547, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 2.24 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 0}, {\"column_name\": \"email\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -1.239777184635766, \"bayes_factor\": 0.4234380485302649, \"comparison_vector_value\": 0, \"m_probability\": 0.42250907994219916, \"u_probability\": 0.9978061286856716, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 2.36 times less likely to be a match\", \"value_l\": \"o.griffiths90@reyes-coleman.com\", \"value_r\": \"a.griffiths@garner-bridges.com\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 0}, {\"column_name\": \"tf_email\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.42250907994219916, \"u_probability\": 0.9978061286856716, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 2.36 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 0}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -5.156104231128363, \"bayes_factor\": 0.028045162816898225, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 0}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -5.391889789559854, \"bayes_factor\": 0.023816582302252427, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 1}, {\"column_name\": \"first_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.1925340745596764, \"bayes_factor\": 0.21876683164040506, \"comparison_vector_value\": 0, \"m_probability\": 0.21528549148688833, \"u_probability\": 0.9840865266118626, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 4.57 times less likely to be a match\", \"value_l\": \"Rowe\", \"value_r\": \"Scott\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 1}, {\"column_name\": \"tf_first_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.21528549148688833, \"u_probability\": 0.9840865266118626, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 4.57 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 1}, {\"column_name\": \"surname\", \"label_for_charts\": \"exact_match\", \"sql_condition\": \"surname_l = surname_r\", \"log2_bayes_factor\": 6.529599913880287, \"bayes_factor\": 92.38584465067325, \"comparison_vector_value\": 2, \"m_probability\": 0.4517645215191846, \"u_probability\": 0.004889975550122249, \"bayes_factor_description\": \"If comparison level is `exact_match` then comparison is 92.39 times more likely to be a match\", \"value_l\": \"Caleb\", \"value_r\": \"Caleb\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 1}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"surname_l = surname_r\", \"log2_bayes_factor\": 0.4168001079781037, \"bayes_factor\": 1.3349633251833741, \"comparison_vector_value\": 2, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.33 times more likely to be a match\", \"value_l\": \"Caleb\", \"value_r\": \"Caleb\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 1}, {\"column_name\": \"dob\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.114723717091652, \"bayes_factor\": 0.23088978993311773, \"comparison_vector_value\": 0, \"m_probability\": 0.22653362300553073, \"u_probability\": 0.9811331331331331, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 4.33 times less likely to be a match\", \"value_l\": \"1992-12-20\", \"value_r\": \"1990-12-11\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 1}, {\"column_name\": \"tf_dob\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.22653362300553073, \"u_probability\": 0.9811331331331331, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 4.33 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 6, \"record_number\": 1}, {\"column_name\": \"city\", \"label_for_charts\": \"Null\", \"sql_condition\": \"city_l IS NULL OR city_r IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"Lvpreool\", \"value_r\": \"nan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 1}, {\"column_name\": \"tf_city\", \"label_for_charts\": \"Null\", \"sql_condition\": \"city_l IS NULL OR city_r IS NULL\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 1}, {\"column_name\": \"email\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -1.239777184635766, \"bayes_factor\": 0.4234380485302649, \"comparison_vector_value\": 0, \"m_probability\": 0.42250907994219916, \"u_probability\": 0.9978061286856716, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 2.36 times less likely to be a match\", \"value_l\": \"calebr@thompson.org\", \"value_r\": \"c.scott@brooks.com\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 1}, {\"column_name\": \"tf_email\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.42250907994219916, \"u_probability\": 0.9978061286856716, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 2.36 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 1}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -3.9925247439885574, \"bayes_factor\": 0.06282468122305176, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 1}]}, \"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"params\": [{\"name\": \"record_number\", \"value\": 0, \"bind\": {\"input\": \"range\", \"min\": 0, \"max\": 1, \"step\": 1}, \"description\": \"Filter by the interation number\"}], \"title\": {\"text\": \"Match weights waterfall chart\", \"subtitle\": \"How each comparison contributes to the final match score\"}, \"transform\": [{\"filter\": \"(datum.record_number == record_number)\"}, {\"filter\": \"(datum.bayes_factor !== 1.0)\"}, {\"window\": [{\"op\": \"sum\", \"field\": \"log2_bayes_factor\", \"as\": \"sum\"}, {\"op\": \"lead\", \"field\": \"column_name\", \"as\": \"lead\"}], \"frame\": [null, 0]}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" ? datum.sum - datum.log2_bayes_factor : datum.sum\", \"as\": \"sum\"}, {\"calculate\": \"datum.lead === null ? datum.column_name : datum.lead\", \"as\": \"lead\"}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" || datum.column_name === \\\"Prior match weight\\\" ? 0 : datum.sum - datum.log2_bayes_factor\", \"as\": \"previous_sum\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"top_label\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"bottom_label\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_top\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_bottom\"}, {\"calculate\": \"(datum.sum + datum.previous_sum) / 2\", \"as\": \"center\"}, {\"calculate\": \"(datum.log2_bayes_factor > 0 ? \\\"+\\\" : \\\"\\\") + datum.log2_bayes_factor\", \"as\": \"text_log2_bayes_factor\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? 4 : -4\", \"as\": \"dy\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? \\\"top\\\" : \\\"bottom\\\"\", \"as\": \"baseline\"}, {\"calculate\": \"1. / (1 + pow(2, -1.*datum.sum))\", \"as\": \"prob\"}, {\"calculate\": \"0*datum.sum\", \"as\": \"zero\"}], \"layer\": [{\"layer\": [{\"mark\": \"rule\", \"encoding\": {\"y\": {\"field\": \"zero\", \"type\": \"quantitative\"}, \"size\": {\"value\": 0.5}, \"color\": {\"value\": \"black\"}}}, {\"mark\": {\"type\": \"bar\", \"width\": 60}, \"encoding\": {\"color\": {\"condition\": {\"value\": \"red\", \"test\": \"(datum.log2_bayes_factor < 0)\"}, \"value\": \"green\"}, \"opacity\": {\"condition\": {\"value\": 1, \"test\": \"datum.column_name == 'Prior match weight' || datum.column_name == 'Final score'\"}, \"value\": 0.5}, \"tooltip\": [{\"type\": \"nominal\", \"field\": \"column_name\", \"title\": \"Comparison column\"}, {\"type\": \"nominal\", \"field\": \"value_l\", \"title\": \"Value (L)\"}, {\"type\": \"nominal\", \"field\": \"value_r\", \"title\": \"Value (R)\"}, {\"type\": \"ordinal\", \"field\": \"label_for_charts\", \"title\": \"Label\"}, {\"type\": \"nominal\", \"field\": \"sql_condition\", \"title\": \"SQL condition\"}, {\"type\": \"nominal\", \"field\": \"comparison_vector_value\", \"title\": \"Comparison vector value\"}, {\"type\": \"quantitative\", \"field\": \"bayes_factor\", \"title\": \"Bayes factor = m/u\", \"format\": \",.4f\"}, {\"type\": \"quantitative\", \"field\": \"log2_bayes_factor\", \"title\": \"Match weight = log2(m/u)\", \"format\": \",.4f\"}, {\"type\": \"quantitative\", \"field\": \"prob\", \"format\": \".4f\", \"title\": \"Adjusted match score\"}, {\"type\": \"nominal\", \"field\": \"bayes_factor_description\", \"title\": \"Match weight description\"}], \"x\": {\"type\": \"nominal\", \"axis\": {\"labelExpr\": \"datum.value == 'Prior' || datum.value == 'Final score' ? '' : datum.value\", \"labelAngle\": -20, \"labelAlign\": \"center\", \"labelPadding\": 10, \"title\": \"Column\", \"grid\": true, \"tickBand\": \"extent\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}}, \"y\": {\"type\": \"quantitative\", \"axis\": {\"grid\": false, \"orient\": \"left\", \"title\": \"log2(Bayes factor)\"}, \"field\": \"previous_sum\"}, \"y2\": {\"field\": \"sum\"}}}, {\"mark\": {\"type\": \"text\", \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"white\"}, \"text\": {\"condition\": {\"type\": \"nominal\", \"field\": \"log2_bayes_factor\", \"format\": \".2f\", \"test\": \"abs(datum.log2_bayes_factor) > 1\"}, \"value\": \"\"}, \"x\": {\"type\": \"nominal\", \"axis\": {\"labelAngle\": 0, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}}, \"y\": {\"type\": \"quantitative\", \"axis\": {\"orient\": \"left\"}, \"field\": \"center\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -25, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"type\": \"nominal\", \"field\": \"column_name\"}, \"x\": {\"type\": \"nominal\", \"axis\": {\"labelAngle\": 0, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}}, \"y\": {\"type\": \"quantitative\", \"field\": \"sum_top\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"fontSize\": 8, \"dy\": -13}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"type\": \"nominal\", \"field\": \"value_l\"}, \"x\": {\"type\": \"nominal\", \"axis\": {\"labelAngle\": 0, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}}, \"y\": {\"type\": \"quantitative\", \"field\": \"sum_top\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"fontSize\": 8, \"dy\": -5}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"type\": \"nominal\", \"field\": \"value_r\"}, \"x\": {\"type\": \"nominal\", \"axis\": {\"labelAngle\": 0, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}}, \"y\": {\"type\": \"quantitative\", \"field\": \"sum_top\"}}}]}, {\"mark\": {\"type\": \"rule\", \"color\": \"black\", \"strokeWidth\": 2, \"x2Offset\": 30, \"xOffset\": -30}, \"encoding\": {\"x\": {\"type\": \"nominal\", \"axis\": {\"labelAngle\": 0, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}}, \"x2\": {\"field\": \"lead\"}, \"y\": {\"type\": \"quantitative\", \"axis\": {\"labelExpr\": \"format(1 / (1 + pow(2, -1*datum.value)), '.2r')\", \"orient\": \"right\", \"title\": \"Probability\"}, \"field\": \"sum\", \"scale\": {\"zero\": false}}}}]}, {\"mode\": \"vega-lite\"});","title":"Step 1: Load a pre-trained linkage model"},{"location":"demos/real_time_record_linkage.html#step-comparing-two-records","text":"It's now possible to compute a match weight for any two records using linker.compare_two_records() record_1 = { 'unique_id' : 1 , 'first_name' : \"Lucas\" , 'surname' : \"Smith\" , 'dob' : \"1984-01-02\" , 'city' : \"London\" , 'email' : \"lucas.smith@hotmail.com\" } record_2 = { 'unique_id' : 2 , 'first_name' : \"Lucas\" , 'surname' : \"Smith\" , 'dob' : \"1983-02-12\" , 'city' : \"Machester\" , 'email' : \"lucas.smith@hotmail.com\" } linker . _settings_obj_ . _retain_intermediate_calculation_columns = True linker . _settings_obj_ . _retain_matching_columns = True df_two = linker . compare_two_records ( record_1 , record_2 ) df_two . as_pandas_dataframe () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } match_weight match_probability unique_id_l unique_id_r first_name_l first_name_r gamma_first_name bf_first_name bf_tf_adj_first_name tf_first_name_l ... bf_tf_adj_city tf_city_l tf_city_r email_l email_r gamma_email bf_email bf_tf_adj_email tf_email_l tf_email_r 0 13.161672 0.999891 1 2 Lucas Lucas 2 87.571229 4.814458 0.001203 ... 1.0 0.212792 NaN lucas.smith@hotmail.com lucas.smith@hotmail.com 1 263.229168 1.0 NaN NaN 1 rows \u00d7 39 columns","title":"Step  Comparing two records"},{"location":"demos/real_time_record_linkage.html#step-3-interactive-comparisons","text":"One interesting applicatin of compare_two_records is to create a simple interface that allows the user to input two records interactively, and get real time feedback. In the following cell we use ipywidets for this purpose. \u2728\u2728 Change the values in the text boxes to see the waterfall chart update in real time. \u2728\u2728 import ipywidgets as widgets fields = [ \"unique_id\" , \"first_name\" , \"surname\" , \"dob\" , \"email\" , \"city\" ] left_text_boxes = [] right_text_boxes = [] inputs_to_interactive_output = {} for f in fields : wl = widgets . Text ( description = f , value = str ( record_1 [ f ])) left_text_boxes . append ( wl ) inputs_to_interactive_output [ f \" { f } _l\" ] = wl wr = widgets . Text ( description = f , value = str ( record_2 [ f ])) right_text_boxes . append ( wr ) inputs_to_interactive_output [ f \" { f } _r\" ] = wr b1 = widgets . VBox ( left_text_boxes ) b2 = widgets . VBox ( right_text_boxes ) ui = widgets . HBox ([ b1 , b2 ]) def myfn ( ** kwargs ): my_args = dict ( kwargs ) record_left = {} record_right = {} for key , value in my_args . items (): if value == '' : value = None if key . endswith ( \"_l\" ): record_left [ key [: - 2 ]] = value if key . endswith ( \"_r\" ): record_right [ key [: - 2 ]] = value linker . _settings_obj_ . _retain_intermediate_calculation_columns = True linker . _settings_obj_ . _retain_matching_columns = True df_two = linker . compare_two_records ( record_left , record_right ) recs = df_two . as_pandas_dataframe () . to_dict ( orient = \"records\" ) from splink.charts import waterfall_chart display ( linker . waterfall_chart ( recs , filter_nulls = False )) out = widgets . interactive_output ( myfn , inputs_to_interactive_output ) display ( ui , out ) HBox(children=(VBox(children=(Text(value='1', description='unique_id'), Text(value='Lucas', description='first\u2026 Output()","title":"Step 3: Interactive comparisons"},{"location":"demos/real_time_record_linkage.html#finding-matching-records-interactively","text":"It is also possible to search the records in the input dataset rapidly using the linker.find_matches_to_new_records() function record = { 'unique_id' : 123987 , 'first_name' : \"Robert\" , 'surname' : \"Alan\" , 'dob' : \"1971-05-24\" , 'city' : \"London\" , 'email' : \"robert255@smith.net\" } df_inc = linker . find_matches_to_new_records ([ record ], blocking_rules = []) . as_pandas_dataframe () df_inc . sort_values ( \"match_weight\" , ascending = False ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } match_weight match_probability unique_id_l unique_id_r first_name_l first_name_r gamma_first_name bf_first_name bf_tf_adj_first_name tf_first_name_l ... bf_tf_adj_city tf_city_l tf_city_r email_l email_r gamma_email bf_email bf_tf_adj_email tf_email_l tf_email_r 1 23.531793 1.000000 0 123987 Robert Robert 2 87.571229 1.604819 0.003610 ... 1.000000 NaN 0.212792 robert255@smith.net robert255@smith.net 1 263.229168 1.730964 0.001267 0.001267 2 14.550320 0.999958 1 123987 Robert Robert 2 87.571229 1.604819 0.003610 ... 1.000000 NaN 0.212792 roberta25@smith.net robert255@smith.net 0 0.423438 1.000000 0.002535 0.001267 4 10.388623 0.999255 3 123987 Robert Robert 2 87.571229 1.604819 0.003610 ... 1.000000 0.007380 0.212792 NaN robert255@smith.net -1 1.000000 1.000000 NaN 0.001267 0 2.427256 0.843228 2 123987 Rob Robert 0 0.218767 1.000000 0.001203 ... 0.259162 0.212792 0.212792 roberta25@smith.net robert255@smith.net 0 0.423438 1.000000 0.002535 0.001267 6 -2.123090 0.186697 8 123987 NaN Robert -1 1.000000 1.000000 NaN ... 1.000000 NaN 0.212792 NaN robert255@smith.net -1 1.000000 1.000000 NaN 0.001267 5 -2.205894 0.178139 754 123987 NaN Robert -1 1.000000 1.000000 NaN ... 1.000000 NaN 0.212792 j.c@whige.wort robert255@smith.net 0 0.423438 1.000000 0.001267 0.001267 3 -2.802309 0.125383 750 123987 NaN Robert -1 1.000000 1.000000 NaN ... 0.259162 0.212792 0.212792 j.c@white.org robert255@smith.net 0 0.423438 1.000000 0.002535 0.001267 7 rows \u00d7 39 columns","title":"Finding matching records interactively"},{"location":"demos/real_time_record_linkage.html#interactive-interface-for-finding-records","text":"Again, we can use ipywidgets to build an interactive interface for the linker.find_matches_to_new_records function from splink.charts import waterfall_chart @widgets . interact ( first_name = 'Robert' , surname = \"Alan\" , dob = \"1971-05-24\" , city = \"London\" , email = \"robert255@smith.net\" ) def interactive_link ( first_name , surname , dob , city , email ): record = { 'unique_id' : 123987 , 'first_name' : first_name , 'surname' : surname , 'dob' : dob , 'city' : city , 'email' : email , 'group' : 0 } for key in record . keys (): if type ( record [ key ]) == str : if record [ key ] . strip () == \"\" : record [ key ] = None df_inc = linker . find_matches_to_new_records ([ record ], blocking_rules = [ f \"(true)\" ]) . as_pandas_dataframe () df_inc = df_inc . sort_values ( \"match_weight\" , ascending = False ) recs = df_inc . to_dict ( orient = \"records\" ) display ( linker . waterfall_chart ( recs , filter_nulls = False )) interactive(children=(Text(value='Robert', description='first_name'), Text(value='Alan', description='surname'\u2026 linker . match_weights_chart () var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG; (function(spec, embedOpt){ let outputDiv = document.currentScript.previousElementSibling; if (outputDiv.id !== \"altair-viz-4663e99319364be8854b4bc5d4c58cbf\") { outputDiv = document.getElementById(\"altair-viz-4663e99319364be8854b4bc5d4c58cbf\"); } const paths = { \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\", \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\", \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\", \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\", }; function maybeLoadScript(lib, version) { var key = `${lib.replace(\"-\", \"\")}_version`; return (VEGA_DEBUG[key] == version) ? Promise.resolve(paths[lib]) : new Promise(function(resolve, reject) { var s = document.createElement('script'); document.getElementsByTagName(\"head\")[0].appendChild(s); s.async = true; s.onload = () => { VEGA_DEBUG[key] = version; return resolve(paths[lib]); }; s.onerror = () => reject(`Error loading script: ${paths[lib]}`); s.src = paths[lib]; }); } function showError(err) { outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`; throw err; } function displayChart(vegaEmbed) { vegaEmbed(outputDiv, spec, embedOpt) .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`)); } if(typeof define === \"function\" && define.amd) { requirejs.config({paths}); require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`)); } else { maybeLoadScript(\"vega\", \"5\") .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\")) .then(() => maybeLoadScript(\"vega-embed\", \"6\")) .catch(showError) .then(() => displayChart(vegaEmbed)); } })({\"config\": {\"view\": {\"width\": 400, \"height\": 60}, \"mark\": {\"tooltip\": null}, \"title\": {\"anchor\": \"middle\"}, \"header\": {\"title\": null}}, \"data\": {\"values\": [{\"comparison_name\": \"probability_two_random_records_match\", \"sql_condition\": null, \"label_for_charts\": \"\", \"m_probability\": null, \"u_probability\": null, \"m_probability_description\": null, \"u_probability_description\": null, \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": null, \"is_null_level\": false, \"bayes_factor\": 0.023816582302252427, \"log2_bayes_factor\": -5.391889789559854, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 0, \"bayes_factor_description\": \"The probability that two random records drawn at random match is 0.023 or one in 43.0 records.This is equivalent to a starting match weight of -5.392.\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": -1}, {\"comparison_name\": \"first_name\", \"sql_condition\": \"first_name_l = first_name_r\", \"label_for_charts\": \"exact_match\", \"m_probability\": 0.5073501669215337, \"u_probability\": 0.0057935713975033705, \"m_probability_description\": \"Amongst matching record comparisons, 50.74% of records are in the exact_match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.58% of records are in the exact_match comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"first_name\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 87.57122888658395, \"log2_bayes_factor\": 6.452385051922501, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `exact_match` then comparison is 87.57 times more likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 0}, {\"comparison_name\": \"first_name\", \"sql_condition\": \"levenshtein(first_name_l, first_name_r) <= 2\", \"label_for_charts\": \"Levenstein <= 2\", \"m_probability\": 0.27736434159157797, \"u_probability\": 0.010119901990634016, \"m_probability_description\": \"Amongst matching record comparisons, 27.74% of records are in the levenstein <= 2 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 1.01% of records are in the levenstein <= 2 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 27.407809072486973, \"log2_bayes_factor\": 4.776515101395072, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `levenstein <= 2` then comparison is 27.41 times more likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 0}, {\"comparison_name\": \"first_name\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.21528549148688833, \"u_probability\": 0.9840865266118626, \"m_probability_description\": \"Amongst matching record comparisons, 21.53% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 98.41% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.21876683164040506, \"log2_bayes_factor\": -2.1925340745596764, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 4.57 times less likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 0}, {\"comparison_name\": \"surname\", \"sql_condition\": \"surname_l = surname_r\", \"label_for_charts\": \"exact_match\", \"m_probability\": 0.4517645215191846, \"u_probability\": 0.004889975550122249, \"m_probability_description\": \"Amongst matching record comparisons, 45.18% of records are in the exact_match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.49% of records are in the exact_match comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"surname\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 92.38584465067325, \"log2_bayes_factor\": 6.529599913880287, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `exact_match` then comparison is 92.39 times more likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"levenshtein(surname_l, surname_r) <= 2\", \"label_for_charts\": \"Levenstein <= 2\", \"m_probability\": 0.3078165102205689, \"u_probability\": 0.007373772654946249, \"m_probability_description\": \"Amongst matching record comparisons, 30.78% of records are in the levenstein <= 2 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.74% of records are in the levenstein <= 2 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 41.74477904659683, \"log2_bayes_factor\": 5.383523868172574, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `levenstein <= 2` then comparison is 41.74 times more likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.24041896826024636, \"u_probability\": 0.9877362517949315, \"m_probability_description\": \"Amongst matching record comparisons, 24.04% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 98.77% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.24340401379756268, \"log2_bayes_factor\": -2.03857513621085, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 4.11 times less likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 1}, {\"comparison_name\": \"dob\", \"sql_condition\": \"dob_l = dob_r\", \"label_for_charts\": \"exact_match\", \"m_probability\": 0.405530771330678, \"u_probability\": 0.0017477477477477479, \"m_probability_description\": \"Amongst matching record comparisons, 40.55% of records are in the exact_match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.17% of records are in the exact_match comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"dob\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 232.03049287476935, \"log2_bayes_factor\": 7.858170603008739, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `exact_match` then comparison is 232.03 times more likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 2}, {\"comparison_name\": \"dob\", \"sql_condition\": \"levenshtein(dob_l, dob_r) <= 2\", \"label_for_charts\": \"Levenstein <= 2\", \"m_probability\": 0.3679356056637918, \"u_probability\": 0.01711911911911912, \"m_probability_description\": \"Amongst matching record comparisons, 36.79% of records are in the levenstein <= 2 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 1.71% of records are in the levenstein <= 2 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 21.492671620753597, \"log2_bayes_factor\": 4.425772921275592, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `levenstein <= 2` then comparison is 21.49 times more likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 2}, {\"comparison_name\": \"dob\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22653362300553073, \"u_probability\": 0.9811331331331331, \"m_probability_description\": \"Amongst matching record comparisons, 22.65% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 98.11% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.23088978993311773, \"log2_bayes_factor\": -2.114723717091652, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 4.33 times less likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 2}, {\"comparison_name\": \"city\", \"sql_condition\": \"city_l = city_r\", \"label_for_charts\": \"exact_match\", \"m_probability\": 0.5782144900964232, \"u_probability\": 0.0551475711801453, \"m_probability_description\": \"Amongst matching record comparisons, 57.82% of records are in the exact_match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 5.51% of records are in the exact_match comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"city\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 10.484858675056154, \"log2_bayes_factor\": 3.3902355104306197, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact_match` then comparison is 10.48 times more likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 3}, {\"comparison_name\": \"city\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.4217855099035769, \"u_probability\": 0.9448524288198547, \"m_probability_description\": \"Amongst matching record comparisons, 42.18% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 94.49% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.4464035832880252, \"log2_bayes_factor\": -1.1635794871398053, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 2.24 times less likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 3}, {\"comparison_name\": \"email\", \"sql_condition\": \"email_l = email_r\", \"label_for_charts\": \"exact_match\", \"m_probability\": 0.5774909200578013, \"u_probability\": 0.0021938713143283602, \"m_probability_description\": \"Amongst matching record comparisons, 57.75% of records are in the exact_match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.22% of records are in the exact_match comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"email\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 263.2291676754963, \"log2_bayes_factor\": 8.04017554864013, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact_match` then comparison is 263.23 times more likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 4}, {\"comparison_name\": \"email\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.42250907994219916, \"u_probability\": 0.9978061286856716, \"m_probability_description\": \"Amongst matching record comparisons, 42.25% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 99.78% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.4234380485302649, \"log2_bayes_factor\": -1.239777184635766, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is 2.36 times less likely to be a match\", \"probability_two_random_records_match\": 0.02326254791526835, \"comparison_sort_order\": 4}]}, \"vconcat\": [{\"height\": 30, \"mark\": {\"type\": \"bar\", \"clip\": true, \"height\": 20}, \"selection\": {\"zoom_selector\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\"]}}, \"transform\": [{\"filter\": \"(datum.comparison_name == 'probability_two_random_records_match')\"}], \"encoding\": {\"color\": {\"type\": \"quantitative\", \"field\": \"log2_bayes_factor\", \"title\": \"Match weight\", \"scale\": {\"range\": [\"red\", \"orange\", \"green\"], \"domain\": [-10, 0, 10]}}, \"tooltip\": [{\"type\": \"nominal\", \"field\": \"comparison_name\", \"title\": \"Comparison name\"}, {\"type\": \"nominal\", \"field\": \"probability_two_random_records_match\", \"format\": \".4f\", \"title\": \"Probability two random records match\"}, {\"type\": \"quantitative\", \"field\": \"log2_bayes_factor\", \"title\": \"Equivalent match weight\", \"format\": \",.4f\"}, {\"type\": \"nominal\", \"field\": \"bayes_factor_description\", \"title\": \"Match weight description\"}], \"x\": {\"type\": \"quantitative\", \"axis\": {\"labels\": false, \"domain\": false, \"title\": \"\", \"ticks\": false}, \"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 10]}}, \"y\": {\"type\": \"nominal\", \"field\": \"label_for_charts\", \"axis\": {\"title\": \"Prior (starting) match weight\", \"titleAngle\": 0, \"titleAlign\": \"right\", \"titleFontWeight\": \"normal\"}, \"sort\": {\"field\": \"comparison_vector_value\", \"order\": \"descending\"}}}}, {\"mark\": {\"type\": \"bar\", \"clip\": true}, \"selection\": {\"zoom_selector\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\"]}}, \"transform\": [{\"filter\": \"(datum.comparison_name != 'probability_two_random_records_match')\"}], \"encoding\": {\"color\": {\"type\": \"quantitative\", \"field\": \"log2_bayes_factor\", \"title\": \"Match weight\", \"scale\": {\"range\": [\"red\", \"orange\", \"green\"], \"domain\": [-10, 0, 10]}}, \"row\": {\"type\": \"nominal\", \"field\": \"comparison_name\", \"sort\": {\"field\": \"comparison_sort_order\"}, \"header\": {\"labelAngle\": 0, \"labelAnchor\": \"middle\", \"labelAlign\": \"left\"}}, \"tooltip\": [{\"type\": \"nominal\", \"field\": \"comparison_name\", \"title\": \"Comparison name\"}, {\"type\": \"ordinal\", \"field\": \"label_for_charts\", \"title\": \"Label\"}, {\"type\": \"nominal\", \"field\": \"sql_condition\", \"title\": \"SQL condition\"}, {\"type\": \"quantitative\", \"field\": \"m_probability\", \"format\": \".4f\", \"title\": \"M probability\"}, {\"type\": \"quantitative\", \"field\": \"u_probability\", \"format\": \".4f\", \"title\": \"U probability\"}, {\"type\": \"quantitative\", \"field\": \"bayes_factor\", \"title\": \"Bayes factor = m/u\", \"format\": \",.4f\"}, {\"type\": \"quantitative\", \"field\": \"log2_bayes_factor\", \"title\": \"Match weight = log2(m/u)\", \"format\": \",.4f\"}, {\"type\": \"nominal\", \"field\": \"bayes_factor_description\", \"title\": \"Match weight description\"}], \"x\": {\"type\": \"quantitative\", \"axis\": {\"title\": \"Comparison level match weight = log2(m/u)\"}, \"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 10]}}, \"y\": {\"type\": \"nominal\", \"field\": \"label_for_charts\", \"axis\": {\"title\": null}, \"sort\": {\"field\": \"comparison_vector_value\", \"order\": \"descending\"}}}, \"resolve\": {\"axis\": {\"y\": \"independent\"}, \"scale\": {\"y\": \"independent\"}}}], \"selection\": {\"zoom_selector\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\"]}}, \"resolve\": {\"axis\": {\"y\": \"independent\"}, \"scale\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Model parameters (components of final match weight)\", \"subtitle\": \"Use mousewheel to zoom\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.2.json\"}, {\"mode\": \"vega-lite\"});","title":"Interactive interface for finding records"},{"location":"dev_guides/caching.html","text":"Caching and pipelining \u00b6 Splink is able to run against multiple SQL backends because all of the core data linking calculations are implemented in SQL. This SQL can therefore be submitted to a chosen SQL backend for execution. Computations in Splink often take the form of a number of select statements run in sequence. For example, the predict() step: Inputs __splink__df_concat_with_tf and outputs __splink__df_blocked Inputs __splink__df_blocked and outputs __splink__df_comparison_vectors Inputs __splink__df_comparison_vectors and outputs __splink__df_match_weight_parts Inputs __splink__df_match_weight_parts and outputs __splink__df_predict To make this run faster, two key optimisations are implmented: Pipelining - combining multiple select statements into a single statemenet using WITH ( CTE ) queries Caching: saving the results of calculations so they don't need recalculating. This is especially useful because some intermediate calculations are reused multiple times during a typical Splink session This article discusses the general implementation of caching and pipelining. The implementation needs some alterations for certain backends like Spark, which lazily evaluate SQL by default. Implementation: Pipelining \u00b6 A SQLPipeline class manages SQL pipelining. A SQLPipeline is composed of a number of SQLTask objects , each of which represents a select statement. The code is fairly straightforward: Given a sequence of select statements, [a,b,c] they are combined into a single query as follows: with a as (a_sql), b as (b_sql), c_sql To make this work, each statement (a,b,c) in the pipeline must refer to the previous step by name. For example, b_sql probably selects from the a_sql table, which has been aliased a . So b_sql must use the table name a to refer to the result of a_sql . To make this tractable, each SQLTask has an output_table_name . For example, the output_table_name for a_sql in the above example is a . For instance, in the predict() pipeline above, the first output_table_name is __splink__df_blocked . By giving each task a meaningful output_table_name , subsequent tasks can reference previous outputs in a way which is semantically clear. Implementation: Caching \u00b6 When a SQL pipeline is executed, it has two output names: A physical_name , which is the name of the materialised table in the output database e.g. __splink__df_predict_cbc9833 A templated_name , which is a descriptive name of what the table represents e.g. __splink__df_predict Each time Splink runs a SQL pipeline, the SQL string is hashed . This creates a unique identifier for that particular SQL string, which serves to identify the output. When Splink is asked to execute a SQL string, before execution, it checks whether the resultant table already exists. If it does, it returns the table rather than recomputing it. For example, when we run linker.predict() , Splink: Generates the SQL tasks Pipelines them into a single SQL statement Hashes the statement to create a physical name for the outputs __splink__df_predict_cbc9833 Checks whether a table with physical name __splink__df_predict_cbc9833 alredy exists in the database If not, executes the SQL statement, creating table __splink__df_predict_cbc9833 in the database. In terms of implementation, the following happens: SQL statements are generated an put in the queue - see here Once all the tasks have been added to the queue, we call _execute_sql_pipeline() see here The SQL is combined into a single pipelined statement here We call _sql_to_splink_dataframe() which returns the table (from the cache if it already exists, or it executes the sql) The table is returned as a SplinkDataframe , an abstraction over a table in a database. See here . Some cached tables do not need a hash \u00b6 A hash is required to uniquely identify some outputs. For example, blocking is used in several places in Splink, with different results . For example, the __splink__df_blocked needed to estimate parameters is different to the __splink__df_blocked needed in the predict() step. As a result, we cannot materialise a single table called __splink__df_blocked in the database and reues it multiple times. This is why we append the hash of the SQL, so that we can uniquely identify the different versions of __splink__df_blocked which are needed in different contexts. There are, however, some tables which are globally unique. They only take a single form, and if they exist in the cache they never need recomputing. An example of this is __splink__df_concat_with_tf , which represents the concatenation of the input dataframes. To create this table, we can execute _sql_to_splink_dataframe with materialise_as_hash set to False . The resultant materialised table will not have a hash appended, and will simply be called __splink__df_concat_with_tf . This is useful, because when performing calculations Splink can now check the cache for __splink__df_concat_with_tf each time it is needed. In fact, many Splink pipelines begin with the assumption that this table exists in the database, because the first SQLTask in the pipeline refers to a table named __splink__df_concat_with_tf . To ensure this is the case, a function is used to create this table if it doesn't exist. Using pipelining to optimise Splink workloads \u00b6 At what point should a pipeline of SQLTask s be executed (materialised into a physical table)? For any individual output, it will usually be fastest to pipeline the full linage of tasks, right from raw data through to the end result. However, there are many intermediate outputs which are used by many different Splink operations. Performance can therefore be improved by computing and saving these intermediate outputs to a cache, to ensure they don't need to be computed repeatedly. This is achieved by enqueueing SQL to a pipline and strategically calling execute_sql_pipeline to materialise results that need to cached.","title":"Caching and pipelining"},{"location":"dev_guides/caching.html#caching-and-pipelining","text":"Splink is able to run against multiple SQL backends because all of the core data linking calculations are implemented in SQL. This SQL can therefore be submitted to a chosen SQL backend for execution. Computations in Splink often take the form of a number of select statements run in sequence. For example, the predict() step: Inputs __splink__df_concat_with_tf and outputs __splink__df_blocked Inputs __splink__df_blocked and outputs __splink__df_comparison_vectors Inputs __splink__df_comparison_vectors and outputs __splink__df_match_weight_parts Inputs __splink__df_match_weight_parts and outputs __splink__df_predict To make this run faster, two key optimisations are implmented: Pipelining - combining multiple select statements into a single statemenet using WITH ( CTE ) queries Caching: saving the results of calculations so they don't need recalculating. This is especially useful because some intermediate calculations are reused multiple times during a typical Splink session This article discusses the general implementation of caching and pipelining. The implementation needs some alterations for certain backends like Spark, which lazily evaluate SQL by default.","title":"Caching and pipelining"},{"location":"dev_guides/caching.html#implementation-pipelining","text":"A SQLPipeline class manages SQL pipelining. A SQLPipeline is composed of a number of SQLTask objects , each of which represents a select statement. The code is fairly straightforward: Given a sequence of select statements, [a,b,c] they are combined into a single query as follows: with a as (a_sql), b as (b_sql), c_sql To make this work, each statement (a,b,c) in the pipeline must refer to the previous step by name. For example, b_sql probably selects from the a_sql table, which has been aliased a . So b_sql must use the table name a to refer to the result of a_sql . To make this tractable, each SQLTask has an output_table_name . For example, the output_table_name for a_sql in the above example is a . For instance, in the predict() pipeline above, the first output_table_name is __splink__df_blocked . By giving each task a meaningful output_table_name , subsequent tasks can reference previous outputs in a way which is semantically clear.","title":"Implementation: Pipelining"},{"location":"dev_guides/caching.html#implementation-caching","text":"When a SQL pipeline is executed, it has two output names: A physical_name , which is the name of the materialised table in the output database e.g. __splink__df_predict_cbc9833 A templated_name , which is a descriptive name of what the table represents e.g. __splink__df_predict Each time Splink runs a SQL pipeline, the SQL string is hashed . This creates a unique identifier for that particular SQL string, which serves to identify the output. When Splink is asked to execute a SQL string, before execution, it checks whether the resultant table already exists. If it does, it returns the table rather than recomputing it. For example, when we run linker.predict() , Splink: Generates the SQL tasks Pipelines them into a single SQL statement Hashes the statement to create a physical name for the outputs __splink__df_predict_cbc9833 Checks whether a table with physical name __splink__df_predict_cbc9833 alredy exists in the database If not, executes the SQL statement, creating table __splink__df_predict_cbc9833 in the database. In terms of implementation, the following happens: SQL statements are generated an put in the queue - see here Once all the tasks have been added to the queue, we call _execute_sql_pipeline() see here The SQL is combined into a single pipelined statement here We call _sql_to_splink_dataframe() which returns the table (from the cache if it already exists, or it executes the sql) The table is returned as a SplinkDataframe , an abstraction over a table in a database. See here .","title":"Implementation: Caching"},{"location":"dev_guides/caching.html#some-cached-tables-do-not-need-a-hash","text":"A hash is required to uniquely identify some outputs. For example, blocking is used in several places in Splink, with different results . For example, the __splink__df_blocked needed to estimate parameters is different to the __splink__df_blocked needed in the predict() step. As a result, we cannot materialise a single table called __splink__df_blocked in the database and reues it multiple times. This is why we append the hash of the SQL, so that we can uniquely identify the different versions of __splink__df_blocked which are needed in different contexts. There are, however, some tables which are globally unique. They only take a single form, and if they exist in the cache they never need recomputing. An example of this is __splink__df_concat_with_tf , which represents the concatenation of the input dataframes. To create this table, we can execute _sql_to_splink_dataframe with materialise_as_hash set to False . The resultant materialised table will not have a hash appended, and will simply be called __splink__df_concat_with_tf . This is useful, because when performing calculations Splink can now check the cache for __splink__df_concat_with_tf each time it is needed. In fact, many Splink pipelines begin with the assumption that this table exists in the database, because the first SQLTask in the pipeline refers to a table named __splink__df_concat_with_tf . To ensure this is the case, a function is used to create this table if it doesn't exist.","title":"Some cached tables do not need a hash"},{"location":"dev_guides/caching.html#using-pipelining-to-optimise-splink-workloads","text":"At what point should a pipeline of SQLTask s be executed (materialised into a physical table)? For any individual output, it will usually be fastest to pipeline the full linage of tasks, right from raw data through to the end result. However, there are many intermediate outputs which are used by many different Splink operations. Performance can therefore be improved by computing and saving these intermediate outputs to a cache, to ensure they don't need to be computed repeatedly. This is achieved by enqueueing SQL to a pipline and strategically calling execute_sql_pipeline to materialise results that need to cached.","title":"Using pipelining to optimise Splink workloads"},{"location":"dev_guides/debug_modes.html","text":"Understanding and debugging Splink's computations \u00b6 Splink contains tooling to help developers understand the underlying computations, how caching and pipelining is working, and debug problems. There are two main mechanisms: debug_mode , and setting different logging levels Debug mode \u00b6 You can turn on debug mode by setting linker.debug_mode = True . This has the following effects: Each step of Splink's calculations are executed in turn. That is, pipelining is switched off. The SQL statements being executed by Splink are displayed The results of the SQL statements are displayed in tabular format This is probably the best way to understand each step of the calculations being performed by Splink - because a lot of the implementation gets 'hidden' within pipelines for performance reasons. Note that enabling debug mode will dramatically reduce Splink's performance! Logging \u00b6 Splink has a range of logging modes that output information about what Splink is doing at different levels of verbosity. Unlike debug mode, logging doesn't affect the performance of Splink. Logging levels \u00b6 You can set the logging level with code like logging.getLogger(\"splink\").setLevel(desired_level) although see notes below about gotyas . The logging levels in Splink are: logging.INFO ( 20 ): This outputs user facing messages about the training status of Splink models 15 : Outputs additional information about time taken and parameter estimation logging.DEBUG ( 10 ): Outputs information about the names of the SQL statements executed logging.DEBUG ( 7 ): Outputs information about the names of the components of the SQL pipelines logging.DEBUG ( 5 ): Outputs the SQL statements themselves How to control logging \u00b6 Note that by default Splink sets the logging level to INFO on initialisation With basic logging \u00b6 import logging linker = DuckDBLinker ( df , settings , set_up_basic_logging = False ) # This must come AFTER the linker is intialised, because the logging level # will be set to INFO logging . getLogger ( \"splink\" ) . setLevel ( logging . DEBUG ) Without basic logging \u00b6 # This code can be anywhere since set_up_basic_logging is False import logging logging . basicConfig ( format = \" %(message)s \" ) splink_logger = logging . getLogger ( \"splink\" ) splink_logger . setLevel ( logging . INFO ) linker = DuckDBLinker ( df , settings , set_up_basic_logging = False )","title":"Understanding and debugging Splink"},{"location":"dev_guides/debug_modes.html#understanding-and-debugging-splinks-computations","text":"Splink contains tooling to help developers understand the underlying computations, how caching and pipelining is working, and debug problems. There are two main mechanisms: debug_mode , and setting different logging levels","title":"Understanding and debugging Splink's computations"},{"location":"dev_guides/debug_modes.html#debug-mode","text":"You can turn on debug mode by setting linker.debug_mode = True . This has the following effects: Each step of Splink's calculations are executed in turn. That is, pipelining is switched off. The SQL statements being executed by Splink are displayed The results of the SQL statements are displayed in tabular format This is probably the best way to understand each step of the calculations being performed by Splink - because a lot of the implementation gets 'hidden' within pipelines for performance reasons. Note that enabling debug mode will dramatically reduce Splink's performance!","title":"Debug mode"},{"location":"dev_guides/debug_modes.html#logging","text":"Splink has a range of logging modes that output information about what Splink is doing at different levels of verbosity. Unlike debug mode, logging doesn't affect the performance of Splink.","title":"Logging"},{"location":"dev_guides/debug_modes.html#logging-levels","text":"You can set the logging level with code like logging.getLogger(\"splink\").setLevel(desired_level) although see notes below about gotyas . The logging levels in Splink are: logging.INFO ( 20 ): This outputs user facing messages about the training status of Splink models 15 : Outputs additional information about time taken and parameter estimation logging.DEBUG ( 10 ): Outputs information about the names of the SQL statements executed logging.DEBUG ( 7 ): Outputs information about the names of the components of the SQL pipelines logging.DEBUG ( 5 ): Outputs the SQL statements themselves","title":"Logging levels"},{"location":"dev_guides/debug_modes.html#how-to-control-logging","text":"Note that by default Splink sets the logging level to INFO on initialisation","title":"How to control logging"},{"location":"dev_guides/debug_modes.html#with-basic-logging","text":"import logging linker = DuckDBLinker ( df , settings , set_up_basic_logging = False ) # This must come AFTER the linker is intialised, because the logging level # will be set to INFO logging . getLogger ( \"splink\" ) . setLevel ( logging . DEBUG )","title":"With basic logging"},{"location":"dev_guides/debug_modes.html#without-basic-logging","text":"# This code can be anywhere since set_up_basic_logging is False import logging logging . basicConfig ( format = \" %(message)s \" ) splink_logger = logging . getLogger ( \"splink\" ) splink_logger . setLevel ( logging . INFO ) linker = DuckDBLinker ( df , settings , set_up_basic_logging = False )","title":"Without basic logging"},{"location":"dev_guides/spark_pipelining_and_caching.html","text":"Caching and pipelining in Spark \u00b6 This article assumes you've read the general guide to caching and pipelining . In Spark, some additions have to be made to this general pattern because all transformation in Spark are lazy . That is, when we call df = spark.sql(sql) , the df is not immediately computed. Furthermore, even when an action is called, the results aren't automatically persisted by Spark to disk. This differs from other backends, which execute SQL as a create table statement, meaning that the result is automatically saved. This interferes with caching, because Splink assumes that when the the function _execute_sql_against_backend() is called, this will be evaluted greedily (immediately evaluated) AND the results will be saved to the 'database'. Another quirk of Spark is that it chunks work up into tasks. This is relevant for two reasons: Tasks can suffer from skew, meaning some take longer than others, which can be bad from a performance point of view. The number of tasks and how data is partitioned controls how many files are output when results are saved. Some Splink operations results in a very large number of small files which can take a long time to read and write, relative to the same data stored in fewer files. Repartitioning can be used to rebalance workloads (reduce skew) and to avoid the 'many small files' problem. Spark-specific modifications \u00b6 The logic for Spark is captured in the implementation of _execute_sql_against_backend() in the spark_linker.py. This has three roles: It determines how to save result - using either persist , checkpoint or saving to .parquet , with .parquet being the default. It determines which results to save. Some small results such __splink__m_u_counts are immediately converted using toPandas() rather than being saved. This is because saving to disk and reloading is expensive and unnecessary. It chooses which Spark dataframes to repartition to reduce the number of files which are written/read Note that repartitioning and saving is independent. Some dataframes are saved without repartitioning. Some dataframes are repartitioned without being saved.","title":"Spark caching"},{"location":"dev_guides/spark_pipelining_and_caching.html#caching-and-pipelining-in-spark","text":"This article assumes you've read the general guide to caching and pipelining . In Spark, some additions have to be made to this general pattern because all transformation in Spark are lazy . That is, when we call df = spark.sql(sql) , the df is not immediately computed. Furthermore, even when an action is called, the results aren't automatically persisted by Spark to disk. This differs from other backends, which execute SQL as a create table statement, meaning that the result is automatically saved. This interferes with caching, because Splink assumes that when the the function _execute_sql_against_backend() is called, this will be evaluted greedily (immediately evaluated) AND the results will be saved to the 'database'. Another quirk of Spark is that it chunks work up into tasks. This is relevant for two reasons: Tasks can suffer from skew, meaning some take longer than others, which can be bad from a performance point of view. The number of tasks and how data is partitioned controls how many files are output when results are saved. Some Splink operations results in a very large number of small files which can take a long time to read and write, relative to the same data stored in fewer files. Repartitioning can be used to rebalance workloads (reduce skew) and to avoid the 'many small files' problem.","title":"Caching and pipelining in Spark"},{"location":"dev_guides/spark_pipelining_and_caching.html#spark-specific-modifications","text":"The logic for Spark is captured in the implementation of _execute_sql_against_backend() in the spark_linker.py. This has three roles: It determines how to save result - using either persist , checkpoint or saving to .parquet , with .parquet being the default. It determines which results to save. Some small results such __splink__m_u_counts are immediately converted using toPandas() rather than being saved. This is because saving to disk and reloading is expensive and unnecessary. It chooses which Spark dataframes to repartition to reduce the number of files which are written/read Note that repartitioning and saving is independent. Some dataframes are saved without repartitioning. Some dataframes are repartitioned without being saved.","title":"Spark-specific modifications"},{"location":"dev_guides/transpilation.html","text":"SQL Transpilation in Splink, and how we support multiple SQL backends \u00b6 In Splink, all the core data linking algorithms are implemented in SQL. This allows computation to be offloaded to a SQL backend of the users choice. One difficulty with this paradigm is that SQL implementations differ - the functions available in (say) the Spark dialect of SQL differ from those available in DuckDB SQL. And to make matters worse, functions with the same name may behave differently (e.g. different arguments, arguments in different orders, etc.). Splink therefore needs a mechanism of writing SQL statements that are able to run against all the target SQL backends (engines). Details are as follows: 1. Core data linking algorithms are Splink \u00b6 Core data linking algorithms are implmented in 'backend agnostic' SQL. So they're written using basic SQL functions that are common across the available in all the target backends, and don't need any translation. It has been possible to write all of the core Splink logic in SQL that is consistent between dialects. However, this is not the case with Comparisons , which tend to use backend specific SQL functions like jaro_winker , whose functino names and signatures differ between backends. 2. User-provided SQL is interpolated into these dialect-agnostic SQL statements \u00b6 The user provides custom SQL is two places in Splink: Blocking rules The sql_condition (see here ) provided as part of a Comparison The user is free to write this SQL however they want. It's up to the user to ensure the SQL they provide will execute successfully in their chosen backend. So the sql_condition must use functions that exist in the target execution engine The custom SQL is interpolated into the the SQL statements generated by Splink. Users are also able to use the comparison_level_library and comparison_library for their chosen backend. These are backend specific and are imported like from splink.spark.spark_comparison_level_library import jaro_winkler_level . This ensures that the syntax matches the chosen execution backend 3. Backends can implement transpilation and or dielct steps to further transform the SQL if needed \u00b6 Occasionally some modifications are needed to the SQL to ensure it executes against the target backend. sqlglot is used for this purpose. For instance, a custom dialect is implemented in the sparklinker. A transformer is implemented in the Athena linker.","title":"Transpilation using sqlglot"},{"location":"dev_guides/transpilation.html#sql-transpilation-in-splink-and-how-we-support-multiple-sql-backends","text":"In Splink, all the core data linking algorithms are implemented in SQL. This allows computation to be offloaded to a SQL backend of the users choice. One difficulty with this paradigm is that SQL implementations differ - the functions available in (say) the Spark dialect of SQL differ from those available in DuckDB SQL. And to make matters worse, functions with the same name may behave differently (e.g. different arguments, arguments in different orders, etc.). Splink therefore needs a mechanism of writing SQL statements that are able to run against all the target SQL backends (engines). Details are as follows:","title":"SQL Transpilation in Splink, and how we support multiple SQL backends"},{"location":"dev_guides/transpilation.html#1-core-data-linking-algorithms-are-splink","text":"Core data linking algorithms are implmented in 'backend agnostic' SQL. So they're written using basic SQL functions that are common across the available in all the target backends, and don't need any translation. It has been possible to write all of the core Splink logic in SQL that is consistent between dialects. However, this is not the case with Comparisons , which tend to use backend specific SQL functions like jaro_winker , whose functino names and signatures differ between backends.","title":"1. Core data linking algorithms are Splink"},{"location":"dev_guides/transpilation.html#2-user-provided-sql-is-interpolated-into-these-dialect-agnostic-sql-statements","text":"The user provides custom SQL is two places in Splink: Blocking rules The sql_condition (see here ) provided as part of a Comparison The user is free to write this SQL however they want. It's up to the user to ensure the SQL they provide will execute successfully in their chosen backend. So the sql_condition must use functions that exist in the target execution engine The custom SQL is interpolated into the the SQL statements generated by Splink. Users are also able to use the comparison_level_library and comparison_library for their chosen backend. These are backend specific and are imported like from splink.spark.spark_comparison_level_library import jaro_winkler_level . This ensures that the syntax matches the chosen execution backend","title":"2. User-provided SQL is interpolated into these dialect-agnostic SQL statements"},{"location":"dev_guides/transpilation.html#3-backends-can-implement-transpilation-and-or-dielct-steps-to-further-transform-the-sql-if-needed","text":"Occasionally some modifications are needed to the SQL to ensure it executes against the target backend. sqlglot is used for this purpose. For instance, a custom dialect is implemented in the sparklinker. A transformer is implemented in the Athena linker.","title":"3. Backends can implement transpilation and or dielct steps to further transform the SQL if needed"},{"location":"includes/abbreviations.html","text":"","title":"Abbreviations"},{"location":"includes/tags.html","text":"Tags \u00b6 Following is a list of relevant tags: [TAGS]","title":"Tags"},{"location":"includes/tags.html#tags","text":"Following is a list of relevant tags: [TAGS]","title":"Tags"},{"location":"settingseditor/editor.html","text":"","title":"Settings Editor"},{"location":"topic_guides/backends.html","text":"Splink's SQL backends: Spark, DuckDB, etc \u00b6 Splink is a Python library. It implements all data linking computations by generating SQL, and submitting the SQL statements to a backend of the user's chosing for execution. For smaller input datasets of up to 1-2 million records, users can link data in Python on their laptop using the DuckDB backend. This is the recommended approach because the DuckDB backend is installed automatically when the user installs Splink using pip install splink . No additional configuration is needed. Linking larger datasets requires highly computationally intensive calculations, and generates datasets which are too large to be processed on a standard laptop. For these scenarios, we recommend using one of Splink's big data backend - currently Spark or AWS Athena. When these backends are used, the SQL generated by Splink is sent to the chosen backend for execution. The Splink code you write is almost identical between backends, so it's straightforward to migrate between backends. Often, it's a good idea to start working using DuckDB on a sample of data, because it will produce results very quickly. When you're comfortable with your model, you may wish to migrate to a big data backend to estimate/predict on the full dataset. Choosing a backend \u00b6 Import the linker from the backend of your choosing, and the backend-specific comparison libraries. Once you have initialised the linker object, there is no difference in the subequent code between backends. Note however, that not all comparison functions are available in all backends. For example, the a Jaro Winkler comparison function doesn't exist in DuckDB or Athena. DuckDB \u00b6 from splink.duckdb.duckdb_linker import DuckDBLinker import splink.duckdb.duckdb_comparison_library as cl import splink.duckdb.duckdb_comparison_level_library as cll linker = DuckDBLinker ( your_args ) Spark \u00b6 from splink.spark.spark_linker import SparkLinker import splink.spark.spark_comparison_library as cl import splink.spark.spark_comparison_level_library as cll linker = SparkLinker ( your_args ) AWS Athena \u00b6 from splink.athena.athena_linker import AthenaLinker import splink.athena.athena_comparison_library as cl import splink.athena.athena_comparison_level_library as cll linker = AthenaLinker ( your_args ) SQlite \u00b6 from splink.sqlite.sqlite_linker import SQLiteLinker import splink.sqlite.sqlite_comparison_library as cl import splink.sqlite.sqlite_comparison_level_library as cll linker = SQLiteLinker ( your_args )","title":"Splink's SQL backends - Spark, DuckDB etc"},{"location":"topic_guides/backends.html#splinks-sql-backends-spark-duckdb-etc","text":"Splink is a Python library. It implements all data linking computations by generating SQL, and submitting the SQL statements to a backend of the user's chosing for execution. For smaller input datasets of up to 1-2 million records, users can link data in Python on their laptop using the DuckDB backend. This is the recommended approach because the DuckDB backend is installed automatically when the user installs Splink using pip install splink . No additional configuration is needed. Linking larger datasets requires highly computationally intensive calculations, and generates datasets which are too large to be processed on a standard laptop. For these scenarios, we recommend using one of Splink's big data backend - currently Spark or AWS Athena. When these backends are used, the SQL generated by Splink is sent to the chosen backend for execution. The Splink code you write is almost identical between backends, so it's straightforward to migrate between backends. Often, it's a good idea to start working using DuckDB on a sample of data, because it will produce results very quickly. When you're comfortable with your model, you may wish to migrate to a big data backend to estimate/predict on the full dataset.","title":"Splink's SQL backends: Spark, DuckDB, etc"},{"location":"topic_guides/backends.html#choosing-a-backend","text":"Import the linker from the backend of your choosing, and the backend-specific comparison libraries. Once you have initialised the linker object, there is no difference in the subequent code between backends. Note however, that not all comparison functions are available in all backends. For example, the a Jaro Winkler comparison function doesn't exist in DuckDB or Athena.","title":"Choosing a backend"},{"location":"topic_guides/backends.html#duckdb","text":"from splink.duckdb.duckdb_linker import DuckDBLinker import splink.duckdb.duckdb_comparison_library as cl import splink.duckdb.duckdb_comparison_level_library as cll linker = DuckDBLinker ( your_args )","title":"DuckDB"},{"location":"topic_guides/backends.html#spark","text":"from splink.spark.spark_linker import SparkLinker import splink.spark.spark_comparison_library as cl import splink.spark.spark_comparison_level_library as cll linker = SparkLinker ( your_args )","title":"Spark"},{"location":"topic_guides/backends.html#aws-athena","text":"from splink.athena.athena_linker import AthenaLinker import splink.athena.athena_comparison_library as cl import splink.athena.athena_comparison_level_library as cll linker = AthenaLinker ( your_args )","title":"AWS Athena"},{"location":"topic_guides/backends.html#sqlite","text":"from splink.sqlite.sqlite_linker import SQLiteLinker import splink.sqlite.sqlite_comparison_library as cl import splink.sqlite.sqlite_comparison_level_library as cll linker = SQLiteLinker ( your_args )","title":"SQlite"},{"location":"topic_guides/blocking_rules.html","text":"Difference between blocking_rules_to_generate_predictions vs blocking rules for estimation \u00b6 What is the difference between the list of blocking_rules_to_generate_predictions specifed in the Splink settings dictionary, and the blocking rule that must be provided as an argument to estimate_parameters_using_expectation_maximisation ? These two kinds of blocking rules can be seen in the following code snippet: settings = { \"link_type\" : \"dedupe_only\" , \"blocking_rules_to_generate_predictions\" : [ \"l.first_name = r.first_name and substr(l.surname,1,1) = substr(r.surname,1,1)\" , \"l.dob = r.dob\" , ], \"comparisons\" : [ levenshtein_at_thresholds ( \"first_name\" , 2 ), exact_match ( \"surname\" ), exact_match ( \"dob\" ), exact_match ( \"city\" , term_frequency_adjustments = True ), exact_match ( \"email\" ), ], } linker = DuckDBLinker ( df , settings ) linker . estimate_u_using_random_sampling ( target_rows = 1e6 ) blocking_rule_for_training = \"l.first_name = r.first_name and l.surname = r.surname\" linker . estimate_parameters_using_expectation_maximisation ( blocking_rule_for_training ) blocking_rule_for_training = \"l.dob = r.dob and l.city = r.city\" linker . estimate_parameters_using_expectation_maximisation ( blocking_rule_for_training ) The answer is that they serve different purposes. What is a blocking rule? \u00b6 Blocking rules are needed because it is usually computationally intractable to compare every record with every other. A blocking rule specifies a constraint on how Splink generates pairwise record comparisons, dramatically reducing the total number of comparisons generated. For example, the blocking rule \"l.first_name = r.first_name and l.surname = r.surname\" will generate pairwise record comparisons amongst pairwise comparisons where first name and surname match. The purpose of blocking_rules_to_generate_predictions \u00b6 blocking_rules_to_generate_predictions are used by Splink when the user called linker.predict() . The purpose of these blocking rules is to try and ensure that pairwise record comparisons are generated for all true matches. For example, settings = { \"blocking_rules_to_generate_predictions\" [ \"l.first_name = r.first_name and l.surname = r.surname\" ] } will generate comparisons for all true matches where names match. But it would miss a true match where there was a typo in (say) the first name. In general, it is usually impossible to find a single rule which both: Reduces the number of comparisons generated to a computatally tractable number Ensures comparisons are generated for all true matches This is why blocking_rules_to_generate_predictions is a list. Suppose we also block on postcode : settings = { \"blocking_rules_to_generate_predictions\" [ \"l.first_name = r.first_name and l.surname = r.surname\" , \"l.postcode = r.postcode\" ] } We will now generate a pairwise comparison for the record where there was a typo in the first name, so long as there isn't also a difference in the postcode. By specifying a variety of blocking_rules_to_generate_predictions , it becomes implausible that a truly matching record would not be captured by at least one of the rules. Note that Splink automatically deduplicates the record comparisons it generates. So, in the example above, the \"l.postcode = r.postcode\" blocking rule generates only records comparisons that were not already captured by the first_name and surname rule. The purpose of the blocking_rule parameter on estimate_parameters_using_expectation_maximisation \u00b6 The purpose of this blocking rule is to reduce the number of pairwise generated to a computationally-tractable number to enable the expectation maximisation algorithm to work. The expectation maximisation algorithm seems to work best when the pairwise record comparisons are a mix of anywhere between around 0.1% and 99.9% true matches. It works less effectively if there are very few examples of either matches or non-matches. It works less efficiently if there is a huge imbalance between the two (e.g. a billion non matches and only a hundred matches). It does not matter if this blocking rule excludes some true matches - it just needs to generate examples of matches and non matches. Since they serve different purposes, the blocking rules most appropriate to use with blocking_rules_to_generate_predictions will often be different to those for estimate_parameters_using_expectation_maximisation , but it is also common for the same rule to be used in both places.","title":"Blocking rules for prediction vs estimation"},{"location":"topic_guides/blocking_rules.html#difference-between-blocking_rules_to_generate_predictions-vs-blocking-rules-for-estimation","text":"What is the difference between the list of blocking_rules_to_generate_predictions specifed in the Splink settings dictionary, and the blocking rule that must be provided as an argument to estimate_parameters_using_expectation_maximisation ? These two kinds of blocking rules can be seen in the following code snippet: settings = { \"link_type\" : \"dedupe_only\" , \"blocking_rules_to_generate_predictions\" : [ \"l.first_name = r.first_name and substr(l.surname,1,1) = substr(r.surname,1,1)\" , \"l.dob = r.dob\" , ], \"comparisons\" : [ levenshtein_at_thresholds ( \"first_name\" , 2 ), exact_match ( \"surname\" ), exact_match ( \"dob\" ), exact_match ( \"city\" , term_frequency_adjustments = True ), exact_match ( \"email\" ), ], } linker = DuckDBLinker ( df , settings ) linker . estimate_u_using_random_sampling ( target_rows = 1e6 ) blocking_rule_for_training = \"l.first_name = r.first_name and l.surname = r.surname\" linker . estimate_parameters_using_expectation_maximisation ( blocking_rule_for_training ) blocking_rule_for_training = \"l.dob = r.dob and l.city = r.city\" linker . estimate_parameters_using_expectation_maximisation ( blocking_rule_for_training ) The answer is that they serve different purposes.","title":"Difference between blocking_rules_to_generate_predictions vs blocking rules for estimation"},{"location":"topic_guides/blocking_rules.html#what-is-a-blocking-rule","text":"Blocking rules are needed because it is usually computationally intractable to compare every record with every other. A blocking rule specifies a constraint on how Splink generates pairwise record comparisons, dramatically reducing the total number of comparisons generated. For example, the blocking rule \"l.first_name = r.first_name and l.surname = r.surname\" will generate pairwise record comparisons amongst pairwise comparisons where first name and surname match.","title":"What is a blocking rule?"},{"location":"topic_guides/blocking_rules.html#the-purpose-of-blocking_rules_to_generate_predictions","text":"blocking_rules_to_generate_predictions are used by Splink when the user called linker.predict() . The purpose of these blocking rules is to try and ensure that pairwise record comparisons are generated for all true matches. For example, settings = { \"blocking_rules_to_generate_predictions\" [ \"l.first_name = r.first_name and l.surname = r.surname\" ] } will generate comparisons for all true matches where names match. But it would miss a true match where there was a typo in (say) the first name. In general, it is usually impossible to find a single rule which both: Reduces the number of comparisons generated to a computatally tractable number Ensures comparisons are generated for all true matches This is why blocking_rules_to_generate_predictions is a list. Suppose we also block on postcode : settings = { \"blocking_rules_to_generate_predictions\" [ \"l.first_name = r.first_name and l.surname = r.surname\" , \"l.postcode = r.postcode\" ] } We will now generate a pairwise comparison for the record where there was a typo in the first name, so long as there isn't also a difference in the postcode. By specifying a variety of blocking_rules_to_generate_predictions , it becomes implausible that a truly matching record would not be captured by at least one of the rules. Note that Splink automatically deduplicates the record comparisons it generates. So, in the example above, the \"l.postcode = r.postcode\" blocking rule generates only records comparisons that were not already captured by the first_name and surname rule.","title":"The purpose of blocking_rules_to_generate_predictions"},{"location":"topic_guides/blocking_rules.html#the-purpose-of-the-blocking_rule-parameter-on-estimate_parameters_using_expectation_maximisation","text":"The purpose of this blocking rule is to reduce the number of pairwise generated to a computationally-tractable number to enable the expectation maximisation algorithm to work. The expectation maximisation algorithm seems to work best when the pairwise record comparisons are a mix of anywhere between around 0.1% and 99.9% true matches. It works less effectively if there are very few examples of either matches or non-matches. It works less efficiently if there is a huge imbalance between the two (e.g. a billion non matches and only a hundred matches). It does not matter if this blocking rule excludes some true matches - it just needs to generate examples of matches and non matches. Since they serve different purposes, the blocking rules most appropriate to use with blocking_rules_to_generate_predictions will often be different to those for estimate_parameters_using_expectation_maximisation , but it is also common for the same rule to be used in both places.","title":"The purpose of the blocking_rule parameter on estimate_parameters_using_expectation_maximisation"},{"location":"topic_guides/customising_comparisons.html","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Defining and customising how record comparisons are made \u00b6 A key feature of Splink is the ability to customise how record comparisons are made - that is, how similarity is defined for different data types. For example, the definition of similarity that is appropriate for a date of birth field is different than for a first name field. By tailoring the definitions of similarity, linking models are more effectively able to distinguish beteween different gradations of similarity, leading to more accurate data linking models. Note that for performance reasons, Splink requires the user to define n discrete levels (gradations) of similarity. Comparing information \u00b6 Comparisons are defined on pairwise record comparisons. Suppose for instance your data contains first_name and surname and dob : id first_name surname dob 1 john smith 1991-04-11 2 jon smith 1991-04-17 3 john smyth 1991-04-11 To compare these records, at the blocking stage, Splink will set these records against each other in a table of pairwise record comparisons: id_l id_r first_name_l first_name_r surname_l surname_r dob_l dob_r 1 2 john jon smith smith 1991-04-11 1991-04-17 1 3 john john smith smyth 1991-04-11 1991-04-11 2 3 jon john smith smyth 1991-04-17 1991-04-11 When defining comparisons, we are defining rules that operate on each row of this latter table of pairwise comparisons Comparisons and ComparisonLevels \u00b6 A Splink model contains a collection of Comparisons and ComparisonLevels organised in a hierarchy. An example is as follows: Data Linking Model \u251c\u2500-- Comparison: Date of birth \u2502 \u251c\u2500-- ComparisonLevel: Exact match \u2502 \u251c\u2500-- ComparisonLevel: Up to one character difference \u2502 \u251c\u2500-- ComparisonLevel: Up to three character difference \u2502 \u251c\u2500-- ComparisonLevel: All other \u251c\u2500-- Comparison: Name \u2502 \u251c\u2500-- ComparisonLevel: Exact match on first name and surname \u2502 \u251c\u2500-- ComparisonLevel: Exact match on first name \u2502 \u251c\u2500-- etc. A fuller description of Comaprison s and ComparisonLevel s can be found here and here respectively. How are these comparisons specified? Three ways of specifying Comparisons \u00b6 In Splink, there are three ways of specifying Comparisons : Using pre-baked comparisons from a backend's ComparisonLibrary . (Most simple/succinct) Composing pre-defined ComparisonLevels from a backend's ComparisonLevelLibrary Writing a full spec of a Comparison by hand (most verbose/flexible) Method 1: Using the ComparisonLibrary \u00b6 The ComparisonLibrary for a each backend ( DuckDB , Spark , etc.) contains pre-baked similarity functions that cover many common use cases. These functions generate an entire Comparison , composed of several ComparisonLevels The following provides an example of using the ComparisonLibrary for Spark from splink.duckdb.duckdb_comparison_library import ( exact_match , levenshtein_at_thresholds , ) first_name_comparison = exact_match ( \"first_name\" ) print ( first_name_comparison . human_readable_description ) Comparison 'Exact match vs. anything else' of first_name. Similarity is assessed using the following ComparisonLevels: - 'Null' with SQL rule: first_name_l IS NULL OR first_name_r IS NULL - 'Exact match' with SQL rule: first_name_l = first_name_r - 'All other comparisons' with SQL rule: ELSE Note that, under the hood, these functions generate a Python dictionary, which conforms to the underlying .json specification of a model: first_name_comparison . as_dict () {'output_column_name': 'first_name', 'comparison_levels': [{'sql_condition': 'first_name_l IS NULL OR first_name_r IS NULL', 'label_for_charts': 'Null', 'is_null_level': True}, {'sql_condition': 'first_name_l = first_name_r', 'label_for_charts': 'Exact match'}, {'sql_condition': 'ELSE', 'label_for_charts': 'All other comparisons'}], 'comparison_description': 'Exact match vs. anything else'} We can now generate a second, more complex comparison: from splink.duckdb.duckdb_comparison_library import ( exact_match , levenshtein_at_thresholds , ) dob_comparison = levenshtein_at_thresholds ( \"dob\" , [ 1 , 2 ]) print ( dob_comparison . human_readable_description ) Comparison 'Exact match vs. levenshtein at thresholds 1, 2 vs. anything else' of dob. Similarity is assessed using the following ComparisonLevels: - 'Null' with SQL rule: dob_l IS NULL OR dob_r IS NULL - 'Exact match' with SQL rule: dob_l = dob_r - 'levenshtein <= 1' with SQL rule: levenshtein(dob_l, dob_r) <= 1 - 'levenshtein <= 2' with SQL rule: levenshtein(dob_l, dob_r) <= 2 - 'All other comparisons' with SQL rule: ELSE These Comparisons can be specified in a data linking model as follows: settings = { \"link_type\" : \"dedupe_only\" , \"blocking_rules_to_generate_predictions\" : [ \"l.first_name = r.first_name\" , \"l.surname = r.surname\" , ], \"comparisons\" : [ exact_match ( \"first_name\" ), levenshtein_at_thresholds ( \"dob\" , [ 1 , 2 ]), ] } Method 2: ComparisonLevels \u00b6 The ComparisonLevels API provides a lower-level API that gives the user greater control over their comparisons. For example, the user may wish to specify a comparison that has levels for a match on dmetaphone and jaro_winkler of the first_name field. The below example assumes the user has derived a column dmeta_first_name which contains the dmetaphone of the first name. from splink.spark.spark_comparison_level_library import exact_match_level , null_level , else_level from splink.spark.spark_comparison_library import levenshtein_at_thresholds comparison_first_name = { 'output_column_name' : 'first_name' , 'comparison_description' : 'First name jaro dmeta' , 'comparison_levels' : [ null_level ( \"first_name\" ), exact_match_level ( \"first_name\" , term_frequency_adjustments = True ), exact_match_level ( \"dmeta_first_name\" , term_frequency_adjustments = True ), else_level () ], } from splink.comparison import Comparison print ( Comparison ( comparison_first_name ) . human_readable_description ) Comparison 'First name jaro dmeta' of first_name and dmeta_first_name. Similarity is assessed using the following ComparisonLevels: - 'Null' with SQL rule: first_name_l IS NULL OR first_name_r IS NULL - 'Exact match' with SQL rule: first_name_l = first_name_r - 'Exact match' with SQL rule: dmeta_first_name_l = dmeta_first_name_r - 'All other comparisons' with SQL rule: ELSE This can now be specified in the settings dictionary as follows: settings = { \"link_type\" : \"dedupe_only\" , \"blocking_rules_to_generate_predictions\" : [ \"l.first_name = r.first_name\" , \"l.surname = r.surname\" , ], \"comparisons\" : [ comparison_first_name , # The comparison specified above using ComparisonLevels levenshtein_at_thresholds ( \"dob\" , [ 1 , 2 ], term_frequency_adjustments = True ), # From comparison_library ] } Method 3: Providing the spec as a dictionary \u00b6 Ultimately, comparisons are specified as a dictionary which conforms to the formal jsonschema specification of the settings dictionary - see [here]https://github.com/moj-analytical-services/splink/blob/master/splink/files/settings_jsonschema.json) and here . The library functions described above are convenience functions that provide a shorthand way to produce valid dictionaries. For maximium control over your settings, you can specify your comparisons as a dictionary. comparison_first_name = { \"output_column_name\" : \"first_name\" , \"comparison_description\" : \"First name jaro dmeta\" , \"comparison_levels\" : [ { \"sql_condition\" : \"first_name_l IS NULL OR first_name_r IS NULL\" , \"label_for_charts\" : \"Null\" , \"is_null_level\" : True , }, { \"sql_condition\" : \"first_name_l = first_name_r\" , \"label_for_charts\" : \"Exact match\" , \"tf_adjustment_column\" : \"first_name\" , \"tf_adjustment_weight\" : 1.0 , \"tf_minimum_u_value\" : 0.001 , }, { \"sql_condition\" : \"dmeta_first_name_l = dmeta_first_name_r\" , \"label_for_charts\" : \"Exact match\" , \"tf_adjustment_column\" : \"dmeta_first_name\" , \"tf_adjustment_weight\" : 1.0 , }, { \"sql_condition\" : \"jaro_winkler_sim(first_name_l, first_name_r) > 0.8\" , \"label_for_charts\" : \"Exact match\" , \"tf_adjustment_column\" : \"first_name\" , \"tf_adjustment_weight\" : 0.5 , \"tf_minimum_u_value\" : 0.001 , }, { \"sql_condition\" : \"ELSE\" , \"label_for_charts\" : \"All other comparisons\" }, ], } settings = { \"link_type\" : \"dedupe_only\" , \"blocking_rules_to_generate_predictions\" : [ \"l.first_name = r.first_name\" , \"l.surname = r.surname\" , ], \"comparisons\" : [ comparison_first_name , # The comparison specified above using the dict levenshtein_at_thresholds ( \"dob\" , [ 1 , 2 ], term_frequency_adjustments = True ), # From comparison_library ] }","title":"Defining and customising comparisons"},{"location":"topic_guides/customising_comparisons.html#defining-and-customising-how-record-comparisons-are-made","text":"A key feature of Splink is the ability to customise how record comparisons are made - that is, how similarity is defined for different data types. For example, the definition of similarity that is appropriate for a date of birth field is different than for a first name field. By tailoring the definitions of similarity, linking models are more effectively able to distinguish beteween different gradations of similarity, leading to more accurate data linking models. Note that for performance reasons, Splink requires the user to define n discrete levels (gradations) of similarity.","title":"Defining and customising how record comparisons are made"},{"location":"topic_guides/customising_comparisons.html#comparing-information","text":"Comparisons are defined on pairwise record comparisons. Suppose for instance your data contains first_name and surname and dob : id first_name surname dob 1 john smith 1991-04-11 2 jon smith 1991-04-17 3 john smyth 1991-04-11 To compare these records, at the blocking stage, Splink will set these records against each other in a table of pairwise record comparisons: id_l id_r first_name_l first_name_r surname_l surname_r dob_l dob_r 1 2 john jon smith smith 1991-04-11 1991-04-17 1 3 john john smith smyth 1991-04-11 1991-04-11 2 3 jon john smith smyth 1991-04-17 1991-04-11 When defining comparisons, we are defining rules that operate on each row of this latter table of pairwise comparisons","title":"Comparing information"},{"location":"topic_guides/customising_comparisons.html#comparisons-and-comparisonlevels","text":"A Splink model contains a collection of Comparisons and ComparisonLevels organised in a hierarchy. An example is as follows: Data Linking Model \u251c\u2500-- Comparison: Date of birth \u2502 \u251c\u2500-- ComparisonLevel: Exact match \u2502 \u251c\u2500-- ComparisonLevel: Up to one character difference \u2502 \u251c\u2500-- ComparisonLevel: Up to three character difference \u2502 \u251c\u2500-- ComparisonLevel: All other \u251c\u2500-- Comparison: Name \u2502 \u251c\u2500-- ComparisonLevel: Exact match on first name and surname \u2502 \u251c\u2500-- ComparisonLevel: Exact match on first name \u2502 \u251c\u2500-- etc. A fuller description of Comaprison s and ComparisonLevel s can be found here and here respectively. How are these comparisons specified?","title":"Comparisons and ComparisonLevels"},{"location":"topic_guides/customising_comparisons.html#three-ways-of-specifying-comparisons","text":"In Splink, there are three ways of specifying Comparisons : Using pre-baked comparisons from a backend's ComparisonLibrary . (Most simple/succinct) Composing pre-defined ComparisonLevels from a backend's ComparisonLevelLibrary Writing a full spec of a Comparison by hand (most verbose/flexible)","title":"Three ways of specifying Comparisons"},{"location":"topic_guides/customising_comparisons.html#method-1-using-the-comparisonlibrary","text":"The ComparisonLibrary for a each backend ( DuckDB , Spark , etc.) contains pre-baked similarity functions that cover many common use cases. These functions generate an entire Comparison , composed of several ComparisonLevels The following provides an example of using the ComparisonLibrary for Spark from splink.duckdb.duckdb_comparison_library import ( exact_match , levenshtein_at_thresholds , ) first_name_comparison = exact_match ( \"first_name\" ) print ( first_name_comparison . human_readable_description ) Comparison 'Exact match vs. anything else' of first_name. Similarity is assessed using the following ComparisonLevels: - 'Null' with SQL rule: first_name_l IS NULL OR first_name_r IS NULL - 'Exact match' with SQL rule: first_name_l = first_name_r - 'All other comparisons' with SQL rule: ELSE Note that, under the hood, these functions generate a Python dictionary, which conforms to the underlying .json specification of a model: first_name_comparison . as_dict () {'output_column_name': 'first_name', 'comparison_levels': [{'sql_condition': 'first_name_l IS NULL OR first_name_r IS NULL', 'label_for_charts': 'Null', 'is_null_level': True}, {'sql_condition': 'first_name_l = first_name_r', 'label_for_charts': 'Exact match'}, {'sql_condition': 'ELSE', 'label_for_charts': 'All other comparisons'}], 'comparison_description': 'Exact match vs. anything else'} We can now generate a second, more complex comparison: from splink.duckdb.duckdb_comparison_library import ( exact_match , levenshtein_at_thresholds , ) dob_comparison = levenshtein_at_thresholds ( \"dob\" , [ 1 , 2 ]) print ( dob_comparison . human_readable_description ) Comparison 'Exact match vs. levenshtein at thresholds 1, 2 vs. anything else' of dob. Similarity is assessed using the following ComparisonLevels: - 'Null' with SQL rule: dob_l IS NULL OR dob_r IS NULL - 'Exact match' with SQL rule: dob_l = dob_r - 'levenshtein <= 1' with SQL rule: levenshtein(dob_l, dob_r) <= 1 - 'levenshtein <= 2' with SQL rule: levenshtein(dob_l, dob_r) <= 2 - 'All other comparisons' with SQL rule: ELSE These Comparisons can be specified in a data linking model as follows: settings = { \"link_type\" : \"dedupe_only\" , \"blocking_rules_to_generate_predictions\" : [ \"l.first_name = r.first_name\" , \"l.surname = r.surname\" , ], \"comparisons\" : [ exact_match ( \"first_name\" ), levenshtein_at_thresholds ( \"dob\" , [ 1 , 2 ]), ] }","title":"Method 1: Using the ComparisonLibrary"},{"location":"topic_guides/customising_comparisons.html#method-2-comparisonlevels","text":"The ComparisonLevels API provides a lower-level API that gives the user greater control over their comparisons. For example, the user may wish to specify a comparison that has levels for a match on dmetaphone and jaro_winkler of the first_name field. The below example assumes the user has derived a column dmeta_first_name which contains the dmetaphone of the first name. from splink.spark.spark_comparison_level_library import exact_match_level , null_level , else_level from splink.spark.spark_comparison_library import levenshtein_at_thresholds comparison_first_name = { 'output_column_name' : 'first_name' , 'comparison_description' : 'First name jaro dmeta' , 'comparison_levels' : [ null_level ( \"first_name\" ), exact_match_level ( \"first_name\" , term_frequency_adjustments = True ), exact_match_level ( \"dmeta_first_name\" , term_frequency_adjustments = True ), else_level () ], } from splink.comparison import Comparison print ( Comparison ( comparison_first_name ) . human_readable_description ) Comparison 'First name jaro dmeta' of first_name and dmeta_first_name. Similarity is assessed using the following ComparisonLevels: - 'Null' with SQL rule: first_name_l IS NULL OR first_name_r IS NULL - 'Exact match' with SQL rule: first_name_l = first_name_r - 'Exact match' with SQL rule: dmeta_first_name_l = dmeta_first_name_r - 'All other comparisons' with SQL rule: ELSE This can now be specified in the settings dictionary as follows: settings = { \"link_type\" : \"dedupe_only\" , \"blocking_rules_to_generate_predictions\" : [ \"l.first_name = r.first_name\" , \"l.surname = r.surname\" , ], \"comparisons\" : [ comparison_first_name , # The comparison specified above using ComparisonLevels levenshtein_at_thresholds ( \"dob\" , [ 1 , 2 ], term_frequency_adjustments = True ), # From comparison_library ] }","title":"Method 2: ComparisonLevels"},{"location":"topic_guides/customising_comparisons.html#method-3-providing-the-spec-as-a-dictionary","text":"Ultimately, comparisons are specified as a dictionary which conforms to the formal jsonschema specification of the settings dictionary - see [here]https://github.com/moj-analytical-services/splink/blob/master/splink/files/settings_jsonschema.json) and here . The library functions described above are convenience functions that provide a shorthand way to produce valid dictionaries. For maximium control over your settings, you can specify your comparisons as a dictionary. comparison_first_name = { \"output_column_name\" : \"first_name\" , \"comparison_description\" : \"First name jaro dmeta\" , \"comparison_levels\" : [ { \"sql_condition\" : \"first_name_l IS NULL OR first_name_r IS NULL\" , \"label_for_charts\" : \"Null\" , \"is_null_level\" : True , }, { \"sql_condition\" : \"first_name_l = first_name_r\" , \"label_for_charts\" : \"Exact match\" , \"tf_adjustment_column\" : \"first_name\" , \"tf_adjustment_weight\" : 1.0 , \"tf_minimum_u_value\" : 0.001 , }, { \"sql_condition\" : \"dmeta_first_name_l = dmeta_first_name_r\" , \"label_for_charts\" : \"Exact match\" , \"tf_adjustment_column\" : \"dmeta_first_name\" , \"tf_adjustment_weight\" : 1.0 , }, { \"sql_condition\" : \"jaro_winkler_sim(first_name_l, first_name_r) > 0.8\" , \"label_for_charts\" : \"Exact match\" , \"tf_adjustment_column\" : \"first_name\" , \"tf_adjustment_weight\" : 0.5 , \"tf_minimum_u_value\" : 0.001 , }, { \"sql_condition\" : \"ELSE\" , \"label_for_charts\" : \"All other comparisons\" }, ], } settings = { \"link_type\" : \"dedupe_only\" , \"blocking_rules_to_generate_predictions\" : [ \"l.first_name = r.first_name\" , \"l.surname = r.surname\" , ], \"comparisons\" : [ comparison_first_name , # The comparison specified above using the dict levenshtein_at_thresholds ( \"dob\" , [ 1 , 2 ], term_frequency_adjustments = True ), # From comparison_library ] }","title":"Method 3: Providing the spec as a dictionary"},{"location":"topic_guides/drivers_of_performance.html","text":"Run times, performance, and linking large data \u00b6 This topic guide covers the fundamental drivers of the run time of Splink jobs. It also describes the tools that are built into Splink that help you to understand how long a job is likely to take. In summary, your choice of blocking rules is by far the most important driver of performance. Additional factors which affect performance are: the complexity of your comparisons, whether you apply term frequency adjustments, whether you choose to set retain_matching_columns and retain_intermediate_calculation_columns to True in your settings, whether you filter out comparisons with a match score below a given threshold (using a threshold_match_probability or threshold_match_weight when you call predict() ). Blocking rules \u00b6 In most large datasets, it is computationally intractable to compare every row with every other row. The number of comparisons grows with the square of the number of input records, using the formula $\\frac{n\\left(n-1\\right)}2$ . For instance, a million input records implies around 500bn comparisons. In Splink, we use a technique called blocking to dramatically reduce the number of comparisons by comparing only records that adhere to certain rules, such as that the first name and date of birth must be equal . Blocking is described further here . Even after blocking, the number of comparisons generated is usually much higher than the number of input records - often between 10 and 1,000 times higher. As a result, the performance of Splink is influenced most heavily by the number of comparisons generated by the blocking rules, rather than the number of input records. This is the case for both main uses of blocking rules in Splink: estimating parameters using expectation maximisation, and generating predictions. (See here for more information on this distinction). How many comparisons will be generated by a blocking rule? \u00b6 The linker.count_num_comparisons_from_blocking_rule() , documented here will compute the number of comparisons that will be generated from a blocking rule. Users are recommended to use this function before attempting linkage, since some blocking rules may imply trillions of comparisons, resulting in record linkage jobs which run for hours and never complete. In general, we recommend a strategy of starting with strict blocking rules, and gradually loosening them. Sticking to less than 10 million comparisons is a good place to start, before scaling jobs up to 100s of millions (DuckDB on a laptop), or sometimes billions (Athena or Spark). Examples of strict and loose blocking rules \u00b6 To give an example of how blocking_rules_to_generate_predictions rules may be incrementally loosened, we may start with the following rule: l.first_name = r.first_name and l.surname = r.surname and l.dob = r.dob . This is a very strict rule, and will only create comparisons where full name and date of birth match. This has the advantage of creating few record comparisons, but the disadvantage that the rule will miss true matches where there are typos or nulls in any of these three fields. This blocking rule could be loosened to: substr(l.first_name,1,1) = substr(r.first_name,1,1) and l.surname = r.surname and l.year_of_birth = r.year_of_birth Now it allows for typos or aliases in the first name, so long as the first letter is the same, and errors in month or day of birth. Depending on the side of your input data, the rule could be further loosened to substr(l.first_name,1,1) = substr(r.first_name,1,1) and l.surname = r.surname or even l.surname = r.surname The user could use the linker.count_num_comparisons_from_blocking_rule() function to select which rule is appropriate for their data.","title":"Run times, performance and linking large data"},{"location":"topic_guides/drivers_of_performance.html#run-times-performance-and-linking-large-data","text":"This topic guide covers the fundamental drivers of the run time of Splink jobs. It also describes the tools that are built into Splink that help you to understand how long a job is likely to take. In summary, your choice of blocking rules is by far the most important driver of performance. Additional factors which affect performance are: the complexity of your comparisons, whether you apply term frequency adjustments, whether you choose to set retain_matching_columns and retain_intermediate_calculation_columns to True in your settings, whether you filter out comparisons with a match score below a given threshold (using a threshold_match_probability or threshold_match_weight when you call predict() ).","title":"Run times, performance, and linking large data"},{"location":"topic_guides/drivers_of_performance.html#blocking-rules","text":"In most large datasets, it is computationally intractable to compare every row with every other row. The number of comparisons grows with the square of the number of input records, using the formula $\\frac{n\\left(n-1\\right)}2$ . For instance, a million input records implies around 500bn comparisons. In Splink, we use a technique called blocking to dramatically reduce the number of comparisons by comparing only records that adhere to certain rules, such as that the first name and date of birth must be equal . Blocking is described further here . Even after blocking, the number of comparisons generated is usually much higher than the number of input records - often between 10 and 1,000 times higher. As a result, the performance of Splink is influenced most heavily by the number of comparisons generated by the blocking rules, rather than the number of input records. This is the case for both main uses of blocking rules in Splink: estimating parameters using expectation maximisation, and generating predictions. (See here for more information on this distinction).","title":"Blocking rules"},{"location":"topic_guides/drivers_of_performance.html#how-many-comparisons-will-be-generated-by-a-blocking-rule","text":"The linker.count_num_comparisons_from_blocking_rule() , documented here will compute the number of comparisons that will be generated from a blocking rule. Users are recommended to use this function before attempting linkage, since some blocking rules may imply trillions of comparisons, resulting in record linkage jobs which run for hours and never complete. In general, we recommend a strategy of starting with strict blocking rules, and gradually loosening them. Sticking to less than 10 million comparisons is a good place to start, before scaling jobs up to 100s of millions (DuckDB on a laptop), or sometimes billions (Athena or Spark).","title":"How many comparisons will be generated by a blocking rule?"},{"location":"topic_guides/drivers_of_performance.html#examples-of-strict-and-loose-blocking-rules","text":"To give an example of how blocking_rules_to_generate_predictions rules may be incrementally loosened, we may start with the following rule: l.first_name = r.first_name and l.surname = r.surname and l.dob = r.dob . This is a very strict rule, and will only create comparisons where full name and date of birth match. This has the advantage of creating few record comparisons, but the disadvantage that the rule will miss true matches where there are typos or nulls in any of these three fields. This blocking rule could be loosened to: substr(l.first_name,1,1) = substr(r.first_name,1,1) and l.surname = r.surname and l.year_of_birth = r.year_of_birth Now it allows for typos or aliases in the first name, so long as the first letter is the same, and errors in month or day of birth. Depending on the side of your input data, the rule could be further loosened to substr(l.first_name,1,1) = substr(r.first_name,1,1) and l.surname = r.surname or even l.surname = r.surname The user could use the linker.count_num_comparisons_from_blocking_rule() function to select which rule is appropriate for their data.","title":"Examples of strict and loose blocking rules"},{"location":"topic_guides/link_type.html","text":"Link type: Linking, Deduping or Both \u00b6 Splink allows data to be linked, deduplicated or both. Linking refers to finding links between datasets, whereas deduplication finding links within datasets. Data linking is therefore only meaningful when more than one dataset is provided. This guide shows how to specify the settings dictionary and initialise the linker for the three link types. Deduplication \u00b6 The dedupe_only link type expects the user to provide a single input table, and is specified as follows from splink.duckdb.duckdb_linker import DuckDBLinker settings = { \"link_type\" : \"dedupe_only\" , # etc. } linker = DuckDBLinker ( df , settings ) Link only \u00b6 The link_only link type expects the user to provide a list of input tables, and is specified as follows: from splink.duckdb.duckdb_linker import DuckDBLinker settings = { \"link_type\" : \"link_only\" , # etc. } input_aliases = [ \"table_1\" , \"table_2\" , \"table_3\" ] linker = DuckDBLinker ([ df_1 , df_2 , df_3 ], settings , input_table_aliases = input_aliases ) The input_table_aliases argument is optional and are used to label the tables in the outputs. If not provided, defaults will be automatically chosen by Splink. Link and dedupe \u00b6 The link_and_dedupe link type expects the user to provide a list of input tables, and is specified as follows: from splink.duckdb.duckdb_linker import DuckDBLinker settings = { \"link_type\" : \"link_and_dedupe\" , # etc. } input_aliases = [ \"table_1\" , \"table_2\" , \"table_3\" ] linker = DuckDBLinker ([ df_1 , df_2 , df_3 ], settings , input_table_aliases = input_aliases ) The input_table_aliases argument is optional and are used to label the tables in the outputs. If not provided, defaults will be automatically chosen by Splink.","title":"Link type - linkings vs deduping"},{"location":"topic_guides/link_type.html#link-type-linking-deduping-or-both","text":"Splink allows data to be linked, deduplicated or both. Linking refers to finding links between datasets, whereas deduplication finding links within datasets. Data linking is therefore only meaningful when more than one dataset is provided. This guide shows how to specify the settings dictionary and initialise the linker for the three link types.","title":"Link type: Linking, Deduping or Both"},{"location":"topic_guides/link_type.html#deduplication","text":"The dedupe_only link type expects the user to provide a single input table, and is specified as follows from splink.duckdb.duckdb_linker import DuckDBLinker settings = { \"link_type\" : \"dedupe_only\" , # etc. } linker = DuckDBLinker ( df , settings )","title":"Deduplication"},{"location":"topic_guides/link_type.html#link-only","text":"The link_only link type expects the user to provide a list of input tables, and is specified as follows: from splink.duckdb.duckdb_linker import DuckDBLinker settings = { \"link_type\" : \"link_only\" , # etc. } input_aliases = [ \"table_1\" , \"table_2\" , \"table_3\" ] linker = DuckDBLinker ([ df_1 , df_2 , df_3 ], settings , input_table_aliases = input_aliases ) The input_table_aliases argument is optional and are used to label the tables in the outputs. If not provided, defaults will be automatically chosen by Splink.","title":"Link only"},{"location":"topic_guides/link_type.html#link-and-dedupe","text":"The link_and_dedupe link type expects the user to provide a list of input tables, and is specified as follows: from splink.duckdb.duckdb_linker import DuckDBLinker settings = { \"link_type\" : \"link_and_dedupe\" , # etc. } input_aliases = [ \"table_1\" , \"table_2\" , \"table_3\" ] linker = DuckDBLinker ([ df_1 , df_2 , df_3 ], settings , input_table_aliases = input_aliases ) The input_table_aliases argument is optional and are used to label the tables in the outputs. If not provided, defaults will be automatically chosen by Splink.","title":"Link and dedupe"},{"location":"topic_guides/optimising_spark.html","text":"Optimising Spark jobs \u00b6 This topic guide describes how to configue Spark to optimise performance - especially large linkage jobs which are slow or are not completing using default settings. It is assumed readers have already read the more general guide to linking big data , and blocking rules are proportionate to the size of the Spark cluster. As a very rough guide, on a small cluster of (say) 8 machines, we recommend starting with blocking rules that generate around 100 million comparisons. Once this is working, loosening the blocking rules to around 1 billion comparisons or more is often achievable. Summary: \u00b6 Ensure blocking rules are not generating too many comparisons. We recommend setting the break_lineage_method to \"parquet\" , which is the default num_partitions_on_repartition should be set so that each file in the output of predict() is roughly 100MB. Try setting spark.default.parallelism to around 5x the number of CPUs in your cluster For a cluster with 10 CPUs, that outputs about 8GB of data in parquet format, the following setup may be appropriate: spark . conf . set ( \"spark.default.parallelism\" , \"50\" ) spark . conf . set ( \"spark.sql.shuffle.partitions\" , \"50\" ) linker = SparkLinker ( person_standardised_nodes , settings , break_lineage_method = \"parquet\" , num_partitions_on_repartition = 80 , ) Breaking lineage \u00b6 Splink uses an iterative algorithm for model training, and more generally, lineage is long and complex. We have found that big jobs fail to complete without further optimisation. This is a well-known problem : \"This long lineage bottleneck is widely known by sophisticated Spark application programmers. A common practice for dealing with long lineage is to have the application program strategically checkpoint RDDs at code locations that truncate much of the lineage for checkpointed data and resume computation immediately from the checkpoint.\" Splink will automatically break lineage in sensible places. We have found in practice that, when running Spark jobs backed by AWS S3, the fastest method of breaking lineage is persisting outputs to .parquet file. You can do this using the break_lineage_method parameter as follows: linker = SparkLinker( person_standardised_nodes, settings, break_lineage_method=\"parquet\" ) Other options are checkpoint and persist . For different Spark setups, particularly if you have fast local storage, you may find these options perform better. Spark Parallelism \u00b6 We suggest setting default parallelism to roughly 5x the number of CPUs in your cluster. This is a very rough rule of thumb, and if you're encountering performance problems you may wish to experiment with different values. One way to set default parallelism is as follows: from pyspark.context import SparkContext , SparkConf from pyspark.sql import SparkSession conf = SparkConf () conf . set ( \"spark.default.parallelism\" , \"50\" ) conf . set ( \"spark.sql.shuffle.partitions\" , \"50\" ) sc = SparkContext . getOrCreate ( conf = conf ) spark = SparkSession ( sc ) In general, increasing parallelism will make Spark 'chunk' your job into a larger amount of smaller tasks. This may solve memory issues. But note there is a tradeoff here: if you increase parallelism too high, Spark may take too much time scheduling large numbers of tasks, and may even run out of memory performing this work. See here . Also note that when blocking, jobs cannot be split into a large number of tasks than the cardinality of the blocking rule. For example, if you block on month of birth, this will be split into 12 tasks, irrespective of the parallelism setting. See here . You can use salting (below) to partially address this limitation. Repartition after blocking \u00b6 For some jobs, setting repartition_after_blocking=True when you initialise the SparkLinker may improve performance. Salting \u00b6 For very large jobs, you may find that salting your blocking keys results in faster run times. General Spark config \u00b6 Splink generates large numbers of record comparisons from relatively small input datasets. This is an unusual type of workload, and so default Spark parameters are not always appropriate. Some of the issues encountered are similar to performance issues encountered with cartesian joins - so some of the tips in relevant articles may help.","title":"Optimising Spark performance"},{"location":"topic_guides/optimising_spark.html#optimising-spark-jobs","text":"This topic guide describes how to configue Spark to optimise performance - especially large linkage jobs which are slow or are not completing using default settings. It is assumed readers have already read the more general guide to linking big data , and blocking rules are proportionate to the size of the Spark cluster. As a very rough guide, on a small cluster of (say) 8 machines, we recommend starting with blocking rules that generate around 100 million comparisons. Once this is working, loosening the blocking rules to around 1 billion comparisons or more is often achievable.","title":"Optimising Spark jobs"},{"location":"topic_guides/optimising_spark.html#summary","text":"Ensure blocking rules are not generating too many comparisons. We recommend setting the break_lineage_method to \"parquet\" , which is the default num_partitions_on_repartition should be set so that each file in the output of predict() is roughly 100MB. Try setting spark.default.parallelism to around 5x the number of CPUs in your cluster For a cluster with 10 CPUs, that outputs about 8GB of data in parquet format, the following setup may be appropriate: spark . conf . set ( \"spark.default.parallelism\" , \"50\" ) spark . conf . set ( \"spark.sql.shuffle.partitions\" , \"50\" ) linker = SparkLinker ( person_standardised_nodes , settings , break_lineage_method = \"parquet\" , num_partitions_on_repartition = 80 , )","title":"Summary:"},{"location":"topic_guides/optimising_spark.html#breaking-lineage","text":"Splink uses an iterative algorithm for model training, and more generally, lineage is long and complex. We have found that big jobs fail to complete without further optimisation. This is a well-known problem : \"This long lineage bottleneck is widely known by sophisticated Spark application programmers. A common practice for dealing with long lineage is to have the application program strategically checkpoint RDDs at code locations that truncate much of the lineage for checkpointed data and resume computation immediately from the checkpoint.\" Splink will automatically break lineage in sensible places. We have found in practice that, when running Spark jobs backed by AWS S3, the fastest method of breaking lineage is persisting outputs to .parquet file. You can do this using the break_lineage_method parameter as follows: linker = SparkLinker( person_standardised_nodes, settings, break_lineage_method=\"parquet\" ) Other options are checkpoint and persist . For different Spark setups, particularly if you have fast local storage, you may find these options perform better.","title":"Breaking lineage"},{"location":"topic_guides/optimising_spark.html#spark-parallelism","text":"We suggest setting default parallelism to roughly 5x the number of CPUs in your cluster. This is a very rough rule of thumb, and if you're encountering performance problems you may wish to experiment with different values. One way to set default parallelism is as follows: from pyspark.context import SparkContext , SparkConf from pyspark.sql import SparkSession conf = SparkConf () conf . set ( \"spark.default.parallelism\" , \"50\" ) conf . set ( \"spark.sql.shuffle.partitions\" , \"50\" ) sc = SparkContext . getOrCreate ( conf = conf ) spark = SparkSession ( sc ) In general, increasing parallelism will make Spark 'chunk' your job into a larger amount of smaller tasks. This may solve memory issues. But note there is a tradeoff here: if you increase parallelism too high, Spark may take too much time scheduling large numbers of tasks, and may even run out of memory performing this work. See here . Also note that when blocking, jobs cannot be split into a large number of tasks than the cardinality of the blocking rule. For example, if you block on month of birth, this will be split into 12 tasks, irrespective of the parallelism setting. See here . You can use salting (below) to partially address this limitation.","title":"Spark Parallelism"},{"location":"topic_guides/optimising_spark.html#repartition-after-blocking","text":"For some jobs, setting repartition_after_blocking=True when you initialise the SparkLinker may improve performance.","title":"Repartition after blocking"},{"location":"topic_guides/optimising_spark.html#salting","text":"For very large jobs, you may find that salting your blocking keys results in faster run times.","title":"Salting"},{"location":"topic_guides/optimising_spark.html#general-spark-config","text":"Splink generates large numbers of record comparisons from relatively small input datasets. This is an unusual type of workload, and so default Spark parameters are not always appropriate. Some of the issues encountered are similar to performance issues encountered with cartesian joins - so some of the tips in relevant articles may help.","title":"General Spark config"},{"location":"topic_guides/salting.html","text":"Salting blocking rules \u00b6 For very large linkages using Apache Spark, Splink supports salting blocking rules. Under certain conditions, this can help Spark better parallelise workflows, leading to shorter run times, and avoiding out of memory errors. It is most likely to help where you have blocking rules that create very large numbers of comparisons (100m records+) and where there is skew in how record comparisons are made (e.g. blocking on full name creates more comparisons amongst 'John Smith's than many other names). Further information about the motivation for salting can be found here . Note that salting is only available for the Spark backend How to use salting \u00b6 To enable salting using the SparkLinker , you provide some of your blocking rules as a dictionary rather than a string. This enables you to choose the number of salts for each blocking rule. Blocking rules provided as plain strings default to no salting ( salting_partitions = 1 ) The following code snippet illustrates: import logging from pyspark.context import SparkContext, SparkConf from pyspark.sql import SparkSession from splink.spark.spark_linker import SparkLinker from splink.spark.spark_comparison_library import levenshtein_at_thresholds, exact_match conf = SparkConf() conf.set(\"spark.driver.memory\", \"12g\") conf.set(\"spark.sql.shuffle.partitions\", \"8\") conf.set(\"spark.default.parallelism\", \"8\") sc = SparkContext.getOrCreate(conf=conf) spark = SparkSession(sc) settings = { \"probability_two_random_records_match\": 0.01, \"link_type\": \"dedupe_only\", \"blocking_rules_to_generate_predictions\": [ \"l.dob = r.dob\", {\"blocking_rule\": \"l.first_name = r.first_name\", \"salting_partitions\": 4}, ], \"comparisons\": [ levenshtein_at_thresholds(\"first_name\", 2), exact_match(\"surname\"), exact_match(\"dob\"), exact_match(\"city\", term_frequency_adjustments=True), exact_match(\"email\"), ], \"retain_matching_columns\": True, \"retain_intermediate_calculation_columns\": True, \"additional_columns_to_retain\": [\"group\"], \"max_iterations\": 1, \"em_convergence\": 0.01, } df = spark.read.csv(\"./tests/datasets/fake_1000_from_splink_demos.csv\", header=True) linker = SparkLinker(df, settings) logging.getLogger(\"splink\").setLevel(5) linker.initialise_settings(settings) linker.deterministic_link() And we can see that salting has been applied by looking at the SQL generated in the log: SELECT l.unique_id AS unique_id_l, r.unique_id AS unique_id_r, l.first_name AS first_name_l, r.first_name AS first_name_r, l.surname AS surname_l, r.surname AS surname_r, l.dob AS dob_l, r.dob AS dob_r, l.city AS city_l, r.city AS city_r, l.tf_city AS tf_city_l, r.tf_city AS tf_city_r, l.email AS email_l, r.email AS email_r, l.`group` AS `group_l`, r.`group` AS `group_r`, '0' AS match_key FROM __splink__df_concat_with_tf AS l INNER JOIN __splink__df_concat_with_tf AS r ON l.dob = r.dob WHERE l.unique_id < r.unique_id UNION ALL SELECT l.unique_id AS unique_id_l, r.unique_id AS unique_id_r, l.first_name AS first_name_l, r.first_name AS first_name_r, l.surname AS surname_l, r.surname AS surname_r, l.dob AS dob_l, r.dob AS dob_r, l.city AS city_l, r.city AS city_r, l.tf_city AS tf_city_l, r.tf_city AS tf_city_r, l.email AS email_l, r.email AS email_r, l.`group` AS `group_l`, r.`group` AS `group_r`, '1' AS match_key FROM __splink__df_concat_with_tf AS l INNER JOIN __splink__df_concat_with_tf AS r ON l.first_name = r.first_name AND CEIL(l.__splink_salt * 4) = 1 AND NOT ( COALESCE(( l.dob = r.dob ), FALSE) ) WHERE l.unique_id < r.unique_id UNION ALL SELECT l.unique_id AS unique_id_l, r.unique_id AS unique_id_r, l.first_name AS first_name_l, r.first_name AS first_name_r, l.surname AS surname_l, r.surname AS surname_r, l.dob AS dob_l, r.dob AS dob_r, l.city AS city_l, r.city AS city_r, l.tf_city AS tf_city_l, r.tf_city AS tf_city_r, l.email AS email_l, r.email AS email_r, l.`group` AS `group_l`, r.`group` AS `group_r`, '1' AS match_key FROM __splink__df_concat_with_tf AS l INNER JOIN __splink__df_concat_with_tf AS r ON l.first_name = r.first_name AND CEIL(l.__splink_salt * 4) = 2 AND NOT ( COALESCE(( l.dob = r.dob ), FALSE) ) WHERE l.unique_id < r.unique_id UNION ALL SELECT l.unique_id AS unique_id_l, r.unique_id AS unique_id_r, l.first_name AS first_name_l, r.first_name AS first_name_r, l.surname AS surname_l, r.surname AS surname_r, l.dob AS dob_l, r.dob AS dob_r, l.city AS city_l, r.city AS city_r, l.tf_city AS tf_city_l, r.tf_city AS tf_city_r, l.email AS email_l, r.email AS email_r, l.`group` AS `group_l`, r.`group` AS `group_r`, '1' AS match_key FROM __splink__df_concat_with_tf AS l INNER JOIN __splink__df_concat_with_tf AS r ON l.first_name = r.first_name AND CEIL(l.__splink_salt * 4) = 3 AND NOT ( COALESCE(( l.dob = r.dob ), FALSE) ) WHERE l.unique_id < r.unique_id UNION ALL SELECT l.unique_id AS unique_id_l, r.unique_id AS unique_id_r, l.first_name AS first_name_l, r.first_name AS first_name_r, l.surname AS surname_l, r.surname AS surname_r, l.dob AS dob_l, r.dob AS dob_r, l.city AS city_l, r.city AS city_r, l.tf_city AS tf_city_l, r.tf_city AS tf_city_r, l.email AS email_l, r.email AS email_r, l.`group` AS `group_l`, r.`group` AS `group_r`, '1' AS match_key FROM __splink__df_concat_with_tf AS l INNER JOIN __splink__df_concat_with_tf AS r ON l.first_name = r.first_name AND CEIL(l.__splink_salt * 4) = 4 AND NOT ( COALESCE(( l.dob = r.dob ), FALSE) ) WHERE l.unique_id < r.unique_id","title":"Salting blocking rules"},{"location":"topic_guides/salting.html#salting-blocking-rules","text":"For very large linkages using Apache Spark, Splink supports salting blocking rules. Under certain conditions, this can help Spark better parallelise workflows, leading to shorter run times, and avoiding out of memory errors. It is most likely to help where you have blocking rules that create very large numbers of comparisons (100m records+) and where there is skew in how record comparisons are made (e.g. blocking on full name creates more comparisons amongst 'John Smith's than many other names). Further information about the motivation for salting can be found here . Note that salting is only available for the Spark backend","title":"Salting blocking rules"},{"location":"topic_guides/salting.html#how-to-use-salting","text":"To enable salting using the SparkLinker , you provide some of your blocking rules as a dictionary rather than a string. This enables you to choose the number of salts for each blocking rule. Blocking rules provided as plain strings default to no salting ( salting_partitions = 1 ) The following code snippet illustrates: import logging from pyspark.context import SparkContext, SparkConf from pyspark.sql import SparkSession from splink.spark.spark_linker import SparkLinker from splink.spark.spark_comparison_library import levenshtein_at_thresholds, exact_match conf = SparkConf() conf.set(\"spark.driver.memory\", \"12g\") conf.set(\"spark.sql.shuffle.partitions\", \"8\") conf.set(\"spark.default.parallelism\", \"8\") sc = SparkContext.getOrCreate(conf=conf) spark = SparkSession(sc) settings = { \"probability_two_random_records_match\": 0.01, \"link_type\": \"dedupe_only\", \"blocking_rules_to_generate_predictions\": [ \"l.dob = r.dob\", {\"blocking_rule\": \"l.first_name = r.first_name\", \"salting_partitions\": 4}, ], \"comparisons\": [ levenshtein_at_thresholds(\"first_name\", 2), exact_match(\"surname\"), exact_match(\"dob\"), exact_match(\"city\", term_frequency_adjustments=True), exact_match(\"email\"), ], \"retain_matching_columns\": True, \"retain_intermediate_calculation_columns\": True, \"additional_columns_to_retain\": [\"group\"], \"max_iterations\": 1, \"em_convergence\": 0.01, } df = spark.read.csv(\"./tests/datasets/fake_1000_from_splink_demos.csv\", header=True) linker = SparkLinker(df, settings) logging.getLogger(\"splink\").setLevel(5) linker.initialise_settings(settings) linker.deterministic_link() And we can see that salting has been applied by looking at the SQL generated in the log: SELECT l.unique_id AS unique_id_l, r.unique_id AS unique_id_r, l.first_name AS first_name_l, r.first_name AS first_name_r, l.surname AS surname_l, r.surname AS surname_r, l.dob AS dob_l, r.dob AS dob_r, l.city AS city_l, r.city AS city_r, l.tf_city AS tf_city_l, r.tf_city AS tf_city_r, l.email AS email_l, r.email AS email_r, l.`group` AS `group_l`, r.`group` AS `group_r`, '0' AS match_key FROM __splink__df_concat_with_tf AS l INNER JOIN __splink__df_concat_with_tf AS r ON l.dob = r.dob WHERE l.unique_id < r.unique_id UNION ALL SELECT l.unique_id AS unique_id_l, r.unique_id AS unique_id_r, l.first_name AS first_name_l, r.first_name AS first_name_r, l.surname AS surname_l, r.surname AS surname_r, l.dob AS dob_l, r.dob AS dob_r, l.city AS city_l, r.city AS city_r, l.tf_city AS tf_city_l, r.tf_city AS tf_city_r, l.email AS email_l, r.email AS email_r, l.`group` AS `group_l`, r.`group` AS `group_r`, '1' AS match_key FROM __splink__df_concat_with_tf AS l INNER JOIN __splink__df_concat_with_tf AS r ON l.first_name = r.first_name AND CEIL(l.__splink_salt * 4) = 1 AND NOT ( COALESCE(( l.dob = r.dob ), FALSE) ) WHERE l.unique_id < r.unique_id UNION ALL SELECT l.unique_id AS unique_id_l, r.unique_id AS unique_id_r, l.first_name AS first_name_l, r.first_name AS first_name_r, l.surname AS surname_l, r.surname AS surname_r, l.dob AS dob_l, r.dob AS dob_r, l.city AS city_l, r.city AS city_r, l.tf_city AS tf_city_l, r.tf_city AS tf_city_r, l.email AS email_l, r.email AS email_r, l.`group` AS `group_l`, r.`group` AS `group_r`, '1' AS match_key FROM __splink__df_concat_with_tf AS l INNER JOIN __splink__df_concat_with_tf AS r ON l.first_name = r.first_name AND CEIL(l.__splink_salt * 4) = 2 AND NOT ( COALESCE(( l.dob = r.dob ), FALSE) ) WHERE l.unique_id < r.unique_id UNION ALL SELECT l.unique_id AS unique_id_l, r.unique_id AS unique_id_r, l.first_name AS first_name_l, r.first_name AS first_name_r, l.surname AS surname_l, r.surname AS surname_r, l.dob AS dob_l, r.dob AS dob_r, l.city AS city_l, r.city AS city_r, l.tf_city AS tf_city_l, r.tf_city AS tf_city_r, l.email AS email_l, r.email AS email_r, l.`group` AS `group_l`, r.`group` AS `group_r`, '1' AS match_key FROM __splink__df_concat_with_tf AS l INNER JOIN __splink__df_concat_with_tf AS r ON l.first_name = r.first_name AND CEIL(l.__splink_salt * 4) = 3 AND NOT ( COALESCE(( l.dob = r.dob ), FALSE) ) WHERE l.unique_id < r.unique_id UNION ALL SELECT l.unique_id AS unique_id_l, r.unique_id AS unique_id_r, l.first_name AS first_name_l, r.first_name AS first_name_r, l.surname AS surname_l, r.surname AS surname_r, l.dob AS dob_l, r.dob AS dob_r, l.city AS city_l, r.city AS city_r, l.tf_city AS tf_city_l, r.tf_city AS tf_city_r, l.email AS email_l, r.email AS email_r, l.`group` AS `group_l`, r.`group` AS `group_r`, '1' AS match_key FROM __splink__df_concat_with_tf AS l INNER JOIN __splink__df_concat_with_tf AS r ON l.first_name = r.first_name AND CEIL(l.__splink_salt * 4) = 4 AND NOT ( COALESCE(( l.dob = r.dob ), FALSE) ) WHERE l.unique_id < r.unique_id","title":"How to use salting"}]}